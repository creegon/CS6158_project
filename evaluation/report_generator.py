"""
è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå™¨
ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š
"""
from typing import Dict
from pathlib import Path
import json
from utils.evaluation_utils import format_percentage


class EvaluationReport:
    """è¯„ä¼°æŠ¥å‘Šç±»"""
    
    def __init__(self, metrics: Dict):
        """
        åˆå§‹åŒ–æŠ¥å‘Š
        
        Args:
            metrics: è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        self.metrics = metrics
    
    def print_summary(self):
        """æ‰“å°è¯„ä¼°æ‘˜è¦"""
        print("\n" + "=" * 70)
        print("è¯„ä¼°ç»“æœæ‘˜è¦")
        print("=" * 70)
        
        total = self.metrics['total_samples']
        overall_acc = self.metrics['overall_accuracy']
        
        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"  æ ·æœ¬æ€»æ•°: {total}")
        print(f"  æ€»ä½“å‡†ç¡®ç‡ (Overall Accuracy): {format_percentage(overall_acc)}")
        
        # Flakyæ£€æµ‹æŒ‡æ ‡
        flaky_metrics = self.metrics['flaky_detection']
        print(f"\nğŸ” Flakyæ£€æµ‹æŒ‡æ ‡:")
        print(f"  å‡†ç¡®ç‡ (Accuracy): {format_percentage(flaky_metrics['accuracy'])}")
        print(f"  ç²¾ç¡®ç‡ (Precision): {format_percentage(flaky_metrics['precision'])}")
        print(f"  å¬å›ç‡ (Recall): {format_percentage(flaky_metrics['recall'])}")
        print(f"  F1åˆ†æ•°: {format_percentage(flaky_metrics['f1'])}")
        
        # æ··æ·†çŸ©é˜µ
        cm = flaky_metrics['confusion_matrix']
        print(f"\n  æ··æ·†çŸ©é˜µ:")
        print(f"                é¢„æµ‹Flaky  é¢„æµ‹Non-Flaky")
        print(f"  å®é™…Flaky      {cm['tp']:>6}      {cm['fn']:>6}")
        print(f"  å®é™…Non-Flaky  {cm['fp']:>6}      {cm['tn']:>6}")
        
        # ç±»åˆ«åˆ†ç±»æŒ‡æ ‡
        category_metrics = self.metrics['category_classification']
        print(f"\nğŸ“‹ ç±»åˆ«åˆ†ç±»æŒ‡æ ‡:")
        print(f"  åˆ†ç±»å‡†ç¡®ç‡: {format_percentage(category_metrics['accuracy'])}")
        
        print(f"\n  å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡:")
        print(f"  {'ç±»åˆ«':<15} {'æ ·æœ¬æ•°':>8} {'å‡†ç¡®ç‡':>10} {'ç²¾ç¡®ç‡':>10} {'å¬å›ç‡':>10} {'F1':>10}")
        print(f"  {'-'*15} {'-'*8} {'-'*10} {'-'*10} {'-'*10} {'-'*10}")
        
        for category, stats in category_metrics['per_category'].items():
            print(f"  {category:<15} {stats['total']:>8} "
                  f"{format_percentage(stats['accuracy']):>10} "
                  f"{format_percentage(stats['precision']):>10} "
                  f"{format_percentage(stats['recall']):>10} "
                  f"{format_percentage(stats['f1']):>10}")
        
        print("=" * 70)
    
    def print_detailed(self):
        """æ‰“å°è¯¦ç»†æŠ¥å‘Š"""
        self.print_summary()
        
        print("\n" + "=" * 70)
        print("è¯¦ç»†åˆ†æ")
        print("=" * 70)
        
        # å„ç±»åˆ«çš„æ”¯æŒåº¦ï¼ˆæ ·æœ¬æ•°ï¼‰
        category_metrics = self.metrics['category_classification']['per_category']
        print(f"\nğŸ“Š ç±»åˆ«åˆ†å¸ƒ:")
        total = self.metrics['total_samples']
        
        for category, stats in sorted(category_metrics.items(), 
                                      key=lambda x: x[1]['total'], 
                                      reverse=True):
            count = stats['total']
            percentage = count / total * 100 if total > 0 else 0
            bar_length = int(percentage / 2)
            bar = 'â–ˆ' * bar_length
            print(f"  {category:<15} {count:>4} ({percentage:>5.2f}%) {bar}")
        
        # æ€§èƒ½åˆ†æ
        print(f"\nğŸ“ˆ æ€§èƒ½åˆ†æ:")
        
        flaky_f1 = self.metrics['flaky_detection']['f1']
        category_acc = self.metrics['category_classification']['accuracy']
        
        if flaky_f1 >= 0.9:
            print(f"  âœ… Flakyæ£€æµ‹æ€§èƒ½ä¼˜ç§€ (F1={format_percentage(flaky_f1)})")
        elif flaky_f1 >= 0.7:
            print(f"  âœ“ Flakyæ£€æµ‹æ€§èƒ½è‰¯å¥½ (F1={format_percentage(flaky_f1)})")
        else:
            print(f"  âš  Flakyæ£€æµ‹æ€§èƒ½éœ€è¦æ”¹è¿› (F1={format_percentage(flaky_f1)})")
        
        if category_acc >= 0.8:
            print(f"  âœ… ç±»åˆ«åˆ†ç±»æ€§èƒ½ä¼˜ç§€ (Acc={format_percentage(category_acc)})")
        elif category_acc >= 0.6:
            print(f"  âœ“ ç±»åˆ«åˆ†ç±»æ€§èƒ½è‰¯å¥½ (Acc={format_percentage(category_acc)})")
        else:
            print(f"  âš  ç±»åˆ«åˆ†ç±»æ€§èƒ½éœ€è¦æ”¹è¿› (Acc={format_percentage(category_acc)})")
        
        print("=" * 70)
    
    def save_to_json(self, output_file: Path):
        """
        ä¿å­˜æŠ¥å‘Šä¸ºJSONæ ¼å¼
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.metrics, f, ensure_ascii=False, indent=2)
        print(f"\nâœ“ è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
    
    def save_to_text(self, output_file: Path):
        """
        ä¿å­˜æŠ¥å‘Šä¸ºæ–‡æœ¬æ ¼å¼
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        import sys
        from io import StringIO
        
        # æ•è·printè¾“å‡º
        old_stdout = sys.stdout
        sys.stdout = StringIO()
        
        self.print_detailed()
        
        output = sys.stdout.getvalue()
        sys.stdout = old_stdout
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(output)
        
        print(f"âœ“ æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
