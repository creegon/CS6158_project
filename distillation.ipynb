{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19203ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本脚本用于调用deepseek v3的api，从而为FlakyLen的数据集增加推理过程\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a39d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# 读取CSV文件\n",
    "csv_file = 'FlakyLens_dataset_with_nonflaky_indented.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# 查看数据格式\n",
    "print(f\"数据集大小: {len(df)} 条\")\n",
    "print(f\"\\n列名: {df.columns.tolist()}\")\n",
    "print(f\"\\n前几行数据:\")\n",
    "print(df.head())\n",
    "print(f\"\\n数据类型:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e081c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化DeepSeek API客户端\n",
    "# 请替换为你的API密钥\n",
    "API_KEY = \"your-deepseek-api-key-here\"\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reasoning_prompt(row):\n",
    "    \"\"\"\n",
    "    根据数据行生成prompt，让模型分析并生成推理过程\n",
    "    需要根据实际的CSV列名调整\n",
    "    \"\"\"\n",
    "    # 这里假设CSV有code、test_name、label等列\n",
    "    # 请根据实际的列名调整\n",
    "    \n",
    "    prompt = f\"\"\"请分析以下测试用例，判断它是否是一个Flaky Test（不稳定测试），并详细说明你的推理过程。\n",
    "\n",
    "测试代码：\n",
    "{row.get('code', row.get('test_code', ''))}\n",
    "\n",
    "请按照以下格式回答：\n",
    "1. 分析测试代码的关键特征\n",
    "2. 识别可能导致测试不稳定的因素（如时间依赖、并发问题、外部依赖等）\n",
    "3. 给出最终判断：是否为Flaky Test（回答\"是\"或\"否\"）\n",
    "4. 解释你是如何得出这个结论的\n",
    "\n",
    "请确保推理过程清晰、有逻辑。\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def call_deepseek_api(prompt, max_retries=3):\n",
    "    \"\"\"\n",
    "    调用DeepSeek API生成推理过程\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"你是一个专业的软件测试专家，擅长分析测试代码并识别Flaky Tests。\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=2000\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"API调用失败 (尝试 {attempt + 1}/{max_retries}): {str(e)}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)  # 指数退避\n",
    "            else:\n",
    "                return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a26d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_alpaca_format(row, reasoning):\n",
    "    \"\"\"\n",
    "    将数据转换为Alpaca格式\n",
    "    Alpaca格式: {instruction, input, output}\n",
    "    \"\"\"\n",
    "    # 根据实际CSV列名调整\n",
    "    test_code = row.get('code', row.get('test_code', ''))\n",
    "    label = row.get('label', row.get('is_flaky', ''))\n",
    "    \n",
    "    # 构建instruction\n",
    "    instruction = \"请分析以下测试用例，判断它是否是一个Flaky Test（不稳定测试），并说明你的推理过程。\"\n",
    "    \n",
    "    # input是测试代码\n",
    "    input_text = f\"测试代码：\\n{test_code}\"\n",
    "    \n",
    "    # output是模型生成的推理过程\n",
    "    output_text = reasoning\n",
    "    \n",
    "    alpaca_item = {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": input_text,\n",
    "        \"output\": output_text\n",
    "    }\n",
    "    \n",
    "    return alpaca_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主处理流程\n",
    "distilled_dataset = []\n",
    "failed_indices = []\n",
    "\n",
    "print(f\"开始处理 {len(df)} 条数据...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    # 生成prompt\n",
    "    prompt = generate_reasoning_prompt(row)\n",
    "    \n",
    "    # 调用API获取推理过程\n",
    "    reasoning = call_deepseek_api(prompt)\n",
    "    \n",
    "    if reasoning is None:\n",
    "        print(f\"\\n警告: 第 {idx} 条数据处理失败\")\n",
    "        failed_indices.append(idx)\n",
    "        continue\n",
    "    \n",
    "    # 转换为Alpaca格式\n",
    "    alpaca_item = convert_to_alpaca_format(row, reasoning)\n",
    "    distilled_dataset.append(alpaca_item)\n",
    "    \n",
    "    # 每处理10条数据暂停一下，避免API限流\n",
    "    if (idx + 1) % 10 == 0:\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # 每处理50条数据保存一次中间结果\n",
    "    if (idx + 1) % 50 == 0:\n",
    "        with open('distillation_dataset_temp.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(distilled_dataset, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"\\n已处理 {idx + 1} 条，中间结果已保存\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"处理完成！成功: {len(distilled_dataset)} 条，失败: {len(failed_indices)} 条\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存最终的蒸馏数据集\n",
    "output_file = 'distillation_dataset.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(distilled_dataset, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n蒸馏数据集已保存到: {output_file}\")\n",
    "print(f\"总共 {len(distilled_dataset)} 条数据\")\n",
    "\n",
    "# 显示一个示例\n",
    "if distilled_dataset:\n",
    "    print(\"\\n示例数据:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(json.dumps(distilled_dataset[0], ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29be370e",
   "metadata": {},
   "source": [
    "## 使用说明\n",
    "\n",
    "1. **准备工作**：\n",
    "   - 确保 `FlakyLens_dataset_with_nonflaky_indented.csv` 文件在同一目录下\n",
    "   - 在第3个单元格中填入你的 DeepSeek API Key\n",
    "   - 安装必要的依赖：`pip install pandas openai tqdm`\n",
    "\n",
    "2. **运行流程**：\n",
    "   - 先运行第2个单元格，查看CSV文件的格式和列名\n",
    "   - 根据实际的列名，调整第4个单元格中的 `generate_reasoning_prompt` 函数\n",
    "   - 同样调整第5个单元格中的 `convert_to_alpaca_format` 函数\n",
    "   - 运行第6个单元格开始处理数据\n",
    "   - 运行第7个单元格保存最终结果\n",
    "\n",
    "3. **注意事项**：\n",
    "   - 脚本会每50条数据保存一次中间结果到 `distillation_dataset_temp.json`\n",
    "   - 如果中断，可以从中间结果继续处理\n",
    "   - API调用有重试机制，失败的数据会被记录\n",
    "   - 每10条数据会暂停1秒，避免触发API限流"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS6158_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
