"""
å¿«é€Ÿå¯åŠ¨è„šæœ¬
æä¾›äº¤äº’å¼ç•Œé¢æ¥è¿è¡Œä¸åŒçš„Agentä»»åŠ¡
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from agents import DistillationAgent, DataExplainerAgent
from evaluation import Evaluator
from utils import (load_csv, split_dataset, save_split_datasets, 
                   create_project_wise_kfold_splits, save_kfold_datasets)
from config import DATASET_PATH, OUTPUT_DIR


def print_menu():
    """æ‰“å°èœå•"""
    print("\n" + "=" * 60)
    print("Flaky Teståˆ†æç³»ç»Ÿ - å¿«é€Ÿå¯åŠ¨")
    print("=" * 60)
    print("1. æ•°æ®è’¸é¦")
    print("2. æ•°æ®è®²è§£")
    print("3. è¯„ä¼°é¢„æµ‹ç»“æœ")
    print("4. æ•°æ®é›†åˆ’åˆ†")
    print("5. é€€å‡º")
    print("=" * 60)


def run_distillation():
    """è¿è¡Œæ•°æ®è’¸é¦ï¼ˆç»Ÿä¸€é…ç½®ï¼‰"""
    print("\n" + "=" * 60)
    print("æ•°æ®è’¸é¦é…ç½®")
    print("=" * 60)
    
    try:
        # é€‰æ‹©æµ‹è¯•æ¨¡å¼
        print("\næµ‹è¯•æ¨¡å¼:")
        print("1. æœ€åNæ¡")
        print("2. å‰Næ¡")
        print("3. éšæœºNæ¡")
        print("4. å…¨éƒ¨æ•°æ®")
        mode_choice = input("é€‰æ‹©æ¨¡å¼ (1-4, é»˜è®¤1): ").strip() or "1"
        
        mode_map = {'1': 'last', '2': 'first', '3': 'random', '4': 'all'}
        mode = mode_map.get(mode_choice, 'last')
        
        # è¾“å…¥æ•°æ®é‡ï¼ˆå¦‚æœä¸æ˜¯å…¨éƒ¨ï¼‰
        if mode != 'all':
            test_size = int(input("è¯·è¾“å…¥æ•°æ®é‡ (é»˜è®¤10): ").strip() or "10")
        else:
            test_size = None
            print("å°†å¤„ç†å…¨éƒ¨æ•°æ®")
        
        # è¾“å…¥å¹¶è¡Œçº¿ç¨‹æ•°
        parallel_workers = int(input("è¯·è¾“å…¥å¹¶è¡Œçº¿ç¨‹æ•° (1-10ï¼Œé»˜è®¤1): ").strip() or "1")
        parallel_workers = max(1, min(10, parallel_workers))
        
        # æ‰¹æ¬¡å¤§å°
        batch_size = int(input("è¯·è¾“å…¥æ‰¹æ¬¡å¤§å° (é»˜è®¤5): ").strip() or "5")
        
        print(f"\né…ç½®:")
        print(f"  æ¨¡å¼: {mode}")
        print(f"  æ•°æ®é‡: {test_size if test_size else 'å…¨éƒ¨'}")
        print(f"  å¹¶è¡Œçº¿ç¨‹: {parallel_workers}")
        print(f"  æ‰¹æ¬¡å¤§å°: {batch_size}")
        
        confirm = input("\nç¡®è®¤å¼€å§‹ï¼Ÿ(y/n): ").strip().lower()
        if confirm != 'y':
            print("å·²å–æ¶ˆ")
            return
        
        # åˆ›å»ºAgentå¹¶è¿è¡Œ
        agent = DistillationAgent(
            test_mode=mode,
            test_size=test_size,
            batch_size=batch_size,
            batch_delay=0.5 if parallel_workers > 1 else 1,
            parallel_workers=parallel_workers
        )
        
        output_name = f'distillation_{mode}_{test_size if test_size else "all"}samples_p{parallel_workers}'
        result = agent.run(output_name=output_name)
        
        print(f"\nâœ“ è’¸é¦å®Œæˆ!")
        print(f"  æˆåŠŸ: {result['success_count']} æ¡")
        print(f"  å¤±è´¥: {result['failed_count']} æ¡")
        print(f"  è€—æ—¶: {result.get('elapsed_time', 0):.2f} ç§’")
        print(f"  è¾“å‡º: {result['output_file']}")
        
    except ValueError as e:
        print(f"âœ— è¾“å…¥é”™è¯¯: {e}")
    except Exception as e:
        print(f"âœ— å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def run_data_explainer():
    """è¿è¡Œæ•°æ®è®²è§£ï¼ˆç»Ÿä¸€é…ç½®ï¼‰"""
    print("\n" + "=" * 60)
    print("æ•°æ®è®²è§£é…ç½®")
    print("=" * 60)
    
    try:
        # è¾“å…¥æ ·æœ¬æ•°
        sample_size = int(input("\nè¯·è¾“å…¥è¦åˆ†æçš„æ ·æœ¬æ•° (é»˜è®¤20): ").strip() or "20")
        
        # éšæœºç§å­
        random_seed = int(input("è¯·è¾“å…¥éšæœºç§å­ (é»˜è®¤42): ").strip() or "42")
        
        print(f"\né…ç½®:")
        print(f"  æ ·æœ¬æ•°: {sample_size}")
        print(f"  éšæœºç§å­: {random_seed}")
        
        confirm = input("\nç¡®è®¤å¼€å§‹ï¼Ÿ(y/n): ").strip().lower()
        if confirm != 'y':
            print("å·²å–æ¶ˆ")
            return
        
        print(f"\nğŸš€ å¯åŠ¨æ•°æ®è®²è§£Agent...")
        
        agent = DataExplainerAgent(
            sample_size=sample_size,
            random_seed=random_seed
        )
        
        result = agent.run(output_name='dataset_analysis')
        
        if result['success']:
            print(f"\nâœ“ åˆ†æå®Œæˆ!")
            print(f"  JSON: {result['json_file']}")
            print(f"  æ–‡æœ¬: {result['txt_file']}")
    
    except ValueError as e:
        print(f"âœ— è¾“å…¥é”™è¯¯: {e}")
    except Exception as e:
        print(f"âœ— å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def run_evaluation():
    """è¿è¡Œè¯„ä¼°ä»»åŠ¡"""
    print("\n" + "=" * 60)
    print("è¯„ä¼°é¢„æµ‹ç»“æœ")
    print("=" * 60)
    
    from pathlib import Path
    output_dir = Path(__file__).parent / 'output'
    
    # åˆ—å‡ºoutputç›®å½•ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶ï¼ˆä¼˜å…ˆæ˜¾ç¤ºå¸¦_with_idçš„æ–‡ä»¶ï¼‰
    json_files = list(output_dir.glob('*_with_id.json'))
    if not json_files:
        # å¦‚æœæ²¡æœ‰å¸¦_with_idçš„æ–‡ä»¶ï¼Œåˆ™æ˜¾ç¤ºæ‰€æœ‰JSONæ–‡ä»¶
        json_files = list(output_dir.glob('*.json'))
    
    if not json_files:
        print("\nâœ— outputç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶")
        print("æç¤º: è¯·å…ˆè¿è¡Œæ•°æ®è’¸é¦ä»»åŠ¡ç”Ÿæˆé¢„æµ‹ç»“æœï¼ˆå»ºè®®ä½¿ç”¨å¸¦_with_idçš„æ–‡ä»¶è¿›è¡Œè¯„ä¼°ï¼‰")
        return
    
    print(f"\næ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶:")
    for i, file in enumerate(json_files, 1):
        # æ ‡æ³¨å“ªäº›æ˜¯å¸¦IDçš„æ–‡ä»¶
        marker = " âœ“ (æ¨è)" if "_with_id" in file.name else ""
        print(f"  {i}. {file.name}{marker}")
    
    try:
        # é€‰æ‹©è¦è¯„ä¼°çš„æ–‡ä»¶
        file_choice = input("\nè¯·é€‰æ‹©è¦è¯„ä¼°çš„æ–‡ä»¶ç¼–å·: ").strip()
        file_idx = int(file_choice) - 1
        
        if file_idx < 0 or file_idx >= len(json_files):
            print("âœ— æ— æ•ˆçš„æ–‡ä»¶ç¼–å·")
            return
        
        prediction_file = json_files[file_idx]
        print(f"\né€‰æ‹©çš„æ–‡ä»¶: {prediction_file.name}")
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å¸¦IDçš„æ–‡ä»¶
        if "_with_id" not in prediction_file.name:
            print("âš  è­¦å‘Š: è¯¥æ–‡ä»¶ä¸åŒ…å«IDå­—æ®µï¼Œè¯„ä¼°å¯èƒ½ä¸å‡†ç¡®")
            confirm = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ").strip().lower()
            if confirm != 'y':
                print("å·²å–æ¶ˆ")
                return
        
        # ä½¿ç”¨é»˜è®¤çš„ground truthæ–‡ä»¶
        ground_truth_file = Path(__file__).parent / 'dataset' / 'FlakyLens_dataset_with_nonflaky_indented.csv'
        
        if not ground_truth_file.exists():
            print(f"âœ— æœªæ‰¾åˆ°ground truthæ–‡ä»¶: {ground_truth_file}")
            return
        
        # åˆ›å»ºè¯„ä¼°å™¨ï¼ˆé€šè¿‡IDå­—æ®µåŒ¹é…ï¼‰
        print("\nğŸš€ å¼€å§‹è¯„ä¼°...")
        print("ğŸ“Œ è¯„ä¼°æ–¹å¼: é€šè¿‡IDå­—æ®µåŒ¹é…é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾")
        evaluator = Evaluator(
            prediction_file=prediction_file,
            ground_truth_file=ground_truth_file,
            label_column='label',
            id_column='id'
        )
        
        # è¿è¡Œè¯„ä¼°
        eval_output_dir = output_dir / 'evaluation'
        metrics = evaluator.run(
            output_dir=eval_output_dir,
            save_report=True,
            detailed=True
        )
        
        print(f"\nâœ“ è¯„ä¼°å®Œæˆ!")
        print(f"  æŠ¥å‘Šå·²ä¿å­˜åˆ°: {eval_output_dir}")
        
    except ValueError as e:
        print(f"âœ— è¾“å…¥é”™è¯¯: {e}")
    except Exception as e:
        print(f"âœ— è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def run_dataset_split():
    """è¿è¡Œæ•°æ®é›†åˆ’åˆ†ï¼ˆç»Ÿä¸€é…ç½®ï¼‰"""
    print("\n" + "=" * 60)
    print("æ•°æ®é›†åˆ’åˆ†")
    print("=" * 60)
    
    try:
        # é€‰æ‹©åˆ’åˆ†ç±»å‹
        print("\nåˆ’åˆ†ç±»å‹:")
        print("1. è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†åˆ’åˆ†")
        print("2. KæŠ˜äº¤å‰éªŒè¯ï¼ˆé¡¹ç›®çº§ç‹¬ç«‹ï¼‰")
        split_type = input("é€‰æ‹©ç±»å‹ (1-2, é»˜è®¤1): ").strip() or "1"
        
        if split_type == '1':
            # è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†åˆ’åˆ†
            print("\n" + "=" * 60)
            print("è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†åˆ’åˆ†")
            print("=" * 60)
            
            # è¾“å…¥åˆ’åˆ†æ¯”ä¾‹
            print("\nè¯·è¾“å…¥åˆ’åˆ†æ¯”ä¾‹ï¼ˆé»˜è®¤ 7:2:1ï¼‰")
            train_ratio = float(input("  è®­ç»ƒé›†æ¯”ä¾‹ (0-1, é»˜è®¤0.7): ").strip() or "0.7")
            val_ratio = float(input("  éªŒè¯é›†æ¯”ä¾‹ (0-1, é»˜è®¤0.2): ").strip() or "0.2")
            test_ratio = float(input("  æµ‹è¯•é›†æ¯”ä¾‹ (0-1, é»˜è®¤0.1): ").strip() or "0.1")
            
            # éªŒè¯æ¯”ä¾‹æ€»å’Œ
            total = train_ratio + val_ratio + test_ratio
            if abs(total - 1.0) > 1e-6:
                print(f"âœ— æ¯”ä¾‹æ€»å’Œå¿…é¡»ä¸º 1ï¼Œå½“å‰ä¸º: {total}")
                return
            
            # æ˜¯å¦ä½¿ç”¨åˆ†å±‚é‡‡æ ·
            use_stratify = input("\næ˜¯å¦ä½¿ç”¨åˆ†å±‚é‡‡æ ·ï¼ˆåŸºäºlabelåˆ—ï¼‰ï¼Ÿ(y/n, é»˜è®¤y): ").strip().lower()
            stratify_column = 'label' if use_stratify != 'n' else None
            
            # éšæœºç§å­
            random_seed = int(input("éšæœºç§å­ (é»˜è®¤42): ").strip() or "42")
            
            print(f"\né…ç½®:")
            print(f"  è®­ç»ƒé›†: {train_ratio*100:.1f}%")
            print(f"  éªŒè¯é›†: {val_ratio*100:.1f}%")
            print(f"  æµ‹è¯•é›†: {test_ratio*100:.1f}%")
            print(f"  åˆ†å±‚é‡‡æ ·: {'æ˜¯ (åŸºäºlabel)' if stratify_column else 'å¦'}")
            print(f"  éšæœºç§å­: {random_seed}")
            
        elif split_type == '2':
            # KæŠ˜äº¤å‰éªŒè¯
            print("\n" + "=" * 60)
            print("KæŠ˜äº¤å‰éªŒè¯ï¼ˆé¡¹ç›®çº§ç‹¬ç«‹ï¼‰")
            print("=" * 60)
            print("ç‰¹ç‚¹:")
            print("  âœ“ åŒä¸€é¡¹ç›®çš„æµ‹è¯•ä¸ä¼šåŒæ—¶å‡ºç°åœ¨è®­ç»ƒå’Œæµ‹è¯•é›†ä¸­")
            print("  âœ“ ç±»åˆ«å¹³è¡¡çº¦æŸï¼ˆæ¯ä¸ªæµ‹è¯•é›†è‡³å°‘åŒ…å«æ¯ç§ç±»åˆ«çš„æœ€å°æ ·æœ¬æ•°ï¼‰")
            print("=" * 60)
            
            # è¾“å…¥å‚æ•°
            n_folds = int(input("\næŠ˜æ•° (é»˜è®¤4): ").strip() or "4")
            min_samples = int(input("æ¯ä¸ªæµ‹è¯•é›†ä¸­æ¯ç±»çš„æœ€å°æ ·æœ¬æ•° (é»˜è®¤4): ").strip() or "4")
            random_seed = int(input("éšæœºç§å­ (é»˜è®¤42): ").strip() or "42")
            
            print(f"\né…ç½®:")
            print(f"  æŠ˜æ•°: {n_folds}")
            print(f"  æ¯ç±»æœ€å°æ ·æœ¬æ•°: {min_samples}")
            print(f"  éšæœºç§å­: {random_seed}")
        
        else:
            print("âœ— æ— æ•ˆçš„é€‰æ‹©")
            return
        
        # è¾“å‡ºæ ¼å¼ï¼ˆä¸¤ç§ç±»å‹éƒ½éœ€è¦ï¼‰
        print("\nè¾“å‡ºæ ¼å¼:")
        print("1. CSV")
        print("2. JSON")
        print("3. ä¸¤è€…éƒ½ä¿å­˜")
        format_choice = input("é€‰æ‹©æ ¼å¼ (1-3, é»˜è®¤1): ").strip() or "1"
        
        confirm = input("\nç¡®è®¤å¼€å§‹åˆ’åˆ†ï¼Ÿ(y/n): ").strip().lower()
        if confirm != 'y':
            print("å·²å–æ¶ˆ")
            return
        
        # åŠ è½½æ•°æ®é›†
        print(f"\nğŸ“‚ åŠ è½½æ•°æ®é›†: {DATASET_PATH}")
        df = load_csv(DATASET_PATH)
        
        if split_type == '1':
            # æ‰§è¡Œè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†åˆ’åˆ†
            print("\nğŸ”€ å¼€å§‹åˆ’åˆ†æ•°æ®é›†...")
            splits = split_dataset(
                df,
                train_ratio=train_ratio,
                val_ratio=val_ratio,
                test_ratio=test_ratio,
                stratify_column=stratify_column,
                random_seed=random_seed,
                shuffle=True
            )
            
            # ä¿å­˜åˆ’åˆ†åçš„æ•°æ®é›†
            output_dir = OUTPUT_DIR / 'splits'
            
            if format_choice in ['1', '3']:
                print("\nğŸ’¾ ä¿å­˜CSVæ ¼å¼...")
                save_split_datasets(splits, output_dir=output_dir, base_name='flaky_dataset', format='csv')
            
            if format_choice in ['2', '3']:
                print("\nğŸ’¾ ä¿å­˜JSONæ ¼å¼...")
                save_split_datasets(splits, output_dir=output_dir, base_name='flaky_dataset', format='json')
            
            print(f"\nâœ“ æ•°æ®é›†åˆ’åˆ†å®Œæˆ!")
            print(f"  è¾“å‡ºç›®å½•: {output_dir}")
        
        elif split_type == '2':
            # æ‰§è¡ŒKæŠ˜äº¤å‰éªŒè¯åˆ’åˆ†
            folds = create_project_wise_kfold_splits(
                df,
                project_column='project',
                category_column='category',
                n_folds=n_folds,
                min_samples_per_category=min_samples,
                random_seed=random_seed
            )
            
            # ä¿å­˜KæŠ˜æ•°æ®é›†
            output_dir = OUTPUT_DIR / 'kfold_splits'
            
            if format_choice in ['1', '3']:
                print("\nğŸ’¾ ä¿å­˜CSVæ ¼å¼...")
                save_kfold_datasets(folds, output_dir=output_dir, base_name='fold', format='csv')
            
            if format_choice in ['2', '3']:
                print("\nğŸ’¾ ä¿å­˜JSONæ ¼å¼...")
                save_kfold_datasets(folds, output_dir=output_dir, base_name='fold', format='json')
            
            print(f"\nâœ“ KæŠ˜äº¤å‰éªŒè¯æ•°æ®é›†åˆ’åˆ†å®Œæˆ!")
            print(f"  è¾“å‡ºç›®å½•: {output_dir}")
            print(f"  å…±ç”Ÿæˆ {n_folds} æŠ˜æ•°æ®")
            print(f"\nğŸ“ æ¯æŠ˜åŒ…å«:")
            print(f"  - fold_X_train.csv/json: è®­ç»ƒé›†")
            print(f"  - fold_X_test.csv/json: æµ‹è¯•é›†")
            print(f"  - fold_X_projects.txt: é¡¹ç›®åˆ—è¡¨")
        
    except ValueError as e:
        print(f"âœ— è¾“å…¥é”™è¯¯: {e}")
    except Exception as e:
        print(f"âœ— åˆ’åˆ†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


        traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    while True:
        print_menu()
        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1-5): ").strip()
        
        if choice == '1':
            run_distillation()
        elif choice == '2':
            run_data_explainer()
        elif choice == '3':
            run_evaluation()
        elif choice == '4':
            run_dataset_split()
        elif choice == '5':
            print("\nğŸ‘‹ å†è§!")
            break
        else:
            print("\nâœ— æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡è¯•")
        
        input("\næŒ‰å›è½¦é”®ç»§ç»­...")


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºå·²ä¸­æ–­ï¼Œå†è§!")
    except Exception as e:
        print(f"\nâœ— å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
