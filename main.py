"""
å¿«é€Ÿå¯åŠ¨è„šæœ¬
æä¾›äº¤äº’å¼ç•Œé¢æ¥è¿è¡Œä¸åŒçš„Agentä»»åŠ¡
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from agents import DistillationAgent, DataExplainerAgent
from evaluation import Evaluator
from utils import (load_csv, split_dataset, save_split_datasets, 
                   create_project_wise_kfold_splits, save_kfold_datasets,
                   APISignatureMatcher, save_config, load_config, 
                   list_saved_configs, delete_config, display_config,
                   switch_provider, get_current_config, show_current_config,
                   list_providers, get_supported_models, show_all_models)
from config import DATASET_PATH, OUTPUT_DIR


def list_available_datasets():
    """åˆ—å‡ºå¯ç”¨çš„æ•°æ®é›†æ–‡ä»¶"""
    from pathlib import Path
    
    dataset_dir = Path(__file__).parent / 'dataset'
    
    # æ”¶é›†æ‰€æœ‰CSVæ–‡ä»¶
    datasets = []
    
    # 1. ä¸»æ•°æ®é›†
    main_dataset = dataset_dir / 'FlakyLens_dataset_with_nonflaky_indented.csv'
    if main_dataset.exists():
        datasets.append(('ä¸»æ•°æ®é›†', main_dataset))
    
    # 2. K-foldåˆ’åˆ†
    kfold_dir = dataset_dir / 'kfold_splits'
    if kfold_dir.exists():
        for fold_file in sorted(kfold_dir.glob('*.csv')):
            fold_name = fold_file.stem.replace('_', ' ').title()
            datasets.append((f'K-Fold: {fold_name}', fold_file))
    
    # 3. å…¶ä»–åˆ’åˆ†
    for csv_file in dataset_dir.glob('*.csv'):
        if csv_file != main_dataset:
            datasets.append((csv_file.stem, csv_file))
    
    return datasets


def select_dataset(prompt="è¯·é€‰æ‹©æ•°æ®é›†", allow_none=False):
    """
    äº¤äº’å¼é€‰æ‹©æ•°æ®é›†
    
    Args:
        prompt: æç¤ºä¿¡æ¯
        allow_none: æ˜¯å¦å…è®¸ä¸é€‰æ‹©ï¼ˆè¿”å›Noneï¼‰
        
    Returns:
        é€‰ä¸­çš„æ•°æ®é›†è·¯å¾„ï¼Œæˆ–None
    """
    datasets = list_available_datasets()
    
    if not datasets:
        print("âœ— æœªæ‰¾åˆ°å¯ç”¨çš„æ•°æ®é›†æ–‡ä»¶")
        return None
    
    print(f"\n{prompt}:")
    if allow_none:
        print("  0. (ä¸ä½¿ç”¨)")
    
    for i, (name, path) in enumerate(datasets, 1):
        print(f"  {i}. {name}")
    
    try:
        choice = input(f"\né€‰æ‹© ({0 if allow_none else 1}-{len(datasets)}): ").strip()
        if not choice:
            return None if allow_none else datasets[0][1]
        
        idx = int(choice)
        
        if idx == 0 and allow_none:
            return None
        
        if idx < 1 or idx > len(datasets):
            print("âœ— æ— æ•ˆçš„é€‰æ‹©")
            return None
        
        return datasets[idx - 1][1]
    
    except ValueError:
        print("âœ— è¾“å…¥æ— æ•ˆ")
        return None


def print_menu():
    """æ‰“å°èœå•"""
    print("\n" + "=" * 60)
    print("Flaky Teståˆ†æç³»ç»Ÿ - å¿«é€Ÿå¯åŠ¨")
    print("=" * 60)
    print("1. æ•°æ®è’¸é¦")
    print("2. æ•°æ®è®²è§£")
    print("3. è¯„ä¼°é¢„æµ‹ç»“æœ")
    print("4. æ•°æ®é›†åˆ’åˆ†")
    print("5. é…ç½®ç®¡ç†")
    print("6. æ¨¡å‹è®¾ç½®")
    print("7. é€€å‡º")
    print("=" * 60)


def run_distillation():
    """è¿è¡Œæ•°æ®è’¸é¦ï¼ˆæ”¯æŒè‡ªå®šä¹‰è®­ç»ƒé›†/æµ‹è¯•é›†å’ŒAPIåŒ¹é…ï¼‰"""
    print("\n" + "=" * 60)
    print("æ•°æ®è’¸é¦é…ç½®")
    print("=" * 60)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„é…ç½®
    saved_configs = list_saved_configs()
    use_saved_config = False
    config_to_save = {}
    
    if saved_configs:
        print("\nğŸ’¾ å‘ç°å·²ä¿å­˜çš„é…ç½®:")
        for i, config_name in enumerate(saved_configs, 1):
            print(f"  {i}. {config_name}")
        print(f"  0. æ–°å»ºé…ç½®")
        
        choice = input("\né€‰æ‹©é…ç½® (0-{}ï¼Œé»˜è®¤0): ".format(len(saved_configs))).strip() or "0"
        
        if choice != '0':
            try:
                idx = int(choice) - 1
                if 0 <= idx < len(saved_configs):
                    config_name = saved_configs[idx]
                    config = load_config(config_name)
                    
                    if config and config.get('task_type') == 'distillation':
                        display_config(config)
                        confirm = input("\nä½¿ç”¨æ­¤é…ç½®ï¼Ÿ(y/n): ").strip().lower()
                        if confirm == 'y':
                            use_saved_config = True
                            # ä»é…ç½®ä¸­æå–å‚æ•°
                            test_dataset = config['test_dataset']
                            train_dataset = config.get('train_dataset')
                            use_api_matching = config.get('use_api_matching', False)
                            top_k_shots = config.get('top_k_shots', 3)
                            mode = config.get('mode', 'random')
                            test_size = config.get('test_size', 10)
                            parallel_workers = config.get('parallel_workers', 5)
                            batch_size = config.get('batch_size', 5)
                    else:
                        print("âœ— é…ç½®ç±»å‹ä¸åŒ¹é…")
            except (ValueError, IndexError):
                print("âœ— æ— æ•ˆé€‰æ‹©")
    
    if not use_saved_config:
        # åŸæœ‰çš„é…ç½®æµç¨‹
        try:
            # Step 1: é€‰æ‹©æµ‹è¯•é›†
            print("\nã€Step 1/5ã€‘é€‰æ‹©æµ‹è¯•é›†")
            test_dataset = select_dataset("è¯·é€‰æ‹©æµ‹è¯•é›†")
            if not test_dataset:
                print("å·²å–æ¶ˆ")
                return
            print(f"âœ“ æµ‹è¯•é›†: {test_dataset.name}")
            
            # Step 2: é€‰æ‹©è®­ç»ƒé›†ï¼ˆå¯é€‰ï¼Œç”¨äºAPIåŒ¹é…ï¼‰
            print("\nã€Step 2/5ã€‘é€‰æ‹©è®­ç»ƒé›†ï¼ˆç”¨äºAPIåŒ¹é…ï¼Œå¯é€‰ï¼‰")
            print("æç¤º: å¦‚æœé€‰æ‹©è®­ç»ƒé›†ï¼Œå°†ä½¿ç”¨APIç­¾ååŒ¹é…æ¥æ£€ç´¢few-shot examples")
            use_api_matching = input("æ˜¯å¦ä½¿ç”¨APIåŒ¹é…ï¼Ÿ(y/n, é»˜è®¤n): ").strip().lower() == 'y'
            
            train_dataset = None
            top_k_shots = 3
            
            if use_api_matching:
                train_dataset = select_dataset("è¯·é€‰æ‹©è®­ç»ƒé›†ï¼ˆç”¨ä½œçŸ¥è¯†åº“ï¼‰", allow_none=True)
                if train_dataset:
                    print(f"âœ“ è®­ç»ƒé›†: {train_dataset.name}")
                    
                    # è®¾ç½®few-shotæ•°é‡
                    top_k_shots = int(input("\nè¯·è¾“å…¥few-shotæ ·æœ¬æ•° (é»˜è®¤3): ").strip() or "3")
                    top_k_shots = max(1, min(10, top_k_shots))
                else:
                    print("âœ“ è·³è¿‡APIåŒ¹é…")
                    use_api_matching = False
            
            # Step 3: é€‰æ‹©æµ‹è¯•æ¨¡å¼
            print("\nã€Step 3/5ã€‘æµ‹è¯•æ¨¡å¼")
            print("1. æœ€åNæ¡")
            print("2. å‰Næ¡")
            print("3. éšæœºNæ¡")
            print("4. å…¨éƒ¨æ•°æ®")
            mode_choice = input("é€‰æ‹©æ¨¡å¼ (1-4, é»˜è®¤3): ").strip() or "3"
            
            mode_map = {'1': 'last', '2': 'first', '3': 'random', '4': 'all'}
            mode = mode_map.get(mode_choice, 'last')
            
            # è¾“å…¥æ•°æ®é‡ï¼ˆå¦‚æœä¸æ˜¯å…¨éƒ¨ï¼‰
            if mode != 'all':
                test_size = int(input("è¯·è¾“å…¥æ•°æ®é‡ (é»˜è®¤10): ").strip() or "10")
            else:
                test_size = None
                print("å°†å¤„ç†å…¨éƒ¨æ•°æ®")
            
            # Step 4: å¹¶è¡Œé…ç½®
            print("\nã€Step 4/5ã€‘å¹¶è¡Œé…ç½®")
            parallel_workers = int(input("è¯·è¾“å…¥å¹¶è¡Œçº¿ç¨‹æ•° (1-10ï¼Œé»˜è®¤5): ").strip() or "5")
            parallel_workers = max(1, min(10, parallel_workers))
            
            batch_size = int(input("è¯·è¾“å…¥æ‰¹æ¬¡å¤§å° (é»˜è®¤5): ").strip() or "5")
            
            # ä¿å­˜é…ç½®ä»¥å¤‡åç”¨
            config_to_save = {
                'task_type': 'distillation',
                'test_dataset': test_dataset,
                'train_dataset': train_dataset,
                'use_api_matching': use_api_matching,
                'top_k_shots': top_k_shots,
                'mode': mode,
                'test_size': test_size,
                'parallel_workers': parallel_workers,
                'batch_size': batch_size
            }
            
        except ValueError as e:
            print(f"âœ— è¾“å…¥é”™è¯¯: {e}")
            return
        except Exception as e:
            print(f"âœ— å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return
    
    try:
        # Step 5: ç¡®è®¤é…ç½®
        print("\nã€Step 5/5ã€‘é…ç½®ç¡®è®¤")
        print("=" * 60)
        print(f"æµ‹è¯•é›†: {test_dataset.name}")
        if use_api_matching and train_dataset:
            print(f"è®­ç»ƒé›†: {train_dataset.name}")
            print(f"APIåŒ¹é…: å¼€å¯ (Top-{top_k_shots} few-shots)")
        else:
            print("APIåŒ¹é…: å…³é—­")
        print(f"æµ‹è¯•æ¨¡å¼: {mode}")
        print(f"æ•°æ®é‡: {test_size if test_size else 'å…¨éƒ¨'}")
        print(f"å¹¶è¡Œçº¿ç¨‹: {parallel_workers}")
        print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
        print("=" * 60)
        
        confirm = input("\nç¡®è®¤å¼€å§‹ï¼Ÿ(y/n): ").strip().lower() or "y"
        if confirm != 'y':
            print("å·²å–æ¶ˆ")
            return
        
        # å¦‚æœæ˜¯æ–°é…ç½®ï¼Œè¯¢é—®æ˜¯å¦ä¿å­˜
        if not use_saved_config and config_to_save:
            save_choice = input("\nğŸ’¾ æ˜¯å¦ä¿å­˜æ­¤é…ç½®ä¾›ä¸‹æ¬¡ä½¿ç”¨ï¼Ÿ(y/n): ").strip().lower()
            if save_choice == 'y':
                config_name = input("è¯·è¾“å…¥é…ç½®åç§°: ").strip()
                if config_name:
                    save_config(config_to_save, config_name)
        
        # åŠ è½½è®­ç»ƒæ•°æ®å¹¶åˆ›å»ºAPIåŒ¹é…å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        api_matcher = None
        train_data = None
        
        if use_api_matching and train_dataset:
            print("\næ­£åœ¨åŠ è½½è®­ç»ƒé›†å¹¶æ„å»ºAPIç´¢å¼•...")
            train_data = load_csv(train_dataset)
            api_matcher = APISignatureMatcher(train_data, code_column='full_code')
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats = api_matcher.get_statistics()
            print(f"âœ“ APIç´¢å¼•æ„å»ºå®Œæˆ:")
            print(f"  - è®­ç»ƒæ ·æœ¬æ•°: {stats['total_train_samples']}")
            print(f"  - å”¯ä¸€APIæ•°: {stats['total_unique_apis']}")
            print(f"  - å¹³å‡APIæ•°/æ ·æœ¬: {stats['avg_apis_per_sample']:.1f}")
            print(f"  - æœ€å¸¸è§API: {', '.join([api for api, _ in stats['most_common_apis'][:5]])}")
        
        # åˆ›å»ºAgentå¹¶è¿è¡Œ
        print("\nğŸš€ å¼€å§‹æ•°æ®è’¸é¦...")
        
        agent = DistillationAgent(
            dataset_path=str(test_dataset),
            test_mode=mode,
            test_size=test_size,
            batch_size=batch_size,
            batch_delay=0.5 if parallel_workers > 1 else 1,
            parallel_workers=parallel_workers,
            api_matcher=api_matcher,
            top_k_shots=top_k_shots if use_api_matching else 0
        )
        
        # æ„å»ºè¾“å‡ºæ–‡ä»¶å
        output_name_parts = [
            'distillation',
            test_dataset.stem,
            mode,
            f'{test_size if test_size else "all"}samples'
        ]
        if use_api_matching:
            output_name_parts.append(f'api_top{top_k_shots}')
        output_name_parts.append(f'p{parallel_workers}')
        
        output_name = '_'.join(output_name_parts)
        result = agent.run(output_name=output_name)
        
        print(f"\nâœ“ è’¸é¦å®Œæˆ!")
        print(f"  æˆåŠŸ: {result['success_count']} æ¡")
        print(f"  å¤±è´¥: {result['failed_count']} æ¡")
        print(f"  è€—æ—¶: {result.get('elapsed_time', 0):.2f} ç§’")
        print(f"  è¾“å‡º: {result['output_file']}")
        
        if use_api_matching:
            print(f"\nğŸ“Š APIåŒ¹é…ç»Ÿè®¡:")
            print(f"  - ä½¿ç”¨è®­ç»ƒé›†: {train_dataset.name}")
            print(f"  - Few-shotæ•°é‡: {top_k_shots}")
            print(f"  - çŸ¥è¯†åº“å¤§å°: {len(train_data)}")
        
    except ValueError as e:
        print(f"âœ— è¾“å…¥é”™è¯¯: {e}")
    except Exception as e:
        print(f"âœ— å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def run_data_explainer():
    """è¿è¡Œæ•°æ®è®²è§£ï¼ˆç»Ÿä¸€é…ç½®ï¼‰"""
    print("\n" + "=" * 60)
    print("æ•°æ®è®²è§£é…ç½®")
    print("=" * 60)
    
    try:
        # è¾“å…¥æ ·æœ¬æ•°
        sample_size = int(input("\nè¯·è¾“å…¥è¦åˆ†æçš„æ ·æœ¬æ•° (é»˜è®¤20): ").strip() or "20")
        
        # éšæœºç§å­
        random_seed = int(input("è¯·è¾“å…¥éšæœºç§å­ (é»˜è®¤42): ").strip() or "42")
        
        print(f"\né…ç½®:")
        print(f"  æ ·æœ¬æ•°: {sample_size}")
        print(f"  éšæœºç§å­: {random_seed}")
        
        confirm = input("\nç¡®è®¤å¼€å§‹ï¼Ÿ(y/n): ").strip().lower()
        if confirm != 'y':
            print("å·²å–æ¶ˆ")
            return
        
        print(f"\nğŸš€ å¯åŠ¨æ•°æ®è®²è§£Agent...")
        
        agent = DataExplainerAgent(
            sample_size=sample_size,
            random_seed=random_seed
        )
        
        result = agent.run(output_name='dataset_analysis')
        
        if result['success']:
            print(f"\nâœ“ åˆ†æå®Œæˆ!")
            print(f"  JSON: {result['json_file']}")
            print(f"  æ–‡æœ¬: {result['txt_file']}")
    
    except ValueError as e:
        print(f"âœ— è¾“å…¥é”™è¯¯: {e}")
    except Exception as e:
        print(f"âœ— å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


def run_evaluation():
    """è¿è¡Œè¯„ä¼°ä»»åŠ¡"""
    print("\n" + "=" * 60)
    print("è¯„ä¼°é¢„æµ‹ç»“æœ")
    print("=" * 60)
    
    from pathlib import Path
    output_dir = Path(__file__).parent / 'output'
    
    # åˆ—å‡ºoutputç›®å½•ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶ï¼ˆä¼˜å…ˆæ˜¾ç¤ºå¸¦_externalçš„æ–‡ä»¶ï¼‰
    json_files = list(output_dir.glob('*_external.json'))
    if not json_files:
        # å¦‚æœæ²¡æœ‰å¸¦_externalçš„æ–‡ä»¶ï¼Œåˆ™æ˜¾ç¤ºæ‰€æœ‰JSONæ–‡ä»¶
        json_files = list(output_dir.glob('*.json'))
    
    if not json_files:
        print("\nâœ— outputç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶")
        print("æç¤º: è¯·å…ˆè¿è¡Œæ•°æ®è’¸é¦ä»»åŠ¡ç”Ÿæˆé¢„æµ‹ç»“æœï¼ˆå»ºè®®ä½¿ç”¨å¸¦_externalçš„æ–‡ä»¶è¿›è¡Œè¯„ä¼°ï¼‰")
        return
    
    print(f"\næ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶:")
    for i, file in enumerate(json_files, 1):
        # æ ‡æ³¨å“ªäº›æ˜¯å¸¦é¢å¤–ä¿¡æ¯çš„æ–‡ä»¶
        marker = " âœ“ (æ¨è)" if "_external" in file.name else ""
        print(f"  {i}. {file.name}{marker}")
    
    try:
        # é€‰æ‹©è¦è¯„ä¼°çš„æ–‡ä»¶
        file_choice = input("\nè¯·é€‰æ‹©è¦è¯„ä¼°çš„æ–‡ä»¶ç¼–å·: ").strip()
        file_idx = int(file_choice) - 1
        
        if file_idx < 0 or file_idx >= len(json_files):
            print("âœ— æ— æ•ˆçš„æ–‡ä»¶ç¼–å·")
            return
        
        prediction_file = json_files[file_idx]
        print(f"\né€‰æ‹©çš„æ–‡ä»¶: {prediction_file.name}")
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å¸¦é¢å¤–ä¿¡æ¯çš„æ–‡ä»¶
        if "_external" not in prediction_file.name:
            print("âš  è­¦å‘Š: è¯¥æ–‡ä»¶ä¸åŒ…å«IDå­—æ®µï¼Œè¯„ä¼°å¯èƒ½ä¸å‡†ç¡®")
            confirm = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ").strip().lower()
            if confirm != 'y':
                print("å·²å–æ¶ˆ")
                return
        
        # ä½¿ç”¨é»˜è®¤çš„ground truthæ–‡ä»¶
        ground_truth_file = Path(__file__).parent / 'dataset' / 'FlakyLens_dataset_with_nonflaky_indented.csv'
        
        if not ground_truth_file.exists():
            print(f"âœ— æœªæ‰¾åˆ°ground truthæ–‡ä»¶: {ground_truth_file}")
            return
        
        # åˆ›å»ºè¯„ä¼°å™¨ï¼ˆé€šè¿‡IDå­—æ®µåŒ¹é…ï¼‰
        print("\nğŸš€ å¼€å§‹è¯„ä¼°...")
        print("ğŸ“Œ è¯„ä¼°æ–¹å¼: é€šè¿‡IDå­—æ®µåŒ¹é…é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾")
        evaluator = Evaluator(
            prediction_file=prediction_file,
            ground_truth_file=ground_truth_file,
            label_column='label',
            id_column='id'
        )
        
        # è¿è¡Œè¯„ä¼°
        eval_output_dir = output_dir / 'evaluation'
        metrics = evaluator.run(
            output_dir=eval_output_dir,
            save_report=True,
            detailed=True
        )
        
        print(f"\nâœ“ è¯„ä¼°å®Œæˆ!")
        print(f"  æŠ¥å‘Šå·²ä¿å­˜åˆ°: {eval_output_dir}")
        
    except ValueError as e:
        print(f"âœ— è¾“å…¥é”™è¯¯: {e}")
    except Exception as e:
        print(f"âœ— è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def run_dataset_split():
    """è¿è¡Œæ•°æ®é›†åˆ’åˆ†ï¼ˆç»Ÿä¸€é…ç½®ï¼‰"""
    print("\n" + "=" * 60)
    print("æ•°æ®é›†åˆ’åˆ†")
    print("=" * 60)
    
    try:
        # é€‰æ‹©åˆ’åˆ†ç±»å‹
        print("\nåˆ’åˆ†ç±»å‹:")
        print("1. è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†åˆ’åˆ†")
        print("2. KæŠ˜äº¤å‰éªŒè¯ï¼ˆé¡¹ç›®çº§ç‹¬ç«‹ï¼‰")
        split_type = input("é€‰æ‹©ç±»å‹ (1-2, é»˜è®¤1): ").strip() or "1"
        
        if split_type == '1':
            # è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†åˆ’åˆ†
            print("\n" + "=" * 60)
            print("è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†åˆ’åˆ†")
            print("=" * 60)
            
            # è¾“å…¥åˆ’åˆ†æ¯”ä¾‹
            print("\nè¯·è¾“å…¥åˆ’åˆ†æ¯”ä¾‹ï¼ˆé»˜è®¤ 7:2:1ï¼‰")
            train_ratio = float(input("  è®­ç»ƒé›†æ¯”ä¾‹ (0-1, é»˜è®¤0.7): ").strip() or "0.7")
            val_ratio = float(input("  éªŒè¯é›†æ¯”ä¾‹ (0-1, é»˜è®¤0.2): ").strip() or "0.2")
            test_ratio = float(input("  æµ‹è¯•é›†æ¯”ä¾‹ (0-1, é»˜è®¤0.1): ").strip() or "0.1")
            
            # éªŒè¯æ¯”ä¾‹æ€»å’Œ
            total = train_ratio + val_ratio + test_ratio
            if abs(total - 1.0) > 1e-6:
                print(f"âœ— æ¯”ä¾‹æ€»å’Œå¿…é¡»ä¸º 1ï¼Œå½“å‰ä¸º: {total}")
                return
            
            # æ˜¯å¦ä½¿ç”¨åˆ†å±‚é‡‡æ ·
            use_stratify = input("\næ˜¯å¦ä½¿ç”¨åˆ†å±‚é‡‡æ ·ï¼ˆåŸºäºlabelåˆ—ï¼‰ï¼Ÿ(y/n, é»˜è®¤y): ").strip().lower()
            stratify_column = 'label' if use_stratify != 'n' else None
            
            # éšæœºç§å­
            random_seed = int(input("éšæœºç§å­ (é»˜è®¤42): ").strip() or "42")
            
            print(f"\né…ç½®:")
            print(f"  è®­ç»ƒé›†: {train_ratio*100:.1f}%")
            print(f"  éªŒè¯é›†: {val_ratio*100:.1f}%")
            print(f"  æµ‹è¯•é›†: {test_ratio*100:.1f}%")
            print(f"  åˆ†å±‚é‡‡æ ·: {'æ˜¯ (åŸºäºlabel)' if stratify_column else 'å¦'}")
            print(f"  éšæœºç§å­: {random_seed}")
            
        elif split_type == '2':
            # KæŠ˜äº¤å‰éªŒè¯
            print("\n" + "=" * 60)
            print("KæŠ˜äº¤å‰éªŒè¯ï¼ˆé¡¹ç›®çº§ç‹¬ç«‹ï¼‰")
            print("=" * 60)
            print("ç‰¹ç‚¹:")
            print("  âœ“ åŒä¸€é¡¹ç›®çš„æµ‹è¯•ä¸ä¼šåŒæ—¶å‡ºç°åœ¨è®­ç»ƒå’Œæµ‹è¯•é›†ä¸­")
            print("  âœ“ ç±»åˆ«å¹³è¡¡çº¦æŸï¼ˆæ¯ä¸ªæµ‹è¯•é›†è‡³å°‘åŒ…å«æ¯ç§ç±»åˆ«çš„æœ€å°æ ·æœ¬æ•°ï¼‰")
            print("=" * 60)
            
            # è¾“å…¥å‚æ•°
            n_folds = int(input("\næŠ˜æ•° (é»˜è®¤4): ").strip() or "4")
            min_samples = int(input("æ¯ä¸ªæµ‹è¯•é›†ä¸­æ¯ç±»çš„æœ€å°æ ·æœ¬æ•° (é»˜è®¤4): ").strip() or "4")
            random_seed = int(input("éšæœºç§å­ (é»˜è®¤42): ").strip() or "42")
            
            print(f"\né…ç½®:")
            print(f"  æŠ˜æ•°: {n_folds}")
            print(f"  æ¯ç±»æœ€å°æ ·æœ¬æ•°: {min_samples}")
            print(f"  éšæœºç§å­: {random_seed}")
        
        else:
            print("âœ— æ— æ•ˆçš„é€‰æ‹©")
            return
        
        # è¾“å‡ºæ ¼å¼ï¼ˆä¸¤ç§ç±»å‹éƒ½éœ€è¦ï¼‰
        print("\nè¾“å‡ºæ ¼å¼:")
        print("1. CSV")
        print("2. JSON")
        print("3. ä¸¤è€…éƒ½ä¿å­˜")
        format_choice = input("é€‰æ‹©æ ¼å¼ (1-3, é»˜è®¤1): ").strip() or "1"
        
        confirm = input("\nç¡®è®¤å¼€å§‹åˆ’åˆ†ï¼Ÿ(y/n): ").strip().lower()
        if confirm != 'y':
            print("å·²å–æ¶ˆ")
            return
        
        # åŠ è½½æ•°æ®é›†
        print(f"\nğŸ“‚ åŠ è½½æ•°æ®é›†: {DATASET_PATH}")
        df = load_csv(DATASET_PATH)
        
        if split_type == '1':
            # æ‰§è¡Œè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†åˆ’åˆ†
            print("\nğŸ”€ å¼€å§‹åˆ’åˆ†æ•°æ®é›†...")
            splits = split_dataset(
                df,
                train_ratio=train_ratio,
                val_ratio=val_ratio,
                test_ratio=test_ratio,
                stratify_column=stratify_column,
                random_seed=random_seed,
                shuffle=True
            )
            
            # ä¿å­˜åˆ’åˆ†åçš„æ•°æ®é›†
            output_dir = OUTPUT_DIR / 'splits'
            
            if format_choice in ['1', '3']:
                print("\nğŸ’¾ ä¿å­˜CSVæ ¼å¼...")
                save_split_datasets(splits, output_dir=output_dir, base_name='flaky_dataset', format='csv')
            
            if format_choice in ['2', '3']:
                print("\nğŸ’¾ ä¿å­˜JSONæ ¼å¼...")
                save_split_datasets(splits, output_dir=output_dir, base_name='flaky_dataset', format='json')
            
            print(f"\nâœ“ æ•°æ®é›†åˆ’åˆ†å®Œæˆ!")
            print(f"  è¾“å‡ºç›®å½•: {output_dir}")
        
        elif split_type == '2':
            # æ‰§è¡ŒKæŠ˜äº¤å‰éªŒè¯åˆ’åˆ†
            folds = create_project_wise_kfold_splits(
                df,
                project_column='project',
                category_column='category',
                n_folds=n_folds,
                min_samples_per_category=min_samples,
                random_seed=random_seed
            )
            
            # ä¿å­˜KæŠ˜æ•°æ®é›†
            output_dir = OUTPUT_DIR / 'kfold_splits'
            
            if format_choice in ['1', '3']:
                print("\nğŸ’¾ ä¿å­˜CSVæ ¼å¼...")
                save_kfold_datasets(folds, output_dir=output_dir, base_name='fold', format='csv')
            
            if format_choice in ['2', '3']:
                print("\nğŸ’¾ ä¿å­˜JSONæ ¼å¼...")
                save_kfold_datasets(folds, output_dir=output_dir, base_name='fold', format='json')
            
            print(f"\nâœ“ KæŠ˜äº¤å‰éªŒè¯æ•°æ®é›†åˆ’åˆ†å®Œæˆ!")
            print(f"  è¾“å‡ºç›®å½•: {output_dir}")
            print(f"  å…±ç”Ÿæˆ {n_folds} æŠ˜æ•°æ®")
            print(f"\nğŸ“ æ¯æŠ˜åŒ…å«:")
            print(f"  - fold_X_train.csv/json: è®­ç»ƒé›†")
            print(f"  - fold_X_test.csv/json: æµ‹è¯•é›†")
            print(f"  - fold_X_projects.txt: é¡¹ç›®åˆ—è¡¨")
        
    except ValueError as e:
        print(f"âœ— è¾“å…¥é”™è¯¯: {e}")
    except Exception as e:
        print(f"âœ— åˆ’åˆ†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


        traceback.print_exc()


def run_config_manager():
    """é…ç½®ç®¡ç†"""
    print("\n" + "=" * 60)
    print("é…ç½®ç®¡ç†")
    print("=" * 60)
    
    while True:
        saved_configs = list_saved_configs()
        
        if not saved_configs:
            print("\nğŸ“ å½“å‰æ²¡æœ‰ä¿å­˜çš„é…ç½®")
            print("\næç¤º: åœ¨æ•°æ®è’¸é¦æˆ–å…¶ä»–ä»»åŠ¡å®Œæˆé…ç½®åï¼Œå¯ä»¥é€‰æ‹©ä¿å­˜é…ç½®ä¾›ä¸‹æ¬¡ä½¿ç”¨")
            return
        
        print(f"\nğŸ’¾ å·²ä¿å­˜çš„é…ç½® (å…±{len(saved_configs)}ä¸ª):")
        for i, config_name in enumerate(saved_configs, 1):
            print(f"  {i}. {config_name}")
        
        print("\næ“ä½œ:")
        print("  v. æŸ¥çœ‹é…ç½®")
        print("  d. åˆ é™¤é…ç½®")
        print("  0. è¿”å›ä¸»èœå•")
        
        choice = input("\né€‰æ‹©æ“ä½œ: ").strip().lower()
        
        if choice == '0':
            break
        elif choice == 'v':
            idx_input = input("è¯·è¾“å…¥è¦æŸ¥çœ‹çš„é…ç½®ç¼–å·: ").strip()
            try:
                idx = int(idx_input) - 1
                if 0 <= idx < len(saved_configs):
                    config_name = saved_configs[idx]
                    config = load_config(config_name)
                    if config:
                        print(f"\nğŸ“„ é…ç½®: {config_name}")
                        display_config(config)
                else:
                    print("âœ— æ— æ•ˆçš„ç¼–å·")
            except ValueError:
                print("âœ— è¯·è¾“å…¥æ•°å­—")
        
        elif choice == 'd':
            idx_input = input("è¯·è¾“å…¥è¦åˆ é™¤çš„é…ç½®ç¼–å·: ").strip()
            try:
                idx = int(idx_input) - 1
                if 0 <= idx < len(saved_configs):
                    config_name = saved_configs[idx]
                    confirm = input(f"ç¡®è®¤åˆ é™¤é…ç½® '{config_name}'? (y/n): ").strip().lower()
                    if confirm == 'y':
                        delete_config(config_name)
                else:
                    print("âœ— æ— æ•ˆçš„ç¼–å·")
            except ValueError:
                print("âœ— è¯·è¾“å…¥æ•°å­—")
        
        else:
            print("âœ— æ— æ•ˆçš„æ“ä½œ")


def run_model_settings():
    """æ¨¡å‹è®¾ç½®"""
    print("\n" + "=" * 60)
    print("æ¨¡å‹è®¾ç½®")
    print("=" * 60)
    
    # æ˜¾ç¤ºå½“å‰é…ç½®
    provider, model, base_url, api_key_status, has_key = get_current_config()
    print(f"\nğŸ“Œ å½“å‰é…ç½®:")
    print(f"   æä¾›å•†: {provider}")
    print(f"   æ¨¡å‹: {model}")
    print(f"   API URL: {base_url}")
    print(f"   APIå¯†é’¥: {api_key_status}")
    
    print("\n" + "-" * 60)
    print("å¯ç”¨æ“ä½œ:")
    print("  1. åˆ‡æ¢æä¾›å•†")
    print("  2. æŸ¥çœ‹å½“å‰æä¾›å•†æ”¯æŒçš„æ¨¡å‹")
    print("  3. æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹")
    print("  0. è¿”å›ä¸»èœå•")
    print("-" * 60)
    
    choice = input("\nè¯·é€‰æ‹©æ“ä½œ: ").strip()
    
    if choice == '1':
        # åˆ‡æ¢æä¾›å•†
        providers = list_providers()
        print("\nğŸ“‹ å¯ç”¨æä¾›å•†:")
        for i, p in enumerate(providers, 1):
            print(f"  {i}. {p.upper()}")
        
        try:
            provider_idx = int(input(f"\nè¯·é€‰æ‹©æä¾›å•† (1-{len(providers)}): ").strip())
            
            if 1 <= provider_idx <= len(providers):
                new_provider = providers[provider_idx - 1]
                if switch_provider(new_provider):
                    print("âš ï¸  è¯·é‡å¯ç¨‹åºä»¥ä½¿æ›´æ”¹ç”Ÿæ•ˆ")
            else:
                print("âœ— æ— æ•ˆçš„é€‰æ‹©")
        except ValueError:
            print("âœ— è¯·è¾“å…¥æ•°å­—")
    
    elif choice == '2':
        # æŸ¥çœ‹å½“å‰æä¾›å•†æ”¯æŒçš„æ¨¡å‹
        models = get_supported_models()
        print(f"\nğŸ“‹ {provider.upper()} æ”¯æŒçš„æ¨¡å‹:")
        
        for i, model in enumerate(models, 1):
            print(f"  {i}. {model}")
        
        print("\nğŸ’¡ æç¤º: å¯ä»¥åœ¨åˆ›å»ºAgentæ—¶é€šè¿‡ model å‚æ•°ä½¿ç”¨æŒ‡å®šæ¨¡å‹")
        print(f"   ç¤ºä¾‹: DistillationAgent(model='{models[0] if models else 'model-name'}')")
    
    elif choice == '3':
        # æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹
        show_all_models()
    
    elif choice == '0':
        return
    else:
        print("âœ— æ— æ•ˆçš„æ“ä½œ")


def main():
    """ä¸»å‡½æ•°"""
    while True:
        print_menu()
        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (1-7): ").strip()
        
        if choice == '1':
            run_distillation()
        elif choice == '2':
            run_data_explainer()
        elif choice == '3':
            run_evaluation()
        elif choice == '4':
            run_dataset_split()
        elif choice == '5':
            run_config_manager()
        elif choice == '6':
            run_model_settings()
        elif choice == '7':
            print("\nğŸ‘‹ å†è§!")
            break
        else:
            print("\nâœ— æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡è¯•")
        
        input("\næŒ‰å›è½¦é”®ç»§ç»­...")


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºå·²ä¸­æ–­ï¼Œå†è§!")
    except Exception as e:
        print(f"\nâœ— å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
