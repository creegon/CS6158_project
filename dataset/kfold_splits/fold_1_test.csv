id,project,test_name,full_code,label,category
1,apache_hadoop,TestDelegationTokenRenewer.testAddRemoveRenewAction,"@Test
public void testAddRemoveRenewAction() throws IOException, InterruptedException {
    TestFileSystem tfs = new TestFileSystem();
    renewer.addRenewAction(tfs);
    for (int i = 0; i < 60; i++) {
        Thread.sleep(RENEW_CYCLE);
        if (tfs.testToken.renewCount > 0) {
            renewer.removeRenewAction(tfs);
            break;
        }
    }
    assertTrue(""Token not renewed even after 1 minute"", tfs.testToken.renewCount > 0);
    assertTrue(""Token not removed"", tfs.testToken.renewCount < MAX_RENEWALS);
    assertTrue(""Token not cancelled"", tfs.testToken.cancelled);
}",async wait,0
5,apache_hadoop,TestPathData.testToFile,"@Test
public void testToFile() throws Exception {
    item = new PathData(""."", conf);
    assertEquals(new File(testDir.toString()), item.toFile());
    item = new PathData(""d1/f1"", conf);
    assertEquals(new File(testDir + ""/d1/f1""), item.toFile());
    item = new PathData(testDir + ""/d1/f1"", conf);
    assertEquals(new File(testDir + ""/d1/f1""), item.toFile());
}",test order dependency,4
8,apache_hadoop,TestLocalDirAllocator.testRemoveContext,"@Test
public void testRemoveContext() throws IOException {
    String dir = buildBufferDir(ROOT, 0);
    String contextCfgItemName = ""application_1340842292563_0004.app.cache.dirs"";
    conf.set(contextCfgItemName, dir);
    LocalDirAllocator localDirAllocator = new LocalDirAllocator(contextCfgItemName);
    localDirAllocator.getLocalPathForWrite(""p1/x"", SMALL_FILE_SIZE, conf);
    assertTrue(LocalDirAllocator.isContextValid(contextCfgItemName));
    LocalDirAllocator.removeContext(contextCfgItemName);
    assertFalse(LocalDirAllocator.isContextValid(contextCfgItemName));
}",test order dependency,4
9,apache_hadoop,TestRMContainerAllocator.testSimple,"@Test
public void testSimple() throws Exception {
    Configuration conf = new Configuration();
    MyResourceManager rm = new MyResourceManager(conf);
    rm.start();
    DrainDispatcher dispatcher = ((DrainDispatcher) (rm.getRMContext().getDispatcher()));
    RMApp app = rm.submitApp(1024);
    dispatcher.await();
    MockNM amNodeManager = rm.registerNode(""amNM:1234"", 2048);
    amNodeManager.nodeHeartbeat(true);
    dispatcher.await();
    ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt().getAppAttemptId();
    rm.sendAMLaunched(appAttemptId);
    dispatcher.await();
    JobId jobId = MRBuilderUtils.newJobId(appAttemptId.getApplicationId(), 0);
    Job mockJob = mock(Job.class);
    when(mockJob.getReport()).thenReturn(MRBuilderUtils.newJobReport(jobId, ""job"", ""user"", RUNNING, 0, 0, 0, 0, 0, 0, ""jobfile""));
    MyContainerAllocator allocator = new MyContainerAllocator(rm, conf, appAttemptId, mockJob);
    MockNM nodeManager1 = rm.registerNode(""h1:1234"", 10240);
    MockNM nodeManager2 = rm.registerNode(""h2:1234"", 10240);
    MockNM nodeManager3 = rm.registerNode(""h3:1234"", 10240);
    dispatcher.await();
    ContainerRequestEvent event1 = createReq(jobId, 1, 1024, new String[]{ ""h1"" });
    allocator.sendRequest(event1);
    ContainerRequestEvent event2 = createReq(jobId, 2, 1024, new String[]{ ""h2"" });
    allocator.sendRequest(event2);
    List<TaskAttemptContainerAssignedEvent> assigned = allocator.schedule();
    dispatcher.await();
    Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size());
    ContainerRequestEvent event3 = createReq(jobId, 3, 1024, new String[]{ ""h3"" });
    allocator.sendRequest(event3);
    assigned = allocator.schedule();
    dispatcher.await();
    Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size());
    nodeManager1.nodeHeartbeat(true);
    nodeManager2.nodeHeartbeat(true);
    nodeManager3.nodeHeartbeat(true);
    dispatcher.await();
    assigned = allocator.schedule();
    dispatcher.await();
    checkAssignments(new ContainerRequestEvent[]{ event1, event2, event3 }, assigned, false);
}",async wait,0
25,apache_hadoop,TestDelegationToken.testDelegationTokenSecretManager,"@Test
public void testDelegationTokenSecretManager() throws Exception {
    DelegationTokenSecretManager dtSecretManager = cluster.getNameNode().getNamesystem().getDelegationTokenSecretManager();
    Token<DelegationTokenIdentifier> token = generateDelegationToken(""SomeUser"", ""JobTracker"");
    try {
        dtSecretManager.renewToken(token, ""FakeRenewer"");
        Assert.fail(""should have failed"");
    } catch (AccessControlException ace) {
    }
    dtSecretManager.renewToken(token, ""JobTracker"");
    DelegationTokenIdentifier identifier = new DelegationTokenIdentifier();
    byte[] tokenId = token.getIdentifier();
    identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId)));
    Assert.assertTrue(null != dtSecretManager.retrievePassword(identifier));
    LOG.info(""Sleep to expire the token"");
    Thread.sleep(6000);
    try {
        dtSecretManager.retrievePassword(identifier);
        Assert.fail(""Token should have expired"");
    } catch (InvalidToken e) {
    }
    dtSecretManager.renewToken(token, ""JobTracker"");
    LOG.info(""Sleep beyond the max lifetime"");
    Thread.sleep(5000);
    try {
        dtSecretManager.renewToken(token, ""JobTracker"");
        Assert.fail(""should have been expired"");
    } catch (InvalidToken it) {
    }
}",concurrency,1
28,apache_hadoop,TestDFSIO.testReadSkip,"@Test
public void testReadSkip() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.getConf().setLong(""test.io.skip.size"", 1);
    bench.randomReadTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_READ_SKIP, execTime);
}",test order dependency,4
38,apache_hadoop,TestDFSIO.testReadBackward,"@Test
public void testReadBackward() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.getConf().setLong(""test.io.skip.size"", -DEFAULT_BUFFER_SIZE);
    bench.randomReadTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_READ_BACKWARD, execTime);
}",test order dependency,4
40,apache_hadoop,TestDFSIO.testReadRandom,"@Test
public void testReadRandom() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.getConf().setLong(""test.io.skip.size"", 0);
    bench.randomReadTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_READ_RANDOM, execTime);
}",test order dependency,4
47,apache_hadoop,TestPeerCache.testEviction,"@Test
public void testEviction() throws Exception {
    final int CAPACITY = 3;
    PeerCache cache = PeerCache.getInstance(CAPACITY, 100000);
    DatanodeID dnIds[] = new DatanodeID[CAPACITY + 1];
    FakePeer peers[] = new FakePeer[CAPACITY + 1];
    for (int i = 0; i < dnIds.length; ++i) {
        dnIds[i] = new DatanodeID(""192.168.0.1"",
        ""fakehostname_"" + i, ""fake_storage_id_"" + i,
        100, 101, 102);
        peers[i] = new FakePeer(dnIds[i], false);
    }
    for (int i = 0; i < CAPACITY; ++i) {
        cache.put(dnIds[i], peers[i]);
    }
    assertEquals(CAPACITY, cache.size());
    cache.put(dnIds[CAPACITY], peers[CAPACITY]);
    assertEquals(CAPACITY, cache.size());
    assertSame(null, cache.get(dnIds[0], false));
    for (int i = 1; i < CAPACITY; ++i) {
        Peer peer = cache.get(dnIds[i], false);
        assertSame(peers[i], peer);
        assertTrue(!peer.isClosed());
        peer.close();
    }
    assertEquals(1, cache.size());
    cache.close();
}",test order dependency,4
51,apache_hadoop,TestHftpFileSystem.testHftpDefaultPorts,"@Test
public void testHftpDefaultPorts() throws IOException {
    resetFileSystem();
    Configuration conf = new Configuration();
    URI uri = URI.create();
    HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf)));
    assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, fs.getDefaultPort());
    assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getDefaultSecurePort());
    assertEquals(uri, fs.getUri());
    assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getCanonicalServiceName());
}",test order dependency,4
75,apache_hadoop,TestPathData.testUnqualifiedUriContents,"@Test
public void testUnqualifiedUriContents() throws Exception {
    dirString = ""d1"";
    item = new PathData(dirString, conf);
    PathData[] items = item.getDirectoryContents();
    assertEquals(sortedString(""d1/f1"", ""d1/f1.1"", ""d1/f2""), sortedString(items));
}",test order dependency,4
96,apache_hadoop,TestBlockFixer.testGeneratedBlock,"@Test
public void testGeneratedBlock() throws Exception {
    LOG.info(""Test testGeneratedBlock started."");
    long blockSize = 8192L;
    int stripeLength = 3;
    mySetup(stripeLength, -1);
    Path file1 = new Path(""/user/dhruba/raidtest/file1"");
    Path destPath = new Path(""/destraid/user/dhruba/raidtest"");
    long crc1 = TestRaidDfs.createTestFile(fileSys, file1, 1, 7, blockSize);
    long file1Len = fileSys.getFileStatus(file1).getLen();
    LOG.info(""Test testGeneratedBlock created test files"");
    Configuration localConf = new Configuration(conf);
    localConf.set(RAID_LOCATION_KEY, ""/destraid"");
    localConf.setInt(""raid.blockfix.interval"", 1000);
    localConf.setLong(""raid.blockfix.filespertask"", 2L);
    try {
        cnode = RaidNode.createRaidNode(null, localConf);
        TestRaidDfs.waitForFileRaided(LOG, fileSys, file1, destPath);
        cnode.stop();
        cnode.join();
        FileStatus srcStat = fileSys.getFileStatus(file1);
        DistributedFileSystem dfs = ((DistributedFileSystem) (fileSys));
        LocatedBlocks locs = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, srcStat.getLen());
        String[] corruptFiles = RaidDFSUtil.getCorruptFiles(conf);
        assertEquals(corruptFiles.length, 0);
        assertEquals(0, cnode.blockFixer.filesFixed());
        corruptBlock(locs.get(0).getBlock().getBlockName());
        reportCorruptBlocks(dfs, file1, new int[]{ 0 }, blockSize);
        corruptFiles = RaidDFSUtil.getCorruptFiles(conf);
        assertEquals(corruptFiles.length, 1);
        assertEquals(corruptFiles[0], file1.toUri().getPath());
        cnode = RaidNode.createRaidNode(null, localConf);
        long start = System.currentTimeMillis();
        while ((cnode.blockFixer.filesFixed() < 1) && ((System.currentTimeMillis() - start) < 120000)) {
            LOG.info(""Test testGeneratedBlock waiting for files to be fixed."");
            Thread.sleep(1000);
        }
        assertEquals(1, cnode.blockFixer.filesFixed());
        cnode.stop();
        cnode.join();
        cnode = null;
        dfs = getDFS(conf, dfs);
        assertTrue(TestRaidDfs.validateFile(dfs, file1, file1Len, crc1));
        locs = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, srcStat.getLen());
        corruptBlock(locs.get(0).getBlock().getBlockName());
        reportCorruptBlocks(dfs, file1, new int[]{ 0 }, blockSize);
        try {
            Thread.sleep(5 * 1000);
        } catch (InterruptedException ignore) {
        }
        try {
            TestRaidDfs.validateFile(dfs, file1, file1Len, crc1);
            fail(""Expected exception not thrown"");
        } catch (ChecksumException ce) {
        } catch (BlockMissingException bme) {
        }
    } catch (Exception e) {
        LOG.info((""Test testGeneratedBlock Exception "" + e) + StringUtils.stringifyException(e));
        throw e;
    } finally {
        myTearDown();
    }
    LOG.info(""Test testGeneratedBlock completed."");
}",concurrency,1
105,apache_hadoop,TestRPCCompatibility.testVersion2ClientVersion2Server,"@Test
public void testVersion2ClientVersion2Server() throws Exception {
    ProtocolSignature.resetCache();
    TestImpl2 impl = new TestImpl2();
    server = new RPC.Builder(conf).setProtocol(TestProtocol2.class).setInstance(impl).setBindAddress(ADDRESS).setPort(0).setNumHandlers(2).setVerbose(false).build();
    server.addProtocol(RPC_WRITABLE, TestProtocol0.class, impl);
    server.start();
    addr = NetUtils.getConnectAddress(server);
    Version2Client client = new Version2Client();
    client.ping();
    assertEquals(""hello"", client.echo(""hello""));
    assertEquals(-3, client.echo(3));
}",test order dependency,4
107,apache_hadoop,TestDelegationTokenForProxyUser.testDelegationTokenWithRealUser,"@Test
public void testDelegationTokenWithRealUser() throws IOException {
    UserGroupInformation ugi = UserGroupInformation.createRemoteUser(REAL_USER);
    final UserGroupInformation proxyUgi = UserGroupInformation.createProxyUserForTesting(PROXY_USER, ugi, GROUP_NAMES);
    try {
        Token<?>[] tokens = proxyUgi.doAs(new PrivilegedExceptionAction<Token<?>[]>() {
            @Override
            public Token<?>[] run() throws IOException {
                return cluster.getFileSystem().addDelegationTokens(""RenewerUser"", null);
            }
        });
        DelegationTokenIdentifier identifier = new DelegationTokenIdentifier();
        byte[] tokenId = tokens[0].getIdentifier();
        identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId)));
        Assert.assertEquals(identifier.getUser().getUserName(), PROXY_USER);
        Assert.assertEquals(identifier.getUser().getRealUser().getUserName(), REAL_USER);
    } catch (InterruptedException e) {
    }
}",test order dependency,4
111,apache_hadoop,TestPathData.testWithStringAndConfForBuggyPath,"@Test
public void testWithStringAndConfForBuggyPath() throws Exception {
    dirString = ""file"" ;
    testDir = new Path(dirString);
    item = new PathData(dirString, conf);
    assertEquals(""file:/tmp"", testDir.toString());
    checkPathData();
}",test order dependency,4
120,apache_hadoop,TestModTime.testModTime,"@Test
public void testModTime() throws IOException {
    Configuration conf = new Configuration();
    MiniDFSCluster cluster = new MiniDFSCluster(conf, numDatanodes, true, null);
    cluster.waitActive();
    InetSocketAddress addr = new InetSocketAddress(""localhost"", cluster.getNameNodePort());
    DFSClient client = new DFSClient(addr, conf);
    DatanodeInfo[] info = client.datanodeReport(LIVE);
    assertEquals(""Number of Datanodes "", numDatanodes, info.length);
    FileSystem fileSys = cluster.getFileSystem();
    int replicas = numDatanodes - 1;
    assertTrue(fileSys instanceof DistributedFileSystem);
    try {
        System.out.println(""Creating testdir1 and testdir1/test1.dat."");
        Path dir1 = new Path(""testdir1"");
        Path file1 = new Path(dir1, ""test1.dat"");
        writeFile(fileSys, file1, replicas);
        FileStatus stat = fileSys.getFileStatus(file1);
        long mtime1 = stat.getModificationTime();
        assertTrue(mtime1 != 0);
        stat = fileSys.getFileStatus(dir1);
        long mdir1 = stat.getModificationTime();
        System.out.println(""Creating testdir1/test2.dat."");
        Path file2 = new Path(dir1, ""test2.dat"");
        writeFile(fileSys, file2, replicas);
        stat = fileSys.getFileStatus(file2);
        stat = fileSys.getFileStatus(dir1);
        assertTrue(stat.getModificationTime() >= mdir1);
        mdir1 = stat.getModificationTime();
        Path dir2 = new Path(""testdir2/"").makeQualified(fileSys);
        System.out.println(""Creating testdir2 "" + dir2);
        assertTrue(fileSys.mkdirs(dir2));
        stat = fileSys.getFileStatus(dir2);
        long mdir2 = stat.getModificationTime();
        Path newfile = new Path(dir2, ""testnew.dat"");
        System.out.println(((""Moving "" + file1) + "" to "") + newfile);
        fileSys.rename(file1, newfile);
        stat = fileSys.getFileStatus(newfile);
        assertTrue(stat.getModificationTime() == mtime1);
        stat = fileSys.getFileStatus(dir1);
        assertTrue(stat.getModificationTime() != mdir1);
        mdir1 = stat.getModificationTime();
        stat = fileSys.getFileStatus(dir2);
        assertTrue(stat.getModificationTime() != mdir2);
        mdir2 = stat.getModificationTime();
        System.out.println(""Deleting testdir2/testnew.dat."");
        assertTrue(fileSys.delete(newfile, true));
        stat = fileSys.getFileStatus(dir1);
        assertTrue(stat.getModificationTime() == mdir1);
        stat = fileSys.getFileStatus(dir2);
        assertTrue(stat.getModificationTime() != mdir2);
        mdir2 = stat.getModificationTime();
        cleanupFile(fileSys, file2);
        cleanupFile(fileSys, dir1);
        cleanupFile(fileSys, dir2);
    } catch (IOException e) {
        info = client.datanodeReport(ALL);
        printDatanodeReport(info);
        throw e;
    } finally {
        fileSys.close();
        cluster.shutdown();
    }
}",time,2
129,apache_hadoop,TestPathData.testWithDirStringAndConf,"@Test
public void testWithDirStringAndConf() throws Exception {
    dirString = ""d1"";
    item = new PathData(dirString, conf);
    checkPathData();
    dirString = ""d1/"";
    item = new PathData(dirString, conf);
    checkPathData();
}",test order dependency,4
135,apache_hadoop,testPendingAndInvalidate,"@Test
public class Test {
    public void testPendingAndInvalidate() throws Exception {
        final Configuration CONF = new HdfsConfiguration();
        MiniDFSCluster cluster = new MiniDFSCluster.Builder(CONF).numDataNodes(DATANODE_COUNT).build();
        cluster.waitActive();
        FSNamesystem namesystem = cluster.getNamesystem();
        BlockManager bm = namesystem.getBlockManager();
        DistributedFileSystem fs = cluster.getFileSystem();
        try {
            Path filePath = new Path(""/tmp.txt"");
            DFSTestUtil.createFile(fs, filePath, 1024, (short) 3, 0L);
            for (DataNode dn : cluster.getDataNodes()) {
                DataNodeTestUtils.setHeartbeatsDisabledForTests(dn, true);
            }
            LocatedBlock block = NameNodeAdapter.getBlockLocations(
            cluster.getNameNode(), filePath.toString(), 0, 1).get(0);
            cluster.getNamesystem().writeLock();
            try {
                bm.findAndMarkBlockAsCorrupt(block.getBlock(), block.getLocations()[0],
                ""STORAGE_ID"", ""TEST"");
            } finally {
                cluster.getNamesystem().writeUnlock();
            }
            BlockManagerTestUtil.computeAllPendingWork(bm);
            BlockManagerTestUtil.updateState(bm);
            assertEquals(bm.getPendingReconstructionBlocksCount(), 1L);
            BlockInfo storedBlock = bm.getStoredBlock(block.getBlock().getLocalBlock());
            assertEquals(bm.pendingReconstruction.getNumReplicas(storedBlock), 2);
            fs.delete(filePath, true);
            int retries = 10;
            long pendingNum = bm.getPendingReconstructionBlocksCount();
            while (pendingNum != 0 && retries-- > 0) {
                Thread.sleep(1000);
                BlockManagerTestUtil.updateState(bm);
                pendingNum = bm.getPendingReconstructionBlocksCount();
            }
            assertEquals(pendingNum, 0L);
        } finally {
            cluster.shutdown();
        }
    }
}",concurrency,1
173,apache_hadoop,TestPathData.testQualifiedUriContents,"@Test
public void testQualifiedUriContents() throws Exception {
    dirString = fs.makeQualified(new Path(""d1"")).toString();
    item = new PathData(dirString, conf);
    PathData[] items = item.getDirectoryContents();
    assertEquals(sortedString(dirString + ""/f1"", dirString + ""/f1.1"", dirString + ""/f2""), sortedString(items));
}",test order dependency,4
198,apache_hadoop,TestPathData.testCwdContents,"@Test
public void testCwdContents() throws Exception {
    dirString = Path.CUR_DIR;
    item = new PathData(dirString, conf);
    PathData[] items = item.getDirectoryContents();
    assertEquals(sortedString(""d1"", ""d2""), sortedString(items));
}",test order dependency,4
209,apache_hadoop,TestHftpFileSystem.testHftpCustomDefaultPorts,"@Test
public void testHftpCustomDefaultPorts() throws IOException {
    resetFileSystem();
    Configuration conf = new Configuration();
    conf.setInt(""dfs.http.port"", 123);
    conf.setInt(""dfs.https.port"", 456);
    URI uri = URI.create();
    HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf)));
    assertEquals(123, fs.getDefaultPort());
    assertEquals(456, fs.getDefaultSecurePort());
    assertEquals(uri, fs.getUri());
    assertEquals(""127.0.0.1:456"", fs.getCanonicalServiceName());
}",test order dependency,4
247,apache_hadoop,TestSecurityUtil.testBuildDTServiceName,"@Test
public void testBuildDTServiceName() {
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
}",test order dependency,4
251,apache_hadoop,TestUnderReplicatedBlocks.testSetrepIncWithUnderReplicatedBlocks,"@Test
public void testSetrepIncWithUnderReplicatedBlocks() throws Exception {
    Configuration conf = new HdfsConfiguration();
    final short REPLICATION_FACTOR = 2;
    final String FILE_NAME = ""/testFile"";
    final Path FILE_PATH = new Path(FILE_NAME);
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(REPLICATION_FACTOR + 1).build();
    try {
        final FileSystem fs = cluster.getFileSystem();
        DFSTestUtil.createFile(fs, FILE_PATH, 1L, REPLICATION_FACTOR, 1L);
        DFSTestUtil.waitReplication(fs, FILE_PATH, REPLICATION_FACTOR);
        final BlockManager bm = cluster.getNamesystem().getBlockManager();
        ExtendedBlock b = DFSTestUtil.getFirstBlock(fs, FILE_PATH);
        DatanodeDescriptor dn = bm.blocksMap.nodeIterator(b.getLocalBlock()).next();
        bm.addToInvalidates(b.getLocalBlock(), dn);
        bm.blocksMap.removeNode(b.getLocalBlock(), dn);
        FsShell shell = new FsShell(conf);
        assertEquals(0, shell.run(new String[]{ ""-setrep"", ""-w"", Integer.toString(1 + REPLICATION_FACTOR), FILE_NAME }));
    } finally {
        cluster.shutdown();
    }
}",async wait,0
256,apache_hadoop,TestDelegationTokenForProxyUser.testWebHdfsDoAs,"@Test
public void testWebHdfsDoAs() throws Exception {
    LOG.info(""START: testWebHdfsDoAs()"");
    ((Log4JLogger) (LOG)).getLogger().setLevel(ALL);
    ((Log4JLogger) (LOG)).getLogger().setLevel(ALL);
    final UserGroupInformation ugi = UserGroupInformation.createRemoteUser(REAL_USER);
    LOG.info(""ugi.getShortUserName()="" + ugi.getShortUserName());
    final WebHdfsFileSystem webhdfs = WebHdfsTestUtil.getWebHdfsFileSystemAs(ugi, config);
    final Path root = new Path(""/"");
    cluster.getFileSystem().setPermission(root, new FsPermission(((short) (0777))));
    {
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, GETHOMEDIRECTORY, root, new DoAsParam(PROXY_USER));
        final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK);
        conn.disconnect();
        final Object responsePath = m.get(Path.class.getSimpleName());
        LOG.info(""responsePath="" + responsePath);
        Assert.assertEquals(""/user/"" + PROXY_USER, responsePath);
    }
    {
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, GETHOMEDIRECTORY, root, new DoAsParam(PROXY_USER) {
            @Override
            public String getName() {
                return ""DOas"";
            }
        });
        final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK);
        conn.disconnect();
        final Object responsePath = m.get(Path.class.getSimpleName());
        LOG.info(""responsePath="" + responsePath);
        Assert.assertEquals(""/user/"" + PROXY_USER, responsePath);
    }
    final Path f = new Path(""/testWebHdfsDoAs/a.txt"");
    {
        final PutOpParam.Op op = Op.CREATE;
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, op, f, new DoAsParam(PROXY_USER));
        HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        conn = WebHdfsTestUtil.twoStepWrite(webhdfs, op, conn);
        final FSDataOutputStream out = WebHdfsTestUtil.write(webhdfs, op, conn, 4096);
        out.write(""Hello, webhdfs user!"".getBytes());
        out.close();
        final FileStatus status = webhdfs.getFileStatus(f);
        LOG.info(""status.getOwner()="" + status.getOwner());
        Assert.assertEquals(PROXY_USER, status.getOwner());
    }
    {
        final PostOpParam.Op op = Op.APPEND;
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, op, f, new DoAsParam(PROXY_USER));
        HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        conn = WebHdfsTestUtil.twoStepWrite(webhdfs, op, conn);
        final FSDataOutputStream out = WebHdfsTestUtil.write(webhdfs, op, conn, 4096);
        out.write(""\nHello again!"".getBytes());
        out.close();
        final FileStatus status = webhdfs.getFileStatus(f);
        LOG.info(""status.getOwner()="" + status.getOwner());
        LOG.info(""status.getLen()  ="" + status.getLen());
        Assert.assertEquals(PROXY_USER, status.getOwner());
    }
}",test order dependency,4
258,apache_hadoop,TestMetricsSystemImpl.testInitFirstVerifyCallBacks,"@Test
public void testInitFirstVerifyCallBacks() throws Exception {
    DefaultMetricsSystem.shutdown();
    new ConfigBuilder().add(""*.period"", 8).add(""test.sink.test.class"", TestSink.class.getName()).add(""test.*.source.filter.exclude"", ""s0"").add(""test.source.s1.metric.filter.exclude"", ""X*"").add(""test.sink.sink1.metric.filter.exclude"", ""Y*"").add(""test.sink.sink2.metric.filter.exclude"", ""Y*"").save(TestMetricsConfig.getTestFilename(""hadoop-metrics2-test""));
    MetricsSystemImpl ms = new MetricsSystemImpl(""Test"");
    ms.start();
    ms.register(""s0"", ""s0 desc"", new TestSource(""s0rec""));
    TestSource s1 = ms.register(""s1"", ""s1 desc"", new TestSource(""s1rec""));
    s1.c1.incr();
    s1.xxx.incr();
    s1.g1.set(2);
    s1.yyy.incr(2);
    s1.s1.add(0);
    MetricsSink sink1 = mock(MetricsSink.class);
    MetricsSink sink2 = mock(MetricsSink.class);
    ms.registerSink(""sink1"", ""sink1 desc"", sink1);
    ms.registerSink(""sink2"", ""sink2 desc"", sink2);
    ms.publishMetricsNow();
    try {
        verify(sink1, timeout(200).times(2)).putMetrics(r1.capture());
        verify(sink2, timeout(200).times(2)).putMetrics(r2.capture());
    } finally {
        ms.stop();
        ms.shutdown();
    }
    List<MetricsRecord> mr1 = r1.getAllValues();
    List<MetricsRecord> mr2 = r2.getAllValues();
    checkMetricsRecords(mr1);
    assertEquals(""output"", mr1, mr2);
}",unordered collections,3
301,apache_hadoop,TestFairScheduler.testContinuousScheduling,"@Test
public void testContinuousScheduling() throws Exception {
    FairScheduler fs = new FairScheduler();
    Configuration conf = createConfiguration();
    conf.setBoolean(CONTINUOUS_SCHEDULING_ENABLED, true);
    fs.reinitialize(conf, resourceManager.getRMContext());
    Assert.assertTrue(""Continuous scheduling should be enabled."", fs.isContinuousSchedulingEnabled());
    RMNode node1 = MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1, ""127.0.0.1"");
    NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
    fs.handle(nodeEvent1);
    Assert.assertEquals(fs.getClusterCapacity().getMemory(), 8 * 1024);
    Assert.assertEquals(fs.getClusterCapacity().getVirtualCores(), 8);
    ApplicationAttemptId appAttemptId = createAppAttemptId(this.APP_ID++, this.ATTEMPT_ID++);
    fs.addApplication(appAttemptId, ""queue11"", ""user11"");
    List<ResourceRequest> ask = new ArrayList<ResourceRequest>();
    ResourceRequest request = createResourceRequest(1024, 1, ANY, 1, 1, true);
    ask.add(request);
    fs.allocate(appAttemptId, ask, new ArrayList<ContainerId>(), null, null);
    Thread.sleep(fs.getConf().getContinuousSchedulingSleepMs() + 500);
    Resource consumption = fs.applications.get(appAttemptId).getCurrentConsumption();
    Assert.assertEquals(1024, consumption.getMemory());
    Assert.assertEquals(1, consumption.getVirtualCores());
}",async wait,0
314,apache_hadoop,TestWritableName.testSetName,"@Test
public void testSetName() throws Exception {
    Configuration conf = new Configuration();
    WritableName.setName(SimpleWritable.class, testName);
    Class<?> test = WritableName.getClass(testName, conf);
    assertTrue(test.equals(SimpleWritable.class));
}",test order dependency,4
321,apache_hadoop,TestPeerCache.testAddAndRetrieve,"@Test
public void testAddAndRetrieve() throws Exception {
    PeerCache cache = PeerCache.getInstance(3, 100000);
    DatanodeID dnId = new DatanodeID(""192.168.0.1"",
    ""fakehostname"", ""fake_storage_id"",
    100, 101, 102);
    FakePeer peer = new FakePeer(dnId, false);
    cache.put(dnId, peer);
    assertTrue(!peer.isClosed());
    assertEquals(1, cache.size());
    assertEquals(peer, cache.get(dnId, false));
    assertEquals(0, cache.size());
    cache.close();
}",test order dependency,4
327,apache_hadoop,TestDFSIO.testRead,"@Test
public void testRead() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.readTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_READ, execTime);
}",test order dependency,4
338,apache_hadoop,TestHftpFileSystem.testHftpCustomUriPortWithDefaultPorts,"@Test
public void testHftpCustomUriPortWithDefaultPorts() throws IOException {
    resetFileSystem();
    Configuration conf = new Configuration();
    URI uri = URI.create() ;
    HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf)));
    assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, fs.getDefaultPort());
    assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getDefaultSecurePort());
    assertEquals(uri, fs.getUri());
    assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getCanonicalServiceName());
}",test order dependency,4
360,apache_hadoop,TestPeerCache.testExpiry,"@Test
public void testExpiry() throws Exception {
    final int CAPACITY = 3;
    final int EXPIRY_PERIOD = 10;
    PeerCache cache = PeerCache.getInstance(CAPACITY, EXPIRY_PERIOD);
    DatanodeID dnIds[] = new DatanodeID[CAPACITY];
    FakePeer peers[] = new FakePeer[CAPACITY];
    for (int i = 0; i < CAPACITY; ++i) {
        dnIds[i] = new DatanodeID(""192.168.0.1"",
        ""fakehostname_"" + i, ""fake_storage_id"",
        100, 101, 102);
        peers[i] = new FakePeer(dnIds[i], false);
    }
    for (int i = 0; i < CAPACITY; ++i) {
        cache.put(dnIds[i], peers[i]);
    }
    Thread.sleep(EXPIRY_PERIOD * 50);
    assertEquals(0, cache.size());
    for (int i = 0; i < CAPACITY; ++i) {
        assertTrue(peers[i].isClosed());
    }
    Thread.sleep(EXPIRY_PERIOD * 50);
    cache.close();
}",test order dependency,4
367,apache_hadoop,TestSecurityUtil.testBuildTokenServiceSockAddr,"@Test
public void testBuildTokenServiceSockAddr() {
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""LocalHost"", 123)).toString());
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""127.0.0.1"", 123)).toString());
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(NetUtils.createSocketAddr(""127.0.0.1"", 123)).toString());
}",test order dependency,4
368,apache_hadoop,TestDFSIO.testWrite,"@Test
public void testWrite() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.writeTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_WRITE, execTime);
}",test order dependency,4
281,apache_hadoop,TestOffsetRange.testConstructor1,"  @Test(expected = IllegalArgumentException.class)
  public void testConstructor1() throws IOException {
    new OffsetRange(0, 0);
  }
",non-flaky,5
282,apache_hadoop,TestOffsetRange.testConstructor2,"  @Test(expected = IllegalArgumentException.class)
  public void testConstructor2() throws IOException {
    new OffsetRange(-1, 0);
  }
",non-flaky,5
283,apache_hadoop,TestOffsetRange.testConstructor3,"  @Test(expected = IllegalArgumentException.class)
  public void testConstructor3() throws IOException {
    new OffsetRange(-3, -1);
  }
",non-flaky,5
284,apache_hadoop,TestOffsetRange.testConstructor4,"  @Test(expected = IllegalArgumentException.class)
  public void testConstructor4() throws IOException {
    new OffsetRange(-3, 100);
  }
",non-flaky,5
285,apache_hadoop,TestOffsetRange.testCompare,"  @Test
  public void testCompare() throws IOException {
    OffsetRange r1 = new OffsetRange(0, 1);
    OffsetRange r2 = new OffsetRange(1, 3);
    OffsetRange r3 = new OffsetRange(1, 3);
    OffsetRange r4 = new OffsetRange(3, 4);

    assertEquals(0, OffsetRange.ReverseComparatorOnMin.compare(r2, r3));
    assertEquals(0, OffsetRange.ReverseComparatorOnMin.compare(r2, r2));
    assertTrue(OffsetRange.ReverseComparatorOnMin.compare(r2, r1) < 0);
    assertTrue(OffsetRange.ReverseComparatorOnMin.compare(r2, r4) > 0);
  }
",non-flaky,5
286,apache_hadoop,TestReaddir.testReaddirBasic,"  @Test
  public void testReaddirBasic() throws IOException {
    // Get inodeId of /tmp
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);

    // Create related part of the XDR request
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeLongAsHyper(0); // cookie
    xdr_req.writeLongAsHyper(0); // verifier
    xdr_req.writeInt(100); // count

    READDIR3Response response = nfsd.readdir(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    List<Entry3> dirents = response.getDirList().getEntries();
    assertTrue(dirents.size() == 5); // inculding dot, dotdot

    // Test start listing from f2
    status = nn.getRpcServer().getFileInfo(testdir + ""/f2"");
    long f2Id = status.getFileId();

    // Create related part of the XDR request
    xdr_req = new XDR();
    handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeLongAsHyper(f2Id); // cookie
    xdr_req.writeLongAsHyper(0); // verifier
    xdr_req.writeInt(100); // count

    response = nfsd.readdir(xdr_req.asReadOnlyWrap(), securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    dirents = response.getDirList().getEntries();
    assertTrue(dirents.size() == 1);
    Entry3 entry = dirents.get(0);
    assertTrue(entry.getName().equals(""f3""));

    // When the cookie is deleted, list starts over no including dot, dotdot
    hdfs.delete(new Path(testdir + ""/f2""), false);

    response = nfsd.readdir(xdr_req.asReadOnlyWrap(), securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    dirents = response.getDirList().getEntries();
    assertTrue(dirents.size() == 2); // No dot, dotdot
  }
",non-flaky,5
287,apache_hadoop,TestReaddir.testReaddirPlus,"  @Test
  public void testReaddirPlus() throws IOException {
    // Get inodeId of /tmp
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    
    // Create related part of the XDR request
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeLongAsHyper(0); // cookie
    xdr_req.writeLongAsHyper(0); // verifier
    xdr_req.writeInt(100); // dirCount
    xdr_req.writeInt(1000); // maxCount

    READDIRPLUS3Response responsePlus = nfsd.readdirplus(xdr_req
        .asReadOnlyWrap(), securityHandler, new InetSocketAddress(""localhost"",
        1234));
    List<EntryPlus3> direntPlus = responsePlus.getDirListPlus().getEntries();
    assertTrue(direntPlus.size() == 5); // including dot, dotdot

    // Test start listing from f2
    status = nn.getRpcServer().getFileInfo(testdir + ""/f2"");
    long f2Id = status.getFileId();

    // Create related part of the XDR request
    xdr_req = new XDR();
    handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeLongAsHyper(f2Id); // cookie
    xdr_req.writeLongAsHyper(0); // verifier
    xdr_req.writeInt(100); // dirCount
    xdr_req.writeInt(1000); // maxCount

    responsePlus = nfsd.readdirplus(xdr_req.asReadOnlyWrap(), securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    direntPlus = responsePlus.getDirListPlus().getEntries();
    assertTrue(direntPlus.size() == 1);
    EntryPlus3 entryPlus = direntPlus.get(0);
    assertTrue(entryPlus.getName().equals(""f3""));

    // When the cookie is deleted, list starts over no including dot, dotdot
    hdfs.delete(new Path(testdir + ""/f2""), false);

    responsePlus = nfsd.readdirplus(xdr_req.asReadOnlyWrap(), securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    direntPlus = responsePlus.getDirListPlus().getEntries();
    assertTrue(direntPlus.size() == 2); // No dot, dotdot
  }
",non-flaky,5
288,apache_hadoop,TestWrites.testAlterWriteRequest,"  @Test
  public void testAlterWriteRequest() throws IOException {
    int len = 20;
    byte[] data = new byte[len];
    ByteBuffer buffer = ByteBuffer.wrap(data);

    for (int i = 0; i < len; i++) {
      buffer.put((byte) i);
    }
    buffer.flip();
    int originalCount = buffer.array().length;
    WRITE3Request request = new WRITE3Request(new FileHandle(), 0, data.length,
        WriteStableHow.UNSTABLE, buffer);

    WriteCtx writeCtx1 = new WriteCtx(request.getHandle(), request.getOffset(),
        request.getCount(), WriteCtx.INVALID_ORIGINAL_COUNT,
        request.getStableHow(), request.getData(), null, 1, false,
        WriteCtx.DataState.NO_DUMP);

    Assert.assertTrue(writeCtx1.getData().array().length == originalCount);

    // Now change the write request
    OpenFileCtx.alterWriteRequest(request, 12);

    WriteCtx writeCtx2 = new WriteCtx(request.getHandle(), request.getOffset(),
        request.getCount(), originalCount, request.getStableHow(),
        request.getData(), null, 2, false, WriteCtx.DataState.NO_DUMP);
    ByteBuffer appendedData = writeCtx2.getData();

    int position = appendedData.position();
    int limit = appendedData.limit();
    Assert.assertTrue(position == 12);
    Assert.assertTrue(limit - position == 8);
    Assert.assertTrue(appendedData.get(position) == (byte) 12);
    Assert.assertTrue(appendedData.get(position + 1) == (byte) 13);
    Assert.assertTrue(appendedData.get(position + 2) == (byte) 14);
    Assert.assertTrue(appendedData.get(position + 7) == (byte) 19);

    // Test current file write offset is at boundaries
    buffer.position(0);
    request = new WRITE3Request(new FileHandle(), 0, data.length,
        WriteStableHow.UNSTABLE, buffer);
    OpenFileCtx.alterWriteRequest(request, 1);
    WriteCtx writeCtx3 = new WriteCtx(request.getHandle(), request.getOffset(),
        request.getCount(), originalCount, request.getStableHow(),
        request.getData(), null, 2, false, WriteCtx.DataState.NO_DUMP);
    appendedData = writeCtx3.getData();
    position = appendedData.position();
    limit = appendedData.limit();
    Assert.assertTrue(position == 1);
    Assert.assertTrue(limit - position == 19);
    Assert.assertTrue(appendedData.get(position) == (byte) 1);
    Assert.assertTrue(appendedData.get(position + 18) == (byte) 19);

    // Reset buffer position before test another boundary
    buffer.position(0);
    request = new WRITE3Request(new FileHandle(), 0, data.length,
        WriteStableHow.UNSTABLE, buffer);
    OpenFileCtx.alterWriteRequest(request, 19);
    WriteCtx writeCtx4 = new WriteCtx(request.getHandle(), request.getOffset(),
        request.getCount(), originalCount, request.getStableHow(),
        request.getData(), null, 2, false, WriteCtx.DataState.NO_DUMP);
    appendedData = writeCtx4.getData();
    position = appendedData.position();
    limit = appendedData.limit();
    Assert.assertTrue(position == 19);
    Assert.assertTrue(limit - position == 1);
    Assert.assertTrue(appendedData.get(position) == (byte) 19);
  }
",non-flaky,5
289,apache_hadoop,TestWrites.testCheckCommit,"  @Test
  public void testCheckCommit() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);

    NfsConfiguration conf = new NfsConfiguration();
    conf.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, false);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(conf), false, conf);

    COMMIT_STATUS ret;

    // Test inactive open file context
    ctx.setActiveStatusForTest(false);
    Channel ch = Mockito.mock(Channel.class);
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_INACTIVE_CTX);

    ctx.getPendingWritesForTest().put(new OffsetRange(5, 10),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_INACTIVE_WITH_PENDING_WRITE);

    // Test request with non zero commit offset
    ctx.setActiveStatusForTest(true);
    Mockito.when(fos.getPos()).thenReturn((long) 10);
    ctx.setNextOffsetForTest(10);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
    // Do_SYNC state will be updated to FINISHED after data sync
    ret = ctx.checkCommit(dfsClient, 5, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);
    
    status = ctx.checkCommitInternal(10, ch, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
    ret = ctx.checkCommit(dfsClient, 10, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);

    ConcurrentNavigableMap<Long, CommitCtx> commits = ctx
        .getPendingCommitsForTest();
    Assert.assertTrue(commits.size() == 0);
    ret = ctx.checkCommit(dfsClient, 11, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_WAIT);
    Assert.assertTrue(commits.size() == 1);
    long key = commits.firstKey();
    Assert.assertTrue(key == 11);

    // Test request with zero commit offset
    commits.remove(new Long(11));
    // There is one pending write [5,10]
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_WAIT);
    Assert.assertTrue(commits.size() == 1);
    key = commits.firstKey();
    Assert.assertTrue(key == 9);

    // Empty pending writes
    ctx.getPendingWritesForTest().remove(new OffsetRange(5, 10));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);
  }
",non-flaky,5
290,apache_hadoop,TestWrites.testCheckCommitLargeFileUpload,"  @Test
  public void testCheckCommitLargeFileUpload() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);

    NfsConfiguration conf = new NfsConfiguration();
    conf.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, true);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(conf), false, conf);

    COMMIT_STATUS ret;

    // Test inactive open file context
    ctx.setActiveStatusForTest(false);
    Channel ch = Mockito.mock(Channel.class);
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_INACTIVE_CTX);

    ctx.getPendingWritesForTest().put(new OffsetRange(10, 15),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_INACTIVE_WITH_PENDING_WRITE);

    // Test request with non zero commit offset
    ctx.setActiveStatusForTest(true);
    Mockito.when(fos.getPos()).thenReturn((long) 8);
    ctx.setNextOffsetForTest(10);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
    // Do_SYNC state will be updated to FINISHED after data sync
    ret = ctx.checkCommit(dfsClient, 5, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);
    
    // Test commit sequential writes
    status = ctx.checkCommitInternal(10, ch, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    ret = ctx.checkCommit(dfsClient, 10, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);

    // Test commit non-sequential writes
    ConcurrentNavigableMap<Long, CommitCtx> commits = ctx
        .getPendingCommitsForTest();
    Assert.assertTrue(commits.size() == 1);
    ret = ctx.checkCommit(dfsClient, 16, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_SUCCESS);
    Assert.assertTrue(commits.size() == 1);
    
    // Test request with zero commit offset
    commits.remove(new Long(10));
    // There is one pending write [10,15]
    ret = ctx.checkCommitInternal(0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    
    ret = ctx.checkCommitInternal(9, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    Assert.assertTrue(commits.size() == 2);

    // Empty pending writes. nextOffset=10, flushed pos=8
    ctx.getPendingWritesForTest().remove(new OffsetRange(10, 15));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    
    // Empty pending writes
    ctx.setNextOffsetForTest((long) 8); // flushed pos = 8
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);
    
  }
",non-flaky,5
291,apache_hadoop,TestWrites.testCheckCommitAixCompatMode,"  @Test
  public void testCheckCommitAixCompatMode() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);

    NfsConfiguration conf = new NfsConfiguration();
    conf.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, false);
    // Enable AIX compatibility mode.
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(new NfsConfiguration()), true, conf);
    
    // Test fall-through to pendingWrites check in the event that commitOffset
    // is greater than the number of bytes we've so far flushed.
    Mockito.when(fos.getPos()).thenReturn((long) 2);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_FINISHED);
    
    // Test the case when we actually have received more bytes than we're trying
    // to commit.
    ctx.getPendingWritesForTest().put(new OffsetRange(0, 10),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    Mockito.when(fos.getPos()).thenReturn((long) 10);
    ctx.setNextOffsetForTest((long)10);
    status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
  }
",non-flaky,5
292,apache_hadoop,TestWrites.testCheckCommitFromRead,"  @Test
  public void testCheckCommitFromRead() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);
    NfsConfiguration config = new NfsConfiguration();

    config.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, false);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(config), false, config);

    FileHandle h = new FileHandle(1); // fake handle for ""/dumpFilePath""
    COMMIT_STATUS ret;
    WriteManager wm = new WriteManager(new ShellBasedIdMapping(config), config, false);
    assertTrue(wm.addOpenFileStream(h, ctx));
    
    // Test inactive open file context
    ctx.setActiveStatusForTest(false);
    Channel ch = Mockito.mock(Channel.class);
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals( COMMIT_STATUS.COMMIT_INACTIVE_CTX, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 0));
    
    ctx.getPendingWritesForTest().put(new OffsetRange(10, 15),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_INACTIVE_WITH_PENDING_WRITE, ret);
    assertEquals(Nfs3Status.NFS3ERR_IO, wm.commitBeforeRead(dfsClient, h, 0));
    
    // Test request with non zero commit offset
    ctx.setActiveStatusForTest(true);
    Mockito.when(fos.getPos()).thenReturn((long) 10);
    ctx.setNextOffsetForTest((long)10);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, ch, 1, attr, false);
    assertEquals(COMMIT_STATUS.COMMIT_DO_SYNC, status);
    // Do_SYNC state will be updated to FINISHED after data sync
    ret = ctx.checkCommit(dfsClient, 5, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_FINISHED, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 5));
 
    status = ctx.checkCommitInternal(10, ch, 1, attr, true);
    assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
    ret = ctx.checkCommit(dfsClient, 10, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_FINISHED, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 10));

    ConcurrentNavigableMap<Long, CommitCtx> commits = ctx
        .getPendingCommitsForTest();
    assertTrue(commits.size() == 0);
    ret = ctx.checkCommit(dfsClient, 11, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_WAIT, ret);
    assertEquals(0, commits.size()); // commit triggered by read doesn't wait
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 11));

    // Test request with zero commit offset
    // There is one pending write [5,10]
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_WAIT, ret);
    assertEquals(0, commits.size());
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 0));

    // Empty pending writes
    ctx.getPendingWritesForTest().remove(new OffsetRange(10, 15));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_FINISHED, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 0));
  }
",non-flaky,5
293,apache_hadoop,TestWrites.testCheckCommitFromReadLargeFileUpload,"  @Test
  public void testCheckCommitFromReadLargeFileUpload() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);
    NfsConfiguration config = new NfsConfiguration();

    config.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, true);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(config), false, config);

    FileHandle h = new FileHandle(1); // fake handle for ""/dumpFilePath""
    COMMIT_STATUS ret;
    WriteManager wm = new WriteManager(new ShellBasedIdMapping(config), config, false);
    assertTrue(wm.addOpenFileStream(h, ctx));
    
    // Test inactive open file context
    ctx.setActiveStatusForTest(false);
    Channel ch = Mockito.mock(Channel.class);
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals( COMMIT_STATUS.COMMIT_INACTIVE_CTX, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 0));
    
    ctx.getPendingWritesForTest().put(new OffsetRange(10, 15),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_INACTIVE_WITH_PENDING_WRITE, ret);
    assertEquals(Nfs3Status.NFS3ERR_IO, wm.commitBeforeRead(dfsClient, h, 0));
    
    // Test request with non zero commit offset
    ctx.setActiveStatusForTest(true);
    Mockito.when(fos.getPos()).thenReturn((long) 6);
    ctx.setNextOffsetForTest((long)10);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, ch, 1, attr, false);
    assertEquals(COMMIT_STATUS.COMMIT_DO_SYNC, status);
    // Do_SYNC state will be updated to FINISHED after data sync
    ret = ctx.checkCommit(dfsClient, 5, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_FINISHED, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 5));
 
    // Test request with sequential writes
    status = ctx.checkCommitInternal(9, ch, 1, attr, true);
    assertTrue(status == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    ret = ctx.checkCommit(dfsClient, 9, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_SPECIAL_WAIT, ret);
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 9));

    // Test request with non-sequential writes
    ConcurrentNavigableMap<Long, CommitCtx> commits = ctx
        .getPendingCommitsForTest();
    assertTrue(commits.size() == 0);
    ret = ctx.checkCommit(dfsClient, 16, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_SPECIAL_SUCCESS, ret);
    assertEquals(0, commits.size()); // commit triggered by read doesn't wait
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 16));

    // Test request with zero commit offset
    // There is one pending write [10,15]
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_SPECIAL_WAIT, ret);
    assertEquals(0, commits.size());
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 0));

    // Empty pending writes
    ctx.getPendingWritesForTest().remove(new OffsetRange(10, 15));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_SPECIAL_WAIT, ret);
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 0));
  }
",non-flaky,5
294,apache_hadoop,TestWrites.testWriteStableHow,"  @Test
  public void testWriteStableHow() throws IOException, InterruptedException {
    NfsConfiguration config = new NfsConfiguration();
    DFSClient client = null;
    MiniDFSCluster cluster = null;
    RpcProgramNfs3 nfsd;
    SecurityHandler securityHandler = Mockito.mock(SecurityHandler.class);
    Mockito.when(securityHandler.getUser()).thenReturn(
        System.getProperty(""user.name""));
    String currentUser = System.getProperty(""user.name"");
    config.set(
            DefaultImpersonationProvider.getTestProvider().
                getProxySuperuserGroupConfKey(currentUser),
            ""*"");
    config.set(
            DefaultImpersonationProvider.getTestProvider().
                getProxySuperuserIpConfKey(currentUser),
            ""*"");
    ProxyUsers.refreshSuperUserGroupsConfiguration(config);

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();
      client = new DFSClient(DFSUtilClient.getNNAddress(config), config);
      int namenodeId = Nfs3Utils.getNamenodeId(config);

      // Use emphral port in case tests are running in parallel
      config.setInt(""nfs3.mountd.port"", 0);
      config.setInt(""nfs3.server.port"", 0);
      
      // Start nfs
      Nfs3 nfs3 = new Nfs3(config);
      nfs3.startServiceInternal(false);
      nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();

      HdfsFileStatus status = client.getFileInfo(""/"");
      FileHandle rootHandle = new FileHandle(status.getFileId(), namenodeId);
      // Create file1
      CREATE3Request createReq = new CREATE3Request(rootHandle, ""file1"",
          Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
      XDR createXdr = new XDR();
      createReq.serialize(createXdr);
      CREATE3Response createRsp = nfsd.create(createXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));
      FileHandle handle = createRsp.getObjHandle();

      // Test DATA_SYNC
      byte[] buffer = new byte[10];
      for (int i = 0; i < 10; i++) {
        buffer[i] = (byte) i;
      }
      WRITE3Request writeReq = new WRITE3Request(handle, 0, 10,
          WriteStableHow.DATA_SYNC, ByteBuffer.wrap(buffer));
      XDR writeXdr = new XDR();
      writeReq.serialize(writeXdr);
      nfsd.write(writeXdr.asReadOnlyWrap(), null, 1, securityHandler,
          new InetSocketAddress(""localhost"", 1234));

      waitWrite(nfsd, handle, 60000);

      // Readback
      READ3Request readReq = new READ3Request(handle, 0, 10);
      XDR readXdr = new XDR();
      readReq.serialize(readXdr);
      READ3Response readRsp = nfsd.read(readXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));

      assertTrue(Arrays.equals(buffer, readRsp.getData().array()));

      // Test FILE_SYNC

      // Create file2
      CREATE3Request createReq2 = new CREATE3Request(rootHandle, ""file2"",
          Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
      XDR createXdr2 = new XDR();
      createReq2.serialize(createXdr2);
      CREATE3Response createRsp2 = nfsd.create(createXdr2.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));
      FileHandle handle2 = createRsp2.getObjHandle();

      WRITE3Request writeReq2 = new WRITE3Request(handle2, 0, 10,
          WriteStableHow.FILE_SYNC, ByteBuffer.wrap(buffer));
      XDR writeXdr2 = new XDR();
      writeReq2.serialize(writeXdr2);
      nfsd.write(writeXdr2.asReadOnlyWrap(), null, 1, securityHandler,
          new InetSocketAddress(""localhost"", 1234));

      waitWrite(nfsd, handle2, 60000);

      // Readback
      READ3Request readReq2 = new READ3Request(handle2, 0, 10);
      XDR readXdr2 = new XDR();
      readReq2.serialize(readXdr2);
      READ3Response readRsp2 = nfsd.read(readXdr2.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));

      assertTrue(Arrays.equals(buffer, readRsp2.getData().array()));
      // FILE_SYNC should sync the file size
      status = client.getFileInfo(""/file2"");
      assertTrue(status.getLen() == 10);

    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
295,apache_hadoop,TestWrites.testOOOWrites,"  @Test
  public void testOOOWrites() throws IOException, InterruptedException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    RpcProgramNfs3 nfsd;
    final int bufSize = 32;
    final int numOOO = 3;
    SecurityHandler securityHandler = Mockito.mock(SecurityHandler.class);
    Mockito.when(securityHandler.getUser()).thenReturn(
        System.getProperty(""user.name""));
    String currentUser = System.getProperty(""user.name"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserGroupConfKey(currentUser),
        ""*"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserIpConfKey(currentUser),
        ""*"");
    ProxyUsers.refreshSuperUserGroupsConfiguration(config);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();

      Nfs3 nfs3 = new Nfs3(config);
      nfs3.startServiceInternal(false);
      nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();

      DFSClient dfsClient = new DFSClient(DFSUtilClient.getNNAddress(config),
          config);
      int namenodeId = Nfs3Utils.getNamenodeId(config);
      HdfsFileStatus status = dfsClient.getFileInfo(""/"");
      FileHandle rootHandle = new FileHandle(status.getFileId(), namenodeId);

      CREATE3Request createReq = new CREATE3Request(rootHandle,
          ""out-of-order-write"" + System.currentTimeMillis(),
          Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
      XDR createXdr = new XDR();
      createReq.serialize(createXdr);
      CREATE3Response createRsp = nfsd.create(createXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));
      FileHandle handle = createRsp.getObjHandle();

      byte[][] oooBuf = new byte[numOOO][bufSize];
      for (int i = 0; i < numOOO; i++) {
        Arrays.fill(oooBuf[i], (byte) i);
      }

      for (int i = 0; i < numOOO; i++) {
        final long offset = (numOOO - 1 - i) * bufSize;
        WRITE3Request writeReq = new WRITE3Request(handle, offset, bufSize,
            WriteStableHow.UNSTABLE, ByteBuffer.wrap(oooBuf[i]));
        XDR writeXdr = new XDR();
        writeReq.serialize(writeXdr);
        nfsd.write(writeXdr.asReadOnlyWrap(), null, 1, securityHandler,
            new InetSocketAddress(""localhost"", 1234));
      }

      waitWrite(nfsd, handle, 60000);
      READ3Request readReq = new READ3Request(handle, bufSize, bufSize);
      XDR readXdr = new XDR();
      readReq.serialize(readXdr);
      READ3Response readRsp = nfsd.read(readXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", config.getInt(
              NfsConfigKeys.DFS_NFS_SERVER_PORT_KEY,
              NfsConfigKeys.DFS_NFS_SERVER_PORT_DEFAULT)));
      assertTrue(Arrays.equals(oooBuf[1], readRsp.getData().array()));
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
296,apache_hadoop,TestWrites.testOverlappingWrites,"  @Test
  public void testOverlappingWrites() throws IOException, InterruptedException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    RpcProgramNfs3 nfsd;
    final int bufSize = 32;
    SecurityHandler securityHandler = Mockito.mock(SecurityHandler.class);
    Mockito.when(securityHandler.getUser()).thenReturn(
        System.getProperty(""user.name""));
    String currentUser = System.getProperty(""user.name"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserGroupConfKey(currentUser),
        ""*"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserIpConfKey(currentUser),
        ""*"");
    ProxyUsers.refreshSuperUserGroupsConfiguration(config);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();

      Nfs3 nfs3 = new Nfs3(config);
      nfs3.startServiceInternal(false);
      nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();

      DFSClient dfsClient = new DFSClient(DFSUtilClient.getNNAddress(config),
          config);
      int namenodeId = Nfs3Utils.getNamenodeId(config);
      HdfsFileStatus status = dfsClient.getFileInfo(""/"");
      FileHandle rootHandle = new FileHandle(status.getFileId(), namenodeId);

      CREATE3Request createReq = new CREATE3Request(rootHandle,
          ""overlapping-writes"" + System.currentTimeMillis(),
          Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
      XDR createXdr = new XDR();
      createReq.serialize(createXdr);
      CREATE3Response createRsp = nfsd.create(createXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));
      FileHandle handle = createRsp.getObjHandle();
      byte[] buffer = new byte[bufSize];
      for (int i = 0; i < bufSize; i++) {
        buffer[i] = (byte) i;
      }
      int[][] ranges = new int[][] {
          {0, 10},
          {5, 7},
          {5, 5},
          {10, 6},
          {18, 6},
          {20, 6},
          {28, 4},
          {16, 2},
          {25, 4}
      };
      for (int i = 0; i < ranges.length; i++) {
        int x[] = ranges[i];
        byte[] tbuffer = new byte[x[1]];
        for (int j = 0; j < x[1]; j++) {
          tbuffer[j] = buffer[x[0] + j];
        }
        WRITE3Request writeReq = new WRITE3Request(handle, (long)x[0], x[1],
            WriteStableHow.UNSTABLE, ByteBuffer.wrap(tbuffer));
        XDR writeXdr = new XDR();
        writeReq.serialize(writeXdr);
        nfsd.write(writeXdr.asReadOnlyWrap(), null, 1, securityHandler,
            new InetSocketAddress(""localhost"", 1234));
      }

      waitWrite(nfsd, handle, 60000);
      READ3Request readReq = new READ3Request(handle, 0, bufSize);
      XDR readXdr = new XDR();
      readReq.serialize(readXdr);
      READ3Response readRsp = nfsd.read(readXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", config.getInt(
              NfsConfigKeys.DFS_NFS_SERVER_PORT_KEY,
              NfsConfigKeys.DFS_NFS_SERVER_PORT_DEFAULT)));

      assertTrue(Arrays.equals(buffer, readRsp.getData().array()));
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
297,apache_hadoop,TestWrites.testCheckSequential,"  @Test
  public void testCheckSequential() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);
    NfsConfiguration config = new NfsConfiguration();

    config.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, false);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(config), false, config);
    
    ctx.getPendingWritesForTest().put(new OffsetRange(5, 10),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ctx.getPendingWritesForTest().put(new OffsetRange(10, 15),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ctx.getPendingWritesForTest().put(new OffsetRange(20, 25),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));

    assertTrue(!ctx.checkSequential(5, 4));
    assertTrue(ctx.checkSequential(9, 5));
    assertTrue(ctx.checkSequential(10, 5));
    assertTrue(ctx.checkSequential(14, 5));
    assertTrue(!ctx.checkSequential(15, 5));
    assertTrue(!ctx.checkSequential(20, 5));
    assertTrue(!ctx.checkSequential(25, 5));
    assertTrue(!ctx.checkSequential(999, 5));
  }
",non-flaky,5
298,apache_hadoop,TestNfs3HttpServer.testHttpServer,"  @Test
  public void testHttpServer() throws Exception {
    Nfs3 nfs = new Nfs3(conf);
    nfs.startServiceInternal(false);
    RpcProgramNfs3 nfsd = (RpcProgramNfs3) nfs.getRpcProgram();
    Nfs3HttpServer infoServer = nfsd.getInfoServer();

    String urlRoot = infoServer.getServerURI().toString();

    // Check default servlets.
    String pageContents = DFSTestUtil.urlGet(new URL(urlRoot + ""/jmx""));
    assertTrue(""Bad contents: "" + pageContents,
        pageContents.contains(""java.lang:type=""));
    System.out.println(""pc:"" + pageContents);

    int port = infoServer.getSecurePort();
    assertTrue(""Can't get https port"", port > 0);
  }
",non-flaky,5
299,apache_hadoop,TestRpcProgramNfs3.testGetattr,"  @Test(timeout = 60000)
  public void testGetattr() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    GETATTR3Request req = new GETATTR3Request(handle);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    GETATTR3Response response1 = nfsd.getattr(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    GETATTR3Response response2 = nfsd.getattr(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
300,apache_hadoop,TestRpcProgramNfs3.testSetattr,"  @Test(timeout = 60000)
  public void testSetattr() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    SetAttr3 symAttr = new SetAttr3(0, 1, 0, 0, null, null,
        EnumSet.of(SetAttrField.UID));
    SETATTR3Request req = new SETATTR3Request(handle, symAttr, false, null);
    req.serialize(xdr_req);

    // Attempt by an unprivileged user should fail.
    SETATTR3Response response1 = nfsd.setattr(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    SETATTR3Response response2 = nfsd.setattr(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
301,apache_hadoop,TestRpcProgramNfs3.testLookup,"  @Test(timeout = 60000)
  public void testLookup() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    LOOKUP3Request lookupReq = new LOOKUP3Request(handle, ""bar"");
    XDR xdr_req = new XDR();
    lookupReq.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    LOOKUP3Response response1 = nfsd.lookup(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    LOOKUP3Response response2 = nfsd.lookup(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
302,apache_hadoop,TestRpcProgramNfs3.testAccess,"  @Test(timeout = 60000)
  public void testAccess() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    ACCESS3Request req = new ACCESS3Request(handle);
    req.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    ACCESS3Response response1 = nfsd.access(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    ACCESS3Response response2 = nfsd.access(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
303,apache_hadoop,TestRpcProgramNfs3.testReadlink,"  @Test(timeout = 60000)
  public void testReadlink() throws Exception {
    // Create a symlink first.
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    SYMLINK3Request req = new SYMLINK3Request(handle, ""fubar"", new SetAttr3(),
        ""bar"");
    req.serialize(xdr_req);
    
    SYMLINK3Response response = nfsd.symlink(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response.getStatus());

    // Now perform readlink operations.
    FileHandle handle2 = response.getObjFileHandle();
    XDR xdr_req2 = new XDR();
    READLINK3Request req2 = new READLINK3Request(handle2);
    req2.serialize(xdr_req2);

    // Attempt by an unpriviledged user should fail.
    READLINK3Response response1 = nfsd.readlink(xdr_req2.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    READLINK3Response response2 = nfsd.readlink(xdr_req2.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
304,apache_hadoop,TestRpcProgramNfs3.testRead,"  @Test(timeout = 60000)
  public void testRead() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);

    READ3Request readReq = new READ3Request(handle, 0, 5);
    XDR xdr_req = new XDR();
    readReq.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    READ3Response response1 = nfsd.read(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    READ3Response response2 = nfsd.read(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
305,apache_hadoop,TestRpcProgramNfs3.testEncryptedReadWrite,"  @Test(timeout = 120000)
  public void testEncryptedReadWrite() throws Exception {
    final int len = 8192;

    final Path zone = new Path(""/zone"");
    hdfs.mkdirs(zone);
    dfsAdmin.createEncryptionZone(zone, TEST_KEY, NO_TRASH);

    final byte[] buffer = new byte[len];
    for (int i = 0; i < len; i++) {
      buffer[i] = (byte) i;
    }

    final String encFile1 = ""/zone/myfile"";
    createFileUsingNfs(encFile1, buffer);
    commit(encFile1, len);
    assertArrayEquals(""encFile1 not equal"",
        getFileContentsUsingNfs(encFile1, len),
        getFileContentsUsingDfs(encFile1, len));

    /*
     * Same thing except this time create the encrypted file using DFS.
     */
    final String encFile2 = ""/zone/myfile2"";
    final Path encFile2Path = new Path(encFile2);
    DFSTestUtil.createFile(hdfs, encFile2Path, len, (short) 1, 0xFEED);
    assertArrayEquals(""encFile2 not equal"",
        getFileContentsUsingNfs(encFile2, len),
        getFileContentsUsingDfs(encFile2, len));
  }
",non-flaky,5
306,apache_hadoop,TestRpcProgramNfs3.testWrite,"  @Test(timeout = 60000)
  public void testWrite() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);

    byte[] buffer = new byte[10];
    for (int i = 0; i < 10; i++) {
      buffer[i] = (byte) i;
    }

    WRITE3Request writeReq = new WRITE3Request(handle, 0, 10,
        WriteStableHow.DATA_SYNC, ByteBuffer.wrap(buffer));
    XDR xdr_req = new XDR();
    writeReq.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    WRITE3Response response1 = nfsd.write(xdr_req.asReadOnlyWrap(),
        null, 1, securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    WRITE3Response response2 = nfsd.write(xdr_req.asReadOnlyWrap(),
        null, 1, securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect response:"", null, response2);
  }
",non-flaky,5
307,apache_hadoop,TestRpcProgramNfs3.testCreate,"  @Test(timeout = 60000)
  public void testCreate() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    CREATE3Request req = new CREATE3Request(handle, ""fubar"",
        Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    CREATE3Response response1 = nfsd.create(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    CREATE3Response response2 = nfsd.create(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
308,apache_hadoop,TestRpcProgramNfs3.testMkdir,"  @Test(timeout = 60000)
  public void testMkdir() throws Exception {//FixME
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    MKDIR3Request req = new MKDIR3Request(handle, ""fubar1"", new SetAttr3());
    req.serialize(xdr_req);
    
    // Attempt to mkdir by an unprivileged user should fail.
    MKDIR3Response response1 = nfsd.mkdir(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    XDR xdr_req2 = new XDR();
    MKDIR3Request req2 = new MKDIR3Request(handle, ""fubar2"", new SetAttr3());
    req2.serialize(xdr_req2);
    
    // Attempt to mkdir by a privileged user should pass.
    MKDIR3Response response2 = nfsd.mkdir(xdr_req2.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
309,apache_hadoop,TestRpcProgramNfs3.testSymlink,"  @Test(timeout = 60000)
  public void testSymlink() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    SYMLINK3Request req = new SYMLINK3Request(handle, ""fubar"", new SetAttr3(),
        ""bar"");
    req.serialize(xdr_req);

    // Attempt by an unprivileged user should fail.
    SYMLINK3Response response1 = nfsd.symlink(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a privileged user should pass.
    SYMLINK3Response response2 = nfsd.symlink(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
310,apache_hadoop,TestRpcProgramNfs3.testRemove,"  @Test(timeout = 60000)
  public void testRemove() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    REMOVE3Request req = new REMOVE3Request(handle, ""bar"");
    req.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    REMOVE3Response response1 = nfsd.remove(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    REMOVE3Response response2 = nfsd.remove(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
311,apache_hadoop,TestRpcProgramNfs3.testRmdir,"  @Test(timeout = 60000)
  public void testRmdir() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    RMDIR3Request req = new RMDIR3Request(handle, ""foo"");
    req.serialize(xdr_req);

    // Attempt by an unprivileged user should fail.
    RMDIR3Response response1 = nfsd.rmdir(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a privileged user should pass.
    RMDIR3Response response2 = nfsd.rmdir(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
312,apache_hadoop,TestRpcProgramNfs3.testRename,"  @Test(timeout = 60000)
  public void testRename() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    RENAME3Request req = new RENAME3Request(handle, ""bar"", handle, ""fubar"");
    req.serialize(xdr_req);
    
    // Attempt by an unprivileged user should fail.
    RENAME3Response response1 = nfsd.rename(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a privileged user should pass.
    RENAME3Response response2 = nfsd.rename(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
313,apache_hadoop,TestRpcProgramNfs3.testReaddir,"  @Test(timeout = 60000)
  public void testReaddir() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    READDIR3Request req = new READDIR3Request(handle, 0, 0, 100);
    req.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    READDIR3Response response1 = nfsd.readdir(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    READDIR3Response response2 = nfsd.readdir(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
314,apache_hadoop,TestRpcProgramNfs3.testReaddirplus,"  @Test(timeout = 60000)
  public void testReaddirplus() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    READDIRPLUS3Request req = new READDIRPLUS3Request(handle, 0, 0, 3, 2);
    req.serialize(xdr_req);
    
    // Attempt by an unprivileged user should fail.
    READDIRPLUS3Response response1 = nfsd.readdirplus(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a privileged user should pass.
    READDIRPLUS3Response response2 = nfsd.readdirplus(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
315,apache_hadoop,TestRpcProgramNfs3.testFsstat,"  @Test(timeout = 60000)
  public void testFsstat() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    FSSTAT3Request req = new FSSTAT3Request(handle);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    FSSTAT3Response response1 = nfsd.fsstat(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    FSSTAT3Response response2 = nfsd.fsstat(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
316,apache_hadoop,TestRpcProgramNfs3.testFsinfo,"  @Test(timeout = 60000)
  public void testFsinfo() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    FSINFO3Request req = new FSINFO3Request(handle);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    FSINFO3Response response1 = nfsd.fsinfo(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    FSINFO3Response response2 = nfsd.fsinfo(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
317,apache_hadoop,TestRpcProgramNfs3.testPathconf,"  @Test(timeout = 60000)
  public void testPathconf() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    PATHCONF3Request req = new PATHCONF3Request(handle);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    PATHCONF3Response response1 = nfsd.pathconf(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    PATHCONF3Response response2 = nfsd.pathconf(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
318,apache_hadoop,TestRpcProgramNfs3.testCommit,"  @Test(timeout = 60000)
  public void testCommit() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    COMMIT3Request req = new COMMIT3Request(handle, 0, 5);
    req.serialize(xdr_req);

    Channel ch = Mockito.mock(Channel.class);

    // Attempt by an unpriviledged user should fail.
    COMMIT3Response response1 = nfsd.commit(xdr_req.asReadOnlyWrap(),
        ch, 1, securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    COMMIT3Response response2 = nfsd.commit(xdr_req.asReadOnlyWrap(),
        ch, 1, securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect COMMIT3Response:"", null, response2);
  }
",non-flaky,5
319,apache_hadoop,TestRpcProgramNfs3.testIdempotent,"  @Test(timeout=10000)
  public void testIdempotent() {
    Object[][] procedures = {
        { Nfs3Constant.NFSPROC3.NULL, 1 },
        { Nfs3Constant.NFSPROC3.GETATTR, 1 },
        { Nfs3Constant.NFSPROC3.SETATTR, 1 },
        { Nfs3Constant.NFSPROC3.LOOKUP, 1 },
        { Nfs3Constant.NFSPROC3.ACCESS, 1 },
        { Nfs3Constant.NFSPROC3.READLINK, 1 },
        { Nfs3Constant.NFSPROC3.READ, 1 },
        { Nfs3Constant.NFSPROC3.WRITE, 1 },
        { Nfs3Constant.NFSPROC3.CREATE, 0 },
        { Nfs3Constant.NFSPROC3.MKDIR, 0 },
        { Nfs3Constant.NFSPROC3.SYMLINK, 0 },
        { Nfs3Constant.NFSPROC3.MKNOD, 0 },
        { Nfs3Constant.NFSPROC3.REMOVE, 0 },
        { Nfs3Constant.NFSPROC3.RMDIR, 0 },
        { Nfs3Constant.NFSPROC3.RENAME, 0 },
        { Nfs3Constant.NFSPROC3.LINK, 0 },
        { Nfs3Constant.NFSPROC3.READDIR, 1 },
        { Nfs3Constant.NFSPROC3.READDIRPLUS, 1 },
        { Nfs3Constant.NFSPROC3.FSSTAT, 1 },
        { Nfs3Constant.NFSPROC3.FSINFO, 1 },
        { Nfs3Constant.NFSPROC3.PATHCONF, 1 },
        { Nfs3Constant.NFSPROC3.COMMIT, 1 } };
    for (Object[] procedure : procedures) {
      boolean idempotent = procedure[1].equals(Integer.valueOf(1));
      Nfs3Constant.NFSPROC3 proc = (Nfs3Constant.NFSPROC3)procedure[0];
      if (idempotent) {
        Assert.assertTrue((""Procedure "" + proc + "" should be idempotent""),
            proc.isIdempotent());
      } else {
        Assert.assertFalse((""Procedure "" + proc + "" should be non-idempotent""),
            proc.isIdempotent());
      }
    }
  }
",non-flaky,5
320,apache_hadoop,TestRpcProgramNfs3.testDeprecatedKeys,"  @Test
  public void testDeprecatedKeys() {
    NfsConfiguration conf = new NfsConfiguration();
    conf.setInt(""nfs3.server.port"", 998);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_SERVER_PORT_KEY, 0) == 998);

    conf.setInt(""nfs3.mountd.port"", 999);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_MOUNTD_PORT_KEY, 0) == 999);

    conf.set(""dfs.nfs.exports.allowed.hosts"", ""host1"");
    assertTrue(conf.get(CommonConfigurationKeys.NFS_EXPORTS_ALLOWED_HOSTS_KEY)
        .equals(""host1""));

    conf.setInt(""dfs.nfs.exports.cache.expirytime.millis"", 1000);
    assertTrue(conf.getInt(
        Nfs3Constant.NFS_EXPORTS_CACHE_EXPIRYTIME_MILLIS_KEY, 0) == 1000);

    conf.setInt(""hadoop.nfs.userupdate.milly"", 10);
    assertTrue(conf.getInt(IdMappingConstant.USERGROUPID_UPDATE_MILLIS_KEY, 0) == 10);

    conf.set(""dfs.nfs3.dump.dir"", ""/nfs/tmp"");
    assertTrue(conf.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY).equals(
        ""/nfs/tmp""));

    conf.setBoolean(""dfs.nfs3.enableDump"", false);
    assertTrue(conf.getBoolean(NfsConfigKeys.DFS_NFS_FILE_DUMP_KEY, true) == false);

    conf.setInt(""dfs.nfs3.max.open.files"", 500);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_MAX_OPEN_FILES_KEY, 0) == 500);

    conf.setInt(""dfs.nfs3.stream.timeout"", 6000);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_KEY, 0) == 6000);

    conf.set(""dfs.nfs3.export.point"", ""/dir1"");
    assertTrue(conf.get(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY).equals(""/dir1""));
  }
",non-flaky,5
321,apache_hadoop,TestNfs3Utils.testGetAccessRightsForUserGroup,"  @Test
  public void testGetAccessRightsForUserGroup() throws IOException {
    Nfs3FileAttributes attr = Mockito.mock(Nfs3FileAttributes.class);
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(3);
    Mockito.when(attr.getMode()).thenReturn(448); // 700
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSREG.toValue());
    assertEquals(""No access should be allowed as UID does not match attribute over mode 700"",
      0, Nfs3Utils.getAccessRightsForUserGroup(3, 3, null, attr));
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(3);
    Mockito.when(attr.getMode()).thenReturn(56); // 070
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSREG.toValue());
    assertEquals(""No access should be allowed as GID does not match attribute over mode 070"",
      0, Nfs3Utils.getAccessRightsForUserGroup(2, 4, null, attr));
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(3);
    Mockito.when(attr.getMode()).thenReturn(7); // 007
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSREG.toValue());
    assertEquals(""Access should be allowed as mode is 007 and UID/GID do not match"",
      61 /* RWX */, Nfs3Utils.getAccessRightsForUserGroup(1, 4, new int[] {5, 6}, attr));
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(10);
    Mockito.when(attr.getMode()).thenReturn(288); // 440
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSREG.toValue());
    assertEquals(""Access should be allowed as mode is 440 and Aux GID does match"",
      1 /* R */, Nfs3Utils.getAccessRightsForUserGroup(3, 4, new int[] {5, 16, 10}, attr));
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(10);
    Mockito.when(attr.getMode()).thenReturn(448); // 700
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSDIR.toValue());
    assertEquals(""Access should be allowed for dir as mode is 700 and UID does match"",
      31 /* Lookup */, Nfs3Utils.getAccessRightsForUserGroup(2, 4, new int[] {5, 16, 10}, attr));
    assertEquals(""No access should be allowed for dir as mode is 700 even though GID does match"",
      0, Nfs3Utils.getAccessRightsForUserGroup(3, 10, new int[] {5, 16, 4}, attr));
    assertEquals(""No access should be allowed for dir as mode is 700 even though AuxGID does match"",
      0, Nfs3Utils.getAccessRightsForUserGroup(3, 20, new int[] {5, 10}, attr));
    
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(10);
    Mockito.when(attr.getMode()).thenReturn(457); // 711
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSDIR.toValue());
    assertEquals(""Access should be allowed for dir as mode is 711 and GID matches"",
        2 /* Lookup */, Nfs3Utils.getAccessRightsForUserGroup(3, 10, new int[] {5, 16, 11}, attr));
  }
",non-flaky,5
322,apache_hadoop,TestDFSClientCache.testEviction,"  @Test
  public void testEviction() throws IOException {
    NfsConfiguration conf = new NfsConfiguration();
    conf.set(FileSystem.FS_DEFAULT_NAME_KEY, ""hdfs://localhost"");

    // Only one entry will be in the cache
    final int MAX_CACHE_SIZE = 1;

    DFSClientCache cache = new DFSClientCache(conf, MAX_CACHE_SIZE);

    int namenodeId = Nfs3Utils.getNamenodeId(conf);
    DFSClient c1 = cache.getDfsClient(""test1"", namenodeId);
    assertTrue(cache.getDfsClient(""test1"", namenodeId)
        .toString().contains(""ugi=test1""));
    assertEquals(c1, cache.getDfsClient(""test1"", namenodeId));
    assertFalse(isDfsClientClose(c1));

    cache.getDfsClient(""test2"", namenodeId);
    assertTrue(isDfsClientClose(c1));
    assertTrue(""cache size should be the max size or less"",
        cache.getClientCache().size() <= MAX_CACHE_SIZE);
  }
",non-flaky,5
323,apache_hadoop,TestDFSClientCache.testGetUserGroupInformationSecure,"  @Test
  public void testGetUserGroupInformationSecure() throws IOException {
    String userName = ""user1"";
    String currentUser = ""test-user"";


    NfsConfiguration conf = new NfsConfiguration();
    conf.set(FileSystem.FS_DEFAULT_NAME_KEY, ""hdfs://localhost"");
    UserGroupInformation currentUserUgi
            = UserGroupInformation.createRemoteUser(currentUser);
    currentUserUgi.setAuthenticationMethod(KERBEROS);
    UserGroupInformation.setLoginUser(currentUserUgi);

    DFSClientCache cache = new DFSClientCache(conf);
    UserGroupInformation ugiResult
            = cache.getUserGroupInformation(userName, currentUserUgi);

    assertThat(ugiResult.getUserName(), is(userName));
    assertThat(ugiResult.getRealUser(), is(currentUserUgi));
    assertThat(
            ugiResult.getAuthenticationMethod(),
            is(UserGroupInformation.AuthenticationMethod.PROXY));
  }
",non-flaky,5
324,apache_hadoop,TestDFSClientCache.testGetUserGroupInformation,"  @Test
  public void testGetUserGroupInformation() throws IOException {
    String userName = ""user1"";
    String currentUser = ""currentUser"";

    UserGroupInformation currentUserUgi = UserGroupInformation
            .createUserForTesting(currentUser, new String[0]);
    NfsConfiguration conf = new NfsConfiguration();
    conf.set(FileSystem.FS_DEFAULT_NAME_KEY, ""hdfs://localhost"");
    DFSClientCache cache = new DFSClientCache(conf);
    UserGroupInformation ugiResult
            = cache.getUserGroupInformation(userName, currentUserUgi);

    assertThat(ugiResult.getUserName(), is(userName));
    assertThat(ugiResult.getRealUser(), is(currentUserUgi));
    assertThat(
            ugiResult.getAuthenticationMethod(),
            is(UserGroupInformation.AuthenticationMethod.PROXY));
  }
",non-flaky,5
325,apache_hadoop,TestViewfsWithNfs3.testNumExports,"  @Test
  public void testNumExports() throws Exception {
    Assert.assertEquals(mountd.getExports().size(),
        viewFs.getChildFileSystems().length);
  }
",non-flaky,5
326,apache_hadoop,TestViewfsWithNfs3.testPaths,"  @Test
  public void testPaths() throws Exception {
    Assert.assertEquals(hdfs1.resolvePath(new Path(""/user1/file1"")),
        viewFs.resolvePath(new Path(""/hdfs1/file1"")));
    Assert.assertEquals(hdfs1.resolvePath(new Path(""/user1/file2"")),
        viewFs.resolvePath(new Path(""/hdfs1/file2"")));
    Assert.assertEquals(hdfs2.resolvePath(new Path(""/user2/dir2"")),
        viewFs.resolvePath(new Path(""/hdfs2/dir2"")));
  }
",non-flaky,5
327,apache_hadoop,TestViewfsWithNfs3.testFileStatus,"  @Test
  public void testFileStatus() throws Exception {
    HdfsFileStatus status = nn1.getRpcServer().getFileInfo(""/user1/file1"");
    FileStatus st = viewFs.getFileStatus(new Path(""/hdfs1/file1""));
    Assert.assertEquals(st.isDirectory(), status.isDirectory());

    HdfsFileStatus status2 = nn2.getRpcServer().getFileInfo(""/user2/dir2"");
    FileStatus st2 = viewFs.getFileStatus(new Path(""/hdfs2/dir2""));
    Assert.assertEquals(st2.isDirectory(), status2.isDirectory());
  }
",non-flaky,5
328,apache_hadoop,TestViewfsWithNfs3.testNfsAccessNN1,"  @Test (timeout = 60000)
  public void testNfsAccessNN1() throws Exception {
    HdfsFileStatus status = nn1.getRpcServer().getFileInfo(""/user1/file1"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs1.getUri());
    testNfsGetAttrResponse(status.getFileId(), namenodeId, Nfs3Status.NFS3_OK);
  }
",non-flaky,5
329,apache_hadoop,TestViewfsWithNfs3.testNfsAccessNN2,"  @Test (timeout = 60000)
  public void testNfsAccessNN2() throws Exception {
    HdfsFileStatus status = nn2.getRpcServer().getFileInfo(""/user2/dir2"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs2.getUri());
    testNfsGetAttrResponse(status.getFileId(), namenodeId, Nfs3Status.NFS3_OK);
  }
",non-flaky,5
330,apache_hadoop,TestViewfsWithNfs3.testWrongNfsAccess,"  @Test (timeout = 60000)
  public void testWrongNfsAccess() throws Exception {
    DFSTestUtil.createFile(viewFs, new Path(""/hdfs1/file3""), 0, (short) 1, 0);
    HdfsFileStatus status = nn1.getRpcServer().getFileInfo(""/user1/file3"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs2.getUri());
    testNfsGetAttrResponse(status.getFileId(), namenodeId,
        Nfs3Status.NFS3ERR_IO);
  }
",non-flaky,5
331,apache_hadoop,TestViewfsWithNfs3.testNfsWriteNN1,"  @Test (timeout = 60000)
  public void testNfsWriteNN1() throws Exception {
    HdfsFileStatus status = nn1.getRpcServer().getFileInfo(""/user1/write1"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs1.getUri());
    testNfsWriteResponse(status.getFileId(), namenodeId);
  }
",non-flaky,5
332,apache_hadoop,TestViewfsWithNfs3.testNfsWriteNN2,"  @Test (timeout = 60000)
  public void testNfsWriteNN2() throws Exception {
    HdfsFileStatus status = nn2.getRpcServer().getFileInfo(""/user2/write2"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs2.getUri());
    testNfsWriteResponse(status.getFileId(), namenodeId);
  }
",non-flaky,5
333,apache_hadoop,TestViewfsWithNfs3.testNfsRenameMultiNN,"  @Test (timeout = 60000)
  public void testNfsRenameMultiNN() throws Exception {
    HdfsFileStatus fromFileStatus = nn1.getRpcServer().getFileInfo(""/user1"");
    int fromNNId = Nfs3Utils.getNamenodeId(config, hdfs1.getUri());
    FileHandle fromHandle =
        new FileHandle(fromFileStatus.getFileId(), fromNNId);

    HdfsFileStatus toFileStatus = nn2.getRpcServer().getFileInfo(""/user2"");
    int toNNId = Nfs3Utils.getNamenodeId(config, hdfs2.getUri());
    FileHandle toHandle = new FileHandle(toFileStatus.getFileId(), toNNId);

    HdfsFileStatus statusBeforeRename =
        nn1.getRpcServer().getFileInfo(""/user1/renameMultiNN"");
    Assert.assertEquals(statusBeforeRename.isDirectory(), false);

    testNfsRename(fromHandle, ""renameMultiNN"",
        toHandle, ""renameMultiNNFail"", Nfs3Status.NFS3ERR_INVAL);

    HdfsFileStatus statusAfterRename =
        nn2.getRpcServer().getFileInfo(""/user2/renameMultiNNFail"");
    Assert.assertEquals(statusAfterRename, null);

    statusAfterRename = nn1.getRpcServer().getFileInfo(""/user1/renameMultiNN"");
    Assert.assertEquals(statusAfterRename.isDirectory(), false);
  }
",non-flaky,5
334,apache_hadoop,TestViewfsWithNfs3.testNfsRenameSingleNN,"  @Test (timeout = 60000)
  public void testNfsRenameSingleNN() throws Exception {
    HdfsFileStatus fromFileStatus = nn1.getRpcServer().getFileInfo(""/user1"");
    int fromNNId = Nfs3Utils.getNamenodeId(config, hdfs1.getUri());
    FileHandle fromHandle =
        new FileHandle(fromFileStatus.getFileId(), fromNNId);

    HdfsFileStatus statusBeforeRename =
        nn1.getRpcServer().getFileInfo(""/user1/renameSingleNN"");
    Assert.assertEquals(statusBeforeRename.isDirectory(), false);

    testNfsRename(fromHandle, ""renameSingleNN"",
        fromHandle, ""renameSingleNNSucess"", Nfs3Status.NFS3_OK);

    HdfsFileStatus statusAfterRename =
        nn1.getRpcServer().getFileInfo(""/user1/renameSingleNNSucess"");
    Assert.assertEquals(statusAfterRename.isDirectory(), false);

    statusAfterRename =
        nn1.getRpcServer().getFileInfo(""/user1/renameSingleNN"");
    Assert.assertEquals(statusAfterRename, null);
  }
",non-flaky,5
335,apache_hadoop,TestOpenFileCtxCache.testEviction,"  @Test
  public void testEviction() throws IOException, InterruptedException {
    NfsConfiguration conf = new NfsConfiguration();

    // Only two entries will be in the cache
    conf.setInt(NfsConfigKeys.DFS_NFS_MAX_OPEN_FILES_KEY, 2);

    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);

    OpenFileCtx context1 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context2 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context3 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context4 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context5 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));

    OpenFileCtxCache cache = new OpenFileCtxCache(conf, 10 * 60 * 100);

    boolean ret = cache.put(new FileHandle(1), context1);
    assertTrue(ret);
    Thread.sleep(1000);
    ret = cache.put(new FileHandle(2), context2);
    assertTrue(ret);
    ret = cache.put(new FileHandle(3), context3);
    assertFalse(ret);
    assertTrue(cache.size() == 2);

    // Wait for the oldest stream to be evict-able, insert again
    Thread.sleep(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);
    assertTrue(cache.size() == 2);

    ret = cache.put(new FileHandle(3), context3);
    assertTrue(ret);
    assertTrue(cache.size() == 2);
    assertTrue(cache.get(new FileHandle(1)) == null);

    // Test inactive entry is evicted immediately
    context3.setActiveStatusForTest(false);
    ret = cache.put(new FileHandle(4), context4);
    assertTrue(ret);

    // Now the cache has context2 and context4
    // Test eviction failure if all entries have pending work.
    context2.getPendingWritesForTest().put(new OffsetRange(0, 100),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    context4.getPendingCommitsForTest().put(new Long(100),
        new CommitCtx(0, null, 0, attr));
    Thread.sleep(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);
    ret = cache.put(new FileHandle(5), context5);
    assertFalse(ret);
  }
",non-flaky,5
336,apache_hadoop,TestOpenFileCtxCache.testScan,"  @Test
  public void testScan() throws IOException, InterruptedException {
    NfsConfiguration conf = new NfsConfiguration();

    // Only two entries will be in the cache
    conf.setInt(NfsConfigKeys.DFS_NFS_MAX_OPEN_FILES_KEY, 2);

    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);

    OpenFileCtx context1 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context2 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context3 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context4 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));

    OpenFileCtxCache cache = new OpenFileCtxCache(conf, 10 * 60 * 100);

    // Test cleaning expired entry
    boolean ret = cache.put(new FileHandle(1), context1);
    assertTrue(ret);
    ret = cache.put(new FileHandle(2), context2);
    assertTrue(ret);
    Thread.sleep(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT + 1);
    cache.scan(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);
    assertTrue(cache.size() == 0);

    // Test cleaning inactive entry
    ret = cache.put(new FileHandle(3), context3);
    assertTrue(ret);
    ret = cache.put(new FileHandle(4), context4);
    assertTrue(ret);
    context3.setActiveStatusForTest(false);
    cache.scan(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_DEFAULT);
    assertTrue(cache.size() == 1);
    assertTrue(cache.get(new FileHandle(3)) == null);
    assertTrue(cache.get(new FileHandle(4)) != null);
  }
",non-flaky,5
337,apache_hadoop,TestClientAccessPrivilege.testClientAccessPrivilegeForRemove,"  @Test(timeout = 60000)
  public void testClientAccessPrivilegeForRemove() throws Exception {
    // Configure ro access for nfs1 service
    config.set(""dfs.nfs.exports.allowed.hosts"", ""* ro"");

    // Start nfs
    Nfs3 nfs = new Nfs3(config);
    nfs.startServiceInternal(false);

    RpcProgramNfs3 nfsd = (RpcProgramNfs3) nfs.getRpcProgram();

    // Create a remove request
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);

    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeString(""f1"");

    // Remove operation
    REMOVE3Response response = nfsd.remove(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));

    // Assert on return code
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response.getStatus());

  }
",non-flaky,5
338,apache_hadoop,TestExportsTable.testHdfsExportPoint,"  @Test
  public void testHdfsExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;

    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();

      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);

      Mountd mountd = nfsServer.getMountd();
      RpcProgramMountd rpcMount = (RpcProgramMountd) mountd.getRpcProgram();
      assertTrue(rpcMount.getExports().size() == 1);

      String exportInMountd = rpcMount.getExports().get(0);
      assertTrue(exportInMountd.equals(""/""));

    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
339,apache_hadoop,TestExportsTable.testViewFsMultipleExportPoint,"  @Test
  public void testViewFsMultipleExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    String clusterName = RandomStringUtils.randomAlphabetic(10);

    String exportPoint = ""/hdfs1,/hdfs2"";
    config.setStrings(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY, exportPoint);
    config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY,
        FsConstants.VIEWFS_SCHEME + ""://"" + clusterName);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster =
          new MiniDFSCluster.Builder(config).nnTopology(
              MiniDFSNNTopology.simpleFederatedTopology(2))
              .numDataNodes(2)
              .build();
      cluster.waitActive();
      DistributedFileSystem hdfs1 = cluster.getFileSystem(0);
      DistributedFileSystem hdfs2 = cluster.getFileSystem(1);
      cluster.waitActive();
      Path base1 = new Path(""/user1"");
      Path base2 = new Path(""/user2"");
      hdfs1.delete(base1, true);
      hdfs2.delete(base2, true);
      hdfs1.mkdirs(base1);
      hdfs2.mkdirs(base2);
      ConfigUtil.addLink(config, clusterName, ""/hdfs1"",
          hdfs1.makeQualified(base1).toUri());
      ConfigUtil.addLink(config, clusterName, ""/hdfs2"",
          hdfs2.makeQualified(base2).toUri());

      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);

      Mountd mountd = nfsServer.getMountd();
      RpcProgramMountd rpcMount = (RpcProgramMountd) mountd.getRpcProgram();
      assertTrue(rpcMount.getExports().size() == 2);

      String exportInMountd1 = rpcMount.getExports().get(0);
      assertTrue(exportInMountd1.equals(""/hdfs1""));

      String exportInMountd2 = rpcMount.getExports().get(1);
      assertTrue(exportInMountd2.equals(""/hdfs2""));

    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
340,apache_hadoop,TestExportsTable.testViewFsInternalExportPoint,"  @Test
  public void testViewFsInternalExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    String clusterName = RandomStringUtils.randomAlphabetic(10);

    String exportPoint = ""/hdfs1/subpath"";
    config.setStrings(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY, exportPoint);
    config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY,
        FsConstants.VIEWFS_SCHEME + ""://"" + clusterName);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster =
          new MiniDFSCluster.Builder(config).nnTopology(
              MiniDFSNNTopology.simpleFederatedTopology(2))
              .numDataNodes(2)
              .build();
      cluster.waitActive();
      DistributedFileSystem hdfs1 = cluster.getFileSystem(0);
      DistributedFileSystem hdfs2 = cluster.getFileSystem(1);
      cluster.waitActive();
      Path base1 = new Path(""/user1"");
      Path base2 = new Path(""/user2"");
      hdfs1.delete(base1, true);
      hdfs2.delete(base2, true);
      hdfs1.mkdirs(base1);
      hdfs2.mkdirs(base2);
      ConfigUtil.addLink(config, clusterName, ""/hdfs1"",
          hdfs1.makeQualified(base1).toUri());
      ConfigUtil.addLink(config, clusterName, ""/hdfs2"",
          hdfs2.makeQualified(base2).toUri());
      Path subPath = new Path(base1, ""subpath"");
      hdfs1.delete(subPath, true);
      hdfs1.mkdirs(subPath);

      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);

      Mountd mountd = nfsServer.getMountd();
      RpcProgramMountd rpcMount = (RpcProgramMountd) mountd.getRpcProgram();
      assertTrue(rpcMount.getExports().size() == 1);

      String exportInMountd = rpcMount.getExports().get(0);
      assertTrue(exportInMountd.equals(exportPoint));
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
341,apache_hadoop,TestExportsTable.testViewFsRootExportPoint,"  @Test
  public void testViewFsRootExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    String clusterName = RandomStringUtils.randomAlphabetic(10);

    String exportPoint = ""/"";
    config.setStrings(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY, exportPoint);
    config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY,
        FsConstants.VIEWFS_SCHEME + ""://"" + clusterName);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster =
          new MiniDFSCluster.Builder(config).nnTopology(
              MiniDFSNNTopology.simpleFederatedTopology(2))
              .numDataNodes(2)
              .build();
      cluster.waitActive();
      DistributedFileSystem hdfs1 = cluster.getFileSystem(0);
      DistributedFileSystem hdfs2 = cluster.getFileSystem(1);
      cluster.waitActive();
      Path base1 = new Path(""/user1"");
      Path base2 = new Path(""/user2"");
      hdfs1.delete(base1, true);
      hdfs2.delete(base2, true);
      hdfs1.mkdirs(base1);
      hdfs2.mkdirs(base2);
      ConfigUtil.addLink(config, clusterName, ""/hdfs1"",
          hdfs1.makeQualified(base1).toUri());
      ConfigUtil.addLink(config, clusterName, ""/hdfs2"",
          hdfs2.makeQualified(base2).toUri());

      exception.expect(FileSystemException.class);
      exception.
          expectMessage(""Only HDFS is supported as underlyingFileSystem, ""
              + ""fs scheme:viewfs"");
      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
342,apache_hadoop,TestExportsTable.testHdfsInternalExportPoint,"  @Test
  public void testHdfsInternalExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;

    String exportPoint = ""/myexport1"";
    config.setStrings(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY, exportPoint);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");
    Path base = new Path(exportPoint);

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();
      DistributedFileSystem hdfs = cluster.getFileSystem(0);
      hdfs.delete(base, true);
      hdfs.mkdirs(base);

      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);

      Mountd mountd = nfsServer.getMountd();
      RpcProgramMountd rpcMount = (RpcProgramMountd) mountd.getRpcProgram();
      assertTrue(rpcMount.getExports().size() == 1);

      String exportInMountd = rpcMount.getExports().get(0);
      assertTrue(exportInMountd.equals(exportPoint));

    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
343,apache_hadoop,TestExportsTable.testInvalidFsExport,"  @Test
  public void testInvalidFsExport() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;

    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();
      config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY,
          FsConstants.LOCAL_FS_URI.toString());

      exception.expect(FileSystemException.class);
      exception.
          expectMessage(""Only HDFS is supported as underlyingFileSystem, ""
              + ""fs scheme:file"");
      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
344,apache_hadoop,TestMountd.testStart,"  @Test
  public void testStart() throws IOException {
    // Start minicluster
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(config).numDataNodes(1)
        .build();
    cluster.waitActive();
    
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    
    int newTimeoutMillis = 1000; // 1s
    // Set the new portmap rpc timeout values and check
    config.setInt(NfsConfigKeys.NFS_UDP_CLIENT_PORTMAP_TIMEOUT_MILLIS_KEY,
                  newTimeoutMillis);
    assertTrue(config.getInt(
                      NfsConfigKeys.NFS_UDP_CLIENT_PORTMAP_TIMEOUT_MILLIS_KEY,
          0) == newTimeoutMillis);

    // Start nfs
    Nfs3 nfs3 = new Nfs3(config);
    nfs3.startServiceInternal(false);

    RpcProgramMountd mountd = (RpcProgramMountd) nfs3.getMountd()
        .getRpcProgram();
    mountd.nullOp(new XDR(), 1234, InetAddress.getByName(""localhost""));
    assertTrue(mountd.getPortmapUdpTimeoutMillis() == newTimeoutMillis);
    RpcProgramNfs3 nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();
    nfsd.nullProcedure();
    assertTrue(nfsd.getPortmapUdpTimeoutMillis() == newTimeoutMillis);
    
    cluster.shutdown();
  }
",non-flaky,5
345,apache_hadoop,TestNetworkTopology.testContains,"  @Test
  public void testContains() throws Exception {
    DatanodeDescriptor nodeNotInMap = 
      DFSTestUtil.getDatanodeDescriptor(""8.8.8.8"", ""/d2/r4"");
    for (int i=0; i < dataNodes.length; i++) {
      assertTrue(cluster.contains(dataNodes[i]));
    }
    assertFalse(cluster.contains(nodeNotInMap));
  }
",non-flaky,5
346,apache_hadoop,TestNetworkTopology.testNumOfChildren,"  @Test
  public void testNumOfChildren() throws Exception {
    assertEquals(cluster.getNumOfLeaves(), dataNodes.length);
  }
",non-flaky,5
347,apache_hadoop,TestNetworkTopology.testCreateInvalidTopology,"  @Test
  public void testCreateInvalidTopology() throws Exception {
    NetworkTopology invalCluster =
        NetworkTopology.getInstance(new Configuration());
    DatanodeDescriptor invalDataNodes[] = new DatanodeDescriptor[] {
        DFSTestUtil.getDatanodeDescriptor(""1.1.1.1"", ""/d1/r1""),
        DFSTestUtil.getDatanodeDescriptor(""2.2.2.2"", ""/d1/r1""),
        DFSTestUtil.getDatanodeDescriptor(""3.3.3.3"", ""/d1"")
    };
    invalCluster.add(invalDataNodes[0]);
    invalCluster.add(invalDataNodes[1]);
    try {
      invalCluster.add(invalDataNodes[2]);
      fail(""expected InvalidTopologyException"");
    } catch (NetworkTopology.InvalidTopologyException e) {
      assertTrue(e.getMessage().startsWith(""Failed to add ""));
      assertTrue(e.getMessage().contains(
          ""You cannot have a rack and a non-rack node at the same "" +
          ""level of the network topology.""));
    }
  }
",non-flaky,5
348,apache_hadoop,TestNetworkTopology.testRacks,"  @Test
  public void testRacks() throws Exception {
    assertEquals(cluster.getNumOfRacks(), 6);
    assertTrue(cluster.isOnSameRack(dataNodes[0], dataNodes[1]));
    assertFalse(cluster.isOnSameRack(dataNodes[1], dataNodes[2]));
    assertTrue(cluster.isOnSameRack(dataNodes[2], dataNodes[3]));
    assertTrue(cluster.isOnSameRack(dataNodes[3], dataNodes[4]));
    assertFalse(cluster.isOnSameRack(dataNodes[4], dataNodes[5]));
    assertTrue(cluster.isOnSameRack(dataNodes[5], dataNodes[6]));
  }
",non-flaky,5
349,apache_hadoop,TestNetworkTopology.testGetDistance,"  @Test
  public void testGetDistance() throws Exception {
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[0]), 0);
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[1]), 2);
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[3]), 4);
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[6]), 6);
    // verify the distance is zero as long as two nodes have the same path.
    // They don't need to refer to the same object.
    NodeBase node1 = new NodeBase(dataNodes[0].getHostName(),
        dataNodes[0].getNetworkLocation());
    NodeBase node2 = new NodeBase(dataNodes[0].getHostName(),
        dataNodes[0].getNetworkLocation());
    assertEquals(0, cluster.getDistance(node1, node2));
    // verify the distance can be computed by path.
    // They don't need to refer to the same object or parents.
    NodeBase node3 = new NodeBase(dataNodes[3].getHostName(),
        dataNodes[3].getNetworkLocation());
    NodeBase node4 = new NodeBase(dataNodes[6].getHostName(),
        dataNodes[6].getNetworkLocation());
    assertEquals(0, NetworkTopology.getDistanceByPath(node1, node2));
    assertEquals(4, NetworkTopology.getDistanceByPath(node2, node3));
    assertEquals(6, NetworkTopology.getDistanceByPath(node2, node4));
  }
",non-flaky,5
350,apache_hadoop,TestNetworkTopology.testSortByDistance,"  @Test
  public void testSortByDistance() throws Exception {
    DatanodeDescriptor[] testNodes = new DatanodeDescriptor[3];
    
    // array contains both local node & local rack node
    testNodes[0] = dataNodes[1];
    testNodes[1] = dataNodes[2];
    testNodes[2] = dataNodes[0];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[0]);
    assertTrue(testNodes[1] == dataNodes[1]);
    assertTrue(testNodes[2] == dataNodes[2]);

    // array contains both local node & local rack node & decommissioned node
    DatanodeDescriptor[] dtestNodes = new DatanodeDescriptor[5];
    dtestNodes[0] = dataNodes[8];
    dtestNodes[1] = dataNodes[12];
    dtestNodes[2] = dataNodes[11];
    dtestNodes[3] = dataNodes[9];
    dtestNodes[4] = dataNodes[10];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[8], dtestNodes, dtestNodes.length - 2);
    assertTrue(dtestNodes[0] == dataNodes[8]);
    assertTrue(dtestNodes[1] == dataNodes[11]);
    assertTrue(dtestNodes[2] == dataNodes[12]);
    assertTrue(dtestNodes[3] == dataNodes[9]);
    assertTrue(dtestNodes[4] == dataNodes[10]);

    // array contains local node
    testNodes[0] = dataNodes[1];
    testNodes[1] = dataNodes[3];
    testNodes[2] = dataNodes[0];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[0]);
    assertTrue(testNodes[1] == dataNodes[1]);
    assertTrue(testNodes[2] == dataNodes[3]);

    // array contains local rack node
    testNodes[0] = dataNodes[5];
    testNodes[1] = dataNodes[3];
    testNodes[2] = dataNodes[1];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[1]);
    assertTrue(testNodes[1] == dataNodes[3]);
    assertTrue(testNodes[2] == dataNodes[5]);

    // array contains local rack node which happens to be in position 0
    testNodes[0] = dataNodes[1];
    testNodes[1] = dataNodes[5];
    testNodes[2] = dataNodes[3];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[1]);
    assertTrue(testNodes[1] == dataNodes[3]);
    assertTrue(testNodes[2] == dataNodes[5]);

    // Same as previous, but with a different random seed to test randomization
    testNodes[0] = dataNodes[1];
    testNodes[1] = dataNodes[5];
    testNodes[2] = dataNodes[3];
    cluster.setRandomSeed(0xDEAD);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[1]);
    assertTrue(testNodes[1] == dataNodes[3]);
    assertTrue(testNodes[2] == dataNodes[5]);

    // Array of just rack-local nodes
    // Expect a random first node
    DatanodeDescriptor first = null;
    boolean foundRandom = false;
    for (int i=5; i<=7; i++) {
      testNodes[0] = dataNodes[5];
      testNodes[1] = dataNodes[6];
      testNodes[2] = dataNodes[7];
      cluster.sortByDistance(dataNodes[i], testNodes, testNodes.length);
      if (first == null) {
        first = testNodes[0];
      } else {
        if (first != testNodes[0]) {
          foundRandom = true;
          break;
        }
      }
    }
    assertTrue(""Expected to find a different first location"", foundRandom);

    // Array of just remote nodes
    // Expect random first node
    first = null;
    for (int i = 1; i <= 4; i++) {
      testNodes[0] = dataNodes[13];
      testNodes[1] = dataNodes[14];
      testNodes[2] = dataNodes[15];
      cluster.sortByDistance(dataNodes[i], testNodes, testNodes.length);
      if (first == null) {
        first = testNodes[0];
      } else {
        if (first != testNodes[0]) {
          foundRandom = true;
          break;
        }
      }
    }
    assertTrue(""Expected to find a different first location"", foundRandom);

    //Reader is not a datanode, but is in one of the datanode's rack.
    testNodes[0] = dataNodes[0];
    testNodes[1] = dataNodes[5];
    testNodes[2] = dataNodes[8];
    Node rackClient = new NodeBase(""/d3/r1/25.25.25"");
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(rackClient, testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[8]);
    assertTrue(testNodes[1] == dataNodes[5]);
    assertTrue(testNodes[2] == dataNodes[0]);

    //Reader is not a datanode , but is in one of the datanode's data center.
    testNodes[0] = dataNodes[8];
    testNodes[1] = dataNodes[5];
    testNodes[2] = dataNodes[0];
    Node dcClient = new NodeBase(""/d1/r2/25.25.25"");
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dcClient, testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[0]);
    assertTrue(testNodes[1] == dataNodes[5]);
    assertTrue(testNodes[2] == dataNodes[8]);

  }
",non-flaky,5
351,apache_hadoop,TestNetworkTopology.testRemove,"  @Test
  public void testRemove() throws Exception {
    for(int i=0; i<dataNodes.length; i++) {
      cluster.remove(dataNodes[i]);
    }
    for(int i=0; i<dataNodes.length; i++) {
      assertFalse(cluster.contains(dataNodes[i]));
    }
    assertEquals(0, cluster.getNumOfLeaves());
    assertEquals(0, cluster.clusterMap.getChildren().size());
    for(int i=0; i<dataNodes.length; i++) {
      cluster.add(dataNodes[i]);
    }
  }
",non-flaky,5
352,apache_hadoop,TestNetworkTopology.testChooseRandomExcludedNode,"  @Test
  public void testChooseRandomExcludedNode() {
    String scope = ""~"" + NodeBase.getPath(dataNodes[0]);
    Map<Node, Integer> frequency = pickNodesAtRandom(100, scope, null);

    for (Node key : dataNodes) {
      // all nodes except the first should be more than zero
      assertTrue(frequency.get(key) > 0 || key == dataNodes[0]);
    }
  }
",non-flaky,5
353,apache_hadoop,TestNetworkTopology.testChooseRandomExcludedRack,"  @Test
  public void testChooseRandomExcludedRack() {
    Map<Node, Integer> frequency = pickNodesAtRandom(100, ""~"" + ""/d2"", null);
    // all the nodes on the second rack should be zero
    for (int j = 0; j < dataNodes.length; j++) {
      int freq = frequency.get(dataNodes[j]);
      if (dataNodes[j].getNetworkLocation().startsWith(""/d2"")) {
        assertEquals(0, freq);
      } else {
        assertTrue(freq > 0);
      }
    }
  }
",non-flaky,5
354,apache_hadoop,TestNetworkTopology.testChooseRandomExcludedNodeList,"  @Test
  public void testChooseRandomExcludedNodeList() {
    String scope = ""~"" + NodeBase.getPath(dataNodes[0]);
    Set<Node> excludedNodes = new HashSet<>();
    excludedNodes.add(dataNodes[3]);
    excludedNodes.add(dataNodes[5]);
    excludedNodes.add(dataNodes[7]);
    excludedNodes.add(dataNodes[9]);
    excludedNodes.add(dataNodes[13]);
    excludedNodes.add(dataNodes[18]);
    Map<Node, Integer> frequency = pickNodesAtRandom(100, scope, excludedNodes);

    assertEquals(""dn[3] should be excluded"", 0,
        frequency.get(dataNodes[3]).intValue());
    assertEquals(""dn[5] should be exclude18d"", 0,
        frequency.get(dataNodes[5]).intValue());
    assertEquals(""dn[7] should be excluded"", 0,
        frequency.get(dataNodes[7]).intValue());
    assertEquals(""dn[9] should be excluded"", 0,
        frequency.get(dataNodes[9]).intValue());
    assertEquals(""dn[13] should be excluded"", 0,
        frequency.get(dataNodes[13]).intValue());
    assertEquals(""dn[18] should be excluded"", 0,
        frequency.get(dataNodes[18]).intValue());
    for (Node key : dataNodes) {
      if (excludedNodes.contains(key)) {
        continue;
      }
      // all nodes except the first should be more than zero
      assertTrue(frequency.get(key) > 0 || key == dataNodes[0]);
    }
  }
",non-flaky,5
355,apache_hadoop,TestNetworkTopology.testChooseRandomExcludeAllNodes,"  @Test
  public void testChooseRandomExcludeAllNodes() {
    String scope = ""~"" + NodeBase.getPath(dataNodes[0]);
    Set<Node> excludedNodes = new HashSet<>();
    for (int i = 0; i < dataNodes.length; i++) {
      excludedNodes.add(dataNodes[i]);
    }
    Map<Node, Integer> frequency = pickNodesAtRandom(100, scope, excludedNodes);
    for (Node key : dataNodes) {
      // all nodes except the first should be more than zero
      assertTrue(frequency.get(key) == 0);
    }
  }
",non-flaky,5
356,apache_hadoop,TestNetworkTopology.testInvalidNetworkTopologiesNotCachedInHdfs,"  @Test(timeout=180000)
  public void testInvalidNetworkTopologiesNotCachedInHdfs() throws Exception {
    // start a cluster
    Configuration conf = new HdfsConfiguration();
    MiniDFSCluster cluster = null;
    try {
      // bad rack topology
      String racks[] = { ""/a/b"", ""/c"" };
      String hosts[] = { ""foo1.example.com"", ""foo2.example.com"" };
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).
          racks(racks).hosts(hosts).build();
      cluster.waitActive();
      
      NamenodeProtocols nn = cluster.getNameNodeRpc();
      Assert.assertNotNull(nn);
      
      // Wait for one DataNode to register.
      // The other DataNode will not be able to register up because of the rack mismatch.
      DatanodeInfo[] info;
      while (true) {
        info = nn.getDatanodeReport(DatanodeReportType.LIVE);
        Assert.assertFalse(info.length == 2);
        if (info.length == 1) {
          break;
        }
        Thread.sleep(1000);
      }
      // Set the network topology of the other node to the match the network
      // topology of the node that came up.
      int validIdx = info[0].getHostName().equals(hosts[0]) ? 0 : 1;
      int invalidIdx = validIdx == 1 ? 0 : 1;
      StaticMapping.addNodeToRack(hosts[invalidIdx], racks[validIdx]);
      LOG.info(""datanode "" + validIdx + "" came up with network location "" + 
        info[0].getNetworkLocation());

      // Restart the DN with the invalid topology and wait for it to register.
      cluster.restartDataNode(invalidIdx);
      Thread.sleep(5000);
      while (true) {
        info = nn.getDatanodeReport(DatanodeReportType.LIVE);
        if (info.length == 2) {
          break;
        }
        if (info.length == 0) {
          LOG.info(""got no valid DNs"");
        } else if (info.length == 1) {
          LOG.info(""got one valid DN: "" + info[0].getHostName() +
              "" (at "" + info[0].getNetworkLocation() + "")"");
        }
        Thread.sleep(1000);
      }
      Assert.assertEquals(info[0].getNetworkLocation(),
                          info[1].getNetworkLocation());
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
357,apache_hadoop,TestPermission.testBackwardCompatibility,"  @Test
  public void testBackwardCompatibility() {
    // Test 1 - old configuration key with decimal 
    // umask value should be handled when set using 
    // FSPermission.setUMask() API
    FsPermission perm = new FsPermission((short)18);
    Configuration conf = new Configuration();
    FsPermission.setUMask(conf, perm);
    assertEquals(18, FsPermission.getUMask(conf).toShort());

    // Test 2 - new configuration key is handled
    conf = new Configuration();
    conf.set(FsPermission.UMASK_LABEL, ""022"");
    assertEquals(18, FsPermission.getUMask(conf).toShort());

    // Test 3 - equivalent valid umask
    conf = new Configuration();
    conf.set(FsPermission.UMASK_LABEL, ""0022"");
    assertEquals(18, FsPermission.getUMask(conf).toShort());

    // Test 4 - invalid umask
    conf = new Configuration();
    conf.set(FsPermission.UMASK_LABEL, ""1222"");
    try {
      FsPermission.getUMask(conf);
      fail(""expect IllegalArgumentException happen"");
    } catch (IllegalArgumentException e) {
     //pass, exception successfully trigger
    }

    // Test 5 - invalid umask
    conf = new Configuration();
    conf.set(FsPermission.UMASK_LABEL, ""01222"");
    try {
      FsPermission.getUMask(conf);
      fail(""expect IllegalArgumentException happen"");
    } catch (IllegalArgumentException e) {
     //pass, exception successfully trigger
    }
  }
",non-flaky,5
358,apache_hadoop,TestPermission.testCreate,"  @Test
  public void testCreate() throws Exception {
    Configuration conf = new HdfsConfiguration();
    conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, true);
    conf.set(FsPermission.UMASK_LABEL, ""000"");
    MiniDFSCluster cluster = null;
    FileSystem fs = null;

    try {
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
      cluster.waitActive();
      fs = FileSystem.get(conf);
      FsPermission rootPerm = checkPermission(fs, ""/"", null);
      FsPermission inheritPerm = FsPermission.createImmutable(
          (short)(rootPerm.toShort() | 0300));

      FsPermission dirPerm = new FsPermission((short)0777);
      fs.mkdirs(new Path(""/a1/a2/a3""), dirPerm);
      checkPermission(fs, ""/a1"", dirPerm);
      checkPermission(fs, ""/a1/a2"", dirPerm);
      checkPermission(fs, ""/a1/a2/a3"", dirPerm);

      dirPerm = new FsPermission((short)0123);
      FsPermission permission = FsPermission.createImmutable(
        (short)(dirPerm.toShort() | 0300));
      fs.mkdirs(new Path(""/aa/1/aa/2/aa/3""), dirPerm);
      checkPermission(fs, ""/aa/1"", permission);
      checkPermission(fs, ""/aa/1/aa/2"", permission);
      checkPermission(fs, ""/aa/1/aa/2/aa/3"", dirPerm);

      FsPermission filePerm = new FsPermission((short)0444);
      Path p = new Path(""/b1/b2/b3.txt"");
      FSDataOutputStream out = fs.create(p, filePerm,
          true, conf.getInt(CommonConfigurationKeys.IO_FILE_BUFFER_SIZE_KEY, 4096),
          fs.getDefaultReplication(p), fs.getDefaultBlockSize(p), null);
      out.write(123);
      out.close();
      checkPermission(fs, ""/b1"", inheritPerm);
      checkPermission(fs, ""/b1/b2"", inheritPerm);
      checkPermission(fs, ""/b1/b2/b3.txt"", filePerm);
      
      conf.set(FsPermission.UMASK_LABEL, ""022"");
      permission = 
        FsPermission.createImmutable((short)0666);
      FileSystem.mkdirs(fs, new Path(""/c1""), new FsPermission(permission));
      FileSystem.create(fs, new Path(""/c1/c2.txt""),
          new FsPermission(permission));
      checkPermission(fs, ""/c1"", permission);
      checkPermission(fs, ""/c1/c2.txt"", permission);
    } finally {
      try {
        if(fs != null) fs.close();
      } catch(Exception e) {
        LOG.error(StringUtils.stringifyException(e));
      }
      try {
        if(cluster != null) cluster.shutdown();
      } catch(Exception e) {
        LOG.error(StringUtils.stringifyException(e));
      }
    }
  }
",non-flaky,5
359,apache_hadoop,TestPermission.testFilePermission,"  @Test
  public void testFilePermission() throws Exception {
    final Configuration conf = new HdfsConfiguration();
    conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, true);
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    cluster.waitActive();

    try {
      nnfs = FileSystem.get(conf);
      // test permissions on files that do not exist
      assertFalse(nnfs.exists(CHILD_FILE1));
      try {
        nnfs.setPermission(CHILD_FILE1, new FsPermission((short)0777));
        assertTrue(false);
      }
      catch(java.io.FileNotFoundException e) {
        LOG.info(""GOOD: got "" + e);
      }
      
      // make sure nn can take user specified permission (with default fs
      // permission umask applied)
      FSDataOutputStream out = nnfs.create(CHILD_FILE1, new FsPermission(
          (short) 0777), true, 1024, (short) 1, 1024, null);
      FileStatus status = nnfs.getFileStatus(CHILD_FILE1);
      // FS_PERMISSIONS_UMASK_DEFAULT is 0022
      assertTrue(status.getPermission().toString().equals(""rwxr-xr-x""));
      nnfs.delete(CHILD_FILE1, false);
      
      // following dir/file creations are legal
      nnfs.mkdirs(CHILD_DIR1);
      status = nnfs.getFileStatus(CHILD_DIR1);
      assertThat(""Expect 755 = 777 (default dir) - 022 (default umask)"",
          status.getPermission().toString(), is(""rwxr-xr-x""));
      out = nnfs.create(CHILD_FILE1);
      status = nnfs.getFileStatus(CHILD_FILE1);
      assertTrue(status.getPermission().toString().equals(""rw-r--r--""));
      byte data[] = new byte[FILE_LEN];
      RAN.nextBytes(data);
      out.write(data);
      out.close();
      nnfs.setPermission(CHILD_FILE1, new FsPermission(""700""));
      status = nnfs.getFileStatus(CHILD_FILE1);
      assertTrue(status.getPermission().toString().equals(""rwx------""));

      // mkdirs with null permission
      nnfs.mkdirs(CHILD_DIR3, null);
      status = nnfs.getFileStatus(CHILD_DIR3);
      assertThat(""Expect 755 = 777 (default dir) - 022 (default umask)"",
          status.getPermission().toString(), is(""rwxr-xr-x""));

      // following read is legal
      byte dataIn[] = new byte[FILE_LEN];
      FSDataInputStream fin = nnfs.open(CHILD_FILE1);
      int bytesRead = fin.read(dataIn);
      assertTrue(bytesRead == FILE_LEN);
      for(int i=0; i<FILE_LEN; i++) {
        assertEquals(data[i], dataIn[i]);
      }

      // test execution bit support for files
      nnfs.setPermission(CHILD_FILE1, new FsPermission(""755""));
      status = nnfs.getFileStatus(CHILD_FILE1);
      assertTrue(status.getPermission().toString().equals(""rwxr-xr-x""));
      nnfs.setPermission(CHILD_FILE1, new FsPermission(""744""));
      status = nnfs.getFileStatus(CHILD_FILE1);
      assertTrue(status.getPermission().toString().equals(""rwxr--r--""));
      nnfs.setPermission(CHILD_FILE1, new FsPermission(""700""));
      
      ////////////////////////////////////////////////////////////////
      // test illegal file/dir creation
      UserGroupInformation userGroupInfo = 
        UserGroupInformation.createUserForTesting(USER_NAME, GROUP_NAMES );
      
      userfs = DFSTestUtil.getFileSystemAs(userGroupInfo, conf);

      // make sure mkdir of a existing directory that is not owned by 
      // this user does not throw an exception.
      userfs.mkdirs(CHILD_DIR1);
      
      // illegal mkdir
      assertTrue(!canMkdirs(userfs, CHILD_DIR2));

      // illegal file creation
      assertTrue(!canCreate(userfs, CHILD_FILE2));

      // illegal file open
      assertTrue(!canOpen(userfs, CHILD_FILE1));

      nnfs.setPermission(ROOT_PATH, new FsPermission((short)0755));
      nnfs.setPermission(CHILD_DIR1, new FsPermission(""777""));
      nnfs.setPermission(new Path(""/""), new FsPermission((short)0777));
      final Path RENAME_PATH = new Path(""/foo/bar"");
      userfs.mkdirs(RENAME_PATH);
      assertTrue(canRename(userfs, RENAME_PATH, CHILD_DIR1));
      // test permissions on files that do not exist
      assertFalse(userfs.exists(CHILD_FILE3));
      try {
        userfs.setPermission(CHILD_FILE3, new FsPermission((short) 0777));
        fail(""setPermission should fail for non-exist file"");
      } catch (java.io.FileNotFoundException ignored) {
      }

      // Make sure any user can create file in root.
      nnfs.setPermission(ROOT_PATH, new FsPermission(""777""));

      testSuperCanChangeOwnerGroup();
      testNonSuperCanChangeToOwnGroup();
      testNonSuperCannotChangeToOtherGroup();
      testNonSuperCannotChangeGroupForOtherFile();
      testNonSuperCannotChangeGroupForNonExistentFile();
      testNonSuperCannotChangeOwner();
      testNonSuperCannotChangeOwnerForOtherFile();
      testNonSuperCannotChangeOwnerForNonExistentFile();
    } finally {
      cluster.shutdown();
    }
  }
",non-flaky,5
360,apache_hadoop,TestPermissionSymlinks.testDelete,"  @Test(timeout = 5000)
  public void testDelete() throws Exception {
    fs.setPermission(linkParent, new FsPermission((short) 0555));
    doDeleteLinkParentNotWritable();

    fs.setPermission(linkParent, new FsPermission((short) 0777));
    fs.setPermission(targetParent, new FsPermission((short) 0555));
    fs.setPermission(target, new FsPermission((short) 0555));
    doDeleteTargetParentAndTargetNotWritable();
  }
",non-flaky,5
361,apache_hadoop,TestPermissionSymlinks.testAclDelete,"  @Test
  public void testAclDelete() throws Exception {
    fs.setAcl(linkParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doDeleteLinkParentNotWritable();

    fs.setAcl(linkParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    fs.setAcl(targetParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doDeleteTargetParentAndTargetNotWritable();
  }
",non-flaky,5
362,apache_hadoop,TestPermissionSymlinks.testReadWhenTargetNotReadable,"  @Test(timeout = 5000)
  public void testReadWhenTargetNotReadable() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0000));
    doReadTargetNotReadable();
  }
",non-flaky,5
363,apache_hadoop,TestPermissionSymlinks.testAclReadTargetNotReadable,"  @Test
  public void testAclReadTargetNotReadable() throws Exception {
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, READ_WRITE),
      aclEntry(ACCESS, USER, user.getUserName(), NONE),
      aclEntry(ACCESS, GROUP, READ),
      aclEntry(ACCESS, OTHER, READ)));
    doReadTargetNotReadable();
  }
",non-flaky,5
364,apache_hadoop,TestPermissionSymlinks.testFileStatus,"  @Test(timeout = 5000)
  public void testFileStatus() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0000));
    doGetFileLinkStatusTargetNotReadable();
  }
",non-flaky,5
365,apache_hadoop,TestPermissionSymlinks.testAclGetFileLinkStatusTargetNotReadable,"  @Test
  public void testAclGetFileLinkStatusTargetNotReadable() throws Exception {
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, READ_WRITE),
      aclEntry(ACCESS, USER, user.getUserName(), NONE),
      aclEntry(ACCESS, GROUP, READ),
      aclEntry(ACCESS, OTHER, READ)));
    doGetFileLinkStatusTargetNotReadable();
  }
",non-flaky,5
366,apache_hadoop,TestPermissionSymlinks.testRenameLinkTargetNotWritableFC,"  @Test(timeout = 5000)
  public void testRenameLinkTargetNotWritableFC() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0555));
    fs.setPermission(targetParent, new FsPermission((short) 0555));
    doRenameLinkTargetNotWritableFC();
  }
",non-flaky,5
367,apache_hadoop,TestPermissionSymlinks.testAclRenameTargetNotWritableFC,"  @Test
  public void testAclRenameTargetNotWritableFC() throws Exception {
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    fs.setAcl(targetParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doRenameLinkTargetNotWritableFC();
  }
",non-flaky,5
368,apache_hadoop,TestPermissionSymlinks.testRenameSrcNotWritableFC,"  @Test(timeout = 5000)
  public void testRenameSrcNotWritableFC() throws Exception {
    fs.setPermission(linkParent, new FsPermission((short) 0555));
    doRenameSrcNotWritableFC();
  }
",non-flaky,5
369,apache_hadoop,TestPermissionSymlinks.testAclRenameSrcNotWritableFC,"  @Test
  public void testAclRenameSrcNotWritableFC() throws Exception {
    fs.setAcl(linkParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doRenameSrcNotWritableFC();
  }
",non-flaky,5
370,apache_hadoop,TestPermissionSymlinks.testRenameLinkTargetNotWritableFS,"  @Test(timeout = 5000)
  public void testRenameLinkTargetNotWritableFS() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0555));
    fs.setPermission(targetParent, new FsPermission((short) 0555));
    doRenameLinkTargetNotWritableFS();
  }
",non-flaky,5
371,apache_hadoop,TestPermissionSymlinks.testAclRenameTargetNotWritableFS,"  @Test
  public void testAclRenameTargetNotWritableFS() throws Exception {
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    fs.setAcl(targetParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doRenameLinkTargetNotWritableFS();
  }
",non-flaky,5
372,apache_hadoop,TestPermissionSymlinks.testRenameSrcNotWritableFS,"  @Test(timeout = 5000)
  public void testRenameSrcNotWritableFS() throws Exception {
    fs.setPermission(linkParent, new FsPermission((short) 0555));
    doRenameSrcNotWritableFS();
  }
",non-flaky,5
373,apache_hadoop,TestPermissionSymlinks.testAclRenameSrcNotWritableFS,"  @Test
  public void testAclRenameSrcNotWritableFS() throws Exception {
    fs.setAcl(linkParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doRenameSrcNotWritableFS();
  }
",non-flaky,5
374,apache_hadoop,TestPermissionSymlinks.run,"  @Test
  public void testAccess() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0002));
    fs.setAcl(target, Arrays.asList(
        aclEntry(ACCESS, USER, ALL),
        aclEntry(ACCESS, GROUP, NONE),
        aclEntry(ACCESS, USER, user.getShortUserName(), WRITE),
        aclEntry(ACCESS, OTHER, WRITE)));
    FileContext myfc = user.doAs(new PrivilegedExceptionAction<FileContext>() {
      @Override
      public FileContext run() throws IOException {
        return FileContext.getFileContext(conf);
      }
",non-flaky,5
375,apache_hadoop,TestRefreshUserMappings.testGroupMappingRefresh,"  @Test
  public void testGroupMappingRefresh() throws Exception {
    DFSAdmin admin = new DFSAdmin(config);
    String [] args =  new String[]{""-refreshUserToGroupsMappings""};
    Groups groups = Groups.getUserToGroupsMappingService(config);
    String user = UserGroupInformation.getCurrentUser().getUserName();
    System.out.println(""first attempt:"");
    List<String> g1 = groups.getGroups(user);
    String [] str_groups = new String [g1.size()];
    g1.toArray(str_groups);
    System.out.println(Arrays.toString(str_groups));
    
    System.out.println(""second attempt, should be same:"");
    List<String> g2 = groups.getGroups(user);
    g2.toArray(str_groups);
    System.out.println(Arrays.toString(str_groups));
    for(int i=0; i<g2.size(); i++) {
      assertEquals(""Should be same group "", g1.get(i), g2.get(i));
    }
    admin.run(args);
    System.out.println(""third attempt(after refresh command), should be different:"");
    List<String> g3 = groups.getGroups(user);
    g3.toArray(str_groups);
    System.out.println(Arrays.toString(str_groups));
    for(int i=0; i<g3.size(); i++) {
      assertFalse(""Should be different group: "" + g1.get(i) + "" and "" + g3.get(i), 
          g1.get(i).equals(g3.get(i)));
    }
    
    // test time out
    Thread.sleep(groupRefreshTimeoutSec*1100);
    System.out.println(""fourth attempt(after timeout), should be different:"");
    List<String> g4 = groups.getGroups(user);
    g4.toArray(str_groups);
    System.out.println(Arrays.toString(str_groups));
    for(int i=0; i<g4.size(); i++) {
      assertFalse(""Should be different group "", g3.get(i).equals(g4.get(i)));
    }
  }
",non-flaky,5
376,apache_hadoop,TestRefreshUserMappings.testRefreshSuperUserGroupsConfiguration,"  @Test
  public void testRefreshSuperUserGroupsConfiguration() throws Exception {
    final String SUPER_USER = ""super_user"";
    final List<String> groupNames1 = new ArrayList<>();
    groupNames1.add(""gr1"");
    groupNames1.add(""gr2"");
    final List<String> groupNames2 = new ArrayList<>();
    groupNames2.add(""gr3"");
    groupNames2.add(""gr4"");

    //keys in conf
    String userKeyGroups = DefaultImpersonationProvider.getTestProvider().
        getProxySuperuserGroupConfKey(SUPER_USER);
    String userKeyHosts = DefaultImpersonationProvider.getTestProvider().
        getProxySuperuserIpConfKey (SUPER_USER);
    
    config.set(userKeyGroups, ""gr3,gr4,gr5""); // superuser can proxy for this group
    config.set(userKeyHosts,""127.0.0.1"");
    ProxyUsers.refreshSuperUserGroupsConfiguration(config);
    
    UserGroupInformation ugi1 = mock(UserGroupInformation.class);
    UserGroupInformation ugi2 = mock(UserGroupInformation.class);
    UserGroupInformation suUgi = mock(UserGroupInformation.class);
    when(ugi1.getRealUser()).thenReturn(suUgi);
    when(ugi2.getRealUser()).thenReturn(suUgi);

    when(suUgi.getShortUserName()).thenReturn(SUPER_USER); // super user
    when(suUgi.getUserName()).thenReturn(SUPER_USER+""L""); // super user
     
    when(ugi1.getShortUserName()).thenReturn(""user1"");
    when(ugi2.getShortUserName()).thenReturn(""user2"");
    
    when(ugi1.getUserName()).thenReturn(""userL1"");
    when(ugi2.getUserName()).thenReturn(""userL2"");

    // set groups for users
    when(ugi1.getGroups()).thenReturn(groupNames1);
    when(ugi2.getGroups()).thenReturn(groupNames2);


    // check before
    try {
      ProxyUsers.authorize(ugi1, ""127.0.0.1"");
      fail(""first auth for "" + ugi1.getShortUserName() + "" should've failed "");
    } catch (AuthorizationException e) {
      // expected
      System.err.println(""auth for "" + ugi1.getUserName() + "" failed"");
    }
    try {
      ProxyUsers.authorize(ugi2, ""127.0.0.1"");
      System.err.println(""auth for "" + ugi2.getUserName() + "" succeeded"");
      // expected
    } catch (AuthorizationException e) {
      fail(""first auth for "" + ugi2.getShortUserName() + "" should've succeeded: "" + e.getLocalizedMessage());
    }
    
    // refresh will look at configuration on the server side
    // add additional resource with the new value
    // so the server side will pick it up
    String rsrc = ""testGroupMappingRefresh_rsrc.xml"";
    addNewConfigResource(rsrc, userKeyGroups, ""gr2"", userKeyHosts, ""127.0.0.1"");  
    
    DFSAdmin admin = new DFSAdmin(config);
    String [] args = new String[]{""-refreshSuperUserGroupsConfiguration""};
    admin.run(args);
    
    try {
      ProxyUsers.authorize(ugi2, ""127.0.0.1"");
      fail(""second auth for "" + ugi2.getShortUserName() + "" should've failed "");
    } catch (AuthorizationException e) {
      // expected
      System.err.println(""auth for "" + ugi2.getUserName() + "" failed"");
    }
    try {
      ProxyUsers.authorize(ugi1, ""127.0.0.1"");
      System.err.println(""auth for "" + ugi1.getUserName() + "" succeeded"");
      // expected
    } catch (AuthorizationException e) {
      fail(""second auth for "" + ugi1.getShortUserName() + "" should've succeeded: "" + e.getLocalizedMessage());
    }
    
    
  }
",non-flaky,5
377,apache_hadoop,TestFcHdfsSetUMask.testMkdirWithExistingDirClear,"  @Test
  public void testMkdirWithExistingDirClear() throws IOException {
    testMkdirWithExistingDir(BLANK_TEST_UMASK, BLANK_PERMISSIONS);
  }
",non-flaky,5
378,apache_hadoop,TestFcHdfsSetUMask.testMkdirWithExistingDirOpen,"  @Test
  public void testMkdirWithExistingDirOpen() throws IOException {
    testMkdirWithExistingDir(WIDE_OPEN_TEST_UMASK, WIDE_OPEN_PERMISSIONS);
  }
",non-flaky,5
379,apache_hadoop,TestFcHdfsSetUMask.testMkdirWithExistingDirMiddle,"  @Test
  public void testMkdirWithExistingDirMiddle() throws IOException {
    testMkdirWithExistingDir(USER_GROUP_OPEN_TEST_UMASK,
        USER_GROUP_OPEN_PERMISSIONS);
  }
",non-flaky,5
380,apache_hadoop,TestFcHdfsSetUMask.testMkdirRecursiveWithNonExistingDirClear,"  @Test
  public void testMkdirRecursiveWithNonExistingDirClear() throws IOException {
    // by default parent directories have -wx------ bits set
    testMkdirRecursiveWithNonExistingDir(BLANK_TEST_UMASK, BLANK_PERMISSIONS, 
        PARENT_PERMS_FOR_BLANK_PERMISSIONS);
  }
",non-flaky,5
2,neo4j_neo4j,RobustJobSchedulerWrapperTest.shouldBeAbleToCancelJob,"@Test
public void shouldBeAbleToCancelJob() throws Exception {
    RobustJobSchedulerWrapper robustWrapper = new RobustJobSchedulerWrapper(actualScheduler, log);
    AtomicInteger count = new AtomicInteger();
    JobHandle jobHandle = robustWrapper.scheduleRecurring(""JobName"", 1, count::incrementAndGet);
    assertEventually(""run count"", count::get, Matchers.greaterThanOrEqualTo(100), DEFAULT_TIMEOUT_MS, MILLISECONDS);
    robustWrapper.cancelAndWaitTermination(jobHandle);
    int finalCount = count.get();
    Thread.sleep(50);
    assertEquals(finalCount, count.get());
}",concurrency,1
14,neo4j_neo4j,RobustJobSchedulerWrapperTest.recurringJobWithExceptionShouldKeepRunning,"@Test
public void recurringJobWithExceptionShouldKeepRunning() throws Exception
{
    RobustJobSchedulerWrapper robustWrapper = new RobustJobSchedulerWrapper( actualScheduler, log );
    AtomicInteger count = new AtomicInteger();
    IllegalStateException e = new IllegalStateException();
    int nRuns = 100;
    JobHandle jobHandle = robustWrapper.scheduleRecurring( ""JobName"", 1, () -> {
        if ( count.get() < nRuns )
        {
            count.incrementAndGet();
            throw e;
        }
    }
    );
    assertEventually( ""run count"", count::get, Matchers.equalTo( nRuns ), DEFAULT_TIMEOUT_MS , MILLISECONDS );
    robustWrapper.cancelAndWaitTermination( jobHandle );
    verify( log, timeout( DEFAULT_TIMEOUT_MS ).times( nRuns ) ).warn( ""Uncaught exception"", e );
}",concurrency,1
128,neo4j_neo4j,createdWorkerThreadsShouldContainConnectorName,"@Test
public void createdWorkerThreadsShouldContainConnectorName() throws Exception
{
    AtomicInteger processNextBatchCount = new AtomicInteger();
    AtomicReference<Thread> poolThread = new AtomicReference<>();
    AtomicReference<String> poolThreadName = new AtomicReference<>();
    String id = UUID.randomUUID().toString();
    BoltConnection connection = newConnection( id );
    when( connection.processNextBatch() ).thenAnswer( inv ->
    {
        poolThread.set( Thread.currentThread() );
        poolThreadName.set( Thread.currentThread().getName() );
        processNextBatchCount.incrementAndGet();
        return true;
    } );
    boltScheduler.start();
    boltScheduler.created( connection );
    boltScheduler.enqueued( connection, Jobs.noop() );
    Predicates.await( () -> processNextBatchCount.get() > 0, 1, MINUTES );
    assertThat( poolThread.get().getName(), not( equalTo( poolThreadName.get() ) ) );
    assertThat( poolThread.get().getName(), containsString( String.format( ""[%s]"", CONNECTOR_KEY ) ) );
    assertThat( poolThread.get().getName(), not( containsString( String.format( ""[%s]"", connection.remoteAddress() ) ) ) );
}",concurrency,1
167,neo4j_neo4j,RaftMessageProcessingMetricTest.shouldBeAbleToUpdateAllMessageTypes,"@Test
public void shouldBeAbleToUpdateAllMessageTypes() throws Throwable
{
    int durationNanos = 5;
    for ( RaftMessages.Type type : RaftMessages.Type.values() )
    {
        metric.updateTimer( type, Duration.ofNanos( durationNanos ) );
        assertEquals( 1, metric.timer( type ).getCount() );
        assertEquals( durationNanos, metric.timer( type ).getSnapshot().getMean(), 0 );
    }
    assertEquals( RaftMessages.Type.values().length, metric.timer().getCount() );
    assertEquals( 0, metric.timer().getSnapshot().getMean(), durationNanos );
}",time,2
215,neo4j_neo4j,shouldPickANewServerToWriteToOnLeaderSwitch,"@Test
public void shouldPickANewServerToWriteToOnLeaderSwitch() throws Throwable
{
    cluster = clusterRule.withNumberOfEdgeMembers( 0 ).startCluster();
    CoreClusterMember leader = cluster.awaitLeader();
    CountDownLatch startTheLeaderSwitching = new CountDownLatch( 1 );
    Thread thread = new Thread( () ->
    {
        try
        {
            startTheLeaderSwitching.await();
            CoreClusterMember theLeader = cluster.awaitLeader();
            switchLeader( theLeader );
        }
        catch ( TimeoutException | InterruptedException e )
        {
        }
    } );
    thread.start();
    Config config = Config.build().withLogging( new JULogging( Level.OFF ) ).toConfig();
    try ( Driver driver = GraphDatabase
    .driver( leader.routingURI(), AuthTokens.basic( ""neo4j"", ""neo4j"" ), config ) )
    {
        boolean success = false;
        Set<BoltServerAddress> seenAddresses = new HashSet<>();
        long deadline = System.currentTimeMillis() + (30 * 1000);
        while ( !success )
        {
            if ( System.currentTimeMillis() > deadline )
            {
                fail( ""Failed to write to the new leader in time"" );
            }
            try ( Session session = driver.session( AccessMode.WRITE ) )
            {
                startTheLeaderSwitching.countDown();
                BoltServerAddress boltServerAddress = ((RoutingNetworkSession) session).address();
                seenAddresses.add( boltServerAddress );
                session.run( ""CREATE (p:Person)"" );
                success = seenAddresses.size() >= 2;
            }
            catch ( Exception e )
            {
                Thread.sleep( 100 );
            }
        }
    }
    finally
    {
        thread.join();
    }
}",concurrency,1
253,neo4j_neo4j,RobustJobSchedulerWrapperTest.recurringJobWithErrorShouldStop,"@Test
public void recurringJobWithErrorShouldStop() throws Exception
{
    RobustJobSchedulerWrapper robustWrapper = new RobustJobSchedulerWrapper( actualScheduler, log );
    AtomicInteger count = new AtomicInteger();
    Error e = new Error();
    JobHandle jobHandle = robustWrapper.scheduleRecurring( ""JobName"", 1, () ->{
        count.incrementAndGet();
        throw e;
    }
    );
    Thread.sleep( 50 );
    assertEventually( ""run count"", count::get, Matchers.equalTo( 1 ), DEFAULT_TIMEOUT_MS , MILLISECONDS );
    robustWrapper.cancelAndWaitTermination( jobHandle );
    verify( log, timeout( DEFAULT_TIMEOUT_MS ).times( 1 ) ).error( ""Uncaught error rethrown"", e );
}",concurrency,1
285,neo4j_neo4j,shouldBuildUpGracefullyUntilReachedMinPoolSize,"@Test
public void shouldBuildUpGracefullyUntilReachedMinPoolSize() throws InterruptedException
{
    StatefulMonitor stateMonitor = new StatefulMonitor();
    FakeClock clock = new FakeClock();
    final LinkedQueuePool<Object> pool = getLinkedQueuePool( stateMonitor, clock, 5 );
    ExecutorService executor = Executors.newCachedThreadPool();
    List<FlyweightHolder<Object>> flyweightHolders = acquireFromPool( pool, 5, executor );
    executor.shutdown();
    for ( FlyweightHolder<Object> flyweightHolder : flyweightHolders )
    {
        flyweightHolder.release();
    }
    executor.awaitTermination( 10, TimeUnit.SECONDS );
    assertEquals( -1, stateMonitor.currentPeakSize.get() );
    assertEquals( -1, stateMonitor.targetSize.get() );
    assertEquals( 0, stateMonitor.disposed.get() );
}",concurrency,1
293,neo4j_neo4j,schema.IndexPopulationIT.shutdownDatabaseDuringIndexPopulations,"@Test
public void shutdownDatabaseDuringIndexPopulations() {
    AssertableLogProvider assertableLogProvider = new AssertableLogProvider(true);
    File storeDir = directory.directory(""shutdownDbTest"");
    Label testLabel = Label.label(""testLabel"");
    String propertyName = ""testProperty"";
    GraphDatabaseService shutDownDb = new TestGraphDatabaseFactory().setInternalLogProvider(assertableLogProvider).newEmbeddedDatabase(storeDir);
    prePopulateDatabase(shutDownDb, testLabel, propertyName);
    try (final Transaction transaction = shutDownDb.beginTx()) {
        shutDownDb.schema().indexFor(testLabel).on(propertyName).create();
        transaction.success();
    }
    shutDownDb.shutdown();
    assertableLogProvider.assertNone(AssertableLogProvider.inLog(IndexPopulationJob.class).anyError());
}",concurrency,1
13832,neo4j_neo4j,LoggingResourcePoolMonitorTest.testUpdatedCurrentPeakSizeLogsOnlyOnChange,"    @Test
    public void testUpdatedCurrentPeakSizeLogsOnlyOnChange() throws Exception
    {
        StringLogger logger = mock( StringLogger.class );
        LoggingResourcePoolMonitor monitor = new LoggingResourcePoolMonitor( logger );

        monitor.updatedCurrentPeakSize( 10 );
        verify( logger, times( 1 ) ).debug( anyString() );

        monitor.updatedCurrentPeakSize( 10 );
        verify( logger, times( 1 ) ).debug( anyString() );

        monitor.updatedCurrentPeakSize( 11 );
        verify( logger, times( 2 ) ).debug( anyString() );
    }
",non-flaky,5
13833,neo4j_neo4j,LoggingResourcePoolMonitorTest.testUpdatedTargetSizeOnlyOnChange,"    @Test
    public void testUpdatedTargetSizeOnlyOnChange() throws Exception
    {
        StringLogger logger = mock( StringLogger.class );
        LoggingResourcePoolMonitor monitor = new LoggingResourcePoolMonitor( logger );

        monitor.updatedTargetSize( 10 );
        verify( logger, times( 1 ) ).debug( anyString() );

        monitor.updatedTargetSize( 10 );
        verify( logger, times( 1 ) ).debug( anyString() );

        monitor.updatedTargetSize( 11 );
        verify( logger, times( 2 ) ).debug( anyString() );
    }
",non-flaky,5
13834,neo4j_neo4j,ResponsePackerTest.obligation,"    @Test
    public void shouldHaveFixedTargetTransactionIdEvenIfLastTransactionIdIsMoving() throws Exception
    {
        // GIVEN
        LogicalTransactionStore transactionStore = mock( LogicalTransactionStore.class );
        long lastAppliedTransactionId = 5L;
        IOCursor<CommittedTransactionRepresentation> endlessCursor = new EndlessCursor( lastAppliedTransactionId+1 );
        when( transactionStore.getTransactions( anyLong() ) ).thenReturn( endlessCursor );
        final long targetTransactionId = 8L;
        final TransactionIdStore transactionIdStore = new DeadSimpleTransactionIdStore( targetTransactionId, 0 );
        ResponsePacker packer = new ResponsePacker( transactionStore, transactionIdStore,
                singletonProvider( new StoreId() ) );

        // WHEN
        Response<Object> response = packer.packTransactionStreamResponse( requestContextStartingAt( 5L ), null );
        final AtomicLong nextExpectedVisit = new AtomicLong( lastAppliedTransactionId );
        response.accept( new Response.Handler()
        {
            @Override
            public void obligation( long txId ) throws IOException
            {
                fail( ""Should not be called"" );
            }
",non-flaky,5
13835,neo4j_neo4j,StoreCopyClientTest.shouldCopyStoreFilesAcrossIfACancellationRequestHappensAfterTheTempStoreHasBeenRecovered,"    @Test
    public void shouldCopyStoreFilesAcrossIfACancellationRequestHappensAfterTheTempStoreHasBeenRecovered()
            throws IOException
",non-flaky,5
13836,neo4j_neo4j,StoreCopyClientTest.shouldEndUpWithAnEmptyStoreIfCancellationRequestIssuedJustBeforeRecoveryTakesPlace,"    @Test
    public void shouldEndUpWithAnEmptyStoreIfCancellationRequestIssuedJustBeforeRecoveryTakesPlace()
            throws IOException
",non-flaky,5
13837,neo4j_neo4j,TransactionCommittingResponseUnpackerTest.testStopShouldAllowTransactionsToCompleteCommitAndApply,"    @Test
    public void testStopShouldAllowTransactionsToCompleteCommitAndApply() throws Throwable
    {
        // Given

        // Handcrafted deep mocks, otherwise the dependency resolution throws ClassCastExceptions
        DependencyResolver dependencyResolver = mock( DependencyResolver.class );
        TransactionIdStore txIdStore = mock( TransactionIdStore.class );

        when( dependencyResolver.resolveDependency( TransactionIdStore.class ) ).thenReturn( txIdStore );

        TransactionAppender appender = mockedTransactionAppender();
        LogicalTransactionStore logicalTransactionStore = mock( LogicalTransactionStore.class );
        when( logicalTransactionStore.getAppender() ).thenReturn( appender );
        when( dependencyResolver.resolveDependency( LogicalTransactionStore.class ) )
                .thenReturn( logicalTransactionStore );

        when( dependencyResolver.resolveDependency( TransactionRepresentationStoreApplier.class ) )
                .thenReturn( mock( TransactionRepresentationStoreApplier.class ) );
        LogFile logFile = mock( LogFile.class );
        when( dependencyResolver.resolveDependency( LogFile.class ) ).thenReturn( logFile );
        LogRotation logRotation = mock(LogRotation.class);
        when( dependencyResolver.resolveDependency( LogRotation.class ) ).thenReturn( logRotation );

        setUpIndexUpdatesValidatorMocking( dependencyResolver );

          /*
           * The tx handler is called on every transaction applied after setting its id to committing
           * but before setting it to applied. We use this to stop the unpacker in the middle of the
           * process.
           */
        StoppingTxHandler stoppingTxHandler = new StoppingTxHandler();

        int maxBatchSize = 10;
        TransactionCommittingResponseUnpacker unpacker = new TransactionCommittingResponseUnpacker(
                dependencyResolver, maxBatchSize );
        stoppingTxHandler.setUnpacker( unpacker );

        // When
        unpacker.start();
        long committingTransactionId = BASE_TX_ID + 1;
        DummyTransactionResponse response = new DummyTransactionResponse( committingTransactionId, 1, appender, maxBatchSize );
        unpacker.unpackResponse( response, stoppingTxHandler );

        // Then
        // we can't verify transactionCommitted since that's part of the TransactionAppender, which we have mocked
        verify( txIdStore, times( 1 ) ).transactionClosed( committingTransactionId );
        verify( appender, times( 1 ) ).append( any( TransactionRepresentation.class ), anyLong() );
        verify( appender, times( 1 ) ).force();
        verify( logRotation, times( 1 ) ).rotateLogIfNeeded( logAppendEvent );

        // Then
          // The txhandler has stopped the unpacker. It should not allow any more transactions to go through
        try
        {
            unpacker.unpackResponse( mock( Response.class ), stoppingTxHandler );
            fail( ""A stopped transaction unpacker should not allow transactions to be applied"" );
        }
        catch( IllegalStateException e)
        {
            // good
        }
        verifyNoMoreInteractions( txIdStore );
        verifyNoMoreInteractions( appender );
    }
",non-flaky,5
13838,neo4j_neo4j,TransactionCommittingResponseUnpackerTest.shouldApplyQueuedTransactionsIfMany,"    @Test
    public void shouldApplyQueuedTransactionsIfMany() throws Throwable
    {
        // GIVEN
        DependencyResolver dependencyResolver = mock( DependencyResolver.class );
        TransactionIdStore txIdStore = mock( TransactionIdStore.class );

        when( dependencyResolver.resolveDependency( TransactionIdStore.class ) ).thenReturn( txIdStore );

        TransactionAppender appender = mockedTransactionAppender();
        LogicalTransactionStore logicalTransactionStore = mock( LogicalTransactionStore.class );
        when( logicalTransactionStore.getAppender() ).thenReturn( appender );
        when( dependencyResolver.resolveDependency( LogicalTransactionStore.class ) )
                .thenReturn( logicalTransactionStore );

        when( dependencyResolver.resolveDependency( TransactionRepresentationStoreApplier.class ) )
                .thenReturn( mock( TransactionRepresentationStoreApplier.class ) );

        setUpIndexUpdatesValidatorMocking( dependencyResolver );

        LogFile logFile = mock( LogFile.class );
        when( dependencyResolver.resolveDependency( LogFile.class ) ).thenReturn( logFile );

        LogRotation logRotation = mock(LogRotation.class);
        when( dependencyResolver.resolveDependency( LogRotation.class ) ).thenReturn( logRotation );

        int maxBatchSize = 3;
        TransactionCommittingResponseUnpacker unpacker = new TransactionCommittingResponseUnpacker(
                dependencyResolver, maxBatchSize );
        unpacker.start();

        // WHEN/THEN
        int txCount = maxBatchSize * 2 - 1;
        unpacker.unpackResponse( new DummyTransactionResponse( 2, txCount, appender, maxBatchSize ), NO_OP_TX_HANDLER );

        // and THEN
        verify( appender, times( txCount ) ).append( any( TransactionRepresentation.class ), anyLong() );
        verify( appender, times( 2 ) ).force();
        verify( logRotation, times( 2 ) ).rotateLogIfNeeded( logAppendEvent );
    }
",non-flaky,5
13839,neo4j_neo4j,TransactionCommittingResponseUnpackerTest.shouldAwaitTransactionObligationsToBeFulfilled,"    @Test
    public void shouldAwaitTransactionObligationsToBeFulfilled() throws Throwable
    {
        // GIVEN
        DependencyResolver dependencyResolver = mock( DependencyResolver.class );

        TransactionIdStore txIdStore = mock( TransactionIdStore.class );
        when( dependencyResolver.resolveDependency( TransactionIdStore.class ) ).thenReturn( txIdStore );

        TransactionAppender appender = mock( TransactionAppender.class );
        LogicalTransactionStore logicalTransactionStore = mock( LogicalTransactionStore.class );
        when( logicalTransactionStore.getAppender() ).thenReturn( appender );
        when( dependencyResolver.resolveDependency( LogicalTransactionStore.class ) )
                .thenReturn( logicalTransactionStore );

        when( dependencyResolver.resolveDependency( TransactionRepresentationStoreApplier.class ) )
                .thenReturn( mock( TransactionRepresentationStoreApplier.class ) );
        TransactionObligationFulfiller obligationFulfiller = mock( TransactionObligationFulfiller.class );
        when( dependencyResolver.resolveDependency( TransactionObligationFulfiller.class ) )
                .thenReturn( obligationFulfiller );
        final TransactionCommittingResponseUnpacker unpacker = new TransactionCommittingResponseUnpacker(
                dependencyResolver );
        unpacker.start();

        // WHEN
        unpacker.unpackResponse( new DummyObligationResponse( 4 ), NO_OP_TX_HANDLER );

        // THEN
        verify( obligationFulfiller, times( 1 ) ).fulfill( 4l );
    }
",non-flaky,5
13840,neo4j_neo4j,TransactionCommittingResponseUnpackerTest.shouldIssueKernelPanicInCaseOfFailureToAppendOrApply,"    @Test
    public void shouldIssueKernelPanicInCaseOfFailureToAppendOrApply() throws Throwable
    {
        // GIVEN
        DependencyResolver dependencyResolver = mock( DependencyResolver.class );

        TransactionIdStore txIdStore = mock( TransactionIdStore.class );
        when( dependencyResolver.resolveDependency( TransactionIdStore.class ) ).thenReturn( txIdStore );

        TransactionAppender appender = mock( TransactionAppender.class );
        LogicalTransactionStore logicalTransactionStore = mock( LogicalTransactionStore.class );
        when( logicalTransactionStore.getAppender() ).thenReturn( appender );
        when( dependencyResolver.resolveDependency( LogicalTransactionStore.class ) )
                .thenReturn( logicalTransactionStore );

        when( dependencyResolver.resolveDependency( TransactionRepresentationStoreApplier.class ) )
                .thenReturn( mock( TransactionRepresentationStoreApplier.class ) );
        TransactionObligationFulfiller obligationFulfiller = mock( TransactionObligationFulfiller.class );
        when( dependencyResolver.resolveDependency( TransactionObligationFulfiller.class ) )
                .thenReturn( obligationFulfiller );
        LogFile logFile = mock( LogFile.class );
        when( dependencyResolver.resolveDependency( LogFile.class ) ).thenReturn( logFile );
        KernelHealth kernelHealth = mock( KernelHealth.class );
        when( dependencyResolver.resolveDependency( KernelHealth.class ) ).thenReturn( kernelHealth );
        LogRotation logRotation = mock(LogRotation.class);
        when( dependencyResolver.resolveDependency( LogRotation.class ) ).thenReturn( logRotation );
        final TransactionCommittingResponseUnpacker unpacker = new TransactionCommittingResponseUnpacker(
                dependencyResolver );
        unpacker.start();

        // WHEN failing to append one or more transactions from a transaction stream response
        IOException failure = new IOException( ""Expected failure"" );
        doThrow( failure ).when( appender ).append( any( TransactionRepresentation.class ), anyLong() );
        try
        {
            unpacker.unpackResponse(
                    new DummyTransactionResponse( BASE_TX_ID+1, 1, appender, 10 ), NO_OP_TX_HANDLER );
            fail( ""Should have failed"" );
        }
        catch ( IOException e )
        {
            assertThat( e.getMessage(), containsString( failure.getMessage() ) );
            verify( kernelHealth ).panic( failure );
        }
    }
",non-flaky,5
13841,neo4j_neo4j,TransactionCommittingResponseUnpackerTest.shouldNotApplyTransactionIfIndexUpdatesValidationFails,"    @Test
    public void shouldNotApplyTransactionIfIndexUpdatesValidationFails() throws Throwable
    {
        // Given
        DependencyResolver resolver = mock( DependencyResolver.class );

        when( resolver.resolveDependency( LogFile.class ) ).thenReturn( mock( LogFile.class ) );
        when( resolver.resolveDependency( LogRotation.class ) ).thenReturn( mock( LogRotation.class ) );
        when( resolver.resolveDependency( TransactionIdStore.class ) ).thenReturn( mock( TransactionIdStore.class ) );
        KernelHealth kernelHealth = mock( KernelHealth.class );
        when( resolver.resolveDependency( KernelHealth.class ) ).thenReturn( kernelHealth );
        LogicalTransactionStore txStore = mock( LogicalTransactionStore.class );
        TransactionAppender appender = mockedTransactionAppender();
        when( txStore.getAppender() ).thenReturn( appender );
        when( resolver.resolveDependency( LogicalTransactionStore.class ) ).thenReturn( txStore );
        TransactionRepresentationStoreApplier storeApplier = mock( TransactionRepresentationStoreApplier.class );
        when( resolver.resolveDependency( TransactionRepresentationStoreApplier.class ) ).thenReturn( storeApplier );

        IndexUpdatesValidator validator = mock( IndexUpdatesValidator.class );
        IOException error = new IOException( ""error"" );
        when( validator.validate( any( TransactionRepresentation.class ), eq( TransactionApplicationMode.EXTERNAL ) ) )
                .thenThrow( error );
        when( resolver.resolveDependency( IndexUpdatesValidator.class ) ).thenReturn( validator );

        TransactionCommittingResponseUnpacker unpacker = new TransactionCommittingResponseUnpacker( resolver );
        unpacker.start();

        Response<?> response = new DummyTransactionResponse( BASE_TX_ID + 1, 1, appender, 10 );

        // When
        try
        {
            unpacker.unpackResponse( response, NO_OP_TX_HANDLER );
            fail( ""Should have thrown "" + IOException.class.getSimpleName() );
        }
        catch ( IOException e )
        {
            assertSame( error, e );
        }

        // Then
        verifyZeroInteractions( storeApplier );
        verify( kernelHealth ).panic( error );
    }
",non-flaky,5
13842,neo4j_neo4j,TransactionCommittingResponseUnpackerTest.shouldNotMarkTransactionsAsCommittedIfAppenderClosed,"    @Test
    public void shouldNotMarkTransactionsAsCommittedIfAppenderClosed() throws Throwable
    {
        // GIVEN an unpacker with close-to-real dependencies injected
        DependencyResolver resolver = mock( DependencyResolver.class );
        // (we don't want this FS in every test in this class, so just don't use EFSR)
        FileSystemAbstraction fs = cleanup.add( new EphemeralFileSystemAbstraction() );
        File directory = new File( ""dir"" );
        fs.mkdirs( directory );
        PhysicalLogFiles logFiles = new PhysicalLogFiles( directory, fs );
        TransactionIdStore transactionIdStore = spy( new DeadSimpleTransactionIdStore() );
        LogVersionRepository logVersionRepository = mock( LogVersionRepository.class );
        TransactionMetadataCache transactionMetadataCache = new TransactionMetadataCache( 10, 10 );
        LogFile logFile = life.add( new PhysicalLogFile( fs, logFiles, 1_000, transactionIdStore,
                logVersionRepository, new PhysicalLogFile.Monitor.Adapter(), transactionMetadataCache ) );
        KernelHealth health = mock( KernelHealth.class );
        LogRotation logRotation = LogRotation.NO_ROTATION;
        LogicalTransactionStore logicalTransactionStore = life.add( new PhysicalLogicalTransactionStore( logFile,
                logRotation, transactionMetadataCache, transactionIdStore, IdOrderingQueue.BYPASS,
                health, true ) );
        IndexUpdatesValidator indexUpdatesValidator = mock( IndexUpdatesValidator.class );
        when( indexUpdatesValidator.validate( any( TransactionRepresentation.class ),
                any( TransactionApplicationMode.class ) ) ).thenReturn( ValidatedIndexUpdates.NONE );
        life.start();
        TransactionAppender appender = logicalTransactionStore.getAppender();
        when( resolver.resolveDependency( LogicalTransactionStore.class ) ).thenReturn( logicalTransactionStore );
        when( resolver.resolveDependency( IndexUpdatesValidator.class ) ).thenReturn( indexUpdatesValidator );
        when( resolver.resolveDependency( TransactionIdStore.class ) ).thenReturn( transactionIdStore );
        when( resolver.resolveDependency( TransactionObligationFulfiller.class ) ).thenReturn( null );
        when( resolver.resolveDependency( LogFile.class ) ).thenReturn( logFile );
        when( resolver.resolveDependency( LogRotation.class ) ).thenReturn( logRotation );
        when( resolver.resolveDependency( KernelHealth.class ) ).thenReturn( health );
        when( resolver.resolveDependency( TransactionObligationFulfiller.class ) ).thenThrow(
                new IllegalArgumentException() );
        TransactionCommittingResponseUnpacker unpacker = new TransactionCommittingResponseUnpacker( resolver );
        unpacker.start();

        // and a closed logFile/appender
        life.shutdown();

        // WHEN packing up a transaction response
        try
        {
            unpacker.unpackResponse( new DummyTransactionResponse( BASE_TX_ID+1, 1, appender, 5 ), NO_OP_TX_HANDLER );
            fail( ""Should have failed"" );
        }
        catch ( Exception e )
        {
            // THEN apart from failing we don't want any committed/closed calls to TransactionIdStore
            verify( transactionIdStore, times( 0 ) ).transactionCommitted( anyLong(), anyLong() );
            verify( transactionIdStore, times( 0 ) ).transactionClosed( anyLong() );
        }
    }
",non-flaky,5
13843,neo4j_neo4j,ResourcePoolTest.shouldNotReuseBrokenInstances,"    @Test
    public void shouldNotReuseBrokenInstances() throws Exception
    {
        ResourcePool<Something> pool = new ResourcePool<Something>( 5 )
        {
            @Override
            protected Something create()
            {
                return new Something();
            }

            @Override
            protected boolean isAlive( Something resource )
            {
                return !resource.closed;
            }
        };

        Something somethingFirst = pool.acquire();
        somethingFirst.doStuff();
        pool.release();

        Something something = pool.acquire();
        assertEquals( somethingFirst, something );
        something.doStuff();
        something.close();
        pool.release();

        Something somethingElse = pool.acquire();
        assertFalse( something == somethingElse );
        somethingElse.doStuff();
    }
",non-flaky,5
13844,neo4j_neo4j,ResourcePoolTest.shouldTimeoutGracefully,"    @Test
    public void shouldTimeoutGracefully() throws InterruptedException
    {
        FakeClock clock = new FakeClock();

        ResourcePool.CheckStrategy timeStrategy = new ResourcePool.CheckStrategy.TimeoutCheckStrategy( 100, clock );

        while ( clock.currentTimeMillis() <= 100 )
        {
            assertFalse( timeStrategy.shouldCheck() );
            clock.forward( 10, TimeUnit.MILLISECONDS );
        }

        assertTrue( timeStrategy.shouldCheck() );

        clock.forward( 1, TimeUnit.MILLISECONDS );
        assertFalse( timeStrategy.shouldCheck() );
    }
",non-flaky,5
13845,neo4j_neo4j,ResourcePoolTest.shouldBuildUpGracefullyUntilReachedMinPoolSize,"    @Test
    public void shouldBuildUpGracefullyUntilReachedMinPoolSize() throws InterruptedException
    {
        // GIVEN
        StatefulMonitor stateMonitor = new StatefulMonitor();
        FakeClock clock = new FakeClock();
        final ResourcePool<Something> pool = getResourcePool( stateMonitor, clock, 5 );

        // WHEN
        acquireFromPool( pool, 5 );

        // THEN
        assertEquals( -1, stateMonitor.currentPeakSize.get() );
        assertEquals( -1, stateMonitor.targetSize.get() ); // that means the target size was not updated
        assertEquals( 0, stateMonitor.disposed.get() ); // no disposed happened, since the count to update is 10
    }
",non-flaky,5
13846,neo4j_neo4j,ResourcePoolTest.shouldBuildUpGracefullyWhilePassingMinPoolSizeBeforeTimerRings,"    @Test
    public void shouldBuildUpGracefullyWhilePassingMinPoolSizeBeforeTimerRings() throws InterruptedException
    {
        // GIVEN
        StatefulMonitor stateMonitor = new StatefulMonitor();
        FakeClock clock = new FakeClock();
        final ResourcePool<Something> pool = getResourcePool( stateMonitor, clock, 5 );

        // WHEN
        acquireFromPool( pool, 15 );

        // THEN
        assertEquals( -1, stateMonitor.currentPeakSize.get() );
        assertEquals( 15, stateMonitor.created.get() );
        assertEquals( -1, stateMonitor.targetSize.get() );
        assertEquals( 0, stateMonitor.disposed.get() );
    }
",non-flaky,5
13847,neo4j_neo4j,ResourcePoolTest.shouldUpdateTargetSizeWhenSpikesOccur,"    @Test
    public void shouldUpdateTargetSizeWhenSpikesOccur() throws Exception
    {
        // given
        final int MIN_SIZE = 5;
        final int MAX_SIZE = 10;

        StatefulMonitor stateMonitor = new StatefulMonitor();
        FakeClock clock = new FakeClock();
        final ResourcePool<Something> pool = getResourcePool( stateMonitor, clock, MIN_SIZE );

        // when
        List<ResourceHolder> holders = acquireFromPool( pool, MAX_SIZE );
        clock.forward( 110, TimeUnit.MILLISECONDS );
        holders.addAll( acquireFromPool( pool, 1 ) ); // Needed to trigger the alarm

        // then
        assertEquals( MAX_SIZE + 1, stateMonitor.currentPeakSize.get() );
        // We have not released anything, so targetSize will not be reduced
        assertEquals( MAX_SIZE + 1, stateMonitor.targetSize.get() ); // + 1 from the acquire

        for ( ResourceHolder holder : holders )
        {
            holder.end();
        }
    }
",non-flaky,5
13848,neo4j_neo4j,ResourcePoolTest.shouldKeepSmallPeakAndNeverDisposeIfAcquireAndReleaseContinuously,"    @Test
    public void shouldKeepSmallPeakAndNeverDisposeIfAcquireAndReleaseContinuously() throws Exception
    {
        // given
        final int MIN_SIZE = 1;

        StatefulMonitor stateMonitor = new StatefulMonitor();
        FakeClock clock = new FakeClock();
        final ResourcePool<Something> pool = getResourcePool( stateMonitor, clock, MIN_SIZE );

        // when
        for ( int i = 0; i < 200; i++ )
        {
            List<ResourceHolder> newOnes = acquireFromPool( pool, 1 );
            CountDownLatch release = new CountDownLatch( newOnes.size() );
            for ( ResourceHolder newOne : newOnes )
            {
                newOne.release( release );
            }
            release.await();
        }

        // then
        assertEquals( -1, stateMonitor.currentPeakSize.get() ); // no alarm has rung, -1 is the default
        assertEquals( 1, stateMonitor.created.get() );
        assertEquals( 0, stateMonitor.disposed.get() ); // we should always be below min size, so 0 dispose calls
    }
",non-flaky,5
13849,neo4j_neo4j,ResourcePoolTest.shouldSlowlyReduceTheNumberOfResourcesInThePoolWhenResourcesAreReleased,"    @Test
    public void shouldSlowlyReduceTheNumberOfResourcesInThePoolWhenResourcesAreReleased() throws Exception
    {
        // given
        final int MIN_SIZE = 50;
        final int MAX_SIZE = 200;

        StatefulMonitor stateMonitor = new StatefulMonitor();
        FakeClock clock = new FakeClock();
        final ResourcePool<Something> pool = getResourcePool( stateMonitor, clock, MIN_SIZE );
        List<ResourceHolder> holders = new LinkedList<ResourceHolder>();

        buildAPeakOfAcquiredResourcesAndTriggerAlarmWithSideEffects( MAX_SIZE, clock, pool, holders );

        // when
        // After the peak, stay below MIN_SIZE concurrent usage, using up all already present resources.
        clock.forward( 110, TimeUnit.MILLISECONDS );
        for ( int i = 0; i < MAX_SIZE; i++ )
        {
            acquireFromPool( pool, 1 ).get( 0 ).release();
        }

        // then

        // currentPeakSize must have reset from the latest alarm to MIN_SIZE.
        assertEquals( 1, stateMonitor.currentPeakSize.get() ); // Alarm
        // targetSize must be set to MIN_SIZE since currentPeakSize was that 2 alarms ago and didn't increase
        assertEquals( MIN_SIZE, stateMonitor.targetSize.get() );
        // Only pooled resources must be used, disposing what is in excess
        // +1 for the alarm from buildAPeakOfAcquiredResourcesAndTriggerAlarmWithSideEffects
        assertEquals( MAX_SIZE - MIN_SIZE + 1, stateMonitor.disposed.get() );
    }
",non-flaky,5
13850,neo4j_neo4j,ResourcePoolTest.shouldMaintainPoolAtHighWatermarkWhenConcurrentUsagePassesMinSize,"    @Test
    public void shouldMaintainPoolAtHighWatermarkWhenConcurrentUsagePassesMinSize() throws Exception
    {
        // given
        final int MIN_SIZE = 50;
        final int MAX_SIZE = 200;
        final int MID_SIZE = 90;

        StatefulMonitor stateMonitor = new StatefulMonitor();
        FakeClock clock = new FakeClock();
        final ResourcePool<Something> pool = getResourcePool( stateMonitor, clock, MIN_SIZE );
        List<ResourceHolder> holders = new LinkedList<ResourceHolder>();

        buildAPeakOfAcquiredResourcesAndTriggerAlarmWithSideEffects( MAX_SIZE, clock, pool, holders );

        // when
        // After the peak, stay at MID_SIZE concurrent usage, using up all already present resources in the process
        // but also keeping the high watermark above the MIN_SIZE
        clock.forward( 110, TimeUnit.MILLISECONDS );
        // Requires some rounds to happen, since there is constant racing between releasing and acquiring which does
        // not always result in reaping of resources, as there is reuse
        for ( int i = 0; i < 10; i++ )
        {
            // The latch is necessary to reduce races between batches
            CountDownLatch release = new CountDownLatch( MID_SIZE );
            for ( ResourceHolder holder : acquireFromPool( pool, MID_SIZE ) )
            {
                holder.release( release );
            }
            release.await();
            clock.forward( 110, TimeUnit.MILLISECONDS );
        }

        // then
        // currentPeakSize should be at MID_SIZE
        assertEquals( MID_SIZE, stateMonitor.currentPeakSize.get() );
        // target size too
        assertEquals( MID_SIZE, stateMonitor.targetSize.get() );
        // only the excess from the MAX_SIZE down to mid size must have been disposed
        // +1 for the alarm from buildAPeakOfAcquiredResourcesAndTriggerAlarmWithSideEffects
        assertEquals( MAX_SIZE - MID_SIZE + 1, stateMonitor.disposed.get() );
    }
",non-flaky,5
13851,neo4j_neo4j,ResourcePoolTest.shouldReclaimAndRecreateWhenLullBetweenSpikesOccurs,"    @Test
    public void shouldReclaimAndRecreateWhenLullBetweenSpikesOccurs() throws Exception
    {
        // given
        final int MIN_SIZE = 50;
        final int BELOW_MIN_SIZE = MIN_SIZE / 5;
        final int MAX_SIZE = 200;

        StatefulMonitor stateMonitor = new StatefulMonitor();
        FakeClock clock = new FakeClock();
        final ResourcePool<Something> pool = getResourcePool( stateMonitor, clock, MIN_SIZE );
        List<ResourceHolder> holders = new LinkedList<ResourceHolder>();

        buildAPeakOfAcquiredResourcesAndTriggerAlarmWithSideEffects( MAX_SIZE, clock, pool, holders );

        // when
        // After the peak, stay well below concurrent usage, using up all already present resources in the process
        clock.forward( 110, TimeUnit.MILLISECONDS );
        // Requires some rounds to happen, since there is constant racing between releasing and acquiring which does
        // not always result in reaping of resources, as there is reuse
        for ( int i = 0; i < 30; i++ )
        {
            // The latch is necessary to reduce races between batches
            CountDownLatch release = new CountDownLatch( BELOW_MIN_SIZE );
            for ( ResourceHolder holder : acquireFromPool( pool, BELOW_MIN_SIZE ) )
            {
                holder.release( release );
            }
            release.await();
            clock.forward( 110, TimeUnit.MILLISECONDS );
        }

        // then
        // currentPeakSize should be at MIN_SIZE / 5
        assertEquals( BELOW_MIN_SIZE, stateMonitor.currentPeakSize.get() );
        // target size should remain at MIN_SIZE
        assertEquals( MIN_SIZE, stateMonitor.targetSize.get() );
        // only the excess from the MAX_SIZE down to min size must have been disposed
        // +1 for the alarm from buildAPeakOfAcquiredResourcesAndTriggerAlarmWithSideEffects
        assertEquals( MAX_SIZE - MIN_SIZE + 1, stateMonitor.disposed.get() );

        stateMonitor.created.set( 0 );
        stateMonitor.disposed.set( 0 );

        // when
        // After the lull, recreate a peak
        buildAPeakOfAcquiredResourcesAndTriggerAlarmWithSideEffects( MAX_SIZE, clock, pool, holders );

        // then
        assertEquals( MAX_SIZE - MIN_SIZE + 1, stateMonitor.created.get() );
        assertEquals( 0, stateMonitor.disposed.get() );

    }
",non-flaky,5
13852,neo4j_neo4j,ServerTest.shouldSendExceptionBackToClientOnInvalidChecksum,"    @Test
    public void shouldSendExceptionBackToClientOnInvalidChecksum() throws Exception
    {
        // Given
        Server<Object, Object> server = newServer( checksumVerifier );
        RequestContext ctx = new RequestContext( 0, 1, 0, 1, 12 );

        doThrow(new IllegalStateException(""123"")).when(checksumVerifier).assertMatch( anyLong(), anyLong() );

        // When
        try
        {
            server.messageReceived( channelCtx( channel ), message( reqType, ctx, channel, EMPTY_SERIALIZER ) );
            fail(""Should have failed."");
        }
        catch(IllegalStateException e)
        {
            // Expected
        }

        // Then
        try
        {
            protocol.deserializeResponse( channel.asBlockingReadHandler(), ByteBuffer.allocateDirect( 1024 ), 1,
                    VOID_DESERIALIZER, mock( ResourceReleaser.class ) );
            fail(""Should have failed."");
        }
        catch(IllegalStateException e)
        {
            assertThat(e.getMessage(), equalTo(""123""));
        }

    }
",non-flaky,5
13853,neo4j_neo4j,TestCommunication.clientGetResponseFromServerViaComLayer,"    @Test
    public void clientGetResponseFromServerViaComLayer() throws Throwable
    {
        MadeUpServerImplementation serverImplementation = new MadeUpServerImplementation( storeIdToUse );
        MadeUpServer server = builder.server( serverImplementation );
        MadeUpClient client = builder.client();
        addToLifeAndStart( server, client );

        int value1 = 10;
        int value2 = 5;
        Response<Integer> response = client.multiply( 10, 5 );
        waitUntilResponseHasBeenWritten( server, 1000 );
        assertEquals( (Integer) (value1 * value2), response.response() );
        assertTrue( serverImplementation.gotCalled() );
        assertTrue( server.responseHasBeenWritten() );
    }
",non-flaky,5
13854,neo4j_neo4j,TestCommunication.makeSureClientStoreIdsMustMatch,"    @Test(expected = MismatchingStoreIdException.class)
    public void makeSureClientStoreIdsMustMatch() throws Throwable
    {
        MadeUpServer server = builder.server();
        MadeUpClient client = builder.storeId( new StoreId( 10, 10, 10, 10 ) ).client();
        addToLifeAndStart( server, client );

        client.multiply( 1, 2 );
    }
",non-flaky,5
13855,neo4j_neo4j,TestCommunication.makeSureServerStoreIdsMustMatch,"    @Test(expected = MismatchingStoreIdException.class)
    public void makeSureServerStoreIdsMustMatch() throws Throwable
    {
        MadeUpServer server = builder.storeId( new StoreId( 10, 10, 10, 10 ) ).server();
        MadeUpClient client = builder.client();
        addToLifeAndStart( server, client );

        client.multiply( 1, 2 );
    }
",non-flaky,5
13856,neo4j_neo4j,TestCommunication.makeSureClientCanStreamBigData,"    @Test
    public void makeSureClientCanStreamBigData() throws Throwable
    {
        MadeUpServer server = builder.server();
        MadeUpClient client = builder.client();
        addToLifeAndStart( server, client );


        client.fetchDataStream( new ToAssertionWriter(), FRAME_LENGTH * 3 );
    }
",non-flaky,5
13857,neo4j_neo4j,TestCommunication.fetchDataStream,"    @Test
    public void clientThrowsServerSideErrorMidwayThroughStreaming() throws Throwable
    {
        final String failureMessage = ""Just failing"";
        MadeUpServerImplementation serverImplementation = new MadeUpServerImplementation( storeIdToUse )
        {
            @Override
            public Response<Void> fetchDataStream( MadeUpWriter writer, int dataSize )
            {
                writer.write( new FailingByteChannel( dataSize, failureMessage ) );
                return new TransactionStreamResponse<>( null, storeIdToUse, TransactionStream.EMPTY,
                        ResourceReleaser.NO_OP );
            }
",non-flaky,5
13858,neo4j_neo4j,TestCommunication.communicateBetweenJvms,"    @Test
    public void communicateBetweenJvms() throws Throwable
    {
        ServerInterface server = builder.serverInOtherJvm();
        server.awaitStarted();
        MadeUpClient client = builder.port( MadeUpServerProcess.PORT ).client();
        life.add( client );
        life.start();

        assertEquals( (Integer) (9 * 5), client.multiply( 9, 5 ).response() );
        client.fetchDataStream( new ToAssertionWriter(), 1024 * 1024 * 3 );

        server.shutdown();
    }
",non-flaky,5
13859,neo4j_neo4j,TestCommunication.throwingServerSideExceptionBackToClient,"    @Test
    public void throwingServerSideExceptionBackToClient() throws Throwable
    {
        MadeUpServer server = builder.server();
        MadeUpClient client = builder.client();
        addToLifeAndStart( server, client );

        String exceptionMessage = ""The message"";
        try
        {
            client.throwException( exceptionMessage );
            fail( ""Should have thrown "" + MadeUpException.class.getSimpleName() );
        }
        catch ( MadeUpException e )
        {   // Good
            assertEquals( exceptionMessage, e.getMessage() );
        }
    }
",non-flaky,5
13860,neo4j_neo4j,TestCommunication.applicationProtocolVersionsMustMatch,"    @Test
    public void applicationProtocolVersionsMustMatch() throws Throwable
    {
        MadeUpServer server = builder.applicationProtocolVersion( (byte) (APPLICATION_PROTOCOL_VERSION + 1) ).server();
        MadeUpClient client = builder.client();
        addToLifeAndStart( server, client );

        try
        {
            client.multiply( 10, 20 );
            fail( ""Shouldn't be able to communicate with different application protocol versions"" );
        }
        catch ( IllegalProtocolVersionException e )
        { /* Good */ }
    }
",non-flaky,5
13861,neo4j_neo4j,TestCommunication.applicationProtocolVersionsMustMatchMultiJvm,"    @Test
    public void applicationProtocolVersionsMustMatchMultiJvm() throws Throwable
    {
        ServerInterface server = builder.applicationProtocolVersion( (byte) (APPLICATION_PROTOCOL_VERSION + 1) )
                                        .serverInOtherJvm();
        server.awaitStarted();
        MadeUpClient client = builder.port( MadeUpServerProcess.PORT ).client();
        life.add( client );
        life.start();

        try
        {
            client.multiply( 10, 20 );
            fail( ""Shouldn't be able to communicate with different application protocol versions"" );
        }
        catch ( IllegalProtocolVersionException e )
        { /* Good */ }

        server.shutdown();
    }
",non-flaky,5
13862,neo4j_neo4j,TestCommunication.internalProtocolVersionsMustMatch,"    @Test
    public void internalProtocolVersionsMustMatch() throws Throwable
    {
        MadeUpServer server = builder.internalProtocolVersion( (byte) 1 ).server();
        MadeUpClient client = builder.internalProtocolVersion( (byte) 2 ).client();
        addToLifeAndStart( server, client );

        try
        {
            client.multiply( 10, 20 );
            fail( ""Shouldn't be able to communicate with different application protocol versions"" );
        }
        catch ( IllegalProtocolVersionException e )
        { /* Good */ }
    }
",non-flaky,5
13863,neo4j_neo4j,TestCommunication.internalProtocolVersionsMustMatchMultiJvm,"    @Test
    public void internalProtocolVersionsMustMatchMultiJvm() throws Throwable
    {
        ServerInterface server = builder.internalProtocolVersion( (byte) 1 ).serverInOtherJvm();
        server.awaitStarted();
        MadeUpClient client = builder.port( MadeUpServerProcess.PORT ).internalProtocolVersion( (byte) 2 ).client();
        life.add( client );
        life.start();

        try
        {
            client.multiply( 10, 20 );
            fail( ""Shouldn't be able to communicate with different application protocol versions"" );
        }
        catch ( IllegalProtocolVersionException e )
        { /* Good */ }

        server.shutdown();
    }
",non-flaky,5
13864,neo4j_neo4j,TestCommunication.serverStopsStreamingToDeadClient,"    @Test
    public void serverStopsStreamingToDeadClient() throws Throwable
    {
        MadeUpServer server = builder.server();
        MadeUpClient client = builder.client();
        addToLifeAndStart( server, client );

        int failAtSize = FRAME_LENGTH / 2;
        ClientCrashingWriter writer = new ClientCrashingWriter( client, failAtSize );
        try
        {
            client.fetchDataStream( writer, FRAME_LENGTH * 10 );
            assertTrue( writer.getSizeRead() >= failAtSize );
            fail( ""Should fail in the middle"" );
        }
        catch ( ComException e )
        {   // Expected
        }
        assertTrue( writer.getSizeRead() >= failAtSize );

        long maxWaitUntil = System.currentTimeMillis() + 2 * 1000;
        while ( !server.responseFailureEncountered() && System.currentTimeMillis() < maxWaitUntil )
        {
            yield();
        }
        assertTrue( ""Failure writing the response should have been encountered"", server.responseFailureEncountered() );
        assertFalse( ""Response shouldn't have been successful"", server.responseHasBeenWritten() );
    }
",non-flaky,5
13865,neo4j_neo4j,TestCommunication.assertMatch,"    @Test
    public void serverContextVerificationCanThrowException() throws Throwable
    {
        final String failureMessage = ""I'm failing"";
        TxChecksumVerifier failingVerifier = new TxChecksumVerifier()
        {
            @Override
            public void assertMatch( long txId, long checksum )
            {
                throw new FailingException( failureMessage );
            }
",non-flaky,5
13866,neo4j_neo4j,TestCommunication.clientCanReadChunkSizeBiggerThanItsOwn,"    @Test
    public void clientCanReadChunkSizeBiggerThanItsOwn() throws Throwable
    {   // Given that frameLength is the same for both client and server.
        int serverChunkSize = 20000;
        int clientChunkSize = serverChunkSize / 10;
        MadeUpServer server = builder.chunkSize( serverChunkSize ).server();
        MadeUpClient client = builder.chunkSize( clientChunkSize ).client();

        addToLifeAndStart( server, client );

        // Tell server to stream data occupying roughly two chunks. The chunks
        // from server are 10 times bigger than the clients chunk size.
        client.fetchDataStream( new ToAssertionWriter(), serverChunkSize * 2 );
    }
",non-flaky,5
13867,neo4j_neo4j,TestCommunication.serverCanReadChunkSizeBiggerThanItsOwn,"    @Test
    public void serverCanReadChunkSizeBiggerThanItsOwn() throws Throwable
    {   // Given that frameLength is the same for both client and server.
        int serverChunkSize = 1000;
        int clientChunkSize = serverChunkSize * 10;
        MadeUpServer server = builder.chunkSize( serverChunkSize ).server();
        MadeUpClient client = builder.chunkSize( clientChunkSize ).client();

        addToLifeAndStart( server, client );

        // Tell server to stream data occupying roughly two chunks. The chunks
        // from server are 10 times bigger than the clients chunk size.
        client.sendDataStream( new DataProducer( clientChunkSize * 2 ) );
    }
",non-flaky,5
13868,neo4j_neo4j,TestCommunication.impossibleToHaveBiggerChunkSizeThanFrameSize,"    @Test
    public void impossibleToHaveBiggerChunkSizeThanFrameSize() throws Throwable
    {
        Builder myBuilder = builder.chunkSize( MadeUpServer.FRAME_LENGTH + 10 );
        try
        {
            myBuilder.server().start();
            fail( ""Shouldn't be possible"" );
        }
        catch ( IllegalArgumentException e )
        {   // Good
        }

        try
        {
            myBuilder.client();
            fail( ""Shouldn't be possible"" );
        }
        catch ( IllegalArgumentException e )
        {   // Good
        }
    }
",non-flaky,5
13869,neo4j_neo4j,TestCommunication.answer,"    @Test
    public void clientShouldUseHandlersToHandleComExceptions()
    {
        // Given
        final String comExceptionMessage = ""The ComException"";

        MadeUpCommunicationInterface communication = mock( MadeUpCommunicationInterface.class, new Answer<Response<?>>()
        {
            @Override
            public Response<?> answer( InvocationOnMock _ ) throws ComException
            {
                throw new ComException( comExceptionMessage );
            }
",non-flaky,5
13870,neo4j_neo4j,TestCommunication.masterResponseShouldBeUnpackedIfRequestTypeRequires,"    @Test
    public void masterResponseShouldBeUnpackedIfRequestTypeRequires() throws IOException
    {
        // Given
        ResponseUnpacker responseUnpacker = mock( ResponseUnpacker.class );
        MadeUpClient client = builder.clientWith( responseUnpacker );
        addToLifeAndStart( builder.server(), client );

        // When
        client.multiply( 42, 42 );

        // Then
        ArgumentCaptor<Response> captor = ArgumentCaptor.forClass( Response.class );
        verify( responseUnpacker ).unpackResponse( captor.capture(), any( TxHandler.class ) );
        assertEquals( storeIdToUse, captor.getValue().getStoreId() );
        assertEquals( 42 * 42, captor.getValue().response() );
    }
",non-flaky,5
13871,neo4j_neo4j,TestCommunication.masterResponseShouldNotBeUnpackedIfRequestTypeDoesNotRequire,"    @Test
    public void masterResponseShouldNotBeUnpackedIfRequestTypeDoesNotRequire()
    {
        // Given
        ResponseUnpacker responseUnpacker = mock( ResponseUnpacker.class );
        MadeUpClient client = builder.clientWith( responseUnpacker );
        addToLifeAndStart( builder.server(), client );

        // When
        client.sendDataStream( new KnownDataByteChannel( 100 ) );

        // Then
        verifyZeroInteractions( responseUnpacker );
    }
",non-flaky,5
13872,neo4j_neo4j,TestCommunication.shouldStreamBackTransactions,"    @Test
    public void shouldStreamBackTransactions() throws Exception
    {
        // GIVEN
        int value = 11, txCount = 3;
        life.add( builder.server() );
        MadeUpClient client = life.add( builder.client() );
        life.start();
        Response<Integer> respone = client.streamBackTransactions( value, txCount );
        TransactionStreamVerifyingResponseHandler handler = new TransactionStreamVerifyingResponseHandler( txCount );

        // WHEN
        respone.accept( handler );
        int responseValue = respone.response();

        // THEN
        assertEquals( value, responseValue );
        assertEquals( txCount, handler.expectedTxId );
    }
",non-flaky,5
13873,neo4j_neo4j,TestCommunication.shouldAdhereToTransactionObligations,"    @Test
    public void shouldAdhereToTransactionObligations() throws Exception
    {
        // GIVEN
        int value = 15;
        long desiredObligation = 8;
        life.add( builder.server() );
        MadeUpClient client = life.add( builder.client() );
        life.start();
        Response<Integer> respone = client.informAboutTransactionObligations( value, desiredObligation );
        TransactionObligationVerifyingResponseHandler handler = new TransactionObligationVerifyingResponseHandler();

        // WHEN
        respone.accept( handler );
        int responseValue = respone.response();

        // THEN
        assertEquals( value, responseValue );
        assertEquals( desiredObligation, handler.obligationTxId );
    }
",non-flaky,5
13874,neo4j_neo4j,ServerUtilTest.shouldIgnoreLogicalLogsWhenCopyingFilesForBackup,"    @Test
    public void shouldIgnoreLogicalLogsWhenCopyingFilesForBackup() throws IOException
    {
        // given
        final FileSystemAbstraction fs = new StubFileSystemAbstraction();

        XaDataSource dataSource = mock( XaDataSource.class );

        FileResourceIterator storeFiles = new FileResourceIterator( fs, testDirectory, ""neostore.nodestore.db"" );
        FileResourceIterator logicalLogs = new FileResourceIterator( fs, testDirectory,
        PhysicalLogFile.DEFAULT_NAME + PhysicalLogFile.DEFAULT_VERSION_SUFFIX + ""0"" );

        when( dataSource.listStoreFiles() ).thenReturn( storeFiles );
        when( dataSource.listLogicalLogs() ).thenReturn( logicalLogs );
        when( dataSource.getBranchId() ).thenReturn( ""branch"".getBytes() );
        when( dataSource.getName() ).thenReturn( ""branch"" );

        XaContainer xaContainer = mock( XaContainer.class );
        when( dataSource.getXaContainer() ).thenReturn( xaContainer );

        XaLogicalLog xaLogicalLog = mock( XaLogicalLog.class );

        when( xaContainer.getLogicalLog() ).thenReturn( xaLogicalLog );

        XaResourceManager xaResourceManager = mock( XaResourceManager.class );
        when( xaContainer.getResourceManager() ).thenReturn( xaResourceManager );

        XaDataSourceManager dsManager = new XaDataSourceManager( StringLogger.DEV_NULL );
        dsManager.registerDataSource( dataSource );

        KernelPanicEventGenerator kernelPanicEventGenerator = mock( KernelPanicEventGenerator.class );
        StoreWriter storeWriter = mock( StoreWriter.class );

        // when
        ServerUtil.rotateLogsAndStreamStoreFiles( testDirectory.absolutePath(), dsManager, kernelPanicEventGenerator,
                StringLogger.DEV_NULL, false, storeWriter, fs, StoreCopyMonitor.NONE );

        // then
        verify( storeWriter ).write( eq( ""neostore.nodestore.db"" ), any( ReadableByteChannel.class ),
                any( ByteBuffer.class ), any( Boolean.class ) );
        verify( storeWriter, never() ).write( eq( PhysicalLogFile.DEFAULT_NAME + PhysicalLogFile.DEFAULT_VERSION_SUFFIX + ""0"" ), any( ReadableByteChannel.class ),
                any( ByteBuffer.class ), any( Boolean.class ) );

    }
",non-flaky,5
13875,neo4j_neo4j,ServerUtilTest.shouldCopyLogicalLogFile,"    @Test
    public void shouldCopyLogicalLogFile() throws IOException
    {
        // given
        final FileSystemAbstraction fs = new StubFileSystemAbstraction();

        XaDataSource dataSource = mock( XaDataSource.class );

        FileResourceIterator storeFiles = new FileResourceIterator( fs, testDirectory );
        FileResourceIterator logicalLogs = new FileResourceIterator( fs, testDirectory, PhysicalLogFile.DEFAULT_NAME + PhysicalLogFile.DEFAULT_VERSION_SUFFIX + ""0"" );

        when( dataSource.listStoreFiles() ).thenReturn( storeFiles );
        when( dataSource.listLogicalLogs() ).thenReturn( logicalLogs );
        when( dataSource.getBranchId() ).thenReturn( ""branch"".getBytes() );
        when( dataSource.getName() ).thenReturn( ""branch"" );

        XaContainer xaContainer = mock( XaContainer.class );
        when( dataSource.getXaContainer() ).thenReturn( xaContainer );

        XaLogicalLog xaLogicalLog = mock( XaLogicalLog.class );

        when( xaContainer.getLogicalLog() ).thenReturn( xaLogicalLog );

        XaResourceManager xaResourceManager = mock( XaResourceManager.class );
        when( xaContainer.getResourceManager() ).thenReturn( xaResourceManager );

        XaDataSourceManager dsManager = new XaDataSourceManager( StringLogger.DEV_NULL );
        dsManager.registerDataSource( dataSource );

        KernelPanicEventGenerator kernelPanicEventGenerator = mock( KernelPanicEventGenerator.class );
        StoreWriter storeWriter = mock( StoreWriter.class );

        // when
        ServerUtil.rotateLogsAndStreamStoreFiles( testDirectory.absolutePath(), dsManager, kernelPanicEventGenerator,
                StringLogger.DEV_NULL, true, storeWriter, fs, StoreCopyMonitor.NONE );

        // then
        verify( storeWriter ).write( eq( PhysicalLogFile.DEFAULT_NAME + PhysicalLogFile.DEFAULT_VERSION_SUFFIX + ""0"" ), any( ReadableByteChannel.class ),
                any( ByteBuffer.class ), any( Boolean.class ) );
    }
",non-flaky,5
13876,neo4j_neo4j,ServerUtilTest.shouldNotThrowFileNotFoundExceptionWhenTryingToCopyAMissingLogicalLogFile,"    @Test
    public void shouldNotThrowFileNotFoundExceptionWhenTryingToCopyAMissingLogicalLogFile() throws IOException
    {
        // given
        final FileSystemAbstraction fs = new StubFileSystemAbstraction();

        XaDataSource dataSource = mock( XaDataSource.class );

        FileResourceIterator storeFiles = new FileResourceIterator( fs, testDirectory, ""neostore.nodestore.db"" );

        FileResourceIterator logicalLogs = new FileResourceIterator( fs, testDirectory,
        PhysicalLogFile.DEFAULT_NAME + PhysicalLogFile.DEFAULT_VERSION_SUFFIX + ""0"" );
        logicalLogs.deleteBeforeCopy( PhysicalLogFile.DEFAULT_NAME + PhysicalLogFile.DEFAULT_VERSION_SUFFIX + ""0"" );

        when( dataSource.listStoreFiles() ).thenReturn( storeFiles );
        when( dataSource.listLogicalLogs() ).thenReturn( logicalLogs );

        when( dataSource.getBranchId() ).thenReturn( ""branch"".getBytes() );
        when( dataSource.getName() ).thenReturn( ""branch"" );

        XaContainer xaContainer = mock( XaContainer.class );
        when( dataSource.getXaContainer() ).thenReturn( xaContainer );

        XaResourceManager xaResourceManager = mock( XaResourceManager.class );
        when( xaContainer.getResourceManager() ).thenReturn( xaResourceManager );

        XaDataSourceManager dsManager = new XaDataSourceManager( StringLogger.DEV_NULL );
        dsManager.registerDataSource( dataSource );

        KernelPanicEventGenerator kernelPanicEventGenerator = mock( KernelPanicEventGenerator.class );
        StoreWriter storeWriter = mock( StoreWriter.class );

        // when
        ServerUtil.rotateLogsAndStreamStoreFiles( testDirectory.absolutePath(), dsManager, kernelPanicEventGenerator,
                StringLogger.DEV_NULL, true, storeWriter, fs, StoreCopyMonitor.NONE );

        // then
        verify( storeWriter ).write( eq( ""neostore.nodestore.db"" ), any( ReadableByteChannel.class ),
                any( ByteBuffer.class ), any( Boolean.class ) );
    }
",non-flaky,5
13877,neo4j_neo4j,ServerUtilTest.shouldThrowFileNotFoundExceptionWhenTryingToCopyAStoreFileWhichDoesNotExist,"    @Test
    public void shouldThrowFileNotFoundExceptionWhenTryingToCopyAStoreFileWhichDoesNotExist() throws IOException
    {
        // given
        final FileSystemAbstraction fs = new StubFileSystemAbstraction();

        XaDataSource dataSource = mock( XaDataSource.class );

        FileResourceIterator storeFiles = new FileResourceIterator( fs, testDirectory, ""neostore.nodestore.db"" );
        storeFiles.deleteBeforeCopy( ""neostore.nodestore.db"" );

        FileResourceIterator logicalLogs = new FileResourceIterator( fs, testDirectory );

        when( dataSource.listStoreFiles() ).thenReturn( storeFiles );
        when( dataSource.listLogicalLogs() ).thenReturn( logicalLogs );


        when( dataSource.getBranchId() ).thenReturn( ""branch"".getBytes() );
        when( dataSource.getName() ).thenReturn( ""branch"" );

        XaContainer xaContainer = mock( XaContainer.class );
        when( dataSource.getXaContainer() ).thenReturn( xaContainer );

        XaResourceManager xaResourceManager = mock( XaResourceManager.class );
        when( xaContainer.getResourceManager() ).thenReturn( xaResourceManager );

        XaDataSourceManager dsManager = new XaDataSourceManager( StringLogger.DEV_NULL );
        dsManager.registerDataSource( dataSource );

        KernelPanicEventGenerator kernelPanicEventGenerator = mock( KernelPanicEventGenerator.class );
        StoreWriter storeWriter = mock( StoreWriter.class );

        // when
        try
        {
            ServerUtil.rotateLogsAndStreamStoreFiles( testDirectory.absolutePath(), dsManager,
                    kernelPanicEventGenerator,
                    StringLogger.DEV_NULL, true, storeWriter, fs, StoreCopyMonitor.NONE );
            fail( ""should have thrown exception"" );
        }
        catch ( ServerFailureException e )
        {
            // then
            assertEquals( java.io.FileNotFoundException.class, e.getCause().getClass() );
        }
    }
",non-flaky,5
13878,neo4j_neo4j,TestSlaveContext.assertSimilarity,"    @Test
    public void assertSimilarity()
    {
        // Different machine ids
        assertFalse( new RequestContext( 1234, 1, 2, 0, 0 ).equals( new RequestContext( 1234, 2, 2, 0, 0 ) ) );

        // Different event identifiers
        assertFalse( new RequestContext( 1234, 1, 10, 0, 0 ).equals( new RequestContext( 1234, 1, 20, 0, 0 ) ) );

        // Different session ids
        assertFalse( new RequestContext( 1001, 1, 5, 0, 0 ).equals( new RequestContext( 1101, 1, 5, 0, 0 ) ) );

        // Same everything
        assertEquals( new RequestContext( 12345, 4, 9, 0, 0 ), new RequestContext( 12345, 4, 9, 0, 0 ) );
    }
",non-flaky,5
13879,neo4j_neo4j,ProtocolTest.shouldSerializeAndDeserializeTransactionRepresentation,"    @Test
    public void shouldSerializeAndDeserializeTransactionRepresentation() throws Exception
    {
        // GIVEN
        PhysicalTransactionRepresentation transaction = new PhysicalTransactionRepresentation( justOneNode() );
        byte[] additionalHeader = ""extra"".getBytes();
        int masterId = 1, authorId = 2;
        long timeStarted = 12345, lastTxWhenStarted = 12, timeCommitted = timeStarted+10;
        transaction.setHeader( additionalHeader, masterId, authorId, timeStarted, lastTxWhenStarted, timeCommitted, -1 );
        Protocol.TransactionSerializer serializer = new Protocol.TransactionSerializer( transaction );
        ChannelBuffer buffer = new ChannelBufferWrapper( new InMemoryLogChannel() );

        // WHEN serializing the transaction
        serializer.write( buffer );

        // THEN deserializing the same transaction should yield the same data.
        // ... remember that this deserializer doesn't read the data source name string. Read it manually here
        assertEquals( NeoStoreDataSource.DEFAULT_DATA_SOURCE_NAME, Protocol.readString( buffer ) );
        TransactionRepresentation readTransaction = Protocol.TRANSACTION_REPRESENTATION_DESERIALIZER.read(
                buffer, ByteBuffer.allocate( 1000 ) );
        assertArrayEquals( additionalHeader, readTransaction.additionalHeader() );
        assertEquals( masterId, readTransaction.getMasterId() );
        assertEquals( authorId, readTransaction.getAuthorId() );
        assertEquals( timeStarted, readTransaction.getTimeStarted() );
        assertEquals( lastTxWhenStarted, readTransaction.getLatestCommittedTxWhenStarted() );
        assertEquals( timeCommitted, readTransaction.getTimeCommitted() );
    }
",non-flaky,5
13880,neo4j_neo4j,StoreMigratorFrom20IT.shouldMigrate,"    @Test
    public void shouldMigrate() throws IOException, ConsistencyCheckIncompleteException
    {
        // WHEN
        upgrader( new StoreMigrator( monitor, fs, DevNullLoggingService.DEV_NULL ) )
                .migrateIfNeeded(
                find20FormatStoreDirectory( storeDir.directory() ), schemaIndexProvider, pageCache );

        // THEN
        assertEquals( 100, monitor.eventSize() );
        assertTrue( monitor.isStarted() );
        assertTrue( monitor.isFinished() );

        GraphDatabaseService database = new GraphDatabaseFactory().newEmbeddedDatabase( storeDir.absolutePath() );
        try
        {
            verifyDatabaseContents( database );
        }
        finally
        {
            // CLEANUP
            database.shutdown();
        }

        try ( NeoStore neoStore = storeFactory.newNeoStore( true ) )
        {
            verifyNeoStore( neoStore );
        }
        assertConsistentStore( storeDir.directory() );
    }
",non-flaky,5
13881,neo4j_neo4j,StoreMigratorFrom20IT.shouldMigrateCluster,"    @Test
    public void shouldMigrateCluster() throws Throwable
    {
        // Given
        File legacyStoreDir = find20FormatStoreDirectory( storeDir.directory() );

        // When
        upgrader( new StoreMigrator( monitor, fs, DevNullLoggingService.DEV_NULL ) ).migrateIfNeeded(
                legacyStoreDir, schemaIndexProvider, pageCache );
        ClusterManager.ManagedCluster cluster = buildClusterWithMasterDirIn( fs, legacyStoreDir, life );
        cluster.await( allSeesAllAsAvailable() );
        cluster.sync();

        // Then
        HighlyAvailableGraphDatabase slave1 = cluster.getAnySlave();
        verifySlaveContents( slave1 );
        verifySlaveContents( cluster.getAnySlave( slave1 ) );
        verifyDatabaseContents( cluster.getMaster() );
    }
",non-flaky,5
13882,neo4j_neo4j,StoreMigratorFrom21IT.mustMendDuplicatePropertiesWhenUpgradingFromVersion21,"    @Test
    public void mustMendDuplicatePropertiesWhenUpgradingFromVersion21() throws Exception
    {
        // The rules:
        // If an index is present, all duplicates should be removed and the property set to the value in the index
        // If an index is not present, the property should be set to the value of the last duplicate in the property
        // chain, all duplicates except the first should be removed
        // If an index is not present, the first property in the duplicate chain should be kept for the users
        // benefit, moved to a special property value, `__DUPLICATE_<propkey>`
        //
        // This is the broken store that we are upgrading:
        //
        //   (#0:Label { keyA: ""actual"", keyA: ""phony!"", keyA: ""phony!"" })
        //   (#1 { keyA: ""actual"", keyA: ""actual"", keyA: ""actual"" })
        //   (#2:Label { keyA: ""real1"", keyA: ""phony"", keyA: ""phony"", keyD: ""real2"", keyD: ""phony"", keyD: ""phony"" })
        //   (#3 { keyA: ""real1"", keyA: ""phony"", keyA: ""phony"", keyD: ""real2"", keyD: ""phony"", keyD: ""phony"" })
        //   (#4 { keyA: ""actual"", keyB: ""actual"", keyC: ""actual"" })
        //   (#0)-[#0:REL { keyA: ""actual"", keyA: ""actual"", keyA: ""actual"" }]->(#1)
        //   (#0)-[#1:REL { keyA: ""real1"", keyA: ""phony"", keyA: ""phony"",
        //                  keyD: ""real2"", keyE: ""phony"", keyF: ""phony"" }]->(#1)
        //   (#2)-[#2:REL { keyA: ""actual"", keyB: ""actual"", keyC: ""actual"" }]->(#0)
        //
        // And this is what we want to end up with, after upgrading:
        //
        //   (#0:Label { keyA: ""actual"" })
        //   (#1 { keyA: ""actual"", __DUPLICATE_keyA: ""actual"" })
        //   (#2:Label { keyA: ""real1"", keyD: ""real2"" })
        //   (#3 { keyA: ""real1"", __DUPLICATE_keyA_1: ""real1"", __DUPLICATE_keyA_2: ""real1"",
        //         keyD: ""real2"", __DUPLICATE_keyD_1: ""real2"", __DUPLICATE_keyD_2: ""real2"" })
        //   (#4 { keyA: ""actual"", keyB: ""actual"", keyC: ""actual"" })
        //   (#0)-[#0:REL { keyA: ""actual"", __DUPLICATE_keyA: ""actual"" }]->(#1)
        //   (#0)-[#1:REL { keyA: ""real1"", __DUPLICATE_keyA_1: ""real1"", __DUPLICATE_keyA_2: ""real1"",
        //                  keyD: ""real2"", __DUPLICATE_keyD_1: ""real2"", __DUPLICATE_keyD_2: ""real2"" }]->(#1)
        //   (#2)-[#2:REL { keyA: ""actual"", keyB: ""actual"", keyC: ""actual"" }]->(#0)

        File dir = MigrationTestUtils.find21FormatStoreDirectoryWithDuplicateProperties( storeDir.directory() );

        GraphDatabaseBuilder builder =
                new GraphDatabaseFactory().newEmbeddedDatabaseBuilder( dir.getAbsolutePath() ).setConfig(
                        GraphDatabaseSettings.allow_store_upgrade, ""true"" );
        GraphDatabaseService database = builder.newGraphDatabase();
        database.shutdown();
        ConsistencyCheckService service = new ConsistencyCheckService();

        ConsistencyCheckService.Result result = service.runFullConsistencyCheck(
                dir.getAbsolutePath(), new Config(), ProgressMonitorFactory.NONE, StringLogger.SYSTEM );
        assertTrue( result.isSuccessful() );

        database = builder.newGraphDatabase();
        // Upgrade is now completed. Verify the contents:
        DependencyResolver dependencyResolver = ((GraphDatabaseAPI) database).getDependencyResolver();
        NeoStoreProvider provider = dependencyResolver.resolveDependency( NeoStoreProvider.class );
        NeoStore store = provider.evaluate();
        NodeStore nodeStore = store.getNodeStore();
        RelationshipStore relStore = store.getRelationshipStore();
        PropertyStore propertyStore = store.getPropertyStore();

        // Verify that the properties appear correct to the outside world:
        try ( Transaction ignore = database.beginTx() )
        {
            verifyPropertiesEqual( database.getNodeById( 0 ),
                    Pair.of( ""keyA"", ""actual"" ) );
            verifyPropertiesEqual( database.getNodeById( 1 ),
                    Pair.of( ""keyA"", ""actual"" ),
                    Pair.of( ""__DUPLICATE_keyA_1"", ""actual"" ),
                    Pair.of( ""__DUPLICATE_keyA_2"", ""actual"" ));
            verifyPropertiesEqual( database.getNodeById( 2 ),
                    Pair.of( ""keyA"", ""real1"" ),
                    Pair.of( ""keyD"", ""real2"" ) );
            verifyPropertiesEqual( database.getNodeById( 3 ),
                    Pair.of( ""keyA"", ""real1"" ),
                    Pair.of( ""__DUPLICATE_keyA_1"", ""real1"" ),
                    Pair.of( ""__DUPLICATE_keyA_2"", ""real1"" ),
                    Pair.of( ""keyD"", ""real2"" ),
                    Pair.of( ""__DUPLICATE_keyD_1"", ""real2"" ),
                    Pair.of( ""__DUPLICATE_keyD_2"", ""real2"" ) );
            verifyPropertiesEqual( database.getNodeById( 4 ),
                    Pair.of( ""keyA"", ""actual"" ),
                    Pair.of( ""keyB"", ""actual"" ),
                    Pair.of( ""keyC"", ""actual"" ) );
            verifyPropertiesEqual( database.getRelationshipById( 0 ),
                    Pair.of( ""keyA"", ""actual"" ),
                    Pair.of( ""__DUPLICATE_keyA_1"", ""actual"" ),
                    Pair.of( ""__DUPLICATE_keyA_2"", ""actual"" ));
            verifyPropertiesEqual( database.getRelationshipById( 1 ),
                    Pair.of( ""keyA"", ""real1"" ),
                    Pair.of( ""__DUPLICATE_keyA_1"", ""real1"" ),
                    Pair.of( ""__DUPLICATE_keyA_2"", ""real1"" ),
                    Pair.of( ""keyD"", ""real2"" ),
                    Pair.of( ""__DUPLICATE_keyD_1"", ""real2"" ),
                    Pair.of( ""__DUPLICATE_keyD_2"", ""real2"" ) );
            verifyPropertiesEqual( database.getRelationshipById( 2 ),
                    Pair.of( ""keyA"", ""actual"" ),
                    Pair.of( ""keyB"", ""actual"" ),
                    Pair.of( ""keyC"", ""actual"" ) );
        }

        // Verify that there are no two properties on the entities, that have the same key:
        // (This is important because the verification above cannot tell if we have two keys with the same value)
        verifyNoDuplicatePropertyKeys( propertyStore, nodeStore.getRecord( 0 ).getNextProp() );
        verifyNoDuplicatePropertyKeys( propertyStore, nodeStore.getRecord( 1 ).getNextProp() );
        verifyNoDuplicatePropertyKeys( propertyStore, nodeStore.getRecord( 2 ).getNextProp() );
        verifyNoDuplicatePropertyKeys( propertyStore, relStore.getRecord( 0 ).getNextProp() );
        verifyNoDuplicatePropertyKeys( propertyStore, relStore.getRecord( 1 ).getNextProp() );

        database.shutdown();
    }
",non-flaky,5
13883,neo4j_neo4j,StoreMigratorFrom19IT.shouldMigrate,"    @Test
    public void shouldMigrate() throws IOException, ConsistencyCheckIncompleteException
    {
        // GIVEN
        File legacyStoreDir = find19FormatHugeStoreDirectory( storeDir.directory() );

        // WHEN
        newStoreUpgrader().migrateIfNeeded( legacyStoreDir, schemaIndexProvider, pageCache );

        // THEN
        assertEquals( 100, monitor.eventSize() );
        assertTrue( monitor.isStarted() );
        assertTrue( monitor.isFinished() );

        GraphDatabaseService database = new GraphDatabaseFactory().newEmbeddedDatabase( storeDir.absolutePath() );

        try
        {
            verifyDatabaseContents( database );
        }
        finally
        {
            // CLEANUP
            database.shutdown();
        }

        try ( NeoStore neoStore = storeFactory.newNeoStore( true ) )
        {
            verifyNeoStore( neoStore );
        }

        assertConsistentStore( storeDir.directory() );
    }
",non-flaky,5
13884,neo4j_neo4j,StoreMigratorFrom19IT.shouldMigrateCluster,"    @Test
    public void shouldMigrateCluster() throws Throwable
    {
        // Given
        File legacyStoreDir = find19FormatHugeStoreDirectory( storeDir.directory() );

        // When
        newStoreUpgrader().migrateIfNeeded( legacyStoreDir, schemaIndexProvider, pageCache );

        ClusterManager.ManagedCluster cluster = buildClusterWithMasterDirIn( fs, legacyStoreDir, life );
        cluster.await( allSeesAllAsAvailable() );
        cluster.sync();

        // Then
        HighlyAvailableGraphDatabase slave1 = cluster.getAnySlave();
        verifySlaveContents( slave1 );
        verifySlaveContents( cluster.getAnySlave( slave1 ) );
        verifyDatabaseContents( cluster.getMaster() );
    }
",non-flaky,5
13885,neo4j_neo4j,StoreMigratorFrom19IT.shouldDeduplicateUniquePropertyIndexKeys,"    @Test
    public void shouldDeduplicateUniquePropertyIndexKeys() throws Exception
    {
        // GIVEN
        // a store that contains two nodes with property ""name"" of which there are two key tokens
        File legacyStoreDir = find19FormatStoreDirectory( storeDir.directory() );

        // WHEN
        // upgrading that store, the two key tokens for ""name"" should be merged

        newStoreUpgrader().migrateIfNeeded( storeDir.directory(), schemaIndexProvider, pageCache );

        // THEN
        // verify that the ""name"" property for both the involved nodes
        GraphDatabaseService db = new GraphDatabaseFactory().newEmbeddedDatabase( storeDir.absolutePath() );
        try
        {
            Node nodeA = getNodeWithName( db, ""A"" );
            assertThat( nodeA, inTx( db, hasProperty( ""name"" ).withValue( ""A"" ) ) );

            Node nodeB = getNodeWithName( db, ""B"" );
            assertThat( nodeB, inTx( db, hasProperty( ""name"" ).withValue( ""B"" ) ) );

            Node nodeC = getNodeWithName( db, ""C"" );
            assertThat( nodeC, inTx( db, hasProperty( ""name"" ).withValue( ""C"" ) ) );
            assertThat( nodeC, inTx( db, hasProperty( ""other"" ).withValue( ""a value"" ) ) );
            assertThat( nodeC, inTx( db, hasProperty( ""third"" ).withValue( ""something"" ) ) );
        }
        finally
        {
            db.shutdown();
        }

        // THEN
        // verify that there are no duplicate keys in the store
        try ( PropertyKeyTokenStore tokenStore = storeFactory.newPropertyKeyTokenStore() )
        {
            Token[] tokens = tokenStore.getTokens( MAX_VALUE );
            assertNoDuplicates( tokens );
        }

        assertConsistentStore( storeDir.directory() );
    }
",non-flaky,5
13886,neo4j_neo4j,DataGeneratorTest.shouldGenerateNodesAndRelationshipsWithProperties,"    @Test
    public void shouldGenerateNodesAndRelationshipsWithProperties() throws Exception
    {
        // given
        Configuration.Builder config = Configuration.builder();
        config.setValue( DataGenerator.node_count, 5 );
        config.setValue( DataGenerator.relationships, asList( new RelationshipSpec( ""FOO"", 1 ),
                                                              new RelationshipSpec( ""BAR"", 2 ) ) );
        config.setValue( DataGenerator.node_properties,
                asList( new PropertySpec( PropertyGenerator.STRING, 2 ) ) );
        config.setValue( DataGenerator.relationship_properties,
                asList( new PropertySpec( PropertyGenerator.STRING, 1 ) ) );

        DataGenerator generator = new DataGenerator( config.build() );

        BatchInserter batchInserter = mock( BatchInserter.class );

        // when
        generator.generateData( batchInserter );

        // then
        verify( batchInserter, times( 5 ) ).createNode( argThat( hasSize( 2 ) ) );
        verify( batchInserter, times( 5 ) ).createRelationship( anyLong(), anyLong(), argThat( hasName( ""FOO"" ) ),
                                                                argThat( hasSize( 1 ) ) );
        verify( batchInserter, times( 10 ) )
                .createRelationship( anyLong(), anyLong(), argThat( hasName( ""BAR"" ) ), argThat( hasSize( 1 ) ) );
        verifyNoMoreInteractions( batchInserter );
    }
",non-flaky,5
13887,neo4j_neo4j,JmxDocTest.dumpJmxInfo,"    @Test
    public void dumpJmxInfo() throws Exception
    {
        List<Triplet<String, String, String>> beanItems = new ArrayList<>();
        AsciiDocListGenerator listGenerator = new AsciiDocListGenerator( ""jmx-list"", ""MBeans exposed by Neo4j"", false );

        MBeanServer mBeanServer = ManagementFactory.getPlatformMBeanServer();
        SortedMap<String, ObjectName> neo4jBeans = new TreeMap<String, ObjectName>(
                String.CASE_INSENSITIVE_ORDER );

        for ( String query : QUERIES )
        {
            Set<ObjectInstance> beans = mBeanServer.queryMBeans(
                    new ObjectName( query ), null );
            for ( ObjectInstance bean : beans )
            {
                ObjectName objectName = bean.getObjectName();
                String name = objectName.getKeyProperty( BEAN_NAME );
                if ( EXCLUDES.contains( name ) )
                {
                    continue;
                }
                String name0 = objectName.getKeyProperty( BEAN_NAME0 );
                if ( name0 != null )
                {
                    name += '/' + name0;
                }
                neo4jBeans.put( name, bean.getObjectName() );
            }

        }
        assertEquals( ""Sanity checking the number of beans found;"",
                EXPECTED_NUMBER_OF_BEANS, neo4jBeans.size() );
        for ( Map.Entry<String, ObjectName> beanEntry : neo4jBeans.entrySet() )
        {
            ObjectName objectName = beanEntry.getValue();
            String name = beanEntry.getKey();
            Set<ObjectInstance> mBeans = mBeanServer.queryMBeans( objectName,
                    null );
            if ( mBeans.size() != 1 )
            {
                throw new IllegalStateException( ""Unexpected size [""
                        + mBeans.size()
                        + ""] of query result for [""
                        + objectName + ""]."" );
            }
            ObjectInstance bean = mBeans.iterator()
                    .next();
            MBeanInfo info = mBeanServer.getMBeanInfo( objectName );
            String description = info.getDescription()
                    .replace( '\n', ' ' );

            String id = getId( name );
            beanItems.add( Triplet.of( id, name, description ) );

            writeDetailsToFile( id, objectName, bean, info, description );
        }
        Writer fw = null;
        try
        {
            fw = AsciiDocGenerator.getFW( ""target/docs/ops"", ""JMX List"" );
            fw.write( listGenerator.generateListAndTableCombo( beanItems ) );
        }
        finally
        {
            if ( fw != null )
            {
                fw.close();
            }
        }
    }
",non-flaky,5
13888,neo4j_neo4j,HaBeanIT.canGetHaBean,"    @Test
    public void canGetHaBean() throws Throwable
    {
        startCluster( 1 );
        HighAvailability ha = ha( cluster.getMaster() );
        assertNotNull( ""could not get ha bean"", ha );
        assertMasterInformation( ha );
    }
",non-flaky,5
13889,neo4j_neo4j,HaBeanIT.testLatestTxInfoIsCorrect,"    @Test
    public void testLatestTxInfoIsCorrect() throws Throwable
    {
        startCluster( 1 );
        HighlyAvailableGraphDatabase db = cluster.getMaster();
        HighAvailability masterHa = ha( db );
        long lastCommitted = masterHa.getLastCommittedTxId();
        try ( Transaction tx = db.beginTx() )
        {
            db.createNode();
            tx.success();
        }
        assertEquals( lastCommitted + 1, masterHa.getLastCommittedTxId() );
    }
",non-flaky,5
13890,neo4j_neo4j,HaBeanIT.testUpdatePullWorksAndUpdatesLastUpdateTime,"    @Test
    public void testUpdatePullWorksAndUpdatesLastUpdateTime() throws Throwable
    {
        startCluster( 2 );
        HighlyAvailableGraphDatabase master = cluster.getMaster();
        HighlyAvailableGraphDatabase slave = cluster.getAnySlave();
        Transaction tx = master.beginTx();
        master.createNode();
        tx.success();
        tx.finish();
        HighAvailability slaveBean = ha( slave );
        DateFormat format = new SimpleDateFormat( ""yyyy-MM-DD kk:mm:ss.SSSZZZZ"" );
        // To begin with, no updates
        slaveBean.update();
        long timeUpdated = format.parse( slaveBean.getLastUpdateTime() ).getTime();
        assertTrue( timeUpdated > 0 );
    }
",non-flaky,5
13891,neo4j_neo4j,HaBeanIT.testAfterGentleMasterSwitchClusterInfoIsCorrect,"    @Test
    public void testAfterGentleMasterSwitchClusterInfoIsCorrect() throws Throwable
    {
        startCluster( 3 );
        RepairKit masterShutdown = cluster.shutdown( cluster.getMaster() );
        cluster.await( ClusterManager.masterAvailable() );
        cluster.await( ClusterManager.masterSeesSlavesAsAvailable( 1 ) );
        for ( HighlyAvailableGraphDatabase db : cluster.getAllMembers() )
        {
            assertEquals( 2, ha( db ).getInstancesInCluster().length );
        }
        masterShutdown.repair();
        cluster.await( ClusterManager.allSeesAllAsAvailable() );
        for ( HighlyAvailableGraphDatabase db : cluster.getAllMembers() )
        {
            HighAvailability bean = ha( db );

            assertEquals( 3, bean.getInstancesInCluster().length );
            for ( ClusterMemberInfo info : bean.getInstancesInCluster() )
            {
                assertTrue( ""every instance should be available"", info.isAvailable() );
                assertTrue( ""every instances should have at least one role"", info.getRoles().length > 0 );
                if ( HighAvailabilityModeSwitcher.MASTER.equals( info.getRoles()[0] ) )
                {
                    assertEquals( ""coordinator should be master"",
                            HighAvailabilityModeSwitcher.MASTER, info.getHaRole() );
                }
                else
                {
                    assertEquals( ""Either master or slave, no other way"",
                            HighAvailabilityModeSwitcher.SLAVE, info.getRoles()[0] );
                    assertEquals( ""instance "" + info.getInstanceId() + "" is cluster slave but HA master"",
                            HighAvailabilityModeSwitcher.SLAVE, info.getHaRole() );
                }
                for ( String uri : info.getUris() )
                {
                    assertTrue( ""roles should contain URIs"",
                            uri.startsWith( ""ha://"" ) || uri.startsWith( ""backup://"" ) );
                }
            }
        }
    }
",non-flaky,5
13892,neo4j_neo4j,HaBeanIT.testAfterHardMasterSwitchClusterInfoIsCorrect,"    @Test
    public void testAfterHardMasterSwitchClusterInfoIsCorrect() throws Throwable
    {
        startCluster( 3 );
        RepairKit masterShutdown = cluster.fail( cluster.getMaster() );
        cluster.await( ClusterManager.masterAvailable() );
        cluster.await( ClusterManager.masterSeesSlavesAsAvailable( 1 ) );
        for ( HighlyAvailableGraphDatabase db : cluster.getAllMembers() )
        {
            if ( db.getInstanceState() == HighAvailabilityMemberState.PENDING )
            {
                continue;
            }
            // Instance that was hard killed will still be in the cluster
            assertEquals( 3, ha( db ).getInstancesInCluster().length );
        }
        masterShutdown.repair();
        cluster.await( ClusterManager.masterAvailable() );
        cluster.await( ClusterManager.masterSeesSlavesAsAvailable( 2 ) );
        for ( HighlyAvailableGraphDatabase db : cluster.getAllMembers() )
        {
            int mastersFound = 0;
            HighAvailability bean = ha( db );

            assertEquals( 3, bean.getInstancesInCluster().length );
            for ( ClusterMemberInfo info : bean.getInstancesInCluster() )
            {
                assertTrue( bean.getInstanceId() + "": every instance should be available: "" + info.getInstanceId(),
                        info.isAvailable() );
                for ( String role : info.getRoles() )
                {
                    if (role.equals( HighAvailabilityModeSwitcher.MASTER ))
                    {
                        mastersFound++;
                    }
                }
            }
            assertEquals( 1, mastersFound );
        }
    }
",non-flaky,5
13893,neo4j_neo4j,HaBeanIT.canGetBranchedStoreBean,"    @Test
    public void canGetBranchedStoreBean() throws Throwable
    {
        startCluster( 1 );
        BranchedStore bs = beans( cluster.getMaster() ).getBranchedStoreBean();
        assertNotNull( ""could not get branched store bean"", bs );
        assertEquals( ""no branched stores for new db"", 0,
                bs.getBranchedStores().length );
    }
",non-flaky,5
13894,neo4j_neo4j,HaBeanIT.joinedInstanceShowsUpAsSlave,"    @Test
    public void joinedInstanceShowsUpAsSlave() throws Throwable
    {
        startCluster( 2 );
        ClusterMemberInfo[] instancesInCluster = ha( cluster.getMaster() ).getInstancesInCluster();
        assertEquals( 2, instancesInCluster.length );
        ClusterMemberInfo[] secondInstancesInCluster = ha( cluster.getAnySlave() ).getInstancesInCluster();
        assertEquals( 2, secondInstancesInCluster.length );
        assertMasterAndSlaveInformation( instancesInCluster );
        assertMasterAndSlaveInformation( secondInstancesInCluster );
    }
",non-flaky,5
13895,neo4j_neo4j,HaBeanIT.leftInstanceDisappearsFromMemberList,"    @Test
    public void leftInstanceDisappearsFromMemberList() throws Throwable
    {
        // Start the second db and make sure it's visible in the member list.
        // Then shut it down to see if it disappears from the member list again.
        startCluster( 3 );
        assertEquals( 3, ha( cluster.getAnySlave() ).getInstancesInCluster().length );
        cluster.shutdown( cluster.getAnySlave() );

        cluster.await( masterSeesMembers( 2 ) );

        assertEquals( 2, ha( cluster.getMaster() ).getInstancesInCluster().length );
        assertMasterInformation( ha( cluster.getMaster() ) );
    }
",non-flaky,5
13896,neo4j_neo4j,HaBeanIT.failedMemberIsStillInMemberListAlthoughFailed,"    @Test
    public void failedMemberIsStillInMemberListAlthoughFailed() throws Throwable
    {
        startCluster( 3 );
        assertEquals( 3, ha( cluster.getAnySlave() ).getInstancesInCluster().length );

        // Fail the instance
        HighlyAvailableGraphDatabase failedDb = cluster.getAnySlave();
        RepairKit dbFailure = cluster.fail( failedDb );
        await( ha( cluster.getMaster() ), dbAlive( false ) );
        await( ha( cluster.getAnySlave( failedDb )), dbAlive( false ) );

        // Repair the failure and come back
        dbFailure.repair();
        for ( HighlyAvailableGraphDatabase db : cluster.getAllMembers() )
        {
            await( ha( db ), dbAvailability( true ) );
            await( ha( db ), dbAlive( true ) );
        }
    }
",non-flaky,5
13897,neo4j_neo4j,BackupHaIT.makeSureBackupCanBePerformedFromClusterWithDefaultName,"    @Test
    public void makeSureBackupCanBePerformedFromClusterWithDefaultName() throws Throwable
    {
        testBackupFromCluster( null );
    }
",non-flaky,5
13898,neo4j_neo4j,BackupHaIT.makeSureBackupCanBePerformedFromWronglyNamedCluster,"    @Test
    public void makeSureBackupCanBePerformedFromWronglyNamedCluster() throws Throwable
    {
        assertEquals( 0, runBackupToolFromOtherJvmToGetExitCode(
                backupArguments( ""localhost:4445"", BACKUP_PATH.getPath(), ""non.existent"" ) ) );
    }
",non-flaky,5
13899,neo4j_neo4j,BackupHaIT.makeSureBackupCanBeRestored,"    @Test
    public void makeSureBackupCanBeRestored() throws Throwable
    {
        // Run backup
        assertEquals( 0, runBackupToolFromOtherJvmToGetExitCode( backupArguments( ""localhost:4445"",
                BACKUP_PATH.getPath(), null ) ) );

        // Add some new data
        DbRepresentation changedData = createSomeData( cluster.getMaster() );

        stopCluster();

        cleanData();

        copyBackup();

        startCluster();

        // Verify that old data is back
        assertThat( changedData.equals( DbRepresentation.of( cluster.getMaster() ) ), equalTo(false) );
    }
",non-flaky,5
13900,neo4j_neo4j,BackupHaIT.makeSureBackupCanBePerformedFromAnyInstance,"    @Test
    public void makeSureBackupCanBePerformedFromAnyInstance() throws Throwable
    {
        Integer[] backupPorts = {4445, 4446, 4447};

        for ( Integer port : backupPorts )
        {
            // Run backup
            assertEquals( 0, runBackupToolFromOtherJvmToGetExitCode( backupArguments( ""localhost:"" + port,
                    BACKUP_PATH.getPath(), null ) ) );

            // Add some new data
            DbRepresentation changedData = createSomeData( cluster.getMaster() );

            stopCluster();

            cleanData();

            copyBackup();

            startCluster();

            // Verify that old data is back
            assertThat( changedData.equals( DbRepresentation.of( cluster.getMaster() ) ), equalTo(false) );
        }
    }
",non-flaky,5
13901,neo4j_neo4j,TestClientThreadIsolation.run,"    @Test
    public void testTransactionsPulled() throws Exception
    {
        final HighlyAvailableGraphDatabase master =
                (HighlyAvailableGraphDatabase) new TestHighlyAvailableGraphDatabaseFactory().
                newHighlyAvailableDatabaseBuilder( TargetDirectory.forTest( TestClientThreadIsolation.class ).cleanDirectory(
                        ""master"" ).getAbsolutePath() ).
                setConfig( ClusterSettings.server_id, ""1"" ).
                newGraphDatabase();

        final HighlyAvailableGraphDatabase slave1 =
                (HighlyAvailableGraphDatabase) new TestHighlyAvailableGraphDatabaseFactory().
                newHighlyAvailableDatabaseBuilder( TargetDirectory.forTest( TestClientThreadIsolation.class ).cleanDirectory(
                        ""slave1"" ).getAbsolutePath() ).
                setConfig( ClusterSettings.cluster_server, ""127.0.0.1:5002"" ).
                setConfig( ClusterSettings.initial_hosts, ""127.0.0.1:5001"" ).
                setConfig( ClusterSettings.server_id, ""2"" ).
                setConfig( HaSettings.max_concurrent_channels_per_slave, ""2"" ).
                setConfig( HaSettings.ha_server, ""127.0.0.1:8001"" ).
                newGraphDatabase();

        Transaction masterTx = master.beginTx();
        master.createNode().createRelationshipTo( master.createNode(),
                DynamicRelationshipType.withName( ""master"" ) ).setProperty(
                ""largeArray"", new int[20000] );
        masterTx.success();
        masterTx.finish();

        Thread thread1 = new Thread( new Runnable()
        {
            public void run()
            {
                // TODO Figure out how to do this
//                Master masterClient = slave1.getBroker().getMaster().first();
//                Response<Integer> response = masterClient.createRelationshipType(
//                        slave1.getSlaveContext( 10 ), ""name"" );
//                slave1.receive( response ); // will be suspended here
//                response.close();
            }
",non-flaky,5
13902,neo4j_neo4j,TestPullUpdatesApplied.leftCluster,"    @Test
    public void testUpdatesAreWrittenToLogBeforeBeingAppliedToStore() throws Exception
    {
        int master = getCurrentMaster();
        addNode( master );
        int toKill = (master + 1) % dbs.length;
        HighlyAvailableGraphDatabase dbToKill = dbs[toKill];

        final CountDownLatch latch1 = new CountDownLatch( 1 );

        final HighlyAvailableGraphDatabase masterDb = dbs[master];
        masterDb.getDependencyResolver().resolveDependency( ClusterClient.class ).addClusterListener(
                new ClusterListener.Adapter()
                {
                    @Override
                    public void leftCluster( InstanceId instanceId, URI member )
                    {
                        latch1.countDown();
                        masterDb.getDependencyResolver().resolveDependency( ClusterClient.class )
                                .removeClusterListener( this );
                    }
",non-flaky,5
13903,neo4j_neo4j,RollingUpgradeIT.doRollingUpgradeFromPreviousVersionWithMasterLast,"    @Test
    public void doRollingUpgradeFromPreviousVersionWithMasterLast() throws Throwable
    {
        /* High level scenario:
         * 1   Have a cluster of 3 instances running <old version>
         * 1.1 Download a <old version> package
         * 1.2 Unpack the <old version> package
         * 1.4 Assembly classpath and start 3 JVMs running <old version>
         * 1.5 Create some data in the cluster
         * 2   Go over each one restarting into <this version>
         * 2.1 Grab a JVM and kill it
         * 2.2 Start that db inside this test JVM, which will run <this version>
         * 2.3 Perform a write transaction to the current master and see that it picks it up
         * 2.4 Perform a write transaction to to this instance and see that master picks it up
         * 3   Make sure the cluster functions after each one has been restarted
         * 3.1 Do basic transactions on master/slaves.
         * 3.2 Do a master switch
         * 3.3 Restart one slave
         * 3.4 Take down the instances and do consistency check */

        try
        {
            startOldVersionCluster();
            rollOverToNewVersion();
            shutdownAndDoConsistencyChecks();
        }
        catch ( Throwable e )
        {
            e.printStackTrace();
            throw e;
        }
    }
",non-flaky,5
13904,neo4j_neo4j,MasterClientTest.newClientsShouldNotIgnoreStoreIdDifferences,"    @Test(expected = MismatchingStoreIdException.class)
    public void newClientsShouldNotIgnoreStoreIdDifferences() throws Throwable
    {
        // Given
        MasterImpl.SPI masterImplSPI = MasterImplTest.mockedSpi( new StoreId( 1, 2, 3, 4 ) );
        when( masterImplSPI.getTransactionChecksum( anyLong() ) ).thenReturn( 5L );

        cleanupRule.add( newMasterServer( masterImplSPI ) );

        StoreId storeId = new StoreId( 5, 6, 7, 8 );
        MasterClient214 masterClient214 = cleanupRule.add( newMasterClient214( storeId ) );

        // When
        masterClient214.handshake( 1, storeId );
    }
",non-flaky,5
13905,neo4j_neo4j,MasterClientTest.clientShouldReadAndApplyTransactionLogsOnNewLockSessionRequest,"    @Test
    public void clientShouldReadAndApplyTransactionLogsOnNewLockSessionRequest() throws Throwable
    {
        // Given
        MasterImpl master = spy( newMasterImpl( mockMasterImplSpiWith( StoreId.DEFAULT ) ) );
        doReturn( voidResponseWithTransactionLogs() ).when( master ).newLockSession( any( RequestContext.class ) );

        cleanupRule.add( newMasterServer( master ) );

        DependencyResolver resolver = mock( DependencyResolver.class );
        LogicalTransactionStore txStore = mock( LogicalTransactionStore.class );
        TransactionRepresentationStoreApplier txApplier = mock( TransactionRepresentationStoreApplier.class );
        TransactionIdStore txIdStore = mock( TransactionIdStore.class );
        TransactionAppender txAppender = mock( TransactionAppender.class );
        when( txAppender.append( any( TransactionRepresentation.class ), anyLong() ) )
                .thenReturn( mock( Commitment.class ) );
        LogFile logFile = mock( LogFile.class );

        when( resolver.resolveDependency( LogicalTransactionStore.class ) ).thenReturn( txStore );
        when( resolver.resolveDependency( TransactionRepresentationStoreApplier.class ) ).thenReturn( txApplier );
        when( resolver.resolveDependency( TransactionIdStore.class ) ).thenReturn( txIdStore );
        when( resolver.resolveDependency( LogFile.class ) ).thenReturn( logFile );
        when( resolver.resolveDependency( LogRotation.class ) ).thenReturn( mock(LogRotation.class) );
        when( txStore.getAppender() ).thenReturn( txAppender );
        IndexUpdatesValidator indexUpdatesValidator = mock( IndexUpdatesValidator.class );
        when( indexUpdatesValidator.validate( any( TransactionRepresentation.class ),
                any( TransactionApplicationMode.class ) ) ).thenReturn( ValidatedIndexUpdates.NONE );
        when( resolver.resolveDependency( IndexUpdatesValidator.class ) ).thenReturn( indexUpdatesValidator );

        ResponseUnpacker unpacker = initAndStart( new TransactionCommittingResponseUnpacker( resolver ) );

        MasterClient masterClient = cleanupRule.add( newMasterClient214( StoreId.DEFAULT, unpacker ) );

        // When
        masterClient.newLockSession( new RequestContext( 1, 2, 3, 4, 5 ) );

        // Then
        verify( txAppender, times( TX_LOG_COUNT ) ).append( any( TransactionRepresentation.class ), anyLong() );
        // we can't verify transactionCommitted since that's part of the TransactionAppender, which we have mocked
        verify( txApplier, times( TX_LOG_COUNT ) )
                .apply( any( TransactionRepresentation.class ), any( ValidatedIndexUpdates.class ),
                        any( LockGroup.class ), anyLong(), any( TransactionApplicationMode.class ) );
        verify( txIdStore, times( TX_LOG_COUNT ) ).transactionClosed( anyLong() );
    }
",non-flaky,5
13906,neo4j_neo4j,TestClusterIndexDeletion.givenClusterWithCreatedIndexWhenDeleteIndexOnMasterThenIndexIsDeletedOnSlave,"    @Test
    public void givenClusterWithCreatedIndexWhenDeleteIndexOnMasterThenIndexIsDeletedOnSlave() throws Throwable
    {
        ClusterManager clusterManager =
            new ClusterManager( fromXml( getClass().getResource( ""/threeinstances.xml"" ).toURI() ),
                TargetDirectory.forTest( getClass() ).cleanDirectory( ""testCluster"" ),
                MapUtil.stringMap( HaSettings.ha_server.name(), "":6001-6005"",
                        HaSettings.tx_push_factor.name(), ""2"" ));
        try
        {
            // Given
            clusterManager.start();

            clusterManager.getDefaultCluster().await( ClusterManager.allSeesAllAsAvailable() );

            GraphDatabaseAPI master = clusterManager.getDefaultCluster().getMaster();
            try ( Transaction tx = master.beginTx() )
            {
                master.index().forNodes( ""Test"" );
                tx.success();
            }

            HighlyAvailableGraphDatabase aSlave = clusterManager.getDefaultCluster().getAnySlave();
            try ( Transaction tx = aSlave.beginTx() )
            {
                assertThat( aSlave.index().existsForNodes( ""Test"" ), equalTo( true ) );
                tx.success();
            }

            // When
            try ( Transaction tx = master.beginTx() )
            {
                master.index().forNodes( ""Test"" ).delete();
                tx.success();
            }

            // Then
            HighlyAvailableGraphDatabase anotherSlave = clusterManager.getDefaultCluster().getAnySlave();
            try ( Transaction tx = anotherSlave.beginTx() )
            {
                assertThat( anotherSlave.index().existsForNodes( ""Test"" ), equalTo( false ) );
                tx.success();
            }
        }
        finally
        {
            clusterManager.stop();
        }
    }
",non-flaky,5
13907,neo4j_neo4j,PullStormIT.run,"    @Test
    public void testPullStorm() throws Throwable
    {
        // given

        ClusterManager clusterManager = new ClusterManager( ClusterManager.clusterWithAdditionalArbiters( 2, 1 ),
                testDirectory.directory(),
                stringMap( HaSettings.pull_interval.name(), ""0"",
                           HaSettings.tx_push_factor.name(), ""1"") );

        clusterManager.start();

        try
        {
            ClusterManager.ManagedCluster cluster = clusterManager.getDefaultCluster();
            cluster.await( ClusterManager.masterAvailable(  ) );
            cluster.await( ClusterManager.masterSeesSlavesAsAvailable( 1 ) );

            // Create data
            final HighlyAvailableGraphDatabase master = cluster.getMaster();
            {
                Transaction tx = master.beginTx();
                for ( int i = 0; i < 1000; i++ )
                {
                    master.createNode().setProperty( ""foo"", ""bar"" );
                }
                tx.success();
                tx.finish();
            }

            // Slave goes down
            HighlyAvailableGraphDatabase slave = cluster.getAnySlave();
            ClusterManager.RepairKit repairKit = cluster.fail( slave );

            // Create more data
            for ( int i = 0; i < 1000; i++ )
            {
                {
                    Transaction tx = master.beginTx();
                    for ( int j = 0; j < 1000; j++ )
                    {
                        master.createNode().setProperty( ""foo"", ""bar"" );
                        master.createNode().setProperty( ""foo"", ""bar"" );
                    }
                    tx.success();
                    tx.finish();
                }
            }

            // Slave comes back online
            repairKit.repair();

            cluster.await( ClusterManager.masterSeesSlavesAsAvailable( 1 ) );

            // when

            // Create 20 concurrent transactions
            System.out.println( ""Pull storm"" );
            ExecutorService executor = Executors.newFixedThreadPool( 20 );
            for ( int i = 0; i < 20; i++ )
            {
                executor.submit( new Runnable()
                {
                    @Override
                    public void run()
                    {
                        Transaction tx = master.beginTx();
                        master.createNode().setProperty( ""foo"", ""bar"" );
                        tx.success();
                        tx.finish(); // This should cause lots of concurrent calls to pullUpdate()
                    }
",non-flaky,5
13908,neo4j_neo4j,TestBlockLogBuffer.onlyOneNonFullBlock,"    @Test
    public void onlyOneNonFullBlock() throws IOException
    {
        byte[] bytes = new byte[255];
        ChannelBuffer wrappedBuffer = ChannelBuffers.wrappedBuffer( bytes );
        wrappedBuffer.resetWriterIndex();
        BlockLogBuffer buffer = new BlockLogBuffer( wrappedBuffer, new Monitors().newMonitor( ByteCounterMonitor.class ) );

        byte byteValue = 5;
        int intValue = 1234;
        long longValue = 574853;
        float floatValue = 304985.5f;
        double doubleValue = 48493.22d;
        final byte[] bytesValue = new byte[] { 1, 5, 2, 6, 3 };
        buffer.put( byteValue );
        buffer.putInt( intValue );
        buffer.putLong( longValue );
        buffer.putFloat( floatValue );
        buffer.putDouble( doubleValue );
        buffer.put( bytesValue, bytesValue.length );
        buffer.close();

        ByteBuffer verificationBuffer = ByteBuffer.wrap( bytes );
        assertEquals( 30, verificationBuffer.get() );
        assertEquals( byteValue, verificationBuffer.get() );
        assertEquals( intValue, verificationBuffer.getInt() );
        assertEquals( longValue, verificationBuffer.getLong() );
        assertEquals( floatValue, verificationBuffer.getFloat(), 0.0 );
        assertEquals( doubleValue, verificationBuffer.getDouble(), 0.0 );
        byte[] actualBytes = new byte[bytesValue.length];
        verificationBuffer.get( actualBytes );
        assertThat( actualBytes, new ArrayMatches<byte[]>( bytesValue ) );
    }
",non-flaky,5
13909,neo4j_neo4j,TestBlockLogBuffer.readSmallPortions,"    @Test
    public void readSmallPortions() throws IOException
    {
        byte[] bytes = new byte[255];
        ChannelBuffer wrappedBuffer = ChannelBuffers.wrappedBuffer( bytes );
        wrappedBuffer.resetWriterIndex();
        BlockLogBuffer buffer = new BlockLogBuffer( wrappedBuffer, new Monitors().newMonitor( ByteCounterMonitor.class ) );

        byte byteValue = 5;
        int intValue = 1234;
        long longValue = 574853;
        buffer.put( byteValue );
        buffer.putInt( intValue );
        buffer.putLong( longValue );
        buffer.close();

        ReadableByteChannel reader = new BlockLogReader( wrappedBuffer );
        ByteBuffer verificationBuffer = ByteBuffer.wrap( new byte[1] );
        reader.read( verificationBuffer );
        verificationBuffer.flip();
        assertEquals( byteValue, verificationBuffer.get() );
        verificationBuffer = ByteBuffer.wrap( new byte[4] );
        reader.read( verificationBuffer );
        verificationBuffer.flip();
        assertEquals( intValue, verificationBuffer.getInt() );
        verificationBuffer = ByteBuffer.wrap( new byte[8] );
        reader.read( verificationBuffer );
        verificationBuffer.flip();
        assertEquals( longValue, verificationBuffer.getLong() );
    }
",non-flaky,5
13910,neo4j_neo4j,TestBlockLogBuffer.readOnlyOneNonFullBlock,"    @Test
    public void readOnlyOneNonFullBlock() throws IOException
    {
        byte[] bytes = new byte[255];
        ChannelBuffer wrappedBuffer = ChannelBuffers.wrappedBuffer( bytes );
        wrappedBuffer.resetWriterIndex();
        BlockLogBuffer buffer = new BlockLogBuffer( wrappedBuffer, new Monitors().newMonitor( ByteCounterMonitor.class ) );

        byte byteValue = 5;
        int intValue = 1234;
        long longValue = 574853;
        float floatValue = 304985.5f;
        double doubleValue = 48493.22d;
        final byte[] bytesValue = new byte[] { 1, 5, 2, 6, 3 };
        buffer.put( byteValue );
        buffer.putInt( intValue );
        buffer.putLong( longValue );
        buffer.putFloat( floatValue );
        buffer.putDouble( doubleValue );
        buffer.put( bytesValue, bytesValue.length );
        buffer.close();

        ReadableByteChannel reader = new BlockLogReader( wrappedBuffer );
        ByteBuffer verificationBuffer = ByteBuffer.wrap( new byte[1000] );
        reader.read( verificationBuffer );
        verificationBuffer.flip();
        assertEquals( byteValue, verificationBuffer.get() );
        assertEquals( intValue, verificationBuffer.getInt() );
        assertEquals( longValue, verificationBuffer.getLong() );
        assertEquals( floatValue, verificationBuffer.getFloat(), 0.0 );
        assertEquals( doubleValue, verificationBuffer.getDouble(), 0.0 );
        byte[] actualBytes = new byte[bytesValue.length];
        verificationBuffer.get( actualBytes );
        assertThat( actualBytes, new ArrayMatches<byte[]>( bytesValue ) );
    }
",non-flaky,5
13911,neo4j_neo4j,TestBlockLogBuffer.onlyOneFullBlock,"    @Test
    public void onlyOneFullBlock() throws Exception
    {
        byte[] bytes = new byte[256];
        ChannelBuffer wrappedBuffer = ChannelBuffers.wrappedBuffer( bytes );
        wrappedBuffer.resetWriterIndex();
        BlockLogBuffer buffer = new BlockLogBuffer( wrappedBuffer, new Monitors().newMonitor( ByteCounterMonitor.class ) );

        byte[] bytesValue = new byte[255];
        bytesValue[0] = 1;
        bytesValue[254] = -1;
        buffer.put( bytesValue, bytesValue.length );
        buffer.close();

        ByteBuffer verificationBuffer = ByteBuffer.wrap( bytes );
        assertEquals( (byte) 255, verificationBuffer.get() );
        byte[] actualBytes = new byte[bytesValue.length];
        verificationBuffer.get( actualBytes );
        assertThat( actualBytes, new ArrayMatches<byte[]>( bytesValue ) );
    }
",non-flaky,5
13912,neo4j_neo4j,TestBlockLogBuffer.readOnlyOneFullBlock,"    @Test
    public void readOnlyOneFullBlock() throws Exception
    {
        byte[] bytes = new byte[256];
        ChannelBuffer wrappedBuffer = ChannelBuffers.wrappedBuffer( bytes );
        wrappedBuffer.resetWriterIndex();
        BlockLogBuffer buffer = new BlockLogBuffer( wrappedBuffer, new Monitors().newMonitor( ByteCounterMonitor.class ) );

        byte[] bytesValue = new byte[255];
        bytesValue[0] = 1;
        bytesValue[254] = -1;
        buffer.put( bytesValue, bytesValue.length );
        buffer.close();

        ReadableByteChannel reader = new BlockLogReader( wrappedBuffer );
        ByteBuffer verificationBuffer = ByteBuffer.wrap( new byte[1000] );
        reader.read( verificationBuffer );
        verificationBuffer.flip();
        byte[] actualBytes = new byte[bytesValue.length];
        verificationBuffer.get( actualBytes );
        assertThat( actualBytes, new ArrayMatches<byte[]>( bytesValue ) );
    }
",non-flaky,5
13913,neo4j_neo4j,TestBlockLogBuffer.canWriteLargestAtomAfterFillingBuffer,"    @Test
    public void canWriteLargestAtomAfterFillingBuffer() throws Exception
    {
        byte[] bytes = new byte[300];
        ChannelBuffer wrappedBuffer = ChannelBuffers.wrappedBuffer( bytes );
        wrappedBuffer.resetWriterIndex();
        BlockLogBuffer buffer = new BlockLogBuffer( wrappedBuffer, new Monitors().newMonitor( ByteCounterMonitor.class ) );

        byte[] bytesValue = new byte[255];
        bytesValue[0] = 1;
        bytesValue[254] = -1;
        long longValue = 123456;
        buffer.put( bytesValue, bytesValue.length );
        buffer.putLong( longValue );
        buffer.close();

        ByteBuffer verificationBuffer = ByteBuffer.wrap( bytes );
        assertEquals( (byte) 0, verificationBuffer.get() );
        byte[] actualBytes = new byte[bytesValue.length];
        verificationBuffer.get( actualBytes );
        assertThat( actualBytes, new ArrayMatches<byte[]>( bytesValue ) );
        assertEquals( (byte) 8, verificationBuffer.get() );
        assertEquals( longValue, verificationBuffer.getLong() );
    }
",non-flaky,5
13914,neo4j_neo4j,TestBlockLogBuffer.canWriteReallyLargeByteArray,"    @Test
    public void canWriteReallyLargeByteArray() throws Exception
    {
        byte[] bytes = new byte[650];
        ChannelBuffer wrappedBuffer = ChannelBuffers.wrappedBuffer( bytes );
        wrappedBuffer.resetWriterIndex();
        BlockLogBuffer buffer = new BlockLogBuffer( wrappedBuffer, new Monitors().newMonitor( ByteCounterMonitor.class ) );

        byte[] bytesValue = new byte[600];
        bytesValue[1] = 1;
        bytesValue[99] = 2;
        bytesValue[199] = 3;
        bytesValue[299] = 4;
        bytesValue[399] = 5;
        bytesValue[499] = 6;
        bytesValue[599] = 7;
        buffer.put( bytesValue, bytesValue.length );
        buffer.close();

        byte[] actual;
        ByteBuffer verificationBuffer = ByteBuffer.wrap( bytes );
        assertEquals( (byte) 0, verificationBuffer.get() );
        actual = new byte[255];
        verificationBuffer.get( actual );
        assertThat( actual, new ArrayMatches<byte[]>( Arrays.copyOfRange( bytesValue, 0, 255 ) ) );
        assertEquals( (byte) 0, verificationBuffer.get() );
        actual = new byte[255];
        verificationBuffer.get( actual );
        assertThat( actual, new ArrayMatches<byte[]>( Arrays.copyOfRange( bytesValue, 255, 510 ) ) );
        assertEquals( (byte) 90, verificationBuffer.get() );
        actual = new byte[90];
        verificationBuffer.get( actual );
        assertThat( actual, new ArrayMatches<byte[]>( Arrays.copyOfRange( bytesValue, 510, 600 ) ) );
    }
",non-flaky,5
13915,neo4j_neo4j,TestBlockLogBuffer.canReaderReallyLargeByteArray,"    @Test
    public void canReaderReallyLargeByteArray() throws Exception
    {
        byte[] bytes = new byte[650];
        ChannelBuffer wrappedBuffer = ChannelBuffers.wrappedBuffer( bytes );
        wrappedBuffer.resetWriterIndex();
        BlockLogBuffer buffer = new BlockLogBuffer( wrappedBuffer, new Monitors().newMonitor( ByteCounterMonitor.class ) );

        byte[] bytesValue = new byte[600];
        bytesValue[1] = 1;
        bytesValue[99] = 2;
        bytesValue[199] = 3;
        bytesValue[299] = 4;
        bytesValue[399] = 5;
        bytesValue[499] = 6;
        bytesValue[599] = 7;
        buffer.put( bytesValue, bytesValue.length );
        buffer.close();

        byte[] actual;
        BlockLogReader reader = new BlockLogReader( wrappedBuffer );
        ByteBuffer verificationBuffer = ByteBuffer.wrap( new byte[1000] );
        reader.read( verificationBuffer );
        verificationBuffer.flip();
        actual = new byte[255];
        verificationBuffer.get( actual );
        assertThat( actual, new ArrayMatches<byte[]>( Arrays.copyOfRange( bytesValue, 0, 255 ) ) );
        actual = new byte[255];
        verificationBuffer.get( actual );
        assertThat( actual, new ArrayMatches<byte[]>( Arrays.copyOfRange( bytesValue, 255, 510 ) ) );
        actual = new byte[90];
        verificationBuffer.get( actual );
        assertThat( actual, new ArrayMatches<byte[]>( Arrays.copyOfRange( bytesValue, 510, 600 ) ) );
    }
",non-flaky,5
13916,neo4j_neo4j,HaCacheIT.shouldUpdateSlaveCacheWhenRemovingRelationshipGroupFromDenseNode,"    @Test
    public void shouldUpdateSlaveCacheWhenRemovingRelationshipGroupFromDenseNode() throws Throwable
    {
        ClusterManager manager = new ClusterManager( clusterOfSize( 3 ), root.directory(),
                                                     stringMap( tx_push_factor.name(), ""2"",
                                                                cache_type.name(), ""strong"",
                                                                dense_node_threshold.name(), """" + DENSE_NODE ) );
        try
        {
            // given
            manager.start();
            ClusterManager.ManagedCluster cluster = manager.getDefaultCluster();
            cluster.await( ClusterManager.masterAvailable() );
            cluster.await( ClusterManager.masterSeesAllSlavesAsAvailable() );
            HighlyAvailableGraphDatabase master = cluster.getMaster();
            long nodeId; // a dense node
            try ( Transaction tx = master.beginTx() )
            {
                Node node = master.createNode();
                for ( int i = 0; i < DENSE_NODE; i++ )
                {
                    node.createRelationshipTo( master.createNode(), withName( ""FOO"" ) );
                }
                master.createNode().createRelationshipTo( node, withName( ""BAR"" ) );

                tx.success();
                nodeId = node.getId();
            }
            // fully cache node on all instances
            int count = 0;
            for ( HighlyAvailableGraphDatabase db : cluster.getAllMembers() )
            {
                try ( Transaction tx = db.beginTx() )
                {
                    int these = count( db.getNodeById( nodeId ).getRelationships() );
                    assertTrue( String.format( ""expected=%s, count here=%s"", count, these ),
                                these != 0 && (count == 0 || these == count) );
                    count = these;
                    tx.success();
                }
            }

            // when
            try ( Transaction tx = master.beginTx() )
            {
                for ( Relationship relationship : master.getNodeById( nodeId ).getRelationships( withName( ""BAR"" ) ) )
                {
                    relationship.delete();
                }
                tx.success();
            }

            // then
            HighlyAvailableGraphDatabase slave = cluster.getAnySlave();
            try ( Transaction tx = slave.beginTx() )
            {
                List<String> relationships = new ArrayList<>();
                for ( Relationship relationship : slave.getNodeById( nodeId ).getRelationships() )
                {
                    relationships.add( String.format( ""(%d)-[%d:%s]->(%d)"",
                                                      relationship.getStartNode().getId(),
                                                      relationship.getId(), relationship.getType().name(),
                                                      relationship.getEndNode().getId() ) );
                }
                assertEquals( joinLines( relationships ), count - 1, relationships.size() );
                assertEquals( count - 1, count( slave.getNodeById( nodeId ).getRelationships() ) );

                tx.success();
            }
        }
        finally
        {
            manager.shutdown();
        }
    }
",non-flaky,5
13917,neo4j_neo4j,MultipleClusterTest.runTwoClusters,"    @Test
    public void runTwoClusters() throws Throwable
    {
        File root = TargetDirectory.forTest( getClass() ).cleanDirectory( ""cluster"" );

        ClusterManager clusterManager = new ClusterManager(
                fromXml( getClass().getResource( ""/twoclustertest.xml"" ).toURI() ), root, MapUtil.stringMap() );

        try
        {
            clusterManager.start();
            ManagedCluster cluster1 = clusterManager.getCluster( ""neo4j.ha"" );

            long cluster1NodeId;
            {
                GraphDatabaseService master = cluster1.getMaster();
                logging.getLogger().info( ""CREATE NODE"" );
                Transaction tx = master.beginTx();
                Node node = master.createNode();
                node.setProperty( ""cluster"", ""neo4j.ha"" );
                cluster1NodeId = node.getId();
                logging.getLogger().info( ""CREATED NODE"" );
                tx.success();
                tx.finish();
            }

            ManagedCluster cluster2 = clusterManager.getCluster( ""neo4j.ha2"" );
            long cluster2NodeId;
            {
                GraphDatabaseService master = cluster2.getMaster();
                logging.getLogger().info( ""CREATE NODE"" );
                Transaction tx = master.beginTx();
                Node node = master.createNode();
                node.setProperty( ""cluster"", ""neo4j.ha2"" );
                cluster2NodeId = node.getId();
                logging.getLogger().info( ""CREATED NODE"" );
                tx.success();
                tx.finish();
            }

            // Verify properties in all cluster nodes
            for ( HighlyAvailableGraphDatabase highlyAvailableGraphDatabase : cluster1.getAllMembers() )
            {
                highlyAvailableGraphDatabase.getDependencyResolver().resolveDependency( UpdatePullerClient.class ).pullUpdates();

                Transaction transaction = highlyAvailableGraphDatabase.beginTx();
                assertEquals( ""neo4j.ha"", highlyAvailableGraphDatabase.getNodeById( cluster1NodeId ).getProperty(
                        ""cluster"" ) );
                transaction.finish();
            }

            for ( HighlyAvailableGraphDatabase highlyAvailableGraphDatabase : cluster2.getAllMembers() )
            {
                highlyAvailableGraphDatabase.getDependencyResolver().resolveDependency( UpdatePullerClient.class ).pullUpdates();

                Transaction transaction = highlyAvailableGraphDatabase.beginTx();
                assertEquals( ""neo4j.ha2"", highlyAvailableGraphDatabase.getNodeById( cluster2NodeId ).getProperty(
                        ""cluster"" ) );
                transaction.finish();
            }
        }
        finally
        {
            clusterManager.stop();
        }
    }
",non-flaky,5
13918,neo4j_neo4j,QuorumWritesIT.testMasterStopsWritesWhenMajorityIsUnavailable,"    @Test
    public void testMasterStopsWritesWhenMajorityIsUnavailable() throws Throwable
    {
        File root = TargetDirectory.forTest( getClass() ).cleanDirectory(
                ""testMasterStopsWritesWhenMajorityIsUnavailable"" );
        ClusterManager clusterManager = new ClusterManager( clusterOfSize( 3 ), root,
                MapUtil.stringMap( HaSettings.tx_push_factor.name(), ""2"", HaSettings.state_switch_timeout.name(), ""5s""
                ) );
        try
        {
            clusterManager.start();
            ClusterManager.ManagedCluster cluster = clusterManager.getDefaultCluster();
            cluster.await( ClusterManager.masterAvailable(  ) );
            cluster.await( ClusterManager.masterSeesAllSlavesAsAvailable() );

            HighlyAvailableGraphDatabase master = cluster.getMaster();

            doTx( master );

            final CountDownLatch latch1 = new CountDownLatch( 1 );
            waitOnHeartbeatFail( master, latch1 );

            HighlyAvailableGraphDatabase slave1 = cluster.getAnySlave();
            cluster.fail( slave1 );

            latch1.await();
            slave1.shutdown();

            doTx( master );

            final CountDownLatch latch2 = new CountDownLatch( 1 );
            waitOnHeartbeatFail( master, latch2 );

            HighlyAvailableGraphDatabase slave2 = cluster.getAnySlave( slave1 );
            ClusterManager.RepairKit rk2 = cluster.fail( slave2 );

            latch2.await();

            // The master should stop saying that it's master
            assertFalse( master.isMaster() );

            try
            {
                doTx( master );
                fail( ""After both slaves fail txs should not go through"" );
            }
            catch ( TransactionFailureException e )
            {
                assertEquals( ""Timeout waiting for cluster to elect master"", e.getMessage() );
            }

            // This is not a hack, this simulates a period of inactivity in the cluster.
            Thread.sleep( 120000 ); // TODO Define ""inactivity"" and await that condition instead of 120 seconds.

            final CountDownLatch latch3 = new CountDownLatch( 1 );
            final CountDownLatch latch4 = new CountDownLatch( 1 );
            final CountDownLatch latch5 = new CountDownLatch( 1 );
            waitOnHeartbeatAlive( master, latch3 );
//            waitOnRoleIsAvailable( master, latch4, HighAvailabilityModeSwitcher.MASTER );
            waitOnRoleIsAvailable( master, latch5, HighAvailabilityModeSwitcher.SLAVE );

            rk2.repair();

            latch3.await();

            cluster.await( ClusterManager.masterAvailable( slave1, slave2 ) );

//            latch4.await();
            latch5.await();

            cluster.await( ClusterManager.masterAvailable(  ) );

            assertTrue( master.isMaster() );
            assertFalse( slave2.isMaster() );

            Node finalNode = doTx( master );

            try ( Transaction transaction = slave2.beginTx() )
            {
                slave2.getNodeById( finalNode.getId() );
                transaction.success();
            }
        }
        finally
        {
            clusterManager.stop();
        }
    }
",non-flaky,5
13919,neo4j_neo4j,QuorumWritesIT.testInstanceCanBeReplacedToReestablishQuorum,"    @Test
    public void testInstanceCanBeReplacedToReestablishQuorum() throws Throwable
    {
        File root = TargetDirectory.forTest( getClass() ).cleanDirectory(
                ""testInstanceCanBeReplacedToReestablishQuorum""
        );
        ClusterManager clusterManager = new ClusterManager( clusterOfSize( 3 ), root,
                MapUtil.stringMap( HaSettings.tx_push_factor.name(), ""2"", HaSettings.state_switch_timeout.name(), ""5s"" ) );
        clusterManager.start();
        ClusterManager.ManagedCluster cluster = clusterManager.getDefaultCluster();

        HighlyAvailableGraphDatabase master = cluster.getMaster();

        cluster.await( ClusterManager.masterSeesAllSlavesAsAvailable() );

        doTx( master );

        final CountDownLatch latch1 = new CountDownLatch( 1 );
        waitOnHeartbeatFail( master, latch1 );

        HighlyAvailableGraphDatabase slave1 = cluster.getAnySlave();
        cluster.fail( slave1 );

        latch1.await();
        slave1.shutdown();

        doTx( master );

        final CountDownLatch latch2 = new CountDownLatch( 1 );
        waitOnHeartbeatFail( master, latch2 );

        HighlyAvailableGraphDatabase slave2 = cluster.getAnySlave( slave1 );
        cluster.fail( slave2 );

        latch2.await();

        // The master should stop saying that it's master
        assertFalse( master.isMaster() );

        try
        {
            doTx( master );
            fail( ""After both slaves fail txs should not go through"" );
        }
        catch ( TransactionFailureException e )
        {
            assertEquals( ""Timeout waiting for cluster to elect master"", e.getMessage() );
        }

        // This is not a hack, this simulates a period of inactivity in the cluster.
        Thread.sleep( 120000 ); // TODO Define ""inactivity"" and await that condition instead of 120 seconds.

        final CountDownLatch latch3 = new CountDownLatch( 1 );
        final CountDownLatch latch4 = new CountDownLatch( 1 );
        final CountDownLatch latch5 = new CountDownLatch( 1 );
        waitOnHeartbeatAlive( master, latch3 );
        waitOnRoleIsAvailable( master, latch4, HighAvailabilityModeSwitcher.MASTER );
        waitOnRoleIsAvailable( master, latch5, HighAvailabilityModeSwitcher.SLAVE );

        HighlyAvailableGraphDatabase replacement =
                (HighlyAvailableGraphDatabase) new TestHighlyAvailableGraphDatabaseFactory().
                newHighlyAvailableDatabaseBuilder( new File( root, ""replacement"" ).getAbsolutePath() ).
                setConfig( ClusterSettings.cluster_server, "":5010"" ).
                setConfig( HaSettings.ha_server, "":6010"" ).
                setConfig( ClusterSettings.server_id, ""3"" ).
                setConfig( ClusterSettings.initial_hosts, cluster.getInitialHostsConfigString() ).
                setConfig( HaSettings.tx_push_factor, ""0"" ).
                newGraphDatabase();

        latch3.await();
        latch4.await();
        latch5.await();

        assertTrue( master.isMaster() );
        assertFalse( replacement.isMaster() );

        Node finalNode = doTx( master );

        Transaction transaction = replacement.beginTx();
        try
        {
            replacement.getNodeById( finalNode.getId() );
        }
        finally
        {
            transaction.finish();
        }

        clusterManager.stop();
        replacement.shutdown();
    }
",non-flaky,5
13920,neo4j_neo4j,ConstraintsInHAIT.creatingConstraintOnSlaveIsNotAllowed,"    @Test
    public void creatingConstraintOnSlaveIsNotAllowed() throws Exception
    {
        // given
        ClusterManager.ManagedCluster cluster = clusterRule.startCluster();
        HighlyAvailableGraphDatabase slave = cluster.getAnySlave();

        slave.beginTx();
        try
        {
            ConstraintCreator constraintCreator = slave.schema()
                    .constraintFor( DynamicLabel.label( ""LabelName"" ) ).assertPropertyIsUnique( ""PropertyName"" );

            // when
            constraintCreator.create();
            fail( ""should have thrown exception"" );
        }
        catch ( InvalidTransactionTypeException e )
        {
            assertThat(e.getMessage(), equalTo(""Modifying the database schema can only be done on the master server, "" +
                    ""this server is a slave. Please issue schema modification commands directly to the master.""));
        }
    }
",non-flaky,5
13921,neo4j_neo4j,ForeignStoreIdIT.emptyForeignDbShouldJoinAfterHavingItsEmptyDbDeleted,"    @Test
    public void emptyForeignDbShouldJoinAfterHavingItsEmptyDbDeleted() throws Exception
    {
        // GIVEN
        // -- one instance running
        firstInstance = new TestHighlyAvailableGraphDatabaseFactory()
                .newHighlyAvailableDatabaseBuilder( DIR.cleanDirectory( ""1"" ).getAbsolutePath() )
                .setConfig( server_id, ""1"" )
                .setConfig( cluster_server, ""127.0.0.1:5001"" )
                .setConfig( ha_server, ""127.0.0.1:6031"" )
                .setConfig( initial_hosts, ""127.0.0.1:5001"" )
                .newGraphDatabase();
        // -- another instance preparing to join with a store with a different store ID
        String foreignDbStoreDir = createAnotherStore( DIR.cleanDirectory( ""2"" ), 0 );

        // WHEN
        // -- the other joins
        foreignInstance = new TestHighlyAvailableGraphDatabaseFactory()
                .newHighlyAvailableDatabaseBuilder( foreignDbStoreDir )
                .setConfig( server_id, ""2"" )
                .setConfig( initial_hosts, ""127.0.0.1:5001"" )
                .setConfig( cluster_server, ""127.0.0.1:5002"" )
                .setConfig( ha_server, ""127.0.0.1:6032"" )
                .newGraphDatabase();
        // -- and creates a node
        long foreignNode = createNode( foreignInstance, ""foreigner"" );

        // THEN
        // -- that node should arrive at the master
        assertEquals( foreignNode, findNode( firstInstance, ""foreigner"" ) );
    }
",non-flaky,5
13922,neo4j_neo4j,ForeignStoreIdIT.nonEmptyForeignDbShouldNotBeAbleToJoin,"    @Test
    public void nonEmptyForeignDbShouldNotBeAbleToJoin() throws Exception
    {
        // GIVEN
        // -- one instance running
        firstInstance = new TestHighlyAvailableGraphDatabaseFactory()
                .newHighlyAvailableDatabaseBuilder( DIR.cleanDirectory( ""1"" ).getAbsolutePath() )
                .setConfig( server_id, ""1"" )
                .setConfig( initial_hosts, ""127.0.0.1:5001"" )
                .setConfig( cluster_server, ""127.0.0.1:5001"" )
                .setConfig( ha_server, ""127.0.0.1:6041"" )
                .newGraphDatabase();
        createNodes( firstInstance, 3, ""first"" );
        // -- another instance preparing to join with a store with a different store ID
        String foreignDbStoreDir = createAnotherStore( DIR.cleanDirectory( ""2"" ), 1 );

        // WHEN
        // -- the other joins
        foreignInstance = new TestHighlyAvailableGraphDatabaseFactory()
                .newHighlyAvailableDatabaseBuilder( foreignDbStoreDir )
                .setConfig( server_id, ""2"" )
                .setConfig( initial_hosts, ""127.0.0.1:5001"" )
                .setConfig( cluster_server, ""127.0.0.1:5002"" )
                .setConfig( ha_server, ""127.0.0.1:6042"" )
                .setConfig( state_switch_timeout, ""5s"" )
                .newGraphDatabase();

        try
        {
            // THEN
            // -- that node should arrive at the master
            createNode( foreignInstance, ""foreigner"" );
            fail( ""Shouldn't be able to create a node, since it shouldn't have joined"" );
        }
        catch ( Exception e )
        {
            // Good
        }
    }
",non-flaky,5
13923,neo4j_neo4j,TestPullUpdates.makeSureUpdatePullerGetsGoingAfterMasterSwitch,"    @Test
    public void makeSureUpdatePullerGetsGoingAfterMasterSwitch() throws Throwable
    {
        File root = TargetDirectory.forTest( getClass() ).cleanDirectory( testName.getMethodName() );
        ClusterManager clusterManager = new ClusterManager( clusterOfSize( 3 ), root, MapUtil.stringMap(
                HaSettings.pull_interval.name(), PULL_INTERVAL+""ms"",
                ClusterSettings.heartbeat_interval.name(), ""2s"",
                ClusterSettings.heartbeat_timeout.name(), ""30s"") );
        clusterManager.start();
        cluster = clusterManager.getDefaultCluster();
        cluster.await( allSeesAllAsAvailable() );

        cluster.info( ""### Creating initial dataset"" );
        long commonNodeId = createNodeOnMaster();

        HighlyAvailableGraphDatabase master = cluster.getMaster();
        setProperty( master, commonNodeId, 1 );
        cluster.info( ""### Initial dataset created"" );
        awaitPropagation( 1, commonNodeId, cluster );

        cluster.info( ""### Shutting down master"" );
        ClusterManager.RepairKit masterShutdownRK = cluster.shutdown( master );

        cluster.info( ""### Awaiting new master"" );
        cluster.await( masterAvailable( master ) );
        cluster.await( masterSeesSlavesAsAvailable( 1 ) );

        cluster.info( ""### Doing a write to master"" );
        setProperty( cluster.getMaster(), commonNodeId, 2 );
        awaitPropagation( 2, commonNodeId, cluster, master );

        cluster.info( ""### Repairing cluster"" );
        masterShutdownRK.repair();
        cluster.await( masterAvailable() );
        cluster.await( masterSeesSlavesAsAvailable( 2 ) );
        cluster.await( allSeesAllAsAvailable() );

        cluster.info( ""### Awaiting change propagation"" );
        awaitPropagation( 2, commonNodeId, cluster );
    }
",non-flaky,5
13924,neo4j_neo4j,TestPullUpdates.pullUpdatesShellAppPullsUpdates,"    @Test
    public void pullUpdatesShellAppPullsUpdates() throws Throwable
    {
        File root = TargetDirectory.forTest( getClass() ).cleanDirectory( testName.getMethodName() );
        Map<Integer, Map<String, String>> instanceConfig = new HashMap<>();
        for (int i = 1; i <= 2; i++)
        {
            Map<String, String> thisInstance =
                    MapUtil.stringMap( ShellSettings.remote_shell_port.name(), """" + (SHELL_PORT + i) );
            instanceConfig.put( i, thisInstance );
        }
        ClusterManager clusterManager = new ClusterManager( clusterOfSize( 2 ), root, MapUtil.stringMap(
                HaSettings.pull_interval.name(), ""0"",
                HaSettings.tx_push_factor.name(), ""0"" ,
                ShellSettings.remote_shell_enabled.name(), ""true""
                ), instanceConfig );
        clusterManager.start();
        cluster = clusterManager.getDefaultCluster();

        long commonNodeId = createNodeOnMaster();

        setProperty( cluster.getMaster(), commonNodeId, 1 );
        callPullUpdatesViaShell( 2 );
        HighlyAvailableGraphDatabase slave = cluster.getAnySlave();
        try ( Transaction tx = slave.beginTx() )
        {
            assertEquals( 1, slave.getNodeById( commonNodeId ).getProperty( ""i"" ) );
        }
    }
",non-flaky,5
13925,neo4j_neo4j,TestPullUpdates.leftCluster,"    @Test
    public void shouldPullUpdatesOnStartupNoMatterWhat() throws Exception
    {
        GraphDatabaseService slave = null;
        GraphDatabaseService master = null;
        try
        {
            File testRootDir = TargetDirectory.forTest( getClass() ).cleanDirectory( testName.getMethodName() );
            File masterDir = new File( testRootDir, ""master"" );
            master = new TestHighlyAvailableGraphDatabaseFactory().
                    newHighlyAvailableDatabaseBuilder( masterDir.getAbsolutePath() )
                    .setConfig( ClusterSettings.server_id, ""1"" )
                    .setConfig( ClusterSettings.initial_hosts, "":5001"" )
                    .newGraphDatabase();

            // Copy the store, then shutdown, so update pulling later makes sense
            File slaveDir = new File( testRootDir, ""slave"" );
            slave = new TestHighlyAvailableGraphDatabaseFactory().
                    newHighlyAvailableDatabaseBuilder( slaveDir.getAbsolutePath() )
                    .setConfig( ClusterSettings.server_id, ""2"" )
                    .setConfig( ClusterSettings.initial_hosts, "":5001"" )
                    .newGraphDatabase();

            // Required to block until the slave has left for sure
            final CountDownLatch slaveLeftLatch = new CountDownLatch( 1 );

            final ClusterClient masterClusterClient = ( (HighlyAvailableGraphDatabase) master ).getDependencyResolver()
                    .resolveDependency( ClusterClient.class );

            masterClusterClient.addClusterListener( new ClusterListener.Adapter()
            {
                @Override
                public void leftCluster( InstanceId instanceId, URI member )
                {
                    slaveLeftLatch.countDown();
                    masterClusterClient.removeClusterListener( this );
                }
",non-flaky,5
13926,neo4j_neo4j,TestProver.aClusterSnapshotShouldEqualItsOrigin,"    @Test
    public void aClusterSnapshotShouldEqualItsOrigin() throws Exception
    {
        // Given
        Logging logging = new TestLogging();
        ClusterConfiguration config = new ClusterConfiguration( ""default"",
                logging.getMessagesLog( ClusterConfiguration.class ),
                ""cluster://localhost:5001"",
                ""cluster://localhost:5002"",
                ""cluster://localhost:5003"" );

        ClusterState state = new ClusterState(
                asList(
                        newClusterInstance( new InstanceId( 1 ), new URI( ""cluster://localhost:5001"" ),
                                new Monitors(), config, logging ),
                        newClusterInstance( new InstanceId( 2 ), new URI( ""cluster://localhost:5002"" ),
                                new Monitors(), config, logging ),
                        newClusterInstance( new InstanceId( 3 ), new URI( ""cluster://localhost:5003"" ),
                                new Monitors(), config, logging ) ),
                emptySetOf( ClusterAction.class )
        );

        // When
        ClusterState snapshot = state.snapshot();

        // Then
        assertEquals( state, snapshot );
        assertEquals( state.hashCode(), snapshot.hashCode() );
    }
",non-flaky,5
13927,neo4j_neo4j,TestProver.twoStatesWithSameSetupAndPendingMessagesShouldBeEqual,"    @Test
    public void twoStatesWithSameSetupAndPendingMessagesShouldBeEqual() throws Exception
    {
        // Given
        Logging logging = new TestLogging();
        ClusterConfiguration config = new ClusterConfiguration( ""default"",
                logging.getMessagesLog( ClusterConfiguration.class ),
                ""cluster://localhost:5001"",
                ""cluster://localhost:5002"",
                ""cluster://localhost:5003"" );

        ClusterState state = new ClusterState(
                asList(
                        newClusterInstance( new InstanceId( 1 ), new URI( ""cluster://localhost:5001"" ),
                                new Monitors(), config, logging ),
                        newClusterInstance( new InstanceId( 2 ), new URI( ""cluster://localhost:5002"" ),
                                new Monitors(), config, logging ),
                        newClusterInstance( new InstanceId( 3 ), new URI( ""cluster://localhost:5003"" ),
                                new Monitors(), config, logging ) ),
                emptySetOf( ClusterAction.class )
        );

        // When
        ClusterState firstState = state.performAction( new MessageDeliveryAction( Message.to( ClusterMessage.join,
                new URI( ""cluster://localhost:5002"" ), new Object[]{""defaultcluster"",
                        new URI[]{new URI( ""cluster://localhost:5003"" )}} ).setHeader( Message.CONVERSATION_ID,
                ""-1"" ).setHeader( Message.FROM, ""cluster://localhost:5002"" ) ) );
        ClusterState secondState = state.performAction( new MessageDeliveryAction( Message.to( ClusterMessage.join,
                new URI( ""cluster://localhost:5002"" ), new Object[]{""defaultcluster"",
                        new URI[]{new URI( ""cluster://localhost:5003"" )}} ).setHeader( Message.CONVERSATION_ID,
                ""-1"" ).setHeader( Message.FROM, ""cluster://localhost:5002"" ) ) );

        // Then
        assertEquals( firstState, secondState );
        assertEquals( firstState.hashCode(), secondState.hashCode() );
    }
",non-flaky,5
13928,neo4j_neo4j,TestProverTimeouts.equalsShouldBeLogicalAndNotExact,"    @Test
    public void equalsShouldBeLogicalAndNotExact() throws Exception
    {
        // Given
        ProverTimeouts timeouts1 = new ProverTimeouts( new URI(""http://asd"") );
        ProverTimeouts timeouts2 = new ProverTimeouts( new URI(""http://asd"") );

        timeouts1.setTimeout( ""a"", Message.internal( ProposerMessage.join ) );
        timeouts1.setTimeout( ""b"", Message.internal( ProposerMessage.join ) );
        timeouts1.setTimeout( ""c"", Message.internal( ProposerMessage.join ) );

        timeouts2.setTimeout( ""b"", Message.internal( ProposerMessage.join ) );
        timeouts2.setTimeout( ""c"", Message.internal( ProposerMessage.join ) );

        // When
        timeouts1.cancelTimeout( ""a"" );

        // Then
        assertEquals(timeouts1, timeouts2);
    }
",non-flaky,5
13929,neo4j_neo4j,ClusterTransactionTest.call,"    @Test
    public void givenClusterWhenShutdownMasterThenCannotStartTransactionOnSlave() throws Throwable
    {
        // Given
        ClusterManager clusterManager = new ClusterManager(
                fromXml( getClass().getResource( ""/threeinstances.xml"" ).toURI() ),
                forTest( getClass() ).cleanDirectory( ""testCluster"" ),
                stringMap( HaSettings.ha_server.name(), "":6001-6005"", HaSettings.tx_push_factor.name(), ""2"" ) );
        try
        {
            clusterManager.start();

            clusterManager.getDefaultCluster().await( ClusterManager.allSeesAllAsAvailable() );

            GraphDatabaseAPI master = clusterManager.getDefaultCluster().getMaster();
            final GraphDatabaseAPI slave = clusterManager.getDefaultCluster().getAnySlave();

            // When
            final FutureTask<Boolean> result = new FutureTask<>( new Callable<Boolean>()
            {
                @Override
                public Boolean call() throws Exception
                {
                    try ( Transaction tx = slave.beginTx() )
                    {
                        tx.acquireWriteLock( slave.getNodeById( 0 ) );
                        // Fail
                        return false;
                    }
                    catch ( Exception e )
                    {
                        // Ok!
                        return true;
                    }
                }
",non-flaky,5
13930,neo4j_neo4j,TransactionConstraintsIT.startTxAsSlaveAndFinishItAfterHavingSwitchedToMasterShouldNotSucceed,"    @Test
    public void startTxAsSlaveAndFinishItAfterHavingSwitchedToMasterShouldNotSucceed() throws Exception
    {
        // GIVEN
        GraphDatabaseService db = cluster.getAnySlave();
        takeTheLeadInAnEventualMasterSwitch( db );

        // WHEN
        Transaction tx = db.beginTx();
        try
        {
            db.createNode().setProperty( ""name"", ""slave"" );
            tx.success();
        }
        finally
        {
            cluster.shutdown( cluster.getMaster() );
            assertFinishGetsTransactionFailure( tx );
        }

        cluster.await( masterAvailable() );

        // THEN
        assertEquals( db, cluster.getMaster() );
        // to prevent a deadlock scenario which occurs if this test exists (and @After starts)
        // before the db has recovered from its KERNEL_PANIC
        awaitFullyOperational( db );
    }
",non-flaky,5
13931,neo4j_neo4j,TransactionConstraintsIT.startTxAsSlaveAndFinishItAfterAnotherMasterBeingAvailableShouldNotSucceed,"    @Test
    public void startTxAsSlaveAndFinishItAfterAnotherMasterBeingAvailableShouldNotSucceed() throws Exception
    {
        // GIVEN
        HighlyAvailableGraphDatabase db = cluster.getAnySlave();

        // WHEN
        HighlyAvailableGraphDatabase theOtherSlave;
        Transaction tx = db.beginTx();
        try
        {
            db.createNode().setProperty( ""name"", ""slave"" );
            tx.success();
        }
        finally
        {
            theOtherSlave = cluster.getAnySlave( db );
            takeTheLeadInAnEventualMasterSwitch( theOtherSlave );
            cluster.shutdown( cluster.getMaster() );
            assertFinishGetsTransactionFailure( tx );
        }

        cluster.await( ClusterManager.masterAvailable() );

        // THEN
        assertFalse( db.isMaster() );
        assertTrue( theOtherSlave.isMaster() );
        // to prevent a deadlock scenario which occurs if this test exists (and @After starts)
        // before the db has recovered from its KERNEL_PANIC
        awaitFullyOperational( db );
    }
",non-flaky,5
64,apache_ignite,testFlowNoConflictsWithClients,"@Test
public void testFlowNoConflictsWithClients() throws Exception {
    startComputation(0, stopFlag0);
    if (!tcpDiscovery())
    return;
    startComputation(1, stopFlag1);
    startComputation(2, stopFlag2);
    startComputation(3, stopFlag3);
    startComputation(4, stopFlag4);
    final Set<Integer> deafClientObservedIds = new ConcurrentHashSet<>();
    startListening(5, true, deafClientObservedIds);
    final Set<Integer> regClientObservedIds = new ConcurrentHashSet<>();
    startListening(6, false, regClientObservedIds);
    START_LATCH.countDown();
    Thread killer = new Thread(new ServerNodeKiller());
    Thread resurrection = new Thread(new ServerNodeResurrection());
    killer.setName(""node-killer-thread"");
    killer.start();
    resurrection.setName(""node-resurrection-thread"");
    resurrection.start();
    while (!updatesQueue.isEmpty())
    Thread.sleep(1000);
    killer.interrupt();
    resurrection.interrupt();
}",concurrency,1
164,apache_ignite,GridCacheRebalancingWithAsyncClearingTest.testCorrectRebalancingCurrentlyRentingPartitions,"@Test
public void testCorrectRebalancingCurrentlyRentingPartitions() throws Exception {
    IgniteEx ignite = ((IgniteEx) (startGrids(3)));
    ignite.cluster().active(true);
    final int keysCnt = SF.applyLB(300000, 10000);
    try (final IgniteDataStreamer<Integer, Integer> ds = ignite.dataStreamer(CACHE_NAME)) {
        log.info(""Writing initial data..."");
        ds.allowOverwrite(true);
        for (int k = 1; k <= keysCnt; k++) {
            ds.addData(k, k);
            if ((k % 10000) == 0) {
                log.info((""Written "" + k) + "" entities."");
            }
        }
        log.info(""Writing initial data finished."");
    }
    startGrid(3);
    resetBaselineTopology();
    stopGrid(3);
    resetBaselineTopology();
    stopGrid(1);
    startGrid(1);
    awaitPartitionMapExchange();
    for (int k = 1; k <= keysCnt; k++) {
        Integer val = ((Integer) (ignite.cache(CACHE_NAME).get(k)));
        Assert.assertNotNull((""Value for "" + k) + "" is null"", val);
        Assert.assertEquals(((""Check failed for "" + k) + "" = "") + val, k, ((int) (val)));
    }
}",concurrency,1
248,apache_ignite,SystemCacheNotConfiguredTest.test,"@Test
public void test() throws Exception {
    captureErr();
    new Thread(this::startServer).start();
    Ignite client = startGrid(getConfiguration(""client"").setClientMode(true));
    IgniteServices services = client.services();
    SimpleService srvc = services.serviceProxy(""service"", SimpleService.class, false);
    Thread.sleep(1000);
    srvc.isWorking();
    assertFalse(getErr().contains(""Cache is not configured:""));
}",async wait,0
305,apache_ignite,IgnitePdsThreadInterruptionTest.testInterruptsOnLFSRead,"@Test
public void testInterruptsOnLFSRead() throws Exception {
    final Ignite ignite = startGrid();
    ignite.active(true);
    final int valLen = 8192;
    final byte[] payload = new byte[valLen];
    final int maxKey = 10000;
    Thread[] workers = new Thread[THREADS_CNT];
    final IgniteCache<Object, Object> cache = ignite.cache(CACHE_NAME);
    for (int i = 0; i < maxKey; i++) {
        cache.put(i, payload);
    }
    final AtomicReference<Throwable> fail = new AtomicReference<>();
    Runnable clo = new Runnable() {
        @Override
        public void run() {
            cache.get(ThreadLocalRandom.current().nextInt(maxKey / 5));
        }
    };
    for (int i = 0; i < workers.length; i++) {
        workers[i] = new Thread(clo);
        workers[i].setName(""reader-"" + i);
        workers[i].setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {
            @Override
            public void uncaughtException(Thread t, Throwable e) {
                fail.compareAndSet(null, e);
            }
        });
    }
    for (Thread worker : workers) {
        worker.start();
    }
    for (int i = 0; i < (workers.length / 2); i++) {
        workers[i].interrupt();
    }
    Thread.sleep(3000);
    stop = true;
    for (Thread worker : workers) {
        worker.join();
    }
    Throwable t = fail.get();
    assertNull(t);
    int verifiedKeys = 0;
    for (int i = 0; i < maxKey; i++) {
        byte[] val = ((byte[]) (cache.get(i)));
        if (val != null) {
            assertEquals(""Illegal length"", valLen, val.length);
            verifiedKeys++;
        }
    }
}",concurrency,1
88771,apache_ignite,SharedRDDExampleSelfTest.testSharedRDDExample,"    @Test
    public void testSharedRDDExample() throws Exception {
        SharedRDDExample.main(EMPTY_ARGS);
    }
",non-flaky,5
88772,apache_ignite,JavaIgniteDataFrameSelfTest.testCatalogExample,"    @Test
    public void testCatalogExample() throws Exception {
        JavaIgniteCatalogExample.main(EMPTY_ARGS);
    }
",non-flaky,5
88773,apache_ignite,JavaIgniteDataFrameSelfTest.testDataFrameExample,"    @Test
    public void testDataFrameExample() throws Exception {
        JavaIgniteDataFrameExample.main(EMPTY_ARGS);
    }
",non-flaky,5
88774,apache_ignite,JavaIgniteDataFrameSelfTest.testDataFrameWriteExample,"    @Test
    public void testDataFrameWriteExample() throws Exception {
        JavaIgniteDataFrameWriteExample.main(EMPTY_ARGS);
    }
",non-flaky,5
88775,apache_ignite,IgniteDataFrameSelfTest.testCatalogExample,"    @Test
    public void testCatalogExample() throws Exception {
        IgniteCatalogExample.main(EMPTY_ARGS);
    }
",non-flaky,5
88776,apache_ignite,IgniteDataFrameSelfTest.testDataFrameExample,"    @Test
    public void testDataFrameExample() throws Exception {
        IgniteDataFrameExample.main(EMPTY_ARGS);
    }
",non-flaky,5
88777,apache_ignite,IgniteDataFrameSelfTest.testDataFrameWriteExample,"    @Test
    public void testDataFrameWriteExample() throws Exception {
        IgniteDataFrameWriteExample.main(EMPTY_ARGS);
    }
",non-flaky,5
88778,apache_ignite,IgniteOsgiServiceTest.testServiceExposedAndCallbacksInvoked,"    @Test
    public void testServiceExposedAndCallbacksInvoked() throws Exception {
        assertNotNull(ignite);
        assertEquals(""testGrid"", ignite.name());

        TestOsgiFlags flags = (TestOsgiFlags) bundleCtx.getService(
            bundleCtx.getAllServiceReferences(TestOsgiFlags.class.getName(), null)[0]);

        assertNotNull(flags);
        assertEquals(Boolean.TRUE, flags.getOnBeforeStartInvoked());
        assertEquals(Boolean.TRUE, flags.getOnAfterStartInvoked());

        // The bundle is still not stopped, therefore these callbacks cannot be tested.
        assertNull(flags.getOnBeforeStopInvoked());
        assertNull(flags.getOnAfterStopInvoked());

        // No exceptions.
        assertNull(flags.getOnAfterStartThrowable());
        assertNull(flags.getOnAfterStopThrowable());
    }
",non-flaky,5
88779,apache_ignite,IgniteKarafFeaturesInstallationTest.testAllBundlesActiveAndFeaturesInstalled,"    @Test
    public void testAllBundlesActiveAndFeaturesInstalled() throws Exception {
        // Asssert all bundles except fragments are ACTIVE.
        for (Bundle b : bundleCtx.getBundles()) {
            System.out.println(String.format(""Checking state of bundle [symbolicName=%s, state=%s]"",
                b.getSymbolicName(), b.getState()));

            if (b.getHeaders().get(Constants.FRAGMENT_HOST) == null)
                assertTrue(b.getState() == Bundle.ACTIVE);
        }

        // Check that according to the FeaturesService, all Ignite features except ignite-log4j are installed.
        Feature[] features = featuresSvc.getFeatures(IGNITE_FEATURES_NAME_REGEX);

        assertNotNull(features);
        assertEquals(EXPECTED_FEATURES, features.length);

        for (Feature f : features) {
            if (IGNORED_FEATURES.contains(f.getName()))
                continue;

            boolean installed = featuresSvc.isInstalled(f);

            System.out.println(String.format(""Checking if feature is installed [featureName=%s, installed=%s]"",
                f.getName(), installed));

            assertTrue(installed);
            assertEquals(PROJECT_VERSION.replaceAll(""-"", "".""), f.getVersion().replaceAll(""-"", "".""));
        }
    }
",non-flaky,5
88780,apache_ignite,LongRunningProcessManagerTest.testStart,"    @Test
    public void testStart() {
        UUID nodeId = UUID.randomUUID();
        UUID procId = UUID.randomUUID();

        Ignite ignite = mock(Ignite.class);
        IgniteCluster cluster = mock(IgniteCluster.class);
        ClusterGroup clusterGrp = mock(ClusterGroup.class);
        IgniteCompute igniteCompute = mock(IgniteCompute.class);
        doReturn(cluster).when(ignite).cluster();
        doReturn(igniteCompute).when(ignite).compute(eq(clusterGrp));
        doReturn(clusterGrp).when(cluster).forNodeId(eq(nodeId));
        doReturn(Collections.singletonList(procId)).when(igniteCompute).call(any(IgniteCallable.class));

        List<LongRunningProcess> list = Collections.singletonList(new LongRunningProcess(nodeId, () -> {}));

        LongRunningProcessManager mgr = new LongRunningProcessManager(ignite);
        Map<UUID, List<UUID>> res = mgr.start(list);

        assertEquals(1, res.size());
        assertTrue(res.containsKey(nodeId));
        assertEquals(procId, res.get(nodeId).iterator().next());

        verify(igniteCompute).call(any(LongRunningProcessStartTask.class));
    }
",non-flaky,5
88781,apache_ignite,LongRunningProcessManagerTest.testPing,"    @Test
    public void testPing() {
        UUID nodeId = UUID.randomUUID();
        UUID procId = UUID.randomUUID();

        Ignite ignite = mock(Ignite.class);
        IgniteCluster cluster = mock(IgniteCluster.class);
        ClusterGroup clusterGrp = mock(ClusterGroup.class);
        IgniteCompute igniteCompute = mock(IgniteCompute.class);
        doReturn(cluster).when(ignite).cluster();
        doReturn(igniteCompute).when(ignite).compute(eq(clusterGrp));
        doReturn(clusterGrp).when(cluster).forNodeId(eq(nodeId));
        doReturn(Collections.singletonList(new LongRunningProcessStatus(LongRunningProcessState.RUNNING)))
            .when(igniteCompute).call(any(IgniteCallable.class));

        Map<UUID, List<UUID>> procIds = new HashMap<>();
        procIds.put(nodeId, Collections.singletonList(procId));

        LongRunningProcessManager mgr = new LongRunningProcessManager(ignite);
        Map<UUID, List<LongRunningProcessStatus>> res = mgr.ping(procIds);

        assertEquals(1, res.size());
        assertTrue(res.containsKey(nodeId));
        assertEquals(LongRunningProcessState.RUNNING, res.get(nodeId).iterator().next().getState());

        verify(igniteCompute).call(any(LongRunningProcessPingTask.class));
    }
",non-flaky,5
88782,apache_ignite,LongRunningProcessManagerTest.testStop,"    @Test
    public void testStop() {
        UUID nodeId = UUID.randomUUID();
        UUID procId = UUID.randomUUID();

        Ignite ignite = mock(Ignite.class);
        IgniteCluster cluster = mock(IgniteCluster.class);
        ClusterGroup clusterGrp = mock(ClusterGroup.class);
        IgniteCompute igniteCompute = mock(IgniteCompute.class);
        doReturn(cluster).when(ignite).cluster();
        doReturn(igniteCompute).when(ignite).compute(eq(clusterGrp));
        doReturn(clusterGrp).when(cluster).forNodeId(eq(nodeId));
        doReturn(Collections.singletonList(new LongRunningProcessStatus(LongRunningProcessState.RUNNING)))
            .when(igniteCompute).call(any(IgniteCallable.class));

        Map<UUID, List<UUID>> procIds = new HashMap<>();
        procIds.put(nodeId, Collections.singletonList(procId));

        LongRunningProcessManager mgr = new LongRunningProcessManager(ignite);
        Map<UUID, List<LongRunningProcessStatus>> res = mgr.stop(procIds, true);

        assertEquals(1, res.size());
        assertTrue(res.containsKey(nodeId));
        assertEquals(LongRunningProcessState.RUNNING, res.get(nodeId).iterator().next().getState());

        verify(igniteCompute).call(any(LongRunningProcessStopTask.class));
    }
",non-flaky,5
88783,apache_ignite,LongRunningProcessManagerTest.testClear,"    @Test
    public void testClear() {
        UUID nodeId = UUID.randomUUID();
        UUID procId = UUID.randomUUID();

        Ignite ignite = mock(Ignite.class);
        IgniteCluster cluster = mock(IgniteCluster.class);
        ClusterGroup clusterGrp = mock(ClusterGroup.class);
        IgniteCompute igniteCompute = mock(IgniteCompute.class);
        doReturn(cluster).when(ignite).cluster();
        doReturn(igniteCompute).when(ignite).compute(eq(clusterGrp));
        doReturn(clusterGrp).when(cluster).forNodeId(eq(nodeId));
        doReturn(Collections.singletonList(new LongRunningProcessStatus(LongRunningProcessState.RUNNING)))
            .when(igniteCompute).call(any(IgniteCallable.class));

        Map<UUID, List<UUID>> procIds = new HashMap<>();
        procIds.put(nodeId, Collections.singletonList(procId));

        LongRunningProcessManager mgr = new LongRunningProcessManager(ignite);
        Map<UUID, List<LongRunningProcessStatus>> res = mgr.clear(procIds);

        assertEquals(1, res.size());
        assertTrue(res.containsKey(nodeId));
        assertEquals(LongRunningProcessState.RUNNING, res.get(nodeId).iterator().next().getState());

        verify(igniteCompute).call(any(LongRunningProcessClearTask.class));
    }
",non-flaky,5
88784,apache_ignite,LongRunningProcessClearTaskTest.testCallProcessNotFound,"    @Test
    public void testCallProcessNotFound() {
        LongRunningProcessClearTask clearTask = createTask(UUID.randomUUID());

        List<LongRunningProcessStatus> statuses = clearTask.call();

        assertEquals(1, statuses.size());

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.NOT_FOUND, status.getState());
        assertNull(status.getException());

        assertEquals(0, metadataStorage.size());
    }
",non-flaky,5
88785,apache_ignite,LongRunningProcessClearTaskTest.testCallProcessIsRunning,"    @Test(expected = IllegalStateException.class)
    public void testCallProcessIsRunning() {
        UUID procId = UUID.randomUUID();

        Future<?> fut = mock(Future.class);
        doReturn(false).when(fut).isDone();
        metadataStorage.put(procId, fut);

        LongRunningProcessClearTask clearTask = createTask(procId);

        clearTask.call();
    }
",non-flaky,5
88786,apache_ignite,LongRunningProcessClearTaskTest.testCallProcessIsDone,"    @Test
    public void testCallProcessIsDone() {
        UUID procId = UUID.randomUUID();

        Future<?> fut = mock(Future.class);
        doReturn(true).when(fut).isDone();
        metadataStorage.put(procId, fut);

        LongRunningProcessClearTask clearTask = createTask(procId);

        List<LongRunningProcessStatus> statuses = clearTask.call();

        assertEquals(1, statuses.size());

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.DONE, status.getState());
        assertNull(status.getException());

        assertEquals(0, metadataStorage.size());
    }
",non-flaky,5
88787,apache_ignite,LongRunningProcessClearTaskTest.testCallProcessIsDoneWithException,"    @Test
    public void testCallProcessIsDoneWithException() throws ExecutionException, InterruptedException {
        UUID procId = UUID.randomUUID();

        Future<?> fut = mock(Future.class);
        doReturn(true).when(fut).isDone();
        doThrow(RuntimeException.class).when(fut).get();
        metadataStorage.put(procId, fut);

        LongRunningProcessClearTask clearTask = createTask(procId);

        List<LongRunningProcessStatus> statuses = clearTask.call();

        assertEquals(1, statuses.size());

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.DONE, status.getState());
        assertNotNull(status.getException());
        assertTrue(status.getException() instanceof RuntimeException);

        assertEquals(0, metadataStorage.size());
    }
",non-flaky,5
88788,apache_ignite,LongRunningProcessStopTaskTest.testCallProcessNotFound,"    @Test
    public void testCallProcessNotFound() {
        LongRunningProcessStopTask stopTask = createTask(UUID.randomUUID(), true);

        List<LongRunningProcessStatus> statuses = stopTask.call();

        assertEquals(1, statuses.size());

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.NOT_FOUND, status.getState());
        assertNull(status.getException());

        assertEquals(0, metadataStorage.size());
    }
",non-flaky,5
88789,apache_ignite,LongRunningProcessStopTaskTest.testCallProcessIsRunning,"    @Test
    public void testCallProcessIsRunning() {
        UUID procId = UUID.randomUUID();

        Future<?> fut = mock(Future.class);
        doReturn(false).when(fut).isDone();
        metadataStorage.put(procId, fut);

        LongRunningProcessStopTask stopTask = createTask(procId, true);

        List<LongRunningProcessStatus> statuses = stopTask.call();

        assertEquals(1, statuses.size());
        verify(fut).cancel(eq(true));

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.DONE, status.getState());
        assertNull(status.getException());

        assertEquals(0, metadataStorage.size());
    }
",non-flaky,5
88790,apache_ignite,LongRunningProcessStopTaskTest.testCallProcessIsDone,"    @Test
    public void testCallProcessIsDone() {
        UUID procId = UUID.randomUUID();

        Future<?> fut = mock(Future.class);
        doReturn(true).when(fut).isDone();
        metadataStorage.put(procId, fut);

        LongRunningProcessStopTask stopTask = createTask(procId, true);

        List<LongRunningProcessStatus> statuses = stopTask.call();

        assertEquals(1, statuses.size());
        verify(fut).cancel(eq(true));

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.DONE, status.getState());
        assertNull(status.getException());

        assertEquals(0, metadataStorage.size());
    }
",non-flaky,5
88791,apache_ignite,LongRunningProcessStopTaskTest.testCallProcessIsDoneWithException,"    @Test
    public void testCallProcessIsDoneWithException() throws ExecutionException, InterruptedException {
        UUID procId = UUID.randomUUID();

        Future<?> fut = mock(Future.class);
        doReturn(true).when(fut).isDone();
        doThrow(RuntimeException.class).when(fut).get();
        metadataStorage.put(procId, fut);

        LongRunningProcessStopTask stopTask = createTask(procId, true);

        List<LongRunningProcessStatus> statuses = stopTask.call();

        assertEquals(1, statuses.size());
        verify(fut).cancel(eq(true));

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.DONE, status.getState());
        assertNotNull(status.getException());
        assertTrue(status.getException() instanceof RuntimeException);

        assertEquals(0, metadataStorage.size());
    }
",non-flaky,5
88792,apache_ignite,LongRunningProcessStartTaskTest.testCall,"    @Test
    public void testCall() throws ExecutionException, InterruptedException {
        LongRunningProcess proc = new LongRunningProcess(UUID.randomUUID(), () -> {});
        LongRunningProcessStartTask task = createTask(proc);
        List<UUID> procIds = task.call();

        assertEquals(1, procIds.size());

        UUID procId = procIds.get(0);

        assertNotNull(metadataStorage.get(procId));

        Future<?> fut = metadataStorage.get(procId);
        fut.get();

        assertEquals(true, fut.isDone());
    }
",non-flaky,5
88793,apache_ignite,LongRunningProcessStartTaskTest.testCallWithException,"    @Test(expected = ExecutionException.class)
    public void testCallWithException() throws ExecutionException, InterruptedException {
        LongRunningProcess proc = new LongRunningProcess(UUID.randomUUID(), () -> {
            throw new RuntimeException();
        });
        LongRunningProcessStartTask task = createTask(proc);
        List<UUID> procIds = task.call();

        assertEquals(1, procIds.size());

        UUID procId = procIds.get(0);

        assertNotNull(metadataStorage.get(procId));

        Future<?> fut = metadataStorage.get(procId);
        fut.get();
    }
",non-flaky,5
88794,apache_ignite,LongRunningProcessPingTaskTest.testCallProcessNotFound,"    @Test
    public void testCallProcessNotFound() {
        LongRunningProcessPingTask pingTask = createTask(UUID.randomUUID());

        List<LongRunningProcessStatus> statuses = pingTask.call();

        assertEquals(1, statuses.size());

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.NOT_FOUND, status.getState());
        assertNull(status.getException());

        assertEquals(0, metadataStorage.size());
    }
",non-flaky,5
88795,apache_ignite,LongRunningProcessPingTaskTest.testCallProcessIsRunning,"    @Test
    public void testCallProcessIsRunning() {
        UUID procId = UUID.randomUUID();

        Future<?> fut = mock(Future.class);
        doReturn(false).when(fut).isDone();
        metadataStorage.put(procId, fut);

        LongRunningProcessPingTask pingTask = createTask(procId);

        List<LongRunningProcessStatus> statuses = pingTask.call();

        assertEquals(1, statuses.size());

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.RUNNING, status.getState());
        assertNull(status.getException());

        assertEquals(1, metadataStorage.size());
    }
",non-flaky,5
88796,apache_ignite,LongRunningProcessPingTaskTest.testCallProcessIsDone,"    @Test
    public void testCallProcessIsDone() {
        UUID procId = UUID.randomUUID();

        Future<?> fut = mock(Future.class);
        doReturn(true).when(fut).isDone();
        metadataStorage.put(procId, fut);

        LongRunningProcessPingTask pingTask = createTask(procId);

        List<LongRunningProcessStatus> statuses = pingTask.call();

        assertEquals(1, statuses.size());

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.DONE, status.getState());
        assertNull(status.getException());

        assertEquals(1, metadataStorage.size());
    }
",non-flaky,5
88797,apache_ignite,LongRunningProcessPingTaskTest.testCallProcessIsDoneWithException,"    @Test
    public void testCallProcessIsDoneWithException() throws ExecutionException, InterruptedException {
        UUID procId = UUID.randomUUID();

        Future<?> fut = mock(Future.class);
        doReturn(true).when(fut).isDone();
        doThrow(RuntimeException.class).when(fut).get();
        metadataStorage.put(procId, fut);

        LongRunningProcessPingTask pingTask = createTask(procId);

        List<LongRunningProcessStatus> statuses = pingTask.call();

        assertEquals(1, statuses.size());

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.DONE, status.getState());
        assertNotNull(status.getException());
        assertTrue(status.getException() instanceof RuntimeException);

        assertEquals(1, metadataStorage.size());
    }
",non-flaky,5
88798,apache_ignite,ProcessManagerWrapperTest.testStart,"    @Test
    public void testStart() {
        wrapper.start(Arrays.asList(1, 2, 3));

        verify(delegate).start(eq(Arrays.asList(""1"", ""2"", ""3"")));
    }
",non-flaky,5
88799,apache_ignite,ProcessManagerWrapperTest.testPing,"    @Test
    public void testPing() {
        Map<UUID, List<UUID>> procIds = Collections.emptyMap();
        wrapper.ping(procIds);

        verify(delegate).ping(eq(procIds));
    }
",non-flaky,5
88800,apache_ignite,ProcessManagerWrapperTest.testStop,"    @Test
    public void testStop() {
        Map<UUID, List<UUID>> procIds = Collections.emptyMap();
        wrapper.stop(procIds, true);

        verify(delegate).stop(eq(procIds), eq(true));
    }
",non-flaky,5
88801,apache_ignite,ProcessManagerWrapperTest.testClear,"    @Test
    public void testClear() {
        Map<UUID, List<UUID>> procIds = Collections.emptyMap();
        wrapper.clear(procIds);

        verify(delegate).clear(eq(procIds));
    }
",non-flaky,5
88802,apache_ignite,LoadTest.testMultithreading,"    @Test
    public void testMultithreading() throws Exception {
        final int THREAD_CNT = 8;
        final int ITERATION_CNT = 20;
        final int BATCH_SIZE = 1000;
        final int PAGE_CNT = 3;

        IgniteConfiguration srvCfg = Config.getServerConfiguration();

        // No peer class loading from thin clients: we need the server to know about this class to deserialize
        // ScanQuery filter.
        srvCfg.setBinaryConfiguration(new BinaryConfiguration().setTypeConfigurations(Arrays.asList(
            new BinaryTypeConfiguration(getClass().getName()),
            new BinaryTypeConfiguration(SerializedLambda.class.getName())
        )));

        try (Ignite ignored = Ignition.start(srvCfg);
             IgniteClient client = Ignition.startClient(new ClientConfiguration().setAddresses(Config.SERVER))
        ) {
            ClientCache<Integer, String> cache = client.createCache(""testMultithreading"");

            AtomicInteger cnt = new AtomicInteger(1);

            AtomicReference<Throwable> error = new AtomicReference<>();

            Runnable assertion = () -> {
                try {
                    int rangeStart = cnt.getAndAdd(BATCH_SIZE);
                    int rangeEnd = rangeStart + BATCH_SIZE;

                    Map<Integer, String> data = IntStream.range(rangeStart, rangeEnd).boxed()
                        .collect(Collectors.toMap(i -> i, i -> String.format(""String %s"", i)));

                    cache.putAll(data);

                    Query<Cache.Entry<Integer, String>> qry = new ScanQuery<Integer, String>()
                        .setPageSize(data.size() / PAGE_CNT)
                        .setFilter((i, s) -> i >= rangeStart && i < rangeEnd);

                    try (QueryCursor<Cache.Entry<Integer, String>> cur = cache.query(qry)) {
                        List<Cache.Entry<Integer, String>> res = cur.getAll();

                        assertEquals(""Unexpected number of entries"", data.size(), res.size());

                        Map<Integer, String> act = res.stream()
                            .collect(Collectors.toMap(Cache.Entry::getKey, Cache.Entry::getValue));

                        assertEquals(""Unexpected entries"", data, act);
                    }
                }
                catch (Throwable ex) {
                    error.set(ex);
                }
            };

            CountDownLatch complete = new CountDownLatch(THREAD_CNT);

            Runnable manyAssertions = () -> {
                for (int i = 0; i < ITERATION_CNT && error.get() == null; i++)
                    assertion.run();

                complete.countDown();
            };

            ExecutorService threadPool = Executors.newFixedThreadPool(THREAD_CNT);

            IntStream.range(0, THREAD_CNT).forEach(t -> threadPool.submit(manyAssertions));

            assertTrue(""Timeout"", complete.await(180, TimeUnit.SECONDS));

            String errMsg = error.get() == null ? """" : error.get().getMessage();

            assertNull(errMsg, error.get());
        }
    }
",non-flaky,5
88803,apache_ignite,ReliabilityTest.testFailover,"    @Test
    public void testFailover() throws Exception {
        final int CLUSTER_SIZE = 3;

        try (LocalIgniteCluster cluster = LocalIgniteCluster.start(CLUSTER_SIZE);
             IgniteClient client = Ignition.startClient(new ClientConfiguration()
                 .setAddresses(cluster.clientAddresses().toArray(new String[CLUSTER_SIZE]))
             )
        ) {
            final Random rnd = new Random();

            final ClientCache<Integer, String> cache = client.getOrCreateCache(
                new ClientCacheConfiguration().setName(""testFailover"").setCacheMode(CacheMode.REPLICATED)
            );

            // Simple operation failover: put/get
            assertOnUnstableCluster(cluster, () -> {
                Integer key = rnd.nextInt();
                String val = key.toString();

                cache.put(key, val);

                String cachedVal = cache.get(key);

                assertEquals(val, cachedVal);
            });

            // Composite operation failover: query
            Map<Integer, String> data = IntStream.rangeClosed(1, 1000).boxed()
                .collect(Collectors.toMap(i -> i, i -> String.format(""String %s"", i)));

            assertOnUnstableCluster(cluster, () -> {
                cache.putAll(data);

                Query<Cache.Entry<Integer, String>> qry =
                    new ScanQuery<Integer, String>().setPageSize(data.size() / 10);

                try (QueryCursor<Cache.Entry<Integer, String>> cur = cache.query(qry)) {
                    List<Cache.Entry<Integer, String>> res = cur.getAll();

                    assertEquals(""Unexpected number of entries"", data.size(), res.size());

                    Map<Integer, String> act = res.stream()
                        .collect(Collectors.toMap(Cache.Entry::getKey, Cache.Entry::getValue));

                    assertEquals(""Unexpected entries"", data, act);
                }
            });

            // Client fails if all nodes go down
            cluster.close();

            boolean igniteUnavailable = false;

            try {
                cache.put(1, ""1"");
            }
            catch (ClientConnectionException ex) {
                igniteUnavailable = true;

                Throwable[] suppressed = ex.getSuppressed();

                assertEquals(suppressed.length, CLUSTER_SIZE - 1);

                assertTrue(Stream.of(suppressed).allMatch(t -> t instanceof ClientConnectionException));
            }

            assertTrue(igniteUnavailable);
        }
    }
",non-flaky,5
88804,apache_ignite,IgniteBinaryTest.testUnmarshalSchemalessIgniteBinaries,"    @Test
    public void testUnmarshalSchemalessIgniteBinaries() throws Exception {
        int key = 1;
        Person val = new Person(key, ""Joe"");

        try (Ignite srv = Ignition.start(Config.getServerConfiguration())) {
            // Add an entry directly to the Ignite server. This stores a schema-less object in the cache and
            // does not register schema in the client's metadata cache.
            srv.cache(Config.DEFAULT_CACHE_NAME).put(key, val);

            try (IgniteClient client = Ignition.startClient(new ClientConfiguration().setAddresses(Config.SERVER))) {
                ClientCache<Integer, Person> cache = client.cache(Config.DEFAULT_CACHE_NAME);

                Person cachedVal = cache.get(key);

                assertEquals(val, cachedVal);
            }
        }
    }
",non-flaky,5
88805,apache_ignite,IgniteBinaryTest.testReadingSchemalessIgniteBinaries,"    @Test
    public void testReadingSchemalessIgniteBinaries() throws Exception {
        int key = 1;
        Person val = new Person(key, ""Joe"");

        try (Ignite srv = Ignition.start(Config.getServerConfiguration())) {
            // Add an entry directly to the Ignite server. This stores a schema-less object in the cache and
            // does not register schema in the client's metadata cache.
            srv.cache(Config.DEFAULT_CACHE_NAME).put(key, val);

            try (IgniteClient client = Ignition.startClient(new ClientConfiguration().setAddresses(Config.SERVER))) {
                ClientCache<Integer, BinaryObject> cache = client.cache(Config.DEFAULT_CACHE_NAME).withKeepBinary();

                BinaryObject cachedVal = cache.get(key);

                assertEquals(val.getId(), cachedVal.field(""id""));
                assertEquals(val.getName(), cachedVal.field(""name""));
            }
        }
    }
",non-flaky,5
88806,apache_ignite,IgniteBinaryTest.testBinaryObjectPutGet,"    @Test
    public void testBinaryObjectPutGet() throws Exception {
        int key = 1;

        try (Ignite ignored = Ignition.start(Config.getServerConfiguration())) {
            try (IgniteClient client =
                     Ignition.startClient(new ClientConfiguration().setAddresses(Config.SERVER))
            ) {
                IgniteBinary binary = client.binary();

                BinaryObject val = binary.builder(""Person"")
                    .setField(""id"", 1, int.class)
                    .setField(""name"", ""Joe"", String.class)
                    .build();

                ClientCache<Integer, BinaryObject> cache = client.cache(Config.DEFAULT_CACHE_NAME).withKeepBinary();

                cache.put(key, val);

                BinaryObject cachedVal =
                    client.cache(Config.DEFAULT_CACHE_NAME).<Integer, BinaryObject>withKeepBinary().get(key);

                assertBinaryObjectsEqual(val, cachedVal);
            }
        }
    }
",non-flaky,5
88807,apache_ignite,IgniteBinaryTest.testBinaryObjectApi,"    @Test
    public void testBinaryObjectApi() throws Exception {
        try (Ignite srv = Ignition.start(Config.getServerConfiguration())) {
            try (IgniteClient client = Ignition.startClient(new ClientConfiguration().setAddresses(Config.SERVER))) {
                // Use ""server-side"" IgniteBinary as a reference to test the thin client IgniteBinary against
                IgniteBinary refBinary = srv.binary();

                IgniteBinary binary = client.binary();

                Person obj = new Person(1, ""Joe"");

                int refTypeId = refBinary.typeId(Person.class.getName());
                int typeId = binary.typeId(Person.class.getName());

                assertEquals(refTypeId, typeId);

                BinaryObject refBinObj = refBinary.toBinary(obj);
                BinaryObject binObj = binary.toBinary(obj);

                assertBinaryObjectsEqual(refBinObj, binObj);

                assertBinaryTypesEqual(refBinary.type(typeId), binary.type(typeId));

                assertBinaryTypesEqual(refBinary.type(Person.class), binary.type(Person.class));

                assertBinaryTypesEqual(refBinary.type(Person.class.getName()), binary.type(Person.class.getName()));

                Collection<BinaryType> refTypes = refBinary.types();
                Collection<BinaryType> types = binary.types();

                assertEquals(refTypes.size(), types.size());

                BinaryObject refEnm = refBinary.buildEnum(Enum.class.getName(), Enum.DEFAULT.ordinal());
                BinaryObject enm = binary.buildEnum(Enum.class.getName(), Enum.DEFAULT.ordinal());

                assertBinaryObjectsEqual(refEnm, enm);

                Map<String, Integer> enumMap = Arrays.stream(Enum.values())
                    .collect(Collectors.toMap(java.lang.Enum::name, java.lang.Enum::ordinal));

                BinaryType refEnumType = refBinary.registerEnum(Enum.class.getName(), enumMap);
                BinaryType enumType = binary.registerEnum(Enum.class.getName(), enumMap);

                assertBinaryTypesEqual(refEnumType, enumType);

                refEnm = refBinary.buildEnum(Enum.class.getName(), Enum.DEFAULT.name());
                enm = binary.buildEnum(Enum.class.getName(), Enum.DEFAULT.name());

                assertBinaryObjectsEqual(refEnm, enm);
            }
        }
    }
",non-flaky,5
88808,apache_ignite,FunctionalTest.testCacheManagement,"    @Test
    public void testCacheManagement() throws Exception {
        try (LocalIgniteCluster ignored = LocalIgniteCluster.start(2);
             IgniteClient client = Ignition.startClient(getClientConfiguration())
        ) {
            final String CACHE_NAME = ""testCacheManagement"";

            ClientCacheConfiguration cacheCfg = new ClientCacheConfiguration().setName(CACHE_NAME)
                .setCacheMode(CacheMode.REPLICATED)
                .setWriteSynchronizationMode(CacheWriteSynchronizationMode.FULL_SYNC);

            int key = 1;
            Person val = new Person(key, Integer.toString(key));

            ClientCache<Integer, Person> cache = client.getOrCreateCache(cacheCfg);

            cache.put(key, val);

            assertEquals(1, cache.size());
            assertEquals(2, cache.size(CachePeekMode.ALL));

            cache = client.cache(CACHE_NAME);

            Person cachedVal = cache.get(key);

            assertEquals(val, cachedVal);

            Object[] cacheNames = new TreeSet<>(client.cacheNames()).toArray();

            assertArrayEquals(new TreeSet<>(Arrays.asList(Config.DEFAULT_CACHE_NAME, CACHE_NAME)).toArray(), cacheNames);

            client.destroyCache(CACHE_NAME);

            cacheNames = client.cacheNames().toArray();

            assertArrayEquals(new Object[] {Config.DEFAULT_CACHE_NAME}, cacheNames);

            cache = client.createCache(CACHE_NAME);

            assertFalse(cache.containsKey(key));

            cacheNames = client.cacheNames().toArray();

            assertArrayEquals(new TreeSet<>(Arrays.asList(Config.DEFAULT_CACHE_NAME, CACHE_NAME)).toArray(), cacheNames);

            client.destroyCache(CACHE_NAME);

            cache = client.createCache(cacheCfg);

            assertFalse(cache.containsKey(key));

            assertArrayEquals(new TreeSet<>(Arrays.asList(Config.DEFAULT_CACHE_NAME, CACHE_NAME)).toArray(), cacheNames);
        }
    }
",non-flaky,5
88809,apache_ignite,FunctionalTest.testCacheConfiguration,"    @Test
    public void testCacheConfiguration() throws Exception {
        try (Ignite ignored = Ignition.start(Config.getServerConfiguration());
             IgniteClient client = Ignition.startClient(getClientConfiguration())
        ) {
            final String CACHE_NAME = ""testCacheConfiguration"";

            ClientCacheConfiguration cacheCfg = new ClientCacheConfiguration().setName(CACHE_NAME)
                .setAtomicityMode(CacheAtomicityMode.TRANSACTIONAL)
                .setBackups(3)
                .setCacheMode(CacheMode.PARTITIONED)
                .setWriteSynchronizationMode(CacheWriteSynchronizationMode.FULL_SYNC)
                .setEagerTtl(false)
                .setGroupName(""FunctionalTest"")
                .setDefaultLockTimeout(12345)
                .setPartitionLossPolicy(PartitionLossPolicy.READ_WRITE_ALL)
                .setReadFromBackup(true)
                .setRebalanceBatchSize(67890)
                .setRebalanceBatchesPrefetchCount(102938)
                .setRebalanceDelay(54321)
                .setRebalanceMode(CacheRebalanceMode.SYNC)
                .setRebalanceOrder(2)
                .setRebalanceThrottle(564738)
                .setRebalanceTimeout(142536)
                .setKeyConfiguration(new CacheKeyConfiguration(""Employee"", ""orgId""))
                .setQueryEntities(new QueryEntity(int.class.getName(), ""Employee"")
                    .setTableName(""EMPLOYEE"")
                    .setFields(
                        Stream.of(
                            new SimpleEntry<>(""id"", Integer.class.getName()),
                            new SimpleEntry<>(""orgId"", Integer.class.getName())
                        ).collect(Collectors.toMap(
                            SimpleEntry::getKey, SimpleEntry::getValue, (a, b) -> a, LinkedHashMap::new
                        ))
                    )
                    .setKeyFields(Collections.singleton(""id""))
                    .setNotNullFields(Collections.singleton(""id""))
                    .setDefaultFieldValues(Collections.singletonMap(""id"", 0))
                    .setIndexes(Collections.singletonList(new QueryIndex(""id"", true, ""IDX_EMPLOYEE_ID"")))
                    .setAliases(Stream.of(""id"", ""orgId"").collect(Collectors.toMap(f -> f, String::toUpperCase)))
                );

            ClientCache cache = client.createCache(cacheCfg);

            assertEquals(CACHE_NAME, cache.getName());

            assertTrue(Comparers.equal(cacheCfg, cache.getConfiguration()));
        }
    }
",non-flaky,5
88810,apache_ignite,FunctionalTest.testPutGet,"    @Test
    public void testPutGet() throws Exception {
        // Existing cache, primitive key and object value
        try (Ignite ignored = Ignition.start(Config.getServerConfiguration());
             IgniteClient client = Ignition.startClient(getClientConfiguration())
        ) {
            ClientCache<Integer, Person> cache = client.getOrCreateCache(Config.DEFAULT_CACHE_NAME);

            Integer key = 1;
            Person val = new Person(key, ""Joe"");

            cache.put(key, val);

            assertTrue(cache.containsKey(key));

            Person cachedVal = cache.get(key);

            assertEquals(val, cachedVal);
        }

        // Non-existing cache, object key and primitive value
        try (Ignite ignored = Ignition.start(Config.getServerConfiguration());
             IgniteClient client = Ignition.startClient(getClientConfiguration())
        ) {
            ClientCache<Person, Integer> cache = client.getOrCreateCache(""testPutGet"");

            Integer val = 1;

            Person key = new Person(val, ""Joe"");

            cache.put(key, val);

            Integer cachedVal = cache.get(key);

            assertEquals(val, cachedVal);
        }

        // Object key and Object value
        try (Ignite ignored = Ignition.start(Config.getServerConfiguration());
             IgniteClient client = Ignition.startClient(getClientConfiguration())
        ) {
            ClientCache<Person, Person> cache = client.getOrCreateCache(""testPutGet"");

            Person key = new Person(1, ""Joe Key"");

            Person val = new Person(1, ""Joe Value"");

            cache.put(key, val);

            Person cachedVal = cache.get(key);

            assertEquals(val, cachedVal);
        }
    }
",non-flaky,5
88811,apache_ignite,FunctionalTest.testBatchPutGet,"    @Test
    public void testBatchPutGet() throws Exception {
        // Existing cache, primitive key and object value
        try (Ignite ignored = Ignition.start(Config.getServerConfiguration());
             IgniteClient client = Ignition.startClient(getClientConfiguration())
        ) {
            ClientCache<Integer, Person> cache = client.cache(Config.DEFAULT_CACHE_NAME);

            Map<Integer, Person> data = IntStream
                .rangeClosed(1, 1000).boxed()
                .collect(Collectors.toMap(i -> i, i -> new Person(i, String.format(""Person %s"", i))));

            cache.putAll(data);

            Map<Integer, Person> cachedData = cache.getAll(data.keySet());

            assertEquals(data, cachedData);
        }

        // Non-existing cache, object key and primitive value
        try (Ignite ignored = Ignition.start(Config.getServerConfiguration());
             IgniteClient client = Ignition.startClient(getClientConfiguration())
        ) {
            ClientCache<Person, Integer> cache = client.createCache(""testBatchPutGet"");

            Map<Person, Integer> data = IntStream
                .rangeClosed(1, 1000).boxed()
                .collect(Collectors.toMap(i -> new Person(i, String.format(""Person %s"", i)), i -> i));

            cache.putAll(data);

            Map<Person, Integer> cachedData = cache.getAll(data.keySet());

            assertEquals(data, cachedData);

            cache.clear();

            assertEquals(0, cache.size(CachePeekMode.ALL));
        }
    }
",non-flaky,5
88812,apache_ignite,FunctionalTest.testAtomicPutGet,"    @Test
    public void testAtomicPutGet() throws Exception {
        try (Ignite ignored = Ignition.start(Config.getServerConfiguration());
             IgniteClient client = Ignition.startClient(getClientConfiguration())
        ) {
            ClientCache<Integer, String> cache = client.createCache(""testRemoveReplace"");

            assertNull(cache.getAndPut(1, ""1""));
            assertEquals(""1"", cache.getAndPut(1, ""1.1""));

            assertEquals(""1.1"", cache.getAndRemove(1));
            assertNull(cache.getAndRemove(1));

            assertTrue(cache.putIfAbsent(1, ""1""));
            assertFalse(cache.putIfAbsent(1, ""1.1""));

            assertEquals(""1"", cache.getAndReplace(1, ""1.1""));
            assertEquals(""1.1"", cache.getAndReplace(1, ""1""));
            assertNull(cache.getAndReplace(2, ""2""));
        }
    }
",non-flaky,5
88813,apache_ignite,FunctionalTest.testRemoveReplace,"    @Test
    public void testRemoveReplace() throws Exception {
        try (Ignite ignored = Ignition.start(Config.getServerConfiguration());
             IgniteClient client = Ignition.startClient(getClientConfiguration())
        ) {
            ClientCache<Integer, String> cache = client.createCache(""testRemoveReplace"");

            Map<Integer, String> data = IntStream.rangeClosed(1, 100).boxed()
                .collect(Collectors.toMap(i -> i, Object::toString));

            cache.putAll(data);

            assertFalse(cache.replace(1, ""2"", ""3""));
            assertEquals(""1"", cache.get(1));
            assertTrue(cache.replace(1, ""1"", ""3""));
            assertEquals(""3"", cache.get(1));

            assertFalse(cache.replace(101, ""101""));
            assertNull(cache.get(101));
            assertTrue(cache.replace(100, ""101""));
            assertEquals(""101"", cache.get(100));

            assertFalse(cache.remove(101));
            assertTrue(cache.remove(100));
            assertNull(cache.get(100));

            assertFalse(cache.remove(99, ""100""));
            assertEquals(""99"", cache.get(99));
            assertTrue(cache.remove(99, ""99""));
            assertNull(cache.get(99));

            cache.put(101, ""101"");

            cache.removeAll(data.keySet());
            assertEquals(1, cache.size());
            assertEquals(""101"", cache.get(101));

            cache.removeAll();
            assertEquals(0, cache.size());
        }
    }
",non-flaky,5
88814,apache_ignite,FunctionalTest.testClientFailsOnStart,"    @Test
    public void testClientFailsOnStart() {
        ClientConnectionException expEx = null;

        try (IgniteClient ignored = Ignition.startClient(getClientConfiguration())) {
            // No-op.
        }
        catch (ClientConnectionException connEx) {
            expEx = connEx;
        }
        catch (Exception ex) {
            fail(String.format(
                ""%s expected but %s was received: %s"",
                ClientConnectionException.class.getName(),
                ex.getClass().getName(),
                ex
            ));
        }

        assertNotNull(
            String.format(""%s expected but no exception was received"", ClientConnectionException.class.getName()),
            expEx
        );
    }
",non-flaky,5
88815,apache_ignite,ClientCacheConfigurationTest.testSerialization,"    @Test
    public void testSerialization() throws IOException, ClassNotFoundException {
        ClientCacheConfiguration target = new ClientCacheConfiguration().setName(""Person"")
            .setAtomicityMode(CacheAtomicityMode.TRANSACTIONAL)
            .setBackups(3)
            .setCacheMode(CacheMode.PARTITIONED)
            .setWriteSynchronizationMode(CacheWriteSynchronizationMode.FULL_SYNC)
            .setEagerTtl(false)
            .setGroupName(""FunctionalTest"")
            .setDefaultLockTimeout(12345)
            .setPartitionLossPolicy(PartitionLossPolicy.READ_WRITE_ALL)
            .setReadFromBackup(true)
            .setRebalanceBatchSize(67890)
            .setRebalanceBatchesPrefetchCount(102938)
            .setRebalanceDelay(54321)
            .setRebalanceMode(CacheRebalanceMode.SYNC)
            .setRebalanceOrder(2)
            .setRebalanceThrottle(564738)
            .setRebalanceTimeout(142536)
            .setKeyConfiguration(new CacheKeyConfiguration(""Employee"", ""orgId""))
            .setQueryEntities(new QueryEntity(int.class.getName(), ""Employee"")
                .setTableName(""EMPLOYEE"")
                .setFields(
                    Stream.of(
                        new SimpleEntry<>(""id"", Integer.class.getName()),
                        new SimpleEntry<>(""orgId"", Integer.class.getName())
                    ).collect(Collectors.toMap(
                        SimpleEntry::getKey, SimpleEntry::getValue, (a, b) -> a, LinkedHashMap::new
                    ))
                )
                .setKeyFields(Collections.singleton(""id""))
                .setNotNullFields(Collections.singleton(""id""))
                .setDefaultFieldValues(Collections.singletonMap(""id"", 0))
                .setIndexes(Collections.singletonList(new QueryIndex(""id"", true, ""IDX_EMPLOYEE_ID"")))
                .setAliases(Stream.of(""id"", ""orgId"").collect(Collectors.toMap(f -> f, String::toUpperCase)))
            );

        ByteArrayOutputStream outBytes = new ByteArrayOutputStream();

        ObjectOutput out = new ObjectOutputStream(outBytes);

        out.writeObject(target);
        out.flush();

        ObjectInput in = new ObjectInputStream(new ByteArrayInputStream(outBytes.toByteArray()));

        Object desTarget = in.readObject();

        assertTrue(Comparers.equal(target, desTarget));
    }
",non-flaky,5
88816,apache_ignite,ClientConfigurationTest.testSerialization,"    @Test
    public void testSerialization() throws IOException, ClassNotFoundException {
        ClientConfiguration target = new ClientConfiguration()
            .setAddresses(""127.0.0.1:10800"", ""127.0.0.1:10801"")
            .setTimeout(123)
            .setBinaryConfiguration(new BinaryConfiguration()
                .setClassNames(Collections.singleton(""Person""))
            )
            .setSslMode(SslMode.REQUIRED)
            .setSslClientCertificateKeyStorePath(""client.jks"")
            .setSslClientCertificateKeyStoreType(""JKS"")
            .setSslClientCertificateKeyStorePassword(""123456"")
            .setSslTrustCertificateKeyStorePath(""trust.jks"")
            .setSslTrustCertificateKeyStoreType(""JKS"")
            .setSslTrustCertificateKeyStorePassword(""123456"")
            .setSslKeyAlgorithm(""SunX509"");

        ByteArrayOutputStream outBytes = new ByteArrayOutputStream();

        ObjectOutput out = new ObjectOutputStream(outBytes);

        out.writeObject(target);
        out.flush();

        ObjectInput in = new ObjectInputStream(new ByteArrayInputStream(outBytes.toByteArray()));

        Object desTarget = in.readObject();

        assertTrue(Comparers.equal(target, desTarget));
    }
",non-flaky,5
88817,apache_ignite,FullyConnectedComponentSearcherTest.testFind,"    @Test
    public void testFind() {
        BitSet[] matrix = provider.provide();

        int nodes = matrix.length;

        BitSet all = new BitSet(nodes);
        for (int i = 0; i < nodes; i++)
            all.set(i);

        FullyConnectedComponentSearcher searcher = new FullyConnectedComponentSearcher(matrix);

        BitSet res = searcher.findLargest(all);
        int size = res.cardinality();

        Assert.assertTrue(""Actual = "" + size + "", Expected = "" + minAcceptableRes,
            size >= minAcceptableRes);
    }
",non-flaky,5
88818,apache_ignite,IgnitePageMemReplaceDelayedWriteUnitTest.testReplacementWithDelayCausesLockForRead,"    @Test
    public void testReplacementWithDelayCausesLockForRead() throws IgniteCheckedException {
        IgniteConfiguration cfg = getConfiguration(16 * MB);

        AtomicInteger totalEvicted = new AtomicInteger();

        ReplacedPageWriter pageWriter = (FullPageId fullPageId, ByteBuffer byteBuf, int tag) -> {
            log.info(""Evicting "" + fullPageId);

            assert getLockedPages(fullPageId).contains(fullPageId);

            assert !getSegment(fullPageId).writeLock().isHeldByCurrentThread();

            totalEvicted.incrementAndGet();
        };

        int pageSize = 4096;
        PageMemoryImpl memory = createPageMemory(cfg, pageWriter, pageSize);

        this.pageMemory = memory;

        long pagesTotal = cfg.getDataStorageConfiguration().getDefaultDataRegionConfiguration().getMaxSize() / pageSize;
        long markDirty = pagesTotal * 2 / 3;
        for (int i = 0; i < markDirty; i++) {
            long pageId = memory.allocatePage(1, 1, PageIdAllocator.FLAG_DATA);
            long ptr = memory.acquirePage(1, pageId);

            memory.releasePage(1, pageId, ptr);
        }

        GridMultiCollectionWrapper<FullPageId> ids = memory.beginCheckpoint();
        int cpPages = ids.size();
        log.info(""Started CP with ["" + cpPages + ""] pages in it, created ["" + markDirty + ""] pages"");

        for (int i = 0; i < cpPages; i++) {
            long pageId = memory.allocatePage(1, 1, PageIdAllocator.FLAG_DATA);
            long ptr = memory.acquirePage(1, pageId);
            memory.releasePage(1, pageId, ptr);
        }

        List<Collection<FullPageId>> stripes = getAllLockedPages();

        assert !stripes.isEmpty();

        for (Collection<FullPageId> pageIds : stripes) {
            assert pageIds.isEmpty();
        }

        assert totalEvicted.get() > 0;

        memory.stop(true);
    }
",non-flaky,5
88819,apache_ignite,IgnitePageMemReplaceDelayedWriteUnitTest.testBackwardCompatibilityMode,"    @Test
    public void testBackwardCompatibilityMode() throws IgniteCheckedException {
        IgniteConfiguration cfg = getConfiguration(16 * MB);

        AtomicInteger totalEvicted = new AtomicInteger();

        ReplacedPageWriter pageWriter = (FullPageId fullPageId, ByteBuffer byteBuf, int tag) -> {
            log.info(""Evicting "" + fullPageId);

            assert getSegment(fullPageId).writeLock().isHeldByCurrentThread();

            totalEvicted.incrementAndGet();
        };

        System.setProperty(IgniteSystemProperties.IGNITE_DELAYED_REPLACED_PAGE_WRITE, ""false"");
        int pageSize = 4096;
        PageMemoryImpl memory;

        try {
            memory = createPageMemory(cfg, pageWriter, pageSize);
        }
        finally {
            System.clearProperty(IgniteSystemProperties.IGNITE_DELAYED_REPLACED_PAGE_WRITE);
        }

        this.pageMemory = memory;

        long pagesTotal = cfg.getDataStorageConfiguration().getDefaultDataRegionConfiguration().getMaxSize() / pageSize;
        long markDirty = pagesTotal * 2 / 3;
        for (int i = 0; i < markDirty; i++) {
            long pageId = memory.allocatePage(1, 1, PageIdAllocator.FLAG_DATA);
            long ptr = memory.acquirePage(1, pageId);

            memory.releasePage(1, pageId, ptr);
        }

        GridMultiCollectionWrapper<FullPageId> ids = memory.beginCheckpoint();
        int cpPages = ids.size();
        log.info(""Started CP with ["" + cpPages + ""] pages in it, created ["" + markDirty + ""] pages"");

        for (int i = 0; i < cpPages; i++) {
            long pageId = memory.allocatePage(1, 1, PageIdAllocator.FLAG_DATA);
            long ptr = memory.acquirePage(1, pageId);
            memory.releasePage(1, pageId, ptr);
        }

        assert totalEvicted.get() > 0;

        memory.stop(true);
    }
",non-flaky,5
88820,apache_ignite,IgniteThrottlingUnitTest.breakInCaseTooFast,"    @Test
    public void breakInCaseTooFast() {
        PagesWriteSpeedBasedThrottle throttle = new PagesWriteSpeedBasedThrottle(pageMemory2g, null, stateChecker, log);

        long time = throttle.getParkTime(0.67,
            (362584 + 67064) / 2,
            328787,
            1,
            60184,
            23103);

        assertTrue(time > 0);
    }
",non-flaky,5
88821,apache_ignite,IgniteThrottlingUnitTest.noBreakIfNotFastWrite,"    @Test
    public void noBreakIfNotFastWrite() {
        PagesWriteSpeedBasedThrottle throttle = new PagesWriteSpeedBasedThrottle(pageMemory2g, null, stateChecker, log);

        long time = throttle.getParkTime(0.47,
            ((362584 + 67064) / 2),
            328787,
            1,
            20103,
            23103);

        assertTrue(time == 0);
    }
",non-flaky,5
88822,apache_ignite,IgniteThrottlingUnitTest.averageCalculation,"    @Test
    public void averageCalculation() throws InterruptedException {
        IntervalBasedMeasurement measurement = new IntervalBasedMeasurement(100, 1);

        for (int i = 0; i < 1000; i++)
            measurement.addMeasurementForAverageCalculation(100);

        assertEquals(100, measurement.getAverage());

        Thread.sleep(220);

        assertEquals(0, measurement.getAverage());

        assertEquals(0, measurement.getSpeedOpsPerSec(System.nanoTime()));
    }
",non-flaky,5
88823,apache_ignite,IgniteThrottlingUnitTest.speedCalculation,"    @Test
    public void speedCalculation() throws InterruptedException {
        IntervalBasedMeasurement measurement = new IntervalBasedMeasurement(100, 1);

        for (int i = 0; i < 1000; i++)
            measurement.setCounter(i, System.nanoTime());

        long speed = measurement.getSpeedOpsPerSec(System.nanoTime());
        System.out.println(""speed measured "" + speed);
        assertTrue(speed > 1000);

        Thread.sleep(230);

        assertEquals(0, measurement.getSpeedOpsPerSec(System.nanoTime()));
    }
",non-flaky,5
88824,apache_ignite,IgniteThrottlingUnitTest.speedWithDelayCalculation,"    @Test
    public void speedWithDelayCalculation() throws InterruptedException {
        IntervalBasedMeasurement measurement = new IntervalBasedMeasurement(100, 1);

        int runs = 10;
        int nanosPark = 100;
        int multiplier = 100000;
        for (int i = 0; i < runs; i++) {
            measurement.setCounter(i * multiplier, System.nanoTime());

            LockSupport.parkNanos(nanosPark);
        }

        long speed = measurement.getSpeedOpsPerSec(System.nanoTime());

        assertTrue(speed > 0);
        long maxSpeed = (TimeUnit.SECONDS.toNanos(1) * multiplier * runs) / ((long)(runs * nanosPark));
        assertTrue(speed < maxSpeed);

        Thread.sleep(200);

        assertEquals(0, measurement.getSpeedOpsPerSec(System.nanoTime()));
    }
",non-flaky,5
88825,apache_ignite,IgniteThrottlingUnitTest.beginOfCp,"    @Test
    public void beginOfCp() {
        PagesWriteSpeedBasedThrottle throttle = new PagesWriteSpeedBasedThrottle(pageMemory2g, null, stateChecker, log);

        assertTrue(throttle.getParkTime(0.01, 100,400000,
            1,
            20103,
            23103) == 0);

        //mark speed 22413 for mark all remaining as dirty
        long time = throttle.getParkTime(0.024, 100, 400000,
            1,
            24000,
            23103);
        assertTrue(time > 0);

        assertTrue(throttle.getParkTime(0.01,
            100,
            400000,
            1,
            22412,
            23103) == 0);
    }
",non-flaky,5
88826,apache_ignite,IgniteThrottlingUnitTest.enforceThrottleAtTheEndOfCp,"    @Test
    public void enforceThrottleAtTheEndOfCp() {
        PagesWriteSpeedBasedThrottle throttle = new PagesWriteSpeedBasedThrottle(pageMemory2g, null, stateChecker, log);

        long time1 = throttle.getParkTime(0.70, 300000, 400000,
            1, 20200, 23000);
        long time2 = throttle.getParkTime(0.71, 300000, 400000,
            1, 20200, 23000);

        assertTrue(time2 >= time1 * 2); // extra slowdown should be applied.

        long time3 = throttle.getParkTime(0.73, 300000, 400000,
            1, 20200, 23000);
        long time4 = throttle.getParkTime(0.74, 300000, 400000,
            1, 20200, 23000);

        assertTrue(time3 > time2);
        assertTrue(time4 > time3);
    }
",non-flaky,5
88827,apache_ignite,IgniteThrottlingUnitTest.tooMuchPagesMarkedDirty,"    @Test
    public void tooMuchPagesMarkedDirty() {
        PagesWriteSpeedBasedThrottle throttle = new PagesWriteSpeedBasedThrottle(pageMemory2g, null, stateChecker, log);

       // 363308	350004	348976	10604
        long time = throttle.getParkTime(0.75,
            ((350004 + 348976) / 2),
            350004-10604,
            4,
            279,
            23933);

        System.err.println(time);

        assertTrue(time == 0);
    }
",non-flaky,5
88828,apache_ignite,IgniteThrottlingUnitTest.warningInCaseTooMuchThrottling,"    @Test
    public void warningInCaseTooMuchThrottling() {
        AtomicInteger warnings = new AtomicInteger(0);
        IgniteLogger log = mock(IgniteLogger.class);

        doAnswer(invocation -> {
            Object[] args = invocation.getArguments();

            System.out.println(""log.info() called with arguments: "" + Arrays.toString(args));

            warnings.incrementAndGet();

            return null;
        }).when(log).info(anyString());

        AtomicInteger written = new AtomicInteger();
        CheckpointWriteProgressSupplier cpProgress = mock(CheckpointWriteProgressSupplier.class);
        when(cpProgress.writtenPagesCounter()).thenReturn(written);

        PagesWriteSpeedBasedThrottle throttle = new PagesWriteSpeedBasedThrottle(pageMemory2g, cpProgress, stateChecker, log) {
            @Override protected void doPark(long throttleParkTimeNs) {
                //do nothing
            }
        };
        throttle.onBeginCheckpoint();
        written.set(200); //emulating some pages written

        for (int i = 0; i < 100000; i++) {
            //emulating high load on marking
            throttle.onMarkDirty(false);

            if (throttle.throttleWeight() > PagesWriteSpeedBasedThrottle.WARN_THRESHOLD)
                break;
        }

        for (int i = 0; i < 1000; i++) {
            //emulating additional page writes to be sure log message is generated

            throttle.onMarkDirty(false);

            if(warnings.get()>0)
                break;
        }

        System.out.println(throttle.throttleWeight());

        assertTrue(warnings.get() > 0);
    }
",non-flaky,5
88829,apache_ignite,RobinHoodBackwardShiftHashMapTest.testShortSize,"    @Test
    public void testShortSize() throws Exception {
        withMap(map -> {
            map.put(1, 1, 0, 0);
            map.put(2, 0, 1, 1);
            map.remove(1, 1);
        }, 2);
    }
",non-flaky,5
88830,apache_ignite,RobinHoodBackwardShiftHashMapTest.testSimplestPutGet,"    @Test
    public void testSimplestPutGet() throws Exception {
        int cnt = 100;
        withMap(map -> {
                for (int i = 0; i < cnt; i++) {
                    int grpId = i + 1;
                    int val = grpId * grpId;

                    assertSizeChanged(""Unique put should be successful "" + grpId,
                        map, () -> map.put(grpId, 1, val, 1));
                    assertEquals(val, map.get(grpId, 1, 0, -1, -2));

                    assertSizeNotChanged(""Duplicate put for "" + grpId,
                        map, () -> map.put(grpId, 1, 1, 1));
                    assertEquals(1, map.get(grpId, 1, 0, -1, -2));
                }

                assertEquals(cnt, map.size());
            }
            , cnt);
    }
",non-flaky,5
88831,apache_ignite,RobinHoodBackwardShiftHashMapTest.testSimplestOverflow,"    @Test(expected = IgniteOutOfMemoryException.class)
    public void testSimplestOverflow() throws Exception {
        withMap(map -> {
                for (int i = 0; i < 10; i++) {
                    int grpId = i + 1;
                    int val = grpId * grpId;
                    assertSizeChanged(""Unique put should be successful ["" + grpId + ""]"", map, () -> map.put(grpId, 1, val, 1));

                    assertEquals(val, map.get(grpId, 1, 0, -1, -2));

                    assertSizeNotChanged(""Duplicate put for "" + grpId, map, () -> map.put(grpId, 1, 1, 1));
                    assertEquals(1, map.get(grpId, 1, 0, -1, -2));
                }

                map.put(11, 1, 11, 1);
            }
            , 10);
    }
",non-flaky,5
88832,apache_ignite,RobinHoodBackwardShiftHashMapTest.testPutRemoveOnSamePlaces,"    @Test
    public void testPutRemoveOnSamePlaces() throws Exception {
        withMap(map -> {
                doAddRemove(map);

                //fill with 1 space left;
                for (int i = 0; i < 99; i++) {
                    int grpId = i + 1;
                    int val = grpId * grpId;
                    assertSizeChanged(""Unique put should be successful "" + grpId, map,
                        () -> map.put(grpId, 1, val, 1));
                }

                doAddRemove(map);
            }
            , 100);
    }
",non-flaky,5
88833,apache_ignite,RobinHoodBackwardShiftHashMapTest.testCollisionOnRemove,"    @Test
    public void testCollisionOnRemove() {
        Map<FullPageId, Long> ctrl = new LinkedHashMap<>();
        int cap = 10;
        FullPageId baseId = new FullPageId(0, 1);

        withMap(map -> {
            for (int i = 0; i < cap; i++) {
                int grpId = i + 1;
                int pageId = findPageIdForCollision(grpId, baseId, cap);
                ctrl.put(new FullPageId(pageId, grpId), (long)grpId);
                map.put(grpId, pageId, (long)grpId, 1);
            }
            for (FullPageId next : ctrl.keySet()) {
                assertTrue(map.remove(next.groupId(), next.pageId()));
            }
        }, cap);
    }
",non-flaky,5
88834,apache_ignite,RobinHoodBackwardShiftHashMapTest.testRandomOpsPutRemove,"    @Test
    public void testRandomOpsPutRemove() {
        doPutRemoveTest(System.currentTimeMillis());
    }
",non-flaky,5
88835,apache_ignite,RobinHoodBackwardShiftHashMapTest.testPutAndCantGetOutdatedValue,"    @Test
    public void testPutAndCantGetOutdatedValue() throws Exception {
        withMap(map -> {
            //fill with 1 space left;
            for (int i = 0; i < 99; i++) {
                int ver = i;
                int grpId = ver + 1;
                int val = grpId * grpId;
                map.put(grpId, 1, val, ver);

                assertEquals(val, map.get(grpId, 1, ver, -1, -2));

                assertEquals(-2, map.get(grpId, 1, ver + 1, -1, -2));
            }
        }, 100);
    }
",non-flaky,5
88836,apache_ignite,RobinHoodBackwardShiftHashMapTest.testPutAndRefreshValue,"    @Test
    public void testPutAndRefreshValue() throws Exception {
        withMap(map -> {
            //fill with 1 space left;
            for (int i = 0; i < 99; i++) {
                int ver = i;
                int grpId = ver + 1;
                int val = grpId * grpId;
                int pageId = 1;
                map.put(grpId, pageId, val, ver);

                map.refresh(grpId, pageId, ver + 1);

                assertEquals(val, map.get(grpId, pageId, ver + 1, -1, -2));

            }

            doAddRemove(map);
        }, 100);
    }
",non-flaky,5
88837,apache_ignite,RobinHoodBackwardShiftHashMapTest.testClearAtWithControlMap3,"    @Test
    public void testClearAtWithControlMap3() throws Exception {
        int cap = 100;

        doRemovalTests(cap, (grpId, pageId) -> {
            int hc = Integer.hashCode(grpId) + 31 * Long.hashCode(pageId);

            return hc % 3 == 0;
        });
    }
",non-flaky,5
88838,apache_ignite,RobinHoodBackwardShiftHashMapTest.testClearAtWithControlMap7,"    @Test
    public void testClearAtWithControlMap7() throws Exception {
        int cap = 100;

        doRemovalTests(cap, (grpId, pageId) -> {
            int hc = Integer.hashCode(grpId) + 31 * Long.hashCode(pageId);

            return hc % 7 == 0;
        });
    }
",non-flaky,5
88839,apache_ignite,RobinHoodBackwardShiftHashMapTest.testClearAllWithControlMap,"    @Test
    public void testClearAllWithControlMap() throws Exception {
        int cap = 100;

        doRemovalTests(cap, (grpId, pageId) -> true);
    }
",non-flaky,5
88840,apache_ignite,FullPageIdTableTest.testRandomOperations,"    @Test
    public void testRandomOperations() throws Exception {
        int cnt = CACHE_ID_RANGE * PAGE_ID_RANGE;

        long mem = FullPageIdTable.requiredMemory(cnt);

        UnsafeMemoryProvider prov = new UnsafeMemoryProvider(log);

        prov.initialize(new long[] {mem});

        DirectMemoryRegion region = prov.nextRegion();

        try {
            long seed = U.currentTimeMillis();

            info(""Seed: "" + seed + ""L; //"");

            Random rnd = new Random(seed);

            LoadedPagesMap tbl = new FullPageIdTable(region.address(), region.size(), true);

            Map<FullPageId, Long> check = new HashMap<>();

            for (int i = 0; i < 10_000; i++) {
                int cacheId = rnd.nextInt(CACHE_ID_RANGE) + 1;
                int pageId = rnd.nextInt(PAGE_ID_RANGE);

                FullPageId fullId = new FullPageId(pageId, cacheId);

                boolean put = rnd.nextInt(3) != -1;

                if (put) {
                    long val = rnd.nextLong();

                    tbl.put(cacheId, pageId, val, 0);
                    check.put(fullId, val);
                }
                else {
                    tbl.remove(cacheId, pageId);
                    check.remove(fullId);
                }

                verifyLinear(tbl, check);

                if (i > 0 && i % 1000 == 0)
                    info(""Done: "" + i);
            }
        }
        finally {
            prov.shutdown(true);
        }
    }
",non-flaky,5
88841,apache_ignite,FullPageIdTableTest.putRemoveScenario,"    @Test
    public void putRemoveScenario() throws Exception {
        long seed = U.currentTimeMillis();

        doPutRemoveTest(seed, false, 1_000_000);
    }
",non-flaky,5
88842,apache_ignite,FullPageIdTableTest.putRemoveScenarioNewMap,"    @Test
    public void putRemoveScenarioNewMap() throws Exception {
        long seed = U.currentTimeMillis();
        doPutRemoveTest(seed, true, 30_000_000);
    }
",non-flaky,5
88843,apache_ignite,ObjectHistogramTest.testBuckets,"    @Test
    public void testBuckets() {
        testBuckets(hist1, new int[] {0, 1, 2, 3, 4, 5}, new int[] {4, 3, 2, 1, 1, 1});
        testBuckets(hist2, new int[] {0, 1, 5, 6}, new int[] {6, 5, 1, 1});
    }
",non-flaky,5
88844,apache_ignite,ObjectHistogramTest.testAdd,"    @Test
    public void testAdd() {
        double val = 100.0;
        hist1.addElement(val);
        Optional<Double> cntr = hist1.getValue(computeBucket(val));

        assertTrue(cntr.isPresent());
        assertEquals(1, cntr.get().intValue());
    }
",non-flaky,5
88845,apache_ignite,ObjectHistogramTest.testAddHist,"    @Test
    public void testAddHist() {
        ObjectHistogram<Double> res = hist1.plus(hist2);
        testBuckets(res, new int[] {0, 1, 2, 3, 4, 5, 6}, new int[] {10, 8, 2, 1, 1, 2, 1});
    }
",non-flaky,5
88846,apache_ignite,ObjectHistogramTest.testDistributionFunction,"    @Test
    public void testDistributionFunction() {
        TreeMap<Integer, Double> distribution = hist1.computeDistributionFunction();

        int[] buckets = new int[distribution.size()];
        double[] sums = new double[distribution.size()];

        int ptr = 0;
        for(int bucket : distribution.keySet()) {
            sums[ptr] = distribution.get(bucket);
            buckets[ptr++] = bucket;
        }

        assertArrayEquals(new int[] {0, 1, 2, 3, 4, 5}, buckets);
        assertArrayEquals(new double[] {4., 7., 9., 10., 11., 12.}, sums, 0.01);
    }
",non-flaky,5
88847,apache_ignite,ObjectHistogramTest.testOfSum,"    @Test
    public void testOfSum() {
        IgniteFunction<Double, Integer> bucketMap = x -> (int) (Math.ceil(x * 100) % 100);
        IgniteFunction<Double, Double> cntrMap = x -> Math.pow(x, 2);

        ObjectHistogram<Double> forAllHistogram = new ObjectHistogram<>(bucketMap, cntrMap);
        Random rnd = new Random();
        List<ObjectHistogram<Double>> partitions = new ArrayList<>();
        int cntOfPartitions = rnd.nextInt(100);
        int sizeOfDataset = rnd.nextInt(10000);
        for(int i = 0; i < cntOfPartitions; i++)
            partitions.add(new ObjectHistogram<>(bucketMap, cntrMap));

        for(int i = 0; i < sizeOfDataset; i++) {
            double objVal = rnd.nextDouble();
            forAllHistogram.addElement(objVal);
            partitions.get(rnd.nextInt(partitions.size())).addElement(objVal);
        }

        Optional<ObjectHistogram<Double>> leftSum = partitions.stream().reduce(ObjectHistogram::plus);
        Optional<ObjectHistogram<Double>> rightSum = partitions.stream().reduce((x,y) -> y.plus(x));
        assertTrue(leftSum.isPresent());
        assertTrue(rightSum.isPresent());
        assertTrue(forAllHistogram.isEqualTo(leftSum.get()));
        assertTrue(forAllHistogram.isEqualTo(rightSum.get()));
        assertTrue(leftSum.get().isEqualTo(rightSum.get()));
    }
",non-flaky,5
88848,apache_ignite,SimpleDatasetTest.basicTest,"    @Test
    public void basicTest() throws Exception {
        Map<Integer, DataPoint> dataPoints = new HashMap<Integer, DataPoint>() {{
            put(1, new DataPoint(42, 10000));
            put(2, new DataPoint(32, 64000));
            put(3, new DataPoint(53, 120000));
            put(4, new DataPoint(24, 70000));
        }};

        // Creates a local simple dataset containing features and providing standard dataset API.
        try (SimpleDataset<?> dataset = DatasetFactory.createSimpleDataset(
            dataPoints,
            2,
            (k, v) -> VectorUtils.of(v.getAge(), v.getSalary())
        )) {
            assertArrayEquals(""Mean values."", new double[] {37.75, 66000.0}, dataset.mean(), 0);

            assertArrayEquals(""Standard deviation values."",
                new double[] {10.871407452579449, 38961.519477556314}, dataset.std(), 0);

            double[][] covExp = new double[][] {
                new double[] {118.1875, 135500.0},
                new double[] {135500.0, 1.518E9}
            };
            double[][] cov = dataset.cov();
            int rowCov = 0;
            for (double[] row : cov)
                assertArrayEquals(""Covariance matrix row "" + rowCov,
                    covExp[rowCov++], row, 0);


            double[][] corrExp = new double[][] {
                new double[] {1.0000000000000002, 0.31990250167874007},
                new double[] {0.31990250167874007, 1.0}
            };
            double[][] corr = dataset.corr();
            int rowCorr = 0;
            for (double[] row : corr)
                assertArrayEquals(""Correlation matrix row "" + rowCorr,
                    corrExp[rowCorr++], row, 0);
        }
    }
",non-flaky,5
88849,apache_ignite,SimpleLabeledDatasetTest.basicTest,"    @Test
    public void basicTest() throws Exception {
        Map<Integer, DataPoint> dataPoints = new HashMap<Integer, DataPoint>() {{
            put(5, new DataPoint(42, 10000));
            put(6, new DataPoint(32, 64000));
            put(7, new DataPoint(53, 120000));
            put(8, new DataPoint(24, 70000));
        }};

        double[][] actualFeatures = new double[2][];
        double[][] actualLabels = new double[2][];
        int[] actualRows = new int[2];

        // Creates a local simple dataset containing features and providing standard dataset API.
        try (SimpleLabeledDataset<?> dataset = DatasetFactory.createSimpleLabeledDataset(
            dataPoints,
            2,
            (k, v) -> VectorUtils.of(v.getAge(), v.getSalary()),
            (k, v) -> new double[] {k, v.getAge(), v.getSalary()}
        )) {
            assertNull(dataset.compute((data, partIdx) -> {
                actualFeatures[partIdx] = data.getFeatures();
                actualLabels[partIdx] = data.getLabels();
                actualRows[partIdx] = data.getRows();
                return null;
            }, (k, v) -> null));
        }

        double[][] expFeatures = new double[][] {
            new double[] {42.0, 32.0, 10000.0, 64000.0},
            new double[] {53.0, 24.0, 120000.0, 70000.0}
        };
        int rowFeat = 0;
        for (double[] row : actualFeatures)
            assertArrayEquals(""Features partition index "" + rowFeat,
                expFeatures[rowFeat++], row, 0);

        double[][] expLabels = new double[][] {
            new double[] {5.0, 6.0, 42.0, 32.0, 10000.0, 64000.0},
            new double[] {7.0, 8.0, 53.0, 24.0, 120000.0, 70000.0}
        };
        int rowLbl = 0;
        for (double[] row : actualLabels)
            assertArrayEquals(""Labels partition index "" + rowLbl,
                expLabels[rowLbl++], row, 0);

        assertArrayEquals(""Rows per partitions"", new int[] {2, 2}, actualRows);
    }
",non-flaky,5
88850,apache_ignite,DatasetWrapperTest.testComputeWithCtx,"    @Test
    public void testComputeWithCtx() {
        doReturn(42).when(dataset).computeWithCtx(any(IgniteTriFunction.class), any(), any());

        Integer res = (Integer) wrapper.computeWithCtx(mock(IgniteTriFunction.class), mock(IgniteBinaryOperator.class),
            null);

        assertEquals(42, res.intValue());

        verify(dataset, times(1)).computeWithCtx(any(IgniteTriFunction.class), any(), any());
    }
",non-flaky,5
88851,apache_ignite,DatasetWrapperTest.testComputeWithCtx2,"    @Test
    public void testComputeWithCtx2() {
        doReturn(42).when(dataset).computeWithCtx(any(IgniteTriFunction.class), any(), any());

        Integer res = (Integer) wrapper.computeWithCtx(mock(IgniteBiFunction.class), mock(IgniteBinaryOperator.class),
            null);

        assertEquals(42, res.intValue());

        verify(dataset, times(1)).computeWithCtx(any(IgniteTriFunction.class), any(), any());
    }
",non-flaky,5
88852,apache_ignite,DatasetWrapperTest.testComputeWithCtx3,"    @Test
    public void testComputeWithCtx3() {
        wrapper.computeWithCtx((ctx, data) -> {
            assertNotNull(ctx);
            assertNotNull(data);
        });

        verify(dataset, times(1)).computeWithCtx(any(IgniteTriFunction.class),
            any(IgniteBinaryOperator.class), any());
    }
",non-flaky,5
88853,apache_ignite,DatasetWrapperTest.testCompute,"    @Test
    public void testCompute() {
        doReturn(42).when(dataset).compute(any(IgniteBiFunction.class), any(), any());

        Integer res = (Integer) wrapper.compute(mock(IgniteBiFunction.class), mock(IgniteBinaryOperator.class),
            null);

        assertEquals(42, res.intValue());

        verify(dataset, times(1)).compute(any(IgniteBiFunction.class), any(), any());
    }
",non-flaky,5
88854,apache_ignite,DatasetWrapperTest.testCompute2,"    @Test
    public void testCompute2() {
        doReturn(42).when(dataset).compute(any(IgniteBiFunction.class), any(IgniteBinaryOperator.class), any());

        Integer res = (Integer) wrapper.compute(mock(IgniteFunction.class), mock(IgniteBinaryOperator.class),
            null);

        assertEquals(42, res.intValue());

        verify(dataset, times(1)).compute(any(IgniteBiFunction.class), any(IgniteBinaryOperator.class), any());
    }
",non-flaky,5
88855,apache_ignite,DatasetWrapperTest.testClose,"    @Test
    public void testClose() throws Exception {
        wrapper.close();

        verify(dataset, times(1)).close();
    }
",non-flaky,5
88856,apache_ignite,LocalDatasetBuilderTest.testBuild,"    @Test
    public void testBuild() {
        Map<Integer, Integer> data = new HashMap<>();
        for (int i = 0; i < 100; i++)
            data.put(i, i);

        LocalDatasetBuilder<Integer, Integer> builder = new LocalDatasetBuilder<>(data, 10);

        LocalDataset<Serializable, TestPartitionData> dataset = buildDataset(builder);

        assertEquals(10, dataset.getCtx().size());
        assertEquals(10, dataset.getData().size());

        AtomicLong cnt = new AtomicLong();

        dataset.compute((partData, partIdx) -> {
           cnt.incrementAndGet();

           int[] arr = partData.data;

           assertEquals(10, arr.length);

           for (int i = 0; i < 10; i++)
               assertEquals(partIdx * 10 + i, arr[i]);
        });

        assertEquals(10, cnt.intValue());
    }
",non-flaky,5
88857,apache_ignite,LocalDatasetBuilderTest.testBuildWithPredicate,"    @Test
    public void testBuildWithPredicate() {
        Map<Integer, Integer> data = new HashMap<>();
        for (int i = 0; i < 100; i++)
            data.put(i, i);

        LocalDatasetBuilder<Integer, Integer> builder = new LocalDatasetBuilder<>(data, (k, v) -> k % 2 == 0,10);

        LocalDataset<Serializable, TestPartitionData> dataset = buildDataset(builder);

        AtomicLong cnt = new AtomicLong();

        dataset.compute((partData, partIdx) -> {
            cnt.incrementAndGet();

            int[] arr = partData.data;

            assertEquals(5, arr.length);

            for (int i = 0; i < 5; i++)
                assertEquals((partIdx * 5 + i) * 2, arr[i]);
        });

        assertEquals(10, cnt.intValue());
    }
",non-flaky,5
88858,apache_ignite,IteratorWithConcurrentModificationCheckerTest.testNextWhenIteratorHasLessElementsThanExpected,"    @Test(expected = ConcurrentModificationException.class)
    public void testNextWhenIteratorHasLessElementsThanExpected() {
        List<Integer> list = Arrays.asList(1, 2, 3);

        Iterator<Integer> iter = new IteratorWithConcurrentModificationChecker<>(list.iterator(), 4, ""Exception"");

        assertEquals(Integer.valueOf(1), iter.next());
        assertEquals(Integer.valueOf(2), iter.next());
        assertEquals(Integer.valueOf(3), iter.next());

        iter.next(); // Should throw an exception.
    }
",non-flaky,5
88859,apache_ignite,IteratorWithConcurrentModificationCheckerTest.testNextWhenIteratorHasMoreElementsThanExpected,"    @Test(expected = ConcurrentModificationException.class)
    public void testNextWhenIteratorHasMoreElementsThanExpected() {
        List<Integer> list = Arrays.asList(1, 2, 3);

        Iterator<Integer> iter = new IteratorWithConcurrentModificationChecker<>(list.iterator(), 2, ""Exception"");

        assertEquals(Integer.valueOf(1), iter.next());
        assertEquals(Integer.valueOf(2), iter.next());

        iter.next(); // Should throw an exception.
    }
",non-flaky,5
88860,apache_ignite,IteratorWithConcurrentModificationCheckerTest.testHasNextWhenIteratorHasLessElementsThanExpected,"    @Test(expected = ConcurrentModificationException.class)
    public void testHasNextWhenIteratorHasLessElementsThanExpected() {
        List<Integer> list = Arrays.asList(1, 2, 3);

        Iterator<Integer> iter = new IteratorWithConcurrentModificationChecker<>(list.iterator(), 4, ""Exception"");

        assertTrue(iter.hasNext());
        iter.next();
        assertTrue(iter.hasNext());
        iter.next();
        assertTrue(iter.hasNext());
        iter.next();

        iter.hasNext(); // Should throw an exception.
    }
",non-flaky,5
88861,apache_ignite,IteratorWithConcurrentModificationCheckerTest.testHasNextWhenIteratorHasMoreElementsThanExpected,"    @Test(expected = ConcurrentModificationException.class)
    public void testHasNextWhenIteratorHasMoreElementsThanExpected() {
        List<Integer> list = Arrays.asList(1, 2, 3);

        Iterator<Integer> iter = new IteratorWithConcurrentModificationChecker<>(list.iterator(), 2, ""Exception"");

        assertTrue(iter.hasNext());
        iter.next();
        assertTrue(iter.hasNext());
        iter.next();

        iter.hasNext(); // Should throw an exception.
    }
",non-flaky,5
88862,apache_ignite,DatasetAffinityFunctionWrapperTest.testReset,"    @Test
    public void testReset() {
        wrapper.reset();

        verify(affinityFunction, times(1)).reset();
    }
",non-flaky,5
88863,apache_ignite,DatasetAffinityFunctionWrapperTest.testPartitions,"    @Test
    public void testPartitions() {
        doReturn(42).when(affinityFunction).partitions();

        int partitions = wrapper.partitions();

        assertEquals(42, partitions);
        verify(affinityFunction, times(1)).partitions();
    }
",non-flaky,5
88864,apache_ignite,DatasetAffinityFunctionWrapperTest.testPartition,"    @Test
    public void testPartition() {
        doReturn(0).when(affinityFunction).partition(eq(42));

        int part = wrapper.partition(42);

        assertEquals(42, part);
        verify(affinityFunction, times(0)).partition(any());
    }
",non-flaky,5
88865,apache_ignite,DatasetAffinityFunctionWrapperTest.testAssignPartitions,"    @Test
    public void testAssignPartitions() {
        List<List<ClusterNode>> nodes = Collections.singletonList(Collections.singletonList(mock(ClusterNode.class)));

        doReturn(nodes).when(affinityFunction).assignPartitions(any());

        List<List<ClusterNode>> resNodes = wrapper.assignPartitions(mock(AffinityFunctionContext.class));

        assertEquals(nodes, resNodes);
        verify(affinityFunction, times(1)).assignPartitions(any());
    }
",non-flaky,5
88866,apache_ignite,DatasetAffinityFunctionWrapperTest.testRemoveNode,"    @Test
    public void testRemoveNode() {
        UUID nodeId = UUID.randomUUID();

        wrapper.removeNode(nodeId);

        verify(affinityFunction, times(1)).removeNode(eq(nodeId));
    }
",non-flaky,5
88867,apache_ignite,PartitionDataStorageTest.testComputeDataIfAbsent,"    @Test
    public void testComputeDataIfAbsent() {
        AtomicLong cnt = new AtomicLong();

        for (int i = 0; i < 10; i++) {
            Integer res = (Integer) dataStorage.computeDataIfAbsent(0, () -> {
                cnt.incrementAndGet();

                return 42;
            });

            assertEquals(42, res.intValue());
        }

        assertEquals(1, cnt.intValue());
    }
",non-flaky,5
88868,apache_ignite,PipelineMdlTest.testPredict,"    @Test
    public void testPredict() {
        Vector weights = new DenseVector(new double[] {2.0, 3.0});

        verifyPredict(getMdl(new LogisticRegressionModel(weights, 1.0).withRawLabels(true)));
    }
",non-flaky,5
88869,apache_ignite,PipelineTest.testTrainWithTheLinearlySeparableCase,"    @Test
    public void testTrainWithTheLinearlySeparableCase() {
        Map<Integer, Double[]> cacheMock = new HashMap<>();

        for (int i = 0; i < twoLinearlySeparableClasses.length; i++) {
            double[] row = twoLinearlySeparableClasses[i];
            Double[] convertedRow = new Double[row.length];
            for (int j = 0; j < row.length; j++)
                convertedRow[j] = row[j];
            cacheMock.put(i, convertedRow);
        }

        LogisticRegressionSGDTrainer<?> trainer = new LogisticRegressionSGDTrainer<>()
            .withUpdatesStgy(new UpdatesStrategy<>(new SimpleGDUpdateCalculator(0.2),
                SimpleGDParameterUpdate::sumLocal, SimpleGDParameterUpdate::avg))
            .withMaxIterations(100000)
            .withLocIterations(100)
            .withBatchSize(10)
            .withSeed(123L);

        PipelineMdl<Integer, Double[]> mdl = new Pipeline<Integer, Double[], Vector>()
            .addFeatureExtractor((k, v) -> VectorUtils.of(Arrays.copyOfRange(v, 1, v.length)))
            .addLabelExtractor((k, v) -> v[0])
            .addPreprocessor(new MinMaxScalerTrainer<Integer, Object[]>())
            .addPreprocessor(new NormalizationTrainer<Integer, Object[]>()
                .withP(1))
            .addTrainer(trainer)
            .fit(
                cacheMock,
                parts
            );

        TestUtils.assertEquals(0, mdl.apply(VectorUtils.of(100, 10)), PRECISION);
        TestUtils.assertEquals(1, mdl.apply(VectorUtils.of(10, 100)), PRECISION);
    }
",non-flaky,5
88870,apache_ignite,PipelineTest.testTrainWithMissedFinalStage,"    @Test(expected = IllegalStateException.class)
    public void testTrainWithMissedFinalStage() {
        Map<Integer, Double[]> cacheMock = new HashMap<>();

        for (int i = 0; i < twoLinearlySeparableClasses.length; i++) {
            double[] row = twoLinearlySeparableClasses[i];
            Double[] convertedRow = new Double[row.length];
            for (int j = 0; j < row.length; j++)
                convertedRow[j] = row[j];
            cacheMock.put(i, convertedRow);
        }

        PipelineMdl<Integer, Double[]> mdl = new Pipeline<Integer, Double[], Vector>()
            .addFeatureExtractor((k, v) -> VectorUtils.of(Arrays.copyOfRange(v, 1, v.length)))
            .addLabelExtractor((k, v) -> v[0])
            .addPreprocessor(new MinMaxScalerTrainer<Integer, Object[]>())
            .addPreprocessor(new NormalizationTrainer<Integer, Object[]>()
                .withP(1))
            .fit(
                cacheMock,
                parts
            );

        TestUtils.assertEquals(0, mdl.apply(VectorUtils.of(100, 10)), PRECISION);
        TestUtils.assertEquals(1, mdl.apply(VectorUtils.of(10, 100)), PRECISION);
    }
",non-flaky,5
83,square_okhttp,CallTest.legalToExecuteTwiceCloning_Async,"@Test
public void legalToExecuteTwiceCloning_Async() throws Exception {
    server.enqueue(new MockResponse().setBody(""abc""));
    server.enqueue(new MockResponse().setBody(""def""));
    Request request = new Request.Builder().url(server.url(""/"")).build();
    Call call = client.newCall(request);
    call.enqueue(callback);
    Call cloned = call.clone();
    cloned.enqueue(callback);
    callback.await(request.url()).assertBody(""abc"");
    callback.await(request.url()).assertBody(""def"");
}",async wait,0
212,square_okhttp,HttpOverHttp2Test.recoverFromCancelReusesConnection,"@Test
public void recoverFromCancelReusesConnection() throws Exception {
    CountDownLatch responseDequeuedLatch = new CountDownLatch(1);
    CountDownLatch requestCanceledLatch = new CountDownLatch(1);
    QueueDispatcher dispatcher = new QueueDispatcher() {
        @Override
        public MockResponse dispatch(RecordedRequest request) throws InterruptedException {
            MockResponse response = super.dispatch(request);
            responseDequeuedLatch.countDown();
            requestCanceledLatch.await();
            return response;
        }
    };
    server.setDispatcher(dispatcher);
    dispatcher.enqueueResponse(new MockResponse().setBodyDelay(10, TimeUnit.SECONDS).setBody(""abc""));
    dispatcher.enqueueResponse(new MockResponse().setBody(""def""));
    client = client.newBuilder().dns(new DoubleInetAddressDns()).build();
    callAndCancel(0, responseDequeuedLatch, requestCanceledLatch);
    Call call = client.newCall(new Request.Builder().url(server.url(""/"")).build());
    Response response = call.execute();
    assertThat(response.body().string()).isEqualTo(""def"");
    assertThat(server.takeRequest().getSequenceNumber()).isEqualTo(1);
}",async wait,0
315,square_okhttp,DuplexTest.duplexWithRedirect,"@Test
public void duplexWithRedirect() throws Exception {
    enableProtocol(HTTP_2);
    MockDuplexResponseBody mockDuplexResponseBody = enqueueResponseWithBody(new MockResponse().clearHeaders().setResponseCode(HttpURLConnection.HTTP_MOVED_PERM).addHeader(""Location: /b""), new MockDuplexResponseBody().sendResponse(""/a has moved!\n"").requestIOException().exhaustResponse());
    server.enqueue(new MockResponse().setBody(""this is /b""));
    Call call = client.newCall(new Request.Builder().url(server.url(""/"")).post(new AsyncRequestBody()).build());
    try (final Response response = call.execute()) {
        BufferedSource responseBody = response.body().source();
        assertThat(responseBody.readUtf8Line()).isEqualTo(""this is /b"");
    }
    BufferedSink requestBody = ((AsyncRequestBody) (call.request().body())).takeSink();
    try {
        requestBody.writeUtf8(""request body\n"");
        requestBody.flush();
        fail();
    } catch (IOException expected) {
        assertThat(expected.getMessage()).isEqualTo(""stream was reset: CANCEL"");
    }
    mockDuplexResponseBody.awaitSuccess();
    assertThat(listener.recordedEventTypes()).containsExactly(""CallStart"", ""DnsStart"", ""DnsEnd"", ""ConnectStart"", ""SecureConnectStart"", ""SecureConnectEnd"", ""ConnectEnd"", ""ConnectionAcquired"", ""RequestHeadersStart"", ""RequestHeadersEnd"", ""RequestBodyStart"", ""ResponseHeadersStart"", ""ResponseHeadersEnd"", ""ResponseBodyStart"", ""ResponseBodyEnd"", ""RequestHeadersStart"", ""RequestHeadersEnd"", ""ResponseHeadersStart"", ""ResponseHeadersEnd"", ""ResponseBodyStart"", ""ResponseBodyEnd"", ""ConnectionReleased"", ""CallEnd"", ""RequestFailed"");
}",async wait,0
94601,square_okhttp,UrlConnectionCacheTest.gzip,"  @Test public void testGoldenCacheResponse() throws Exception {
  public Buffer gzip(String data) throws IOException {
    Buffer result = new Buffer();
    BufferedSink sink = Okio.buffer(new GzipSink(result));
    sink.writeUtf8(data);
    sink.close();
    return result;
  }
",non-flaky,5
94602,square_okhttp,OkUrlFactoryTest.setInstanceFollowRedirectsFalse,"  @Test
  public void setInstanceFollowRedirectsFalse() throws Exception {
    server.enqueue(new MockResponse()
        .setResponseCode(302)
        .addHeader(""Location: /b"")
        .setBody(""A""));
    server.enqueue(new MockResponse()
        .setBody(""B""));

    HttpURLConnection connection = factory.open(server.url(""/a"").url());
    connection.setInstanceFollowRedirects(false);
    assertResponseBody(connection, ""A"");
    assertResponseCode(connection, 302);
  }
",non-flaky,5
94603,square_okhttp,OkUrlFactoryTest.checkURLPermitted,"  @Test
  public void testURLFilter() throws Exception {
    server.enqueue(new MockResponse()
        .setBody(""B""));
    final URL blockedURL = server.url(""/a"").url();
    factory.setUrlFilter(new URLFilter() {
      @Override
      public void checkURLPermitted(URL url) throws IOException {
        if (blockedURL.equals(url)) {
          throw new IOException(""Blocked"");
        }
      }
",non-flaky,5
94604,square_okhttp,OkUrlFactoryTest.checkURLPermitted,"  @Test
  public void testURLFilterRedirect() throws Exception {
    MockWebServer cleartextServer = new MockWebServer();
    cleartextServer.enqueue(new MockResponse()
        .setBody(""Blocked!""));
    final URL blockedURL = cleartextServer.url(""/"").url();

    SslClient contextBuilder = SslClient.localhost();
    server.useHttps(contextBuilder.socketFactory, false);
    factory.setClient(factory.client().newBuilder()
        .sslSocketFactory(contextBuilder.socketFactory, contextBuilder.trustManager)
        .followSslRedirects(true)
        .build());
    factory.setUrlFilter(new URLFilter() {
      @Override
      public void checkURLPermitted(URL url) throws IOException {
        if (blockedURL.equals(url)) {
          throw new IOException(""Blocked"");
        }
      }
",non-flaky,5
94605,square_okhttp,URLEncodingTest.get,"  @Test @Ignore public void lenientUrlToUriNul() throws Exception {
      @Override public Response get(Request request) throws IOException {
        uriReference.set(request.url().uri());
        throw new UnsupportedOperationException();
      }
",non-flaky,5
94606,square_okhttp,CookiesTest.testNetscapeResponse,"  @Test
  public void testNetscapeResponse() throws Exception {
    CookieManager cookieManager = new CookieManager(null, ACCEPT_ORIGINAL_SERVER);
    client = client.newBuilder()
        .cookieJar(new JavaNetCookieJar(cookieManager))
        .build();
    MockWebServer server = new MockWebServer();
    server.start();

    HttpUrl urlWithIpAddress = urlWithIpAddress(server, ""/path/foo"");
    server.enqueue(new MockResponse().addHeader(""Set-Cookie: a=android; ""
        + ""expires=Fri, 31-Dec-9999 23:59:59 GMT; ""
        + ""path=/path; ""
        + ""domain="" + urlWithIpAddress.host() + ""; ""
        + ""secure""));
    get(urlWithIpAddress);

    List<HttpCookie> cookies = cookieManager.getCookieStore().getCookies();
    assertEquals(1, cookies.size());
    HttpCookie cookie = cookies.get(0);
    assertEquals(""a"", cookie.getName());
    assertEquals(""android"", cookie.getValue());
    assertEquals(null, cookie.getComment());
    assertEquals(null, cookie.getCommentURL());
    assertEquals(false, cookie.getDiscard());
    assertTrue(cookie.getMaxAge() > 100000000000L);
    assertEquals(""/path"", cookie.getPath());
    assertEquals(true, cookie.getSecure());
    assertEquals(0, cookie.getVersion());
  }
",non-flaky,5
94607,square_okhttp,CookiesTest.put,"  @Test public void cookieHandlerLikeAndroid() throws Exception {
      @Override public void put(URI uri, Map<String, List<String>> map) throws IOException {
      }
",non-flaky,5
94608,square_okhttp,CacheTest.assertCookies,"  @Test public void getHeadersRetainsCached200LevelWarnings() throws Exception {
  public void assertCookies(HttpUrl url, String... expectedCookies) throws Exception {
    List<String> actualCookies = new ArrayList<>();
    for (HttpCookie cookie : cookieManager.getCookieStore().get(url.uri())) {
      actualCookies.add(cookie.toString());
    }
    assertEquals(Arrays.asList(expectedCookies), actualCookies);
  }
",non-flaky,5
94609,square_okhttp,CacheTest.intercept,"  @Test public void networkInterceptorInvokedForConditionalGet() throws Exception {
          @Override public Response intercept(Chain chain) throws IOException {
            ifNoneMatch.compareAndSet(null, chain.request().header(""If-None-Match""));
            return chain.proceed(chain.request());
          }
",non-flaky,5
94610,square_okhttp,CacheTest.intercept,"  @Test public void networkInterceptorNotInvokedForFullyCached() throws Exception {
          @Override public Response intercept(Chain chain) throws IOException {
            throw new AssertionError();
          }
",non-flaky,5
94611,square_okhttp,CacheTest.gzip,"  @Test public void etagConditionCanBeNonAscii() throws Exception {
  public Buffer gzip(String data) throws IOException {
    Buffer result = new Buffer();
    BufferedSink sink = Okio.buffer(new GzipSink(result));
    sink.writeUtf8(data);
    sink.close();
    return result;
  }
",non-flaky,5
94612,square_okhttp,MultipartBodyTest.contentType,"  @Test public void streamingPartHasNoLength() throws Exception {
      @Override public MediaType contentType() {
        return null;
      }
",non-flaky,5
94613,square_okhttp,URLConnectionTest.createSocket,"  @Test public void contentDisagreesWithContentLengthHeaderBodyTooShort() throws IOException {
  public void testConnectViaSocketFactory(boolean useHttps) throws IOException {
    SocketFactory uselessSocketFactory = new SocketFactory() {
      public Socket createSocket() {
        throw new IllegalArgumentException(""useless"");
      }
",non-flaky,5
94614,square_okhttp,URLConnectionTest.select,"  @Test public void redirectWithProxySelector() throws Exception {
          @Override public List<Proxy> select(URI uri) {
            proxySelectionRequests.add(uri);
            MockWebServer proxyServer = (uri.getPort() == server.getPort())
                ? server
                : server2;
            return Arrays.asList(proxyServer.toProxyAddress());
          }
",non-flaky,5
94615,square_okhttp,URLConnectionTest.intercept,"  @Test public void interceptorsNotInvoked() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        throw new AssertionError();
      }
",non-flaky,5
94616,square_okhttp,URLConnectionTest.lookup,"  @Test public void unexpectedExceptionSync() throws Exception {
          @Override public List<InetAddress> lookup(String hostname) {
            throw new RuntimeException(""boom!"");
          }
",non-flaky,5
94617,square_okhttp,URLConnectionTest.lookup,"  @Test public void unexpectedExceptionAsync() throws Exception {
          @Override public List<InetAddress> lookup(String hostname) {
            throw new RuntimeException(""boom!"");
          }
",non-flaky,5
94618,square_okhttp,URLConnectionTest.gzip,"  @Test public void callsNotManagedByDispatcher() throws Exception {
  public Buffer gzip(String data) throws IOException {
    Buffer result = new Buffer();
    BufferedSink gzipSink = Okio.buffer(new GzipSink(result));
    gzipSink.writeUtf8(data);
    gzipSink.close();
    return result;
  }
",non-flaky,5
94619,square_okhttp,InterceptorTest.intercept,"  @Test public void applicationInterceptorsCanShortCircuitResponses() throws Exception {
          @Override public Response intercept(Chain chain) throws IOException {
            return interceptorResponse;
          }
",non-flaky,5
94620,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsCannotShortCircuitResponses() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        return new Response.Builder()
            .request(chain.request())
            .protocol(Protocol.HTTP_1_1)
            .code(200)
            .message(""Intercepted!"")
            .body(ResponseBody.create(MediaType.parse(""text/plain; charset=utf-8""), ""abc""))
            .build();
      }
",non-flaky,5
94621,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsCannotCallProceedMultipleTimes() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        chain.proceed(chain.request());
        return chain.proceed(chain.request());
      }
",non-flaky,5
94622,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsCannotChangeServerAddress() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Address address = chain.connection().route().address();
        String sameHost = address.url().host();
        int differentPort = address.url().port() + 1;
        return chain.proceed(chain.request().newBuilder()
            .url(HttpUrl.parse(""http://"" + sameHost + "":"" + differentPort + ""/""))
            .build());
      }
",non-flaky,5
94623,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsHaveConnectionAccess() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Connection connection = chain.connection();
        assertNotNull(connection);
        return chain.proceed(chain.request());
      }
",non-flaky,5
94624,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsObserveNetworkHeaders() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        // The network request has everything: User-Agent, Host, Accept-Encoding.
        Request networkRequest = chain.request();
        assertNotNull(networkRequest.header(""User-Agent""));
        assertEquals(server.getHostName() + "":"" + server.getPort(),
            networkRequest.header(""Host""));
        assertNotNull(networkRequest.header(""Accept-Encoding""));

        // The network response also has everything, including the raw gzipped content.
        Response networkResponse = chain.proceed(networkRequest);
        assertEquals(""gzip"", networkResponse.header(""Content-Encoding""));
        return networkResponse;
      }
",non-flaky,5
94625,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsCanChangeRequestMethodFromGetToPost() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Request originalRequest = chain.request();
        MediaType mediaType = MediaType.parse(""text/plain"");
        RequestBody body = RequestBody.create(mediaType, ""abc"");
        return chain.proceed(originalRequest.newBuilder()
            .method(""POST"", body)
            .header(""Content-Type"", mediaType.toString())
            .header(""Content-Length"", Long.toString(body.contentLength()))
            .build());
      }
",non-flaky,5
94626,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsRewriteRequestToServer() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Request originalRequest = chain.request();
        return chain.proceed(originalRequest.newBuilder()
            .method(""POST"", uppercase(originalRequest.body()))
            .addHeader(""OkHttp-Intercepted"", ""yep"")
            .build());
      }
",non-flaky,5
94627,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsRewriteResponseFromServer() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Response originalResponse = chain.proceed(chain.request());
        return originalResponse.newBuilder()
            .body(uppercase(originalResponse.body()))
            .addHeader(""OkHttp-Intercepted"", ""yep"")
            .build();
      }
",non-flaky,5
94628,square_okhttp,InterceptorTest.intercept,"  @Test public void multipleNetworkInterceptors() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Request originalRequest = chain.request();
        Response originalResponse = chain.proceed(originalRequest.newBuilder()
            .addHeader(""Request-Interceptor"", ""Android"") // 1. Added first.
            .build());
        return originalResponse.newBuilder()
            .addHeader(""Response-Interceptor"", ""Donut"") // 4. Added last.
            .build();
      }
",non-flaky,5
94629,square_okhttp,InterceptorTest.intercept,"  @Test public void asyncNetworkInterceptors() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Response originalResponse = chain.proceed(chain.request());
        return originalResponse.newBuilder()
            .addHeader(""OkHttp-Intercepted"", ""yep"")
            .build();
      }
",non-flaky,5
94630,square_okhttp,InterceptorTest.intercept,"  @Test public void applicationInterceptorsCanMakeMultipleRequestsToServer() throws Exception {
          @Override public Response intercept(Chain chain) throws IOException {
            Response response1 = chain.proceed(chain.request());
            response1.body().close();
            return chain.proceed(chain.request());
          }
",non-flaky,5
94631,square_okhttp,InterceptorTest.intercept,"  @Test public void interceptorMakesAnUnrelatedRequest() throws Exception {
          @Override public Response intercept(Chain chain) throws IOException {
            if (chain.request().url().encodedPath().equals(""/b"")) {
              Request requestA = new Request.Builder()
                  .url(server.url(""/a""))
                  .build();
              Response responseA = client.newCall(requestA).execute();
              assertEquals(""a"", responseA.body().string());
            }

            return chain.proceed(chain.request());
          }
",non-flaky,5
94632,square_okhttp,InterceptorTest.intercept,"  @Test public void interceptorMakesAnUnrelatedAsyncRequest() throws Exception {
          @Override public Response intercept(Chain chain) throws IOException {
            if (chain.request().url().encodedPath().equals(""/b"")) {
              Request requestA = new Request.Builder()
                  .url(server.url(""/a""))
                  .build();

              try {
                RecordingCallback callbackA = new RecordingCallback();
                client.newCall(requestA).enqueue(callbackA);
                callbackA.await(requestA.url()).assertBody(""a"");
              } catch (Exception e) {
                throw new RuntimeException(e);
              }
            }

            return chain.proceed(chain.request());
          }
",non-flaky,5
94633,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorThrowsRuntimeExceptionSynchronous() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        throw new RuntimeException(""boom!"");
      }
",non-flaky,5
94634,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorModifiedRequestIsReturned() throws IOException {
      @Override public Response intercept(Chain chain) throws IOException {
        return chain.proceed(chain.request().newBuilder()
            .header(""User-Agent"", ""intercepted request"")
            .build());
      }
",non-flaky,5
94635,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorThrowsRuntimeExceptionAsynchronous() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        throw new RuntimeException(""boom!"");
      }
",non-flaky,5
94636,square_okhttp,InterceptorTest.intercept,"  @Test public void applicationInterceptorReturnsNull() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        chain.proceed(chain.request());
        return null;
      }
",non-flaky,5
94637,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorReturnsNull() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        chain.proceed(chain.request());
        return null;
      }
",non-flaky,5
94638,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorReturnsConnectionOnEmptyBody() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Response response = chain.proceed(chain.request());
        assertNotNull(chain.connection());
        return response;
      }
",non-flaky,5
94639,square_okhttp,ResponseTest.close,"  @Test public void eachPeakIsIndependent() throws Exception {
      @Override public void close() throws IOException {
        closed = true;
      }
",non-flaky,5
94640,square_okhttp,SocksProxyTest.select,"  @Test public void proxySelector() throws Exception {
      @Override public List<Proxy> select(URI uri) {
        return Collections.singletonList(socksProxy.proxy());
      }
",non-flaky,5
94641,square_okhttp,DispatcherTest.intercept,"  @Test public void synchronousCallAccessors() throws Exception {
              @Override public Response intercept(Chain chain) throws IOException {
                try {
                  ready.countDown();
                  waiting.await();
                } catch (InterruptedException e) {
                  throw new AssertionError();
                }
                throw new IOException();
              }
",non-flaky,5
94642,square_okhttp,DispatcherTest.run,"  @Test public void idleCallbackInvokedWhenIdle() throws InterruptedException {
      @Override public void run() {
        idle.set(true);
      }
",non-flaky,5
94643,square_okhttp,OkHttpClientTest.intercept,"  @Test public void clonedInterceptorsListsAreIndependent() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        return chain.proceed(chain.request());
      }
",non-flaky,5
94644,square_okhttp,ConnectionReuseTest.intercept,"  @Test public void connectionsAreNotReusedIfNetworkInterceptorInterferes() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Response response = chain.proceed(chain.request());
        return response.newBuilder()
            .body(ResponseBody.create(null, ""unrelated response body!""))
            .build();
      }
",non-flaky,5
94645,square_okhttp,ConnectionSpecSelectorTest.nonRetryableIOException,"  @Test
  public void nonRetryableIOException() throws Exception {
    ConnectionSpecSelector connectionSpecSelector =
        createConnectionSpecSelector(ConnectionSpec.MODERN_TLS, ConnectionSpec.COMPATIBLE_TLS);
    SSLSocket socket = createSocketWithEnabledProtocols(TlsVersion.TLS_1_1, TlsVersion.TLS_1_0);
    connectionSpecSelector.configureSecureSocket(socket);

    boolean retry = connectionSpecSelector.connectionFailed(
        new IOException(""Non-handshake exception""));
    assertFalse(retry);
    socket.close();
  }
",non-flaky,5
94646,square_okhttp,ConnectionSpecSelectorTest.nonRetryableSSLHandshakeException,"  @Test
  public void nonRetryableSSLHandshakeException() throws Exception {
    ConnectionSpecSelector connectionSpecSelector =
        createConnectionSpecSelector(ConnectionSpec.MODERN_TLS, ConnectionSpec.COMPATIBLE_TLS);
    SSLSocket socket = createSocketWithEnabledProtocols(TlsVersion.TLS_1_1, TlsVersion.TLS_1_0);
    connectionSpecSelector.configureSecureSocket(socket);

    SSLHandshakeException trustIssueException =
        new SSLHandshakeException(""Certificate handshake exception"");
    trustIssueException.initCause(new CertificateException());
    boolean retry = connectionSpecSelector.connectionFailed(trustIssueException);
    assertFalse(retry);
    socket.close();
  }
",non-flaky,5
94647,square_okhttp,ConnectionSpecSelectorTest.retryableSSLHandshakeException,"  @Test
  public void retryableSSLHandshakeException() throws Exception {
    ConnectionSpecSelector connectionSpecSelector =
        createConnectionSpecSelector(ConnectionSpec.MODERN_TLS, ConnectionSpec.COMPATIBLE_TLS);
    SSLSocket socket = createSocketWithEnabledProtocols(TlsVersion.TLS_1_1, TlsVersion.TLS_1_0);
    connectionSpecSelector.configureSecureSocket(socket);

    boolean retry = connectionSpecSelector.connectionFailed(RETRYABLE_EXCEPTION);
    assertTrue(retry);
    socket.close();
  }
",non-flaky,5
94648,square_okhttp,ConnectionSpecSelectorTest.someFallbacksSupported,"  @Test
  public void someFallbacksSupported() throws Exception {
    ConnectionSpec sslV3 =
        new ConnectionSpec.Builder(ConnectionSpec.MODERN_TLS)
            .tlsVersions(TlsVersion.SSL_3_0)
            .build();

    ConnectionSpecSelector connectionSpecSelector = createConnectionSpecSelector(
        ConnectionSpec.MODERN_TLS, ConnectionSpec.COMPATIBLE_TLS, sslV3);

    TlsVersion[] enabledSocketTlsVersions = {TlsVersion.TLS_1_1, TlsVersion.TLS_1_0};
    SSLSocket socket = createSocketWithEnabledProtocols(enabledSocketTlsVersions);

    // MODERN_TLS is used here.
    connectionSpecSelector.configureSecureSocket(socket);
    assertEnabledProtocols(socket, TlsVersion.TLS_1_1, TlsVersion.TLS_1_0);

    boolean retry = connectionSpecSelector.connectionFailed(RETRYABLE_EXCEPTION);
    assertTrue(retry);
    socket.close();

    // COMPATIBLE_TLS is used here.
    socket = createSocketWithEnabledProtocols(enabledSocketTlsVersions);
    connectionSpecSelector.configureSecureSocket(socket);
    assertEnabledProtocols(socket, TlsVersion.TLS_1_0);

    retry = connectionSpecSelector.connectionFailed(RETRYABLE_EXCEPTION);
    assertFalse(retry);
    socket.close();

    // sslV3 is not used because SSLv3 is not enabled on the socket.
  }
",non-flaky,5
94649,square_okhttp,RouteSelectorTest.select,"  @Test public void proxySelectorReturnsNull() throws Exception {
      @Override public List<Proxy> select(URI uri) {
        assertEquals(uriHost, uri.getHost());
        return null;
      }
",non-flaky,5
94650,square_okhttp,RelayTest.call,"  @Test public void racingReaders() throws Exception {
      @Override public ByteString call() throws Exception {
        Buffer buffer = new Buffer();
        while (source.read(buffer, 16384) != -1) {
        }
        source.close();
        return buffer.readByteString();
      }
",non-flaky,5
94651,square_okhttp,Jdk9PlatformTest.buildsWhenJdk9,"  @Test
  public void buildsWhenJdk9() {
    assumeTrue(getPlatform().equals(""jdk9""));

    assertNotNull(Jdk9Platform.buildIfSupported());
  }
",non-flaky,5
94652,square_okhttp,Jdk9PlatformTest.findsAlpnMethods,"  @Test
  public void findsAlpnMethods() {
    assumeTrue(getPlatform().equals(""jdk9""));

    Jdk9Platform platform = Jdk9Platform.buildIfSupported();

    assertEquals(""getApplicationProtocol"", platform.getProtocolMethod.getName());
    assertEquals(""setApplicationProtocols"", platform.setProtocolMethod.getName());
  }
",non-flaky,5
94653,square_okhttp,JdkWithJettyBootPlatformTest.testBuildsWithJettyBoot,"  @Test
  public void testBuildsWithJettyBoot() {
    assumeTrue(getPlatform().equals(""jdk-with-jetty-boot""));

    assertNotNull(JdkWithJettyBootPlatform.buildIfSupported());
  }
",non-flaky,5
94654,square_okhttp,OptionalMethodTest.isSupported,"  @Test
  public void isSupported() throws Exception {
    {
      BaseClass base = new BaseClass();
      assertTrue(STRING_METHOD_RETURNS_ANY.isSupported(base));
      assertTrue(STRING_METHOD_RETURNS_STRING.isSupported(base));
      assertFalse(STRING_METHOD_RETURNS_INT.isSupported(base));
      assertTrue(VOID_METHOD_RETURNS_ANY.isSupported(base));
      assertTrue(VOID_METHOD_RETURNS_VOID.isSupported(base));
      assertFalse(SUBCLASS_METHOD_RETURNS_ANY.isSupported(base));
      assertFalse(SUBCLASS_METHOD_RETURNS_STRING.isSupported(base));
      assertFalse(SUBCLASS_METHOD_RETURNS_INT.isSupported(base));
      assertFalse(METHOD_WITH_ARGS_WRONG_PARAMS.isSupported(base));
      assertFalse(METHOD_WITH_ARGS_CORRECT_PARAMS.isSupported(base));
    }
    {
      SubClass1 subClass1 = new SubClass1();
      assertTrue(STRING_METHOD_RETURNS_ANY.isSupported(subClass1));
      assertTrue(STRING_METHOD_RETURNS_STRING.isSupported(subClass1));
      assertFalse(STRING_METHOD_RETURNS_INT.isSupported(subClass1));
      assertTrue(VOID_METHOD_RETURNS_ANY.isSupported(subClass1));
      assertTrue(VOID_METHOD_RETURNS_VOID.isSupported(subClass1));
      assertTrue(SUBCLASS_METHOD_RETURNS_ANY.isSupported(subClass1));
      assertTrue(SUBCLASS_METHOD_RETURNS_STRING.isSupported(subClass1));
      assertFalse(SUBCLASS_METHOD_RETURNS_INT.isSupported(subClass1));
      assertFalse(METHOD_WITH_ARGS_WRONG_PARAMS.isSupported(subClass1));
      assertTrue(METHOD_WITH_ARGS_CORRECT_PARAMS.isSupported(subClass1));
    }
    {
      SubClass2 subClass2 = new SubClass2();
      assertTrue(STRING_METHOD_RETURNS_ANY.isSupported(subClass2));
      assertTrue(STRING_METHOD_RETURNS_STRING.isSupported(subClass2));
      assertFalse(STRING_METHOD_RETURNS_INT.isSupported(subClass2));
      assertTrue(VOID_METHOD_RETURNS_ANY.isSupported(subClass2));
      assertTrue(VOID_METHOD_RETURNS_VOID.isSupported(subClass2));
      assertTrue(SUBCLASS_METHOD_RETURNS_ANY.isSupported(subClass2));
      assertFalse(SUBCLASS_METHOD_RETURNS_STRING.isSupported(subClass2));
      assertTrue(SUBCLASS_METHOD_RETURNS_INT.isSupported(subClass2));
      assertFalse(METHOD_WITH_ARGS_WRONG_PARAMS.isSupported(subClass2));
      assertTrue(METHOD_WITH_ARGS_CORRECT_PARAMS.isSupported(subClass2));
    }
  }
",non-flaky,5
94655,square_okhttp,OptionalMethodTest.invoke,"  @Test
  public void invoke() throws Exception {
    {
      BaseClass base = new BaseClass();
      assertEquals(""string"", STRING_METHOD_RETURNS_STRING.invoke(base));
      assertEquals(""string"", STRING_METHOD_RETURNS_ANY.invoke(base));
      assertErrorOnInvoke(STRING_METHOD_RETURNS_INT, base);
      assertNull(VOID_METHOD_RETURNS_ANY.invoke(base));
      assertNull(VOID_METHOD_RETURNS_VOID.invoke(base));
      assertErrorOnInvoke(SUBCLASS_METHOD_RETURNS_ANY, base);
      assertErrorOnInvoke(SUBCLASS_METHOD_RETURNS_STRING, base);
      assertErrorOnInvoke(SUBCLASS_METHOD_RETURNS_INT, base);
      assertErrorOnInvoke(METHOD_WITH_ARGS_WRONG_PARAMS, base);
      assertErrorOnInvoke(METHOD_WITH_ARGS_CORRECT_PARAMS, base);
    }
    {
      SubClass1 subClass1 = new SubClass1();
      assertEquals(""string"", STRING_METHOD_RETURNS_STRING.invoke(subClass1));
      assertEquals(""string"", STRING_METHOD_RETURNS_ANY.invoke(subClass1));
      assertErrorOnInvoke(STRING_METHOD_RETURNS_INT, subClass1);
      assertNull(VOID_METHOD_RETURNS_ANY.invoke(subClass1));
      assertNull(VOID_METHOD_RETURNS_VOID.invoke(subClass1));
      assertEquals(""subclassMethod1"", SUBCLASS_METHOD_RETURNS_ANY.invoke(subClass1));
      assertEquals(""subclassMethod1"", SUBCLASS_METHOD_RETURNS_STRING.invoke(subClass1));
      assertErrorOnInvoke(SUBCLASS_METHOD_RETURNS_INT, subClass1);
      assertErrorOnInvoke(METHOD_WITH_ARGS_WRONG_PARAMS, subClass1);
      assertEquals(""arg"", METHOD_WITH_ARGS_CORRECT_PARAMS.invoke(subClass1, ""arg""));
    }

    {
      SubClass2 subClass2 = new SubClass2();
      assertEquals(""string"", STRING_METHOD_RETURNS_STRING.invoke(subClass2));
      assertEquals(""string"", STRING_METHOD_RETURNS_ANY.invoke(subClass2));
      assertErrorOnInvoke(STRING_METHOD_RETURNS_INT, subClass2);
      assertNull(VOID_METHOD_RETURNS_ANY.invoke(subClass2));
      assertNull(VOID_METHOD_RETURNS_VOID.invoke(subClass2));
      assertEquals(1234, SUBCLASS_METHOD_RETURNS_ANY.invoke(subClass2));
      assertErrorOnInvoke(SUBCLASS_METHOD_RETURNS_STRING, subClass2);
      assertEquals(1234, SUBCLASS_METHOD_RETURNS_INT.invoke(subClass2));
      assertErrorOnInvoke(METHOD_WITH_ARGS_WRONG_PARAMS, subClass2);
      assertEquals(""arg"", METHOD_WITH_ARGS_CORRECT_PARAMS.invoke(subClass2, ""arg""));
    }
  }
",non-flaky,5
94656,square_okhttp,OptionalMethodTest.invokeBadArgs,"  @Test
  public void invokeBadArgs() throws Exception {
    SubClass1 subClass1 = new SubClass1();
    assertIllegalArgumentExceptionOnInvoke(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1); // no args
    assertIllegalArgumentExceptionOnInvoke(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1, 123);
    assertIllegalArgumentExceptionOnInvoke(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1, true);
    assertIllegalArgumentExceptionOnInvoke(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1,
        new Object());
    assertIllegalArgumentExceptionOnInvoke(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1, ""one"",
        ""two"");
  }
",non-flaky,5
94657,square_okhttp,OptionalMethodTest.invokeWithException,"  @Test
  public void invokeWithException() throws Exception {
    SubClass2 subClass2 = new SubClass2();
    try {
      THROWS_EXCEPTION.invoke(subClass2);
    } catch (InvocationTargetException expected) {
      assertTrue(expected.getTargetException() instanceof IOException);
    }

    try {
      THROWS_RUNTIME_EXCEPTION.invoke(subClass2);
    } catch (InvocationTargetException expected) {
      assertTrue(expected.getTargetException() instanceof NumberFormatException);
    }
  }
",non-flaky,5
94658,square_okhttp,OptionalMethodTest.invokeNonPublic,"  @Test
  public void invokeNonPublic() throws Exception {
    SubClass2 subClass2 = new SubClass2();
    assertFalse(NON_PUBLIC.isSupported(subClass2));
    assertErrorOnInvoke(NON_PUBLIC, subClass2);
  }
",non-flaky,5
94659,square_okhttp,OptionalMethodTest.invokeOptional,"  @Test
  public void invokeOptional() throws Exception {
    {
      BaseClass base = new BaseClass();
      assertEquals(""string"", STRING_METHOD_RETURNS_STRING.invokeOptional(base));
      assertEquals(""string"", STRING_METHOD_RETURNS_ANY.invokeOptional(base));
      assertNull(STRING_METHOD_RETURNS_INT.invokeOptional(base));
      assertNull(VOID_METHOD_RETURNS_ANY.invokeOptional(base));
      assertNull(VOID_METHOD_RETURNS_VOID.invokeOptional(base));
      assertNull(SUBCLASS_METHOD_RETURNS_ANY.invokeOptional(base));
      assertNull(SUBCLASS_METHOD_RETURNS_STRING.invokeOptional(base));
      assertNull(SUBCLASS_METHOD_RETURNS_INT.invokeOptional(base));
      assertNull(METHOD_WITH_ARGS_WRONG_PARAMS.invokeOptional(base));
      assertNull(METHOD_WITH_ARGS_CORRECT_PARAMS.invokeOptional(base));
    }
    {
      SubClass1 subClass1 = new SubClass1();
      assertEquals(""string"", STRING_METHOD_RETURNS_STRING.invokeOptional(subClass1));
      assertEquals(""string"", STRING_METHOD_RETURNS_ANY.invokeOptional(subClass1));
      assertNull(STRING_METHOD_RETURNS_INT.invokeOptional(subClass1));
      assertNull(VOID_METHOD_RETURNS_ANY.invokeOptional(subClass1));
      assertNull(VOID_METHOD_RETURNS_VOID.invokeOptional(subClass1));
      assertEquals(""subclassMethod1"", SUBCLASS_METHOD_RETURNS_ANY.invokeOptional(subClass1));
      assertEquals(""subclassMethod1"", SUBCLASS_METHOD_RETURNS_STRING.invokeOptional(subClass1));
      assertNull(SUBCLASS_METHOD_RETURNS_INT.invokeOptional(subClass1));
      assertNull(METHOD_WITH_ARGS_WRONG_PARAMS.invokeOptional(subClass1));
      assertEquals(""arg"", METHOD_WITH_ARGS_CORRECT_PARAMS.invokeOptional(subClass1, ""arg""));
    }

    {
      SubClass2 subClass2 = new SubClass2();
      assertEquals(""string"", STRING_METHOD_RETURNS_STRING.invokeOptional(subClass2));
      assertEquals(""string"", STRING_METHOD_RETURNS_ANY.invokeOptional(subClass2));
      assertNull(STRING_METHOD_RETURNS_INT.invokeOptional(subClass2));
      assertNull(VOID_METHOD_RETURNS_ANY.invokeOptional(subClass2));
      assertNull(VOID_METHOD_RETURNS_VOID.invokeOptional(subClass2));
      assertEquals(1234, SUBCLASS_METHOD_RETURNS_ANY.invokeOptional(subClass2));
      assertNull(SUBCLASS_METHOD_RETURNS_STRING.invokeOptional(subClass2));
      assertEquals(1234, SUBCLASS_METHOD_RETURNS_INT.invokeOptional(subClass2));
      assertNull(METHOD_WITH_ARGS_WRONG_PARAMS.invokeOptional(subClass2));
      assertEquals(""arg"", METHOD_WITH_ARGS_CORRECT_PARAMS.invokeOptional(subClass2, ""arg""));
    }
  }
",non-flaky,5
94660,square_okhttp,OptionalMethodTest.invokeOptionalBadArgs,"  @Test
  public void invokeOptionalBadArgs() throws Exception {
    SubClass1 subClass1 = new SubClass1();
    assertIllegalArgumentExceptionOnInvokeOptional(METHOD_WITH_ARGS_CORRECT_PARAMS,
        subClass1); // no args
    assertIllegalArgumentExceptionOnInvokeOptional(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1, 123);
    assertIllegalArgumentExceptionOnInvokeOptional(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1,
        true);
    assertIllegalArgumentExceptionOnInvokeOptional(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1,
        new Object());
    assertIllegalArgumentExceptionOnInvokeOptional(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1,
        ""one"", ""two"");
  }
",non-flaky,5
94661,square_okhttp,OptionalMethodTest.invokeOptionalWithException,"  @Test
  public void invokeOptionalWithException() throws Exception {
    SubClass2 subClass2 = new SubClass2();
    try {
      THROWS_EXCEPTION.invokeOptional(subClass2);
    } catch (InvocationTargetException expected) {
      assertTrue(expected.getTargetException() instanceof IOException);
    }

    try {
      THROWS_RUNTIME_EXCEPTION.invokeOptional(subClass2);
    } catch (InvocationTargetException expected) {
      assertTrue(expected.getTargetException() instanceof NumberFormatException);
    }
  }
",non-flaky,5
94662,square_okhttp,OptionalMethodTest.invokeOptionalNonPublic,"  @Test
  public void invokeOptionalNonPublic() throws Exception {
    SubClass2 subClass2 = new SubClass2();
    assertFalse(NON_PUBLIC.isSupported(subClass2));
    assertErrorOnInvokeOptional(NON_PUBLIC, subClass2);
  }
",non-flaky,5
94663,square_okhttp,Http2Test.headers,"  @Test public void onlyOneLiteralHeadersFrame() throws IOException {
      @Override public void headers(boolean inFinished, int streamId,
          int associatedStreamId, List<Header> headerBlock) {
        assertTrue(inFinished);
        assertEquals(expectedStreamId, streamId);
        assertEquals(-1, associatedStreamId);
        assertEquals(sentHeaders, headerBlock);
      }
",non-flaky,5
94664,square_okhttp,Http2Test.priority,"  @Test public void headersWithPriority() throws IOException {
      @Override public void priority(int streamId, int streamDependency, int weight,
          boolean exclusive) {
        assertEquals(0, streamDependency);
        assertEquals(256, weight);
        assertFalse(exclusive);
      }
",non-flaky,5
94665,square_okhttp,Http2Test.headers,"  @Test public void headersFrameThenContinuation() throws IOException {
      @Override public void headers(boolean inFinished, int streamId,
          int associatedStreamId, List<Header> headerBlock) {
        assertFalse(inFinished);
        assertEquals(expectedStreamId, streamId);
        assertEquals(-1, associatedStreamId);
        assertEquals(sentHeaders, headerBlock);
      }
",non-flaky,5
94666,square_okhttp,Http2Test.pushPromise,"  @Test public void pushPromise() throws IOException {
      public void pushPromise(int streamId, int promisedStreamId, List<Header> headerBlock) {
        assertEquals(expectedStreamId, streamId);
        assertEquals(expectedPromisedStreamId, promisedStreamId);
        assertEquals(pushPromise, headerBlock);
      }
",non-flaky,5
94667,square_okhttp,Http2Test.pushPromise,"  @Test public void pushPromiseThenContinuation() throws IOException {
      public void pushPromise(int streamId, int promisedStreamId, List<Header> headerBlock) {
        assertEquals(expectedStreamId, streamId);
        assertEquals(expectedPromisedStreamId, promisedStreamId);
        assertEquals(pushPromise, headerBlock);
      }
",non-flaky,5
94668,square_okhttp,Http2Test.rstStream,"  @Test public void readRstStreamFrame() throws IOException {
      @Override public void rstStream(int streamId, ErrorCode errorCode) {
        assertEquals(expectedStreamId, streamId);
        assertEquals(ErrorCode.PROTOCOL_ERROR, errorCode);
      }
",non-flaky,5
94669,square_okhttp,Http2Test.settings,"  @Test public void readSettingsFrame() throws IOException {
      @Override public void settings(boolean clearPrevious, Settings settings) {
        assertFalse(clearPrevious); // No clearPrevious in HTTP/2.
        assertEquals(reducedTableSizeBytes, settings.getHeaderTableSize());
        assertEquals(false, settings.getEnablePush(true));
      }
",non-flaky,5
94670,square_okhttp,Http2Test.settings,"  @Test public void readSettingsFrameUnknownSettingId() throws IOException {
      @Override public void settings(boolean clearPrevious, Settings settings) {
        settingValue.set(settings.get(7));
      }
",non-flaky,5
94671,square_okhttp,Http2Test.ping,"  @Test public void pingRoundTrip() throws IOException {
      @Override public void ping(boolean ack, int payload1, int payload2) {
        assertTrue(ack);
        assertEquals(expectedPayload1, payload1);
        assertEquals(expectedPayload2, payload2);
      }
",non-flaky,5
94672,square_okhttp,Http2Test.data,"  @Test public void maxLengthDataFrame() throws IOException {
      @Override public void data(boolean inFinished, int streamId, BufferedSource source,
          int length) throws IOException {
        assertFalse(inFinished);
        assertEquals(expectedStreamId, streamId);
        assertEquals(Http2.INITIAL_MAX_FRAME_SIZE, length);
        ByteString data = source.readByteString(length);
        for (byte b : data.toByteArray()) {
          assertEquals(2, b);
        }
      }
",non-flaky,5
94673,square_okhttp,Http2Test.windowUpdate,"  @Test public void windowUpdateRoundTrip() throws IOException {
      @Override public void windowUpdate(int streamId, long windowSizeIncrement) {
        assertEquals(expectedStreamId, streamId);
        assertEquals(expectedWindowSizeIncrement, windowSizeIncrement);
      }
",non-flaky,5
94674,square_okhttp,Http2Test.goAway,"  @Test public void goAwayWithoutDebugDataRoundTrip() throws IOException {
      @Override public void goAway(
          int lastGoodStreamId, ErrorCode errorCode, ByteString debugData) {
        assertEquals(expectedStreamId, lastGoodStreamId);
        assertEquals(expectedError, errorCode);
        assertEquals(0, debugData.size());
      }
",non-flaky,5
94675,square_okhttp,Http2Test.goAway,"  @Test public void goAwayWithDebugDataRoundTrip() throws IOException {
      @Override public void goAway(
          int lastGoodStreamId, ErrorCode errorCode, ByteString debugData) {
        assertEquals(0, lastGoodStreamId);
        assertEquals(expectedError, errorCode);
        assertEquals(expectedData, debugData);
      }
",non-flaky,5
94676,square_okhttp,Http2Test.headers,"  @Test public void streamIdHasReservedBit() throws IOException {
      @Override public void headers(boolean inFinished, int streamId,
          int associatedStreamId, List<Header> headerBlock) {
        assertFalse(inFinished);
        assertEquals(expectedStreamId, streamId);
        assertEquals(-1, associatedStreamId);
        assertEquals(headerEntries(""foo"", ""barrr"", ""baz"", ""qux""), headerBlock);
      }
",non-flaky,5
94677,square_okhttp,Http2ConnectionTest.onStream,"  @Test public void serverSendsSettingsToClient() throws Exception {
      @Override public void onStream(Http2Stream stream) throws IOException {
        throw new AssertionError();
      }
",non-flaky,5
94678,square_okhttp,Http2ConnectionTest.onRequest,"  @Test public void blockedStreamDoesntStarveNewStream() throws Exception {
    @Override public boolean onRequest(int streamId, List<Header> requestHeaders) {
      return false;
    }
",non-flaky,5
94679,square_okhttp,DisconnectTest.run,"  @Test public void interruptReadingResponseBody() throws Exception {
      @Override public void run() {
        try {
          sleep(delayMillis);
          connection.disconnect();
        } catch (InterruptedException e) {
          throw new RuntimeException(e);
        }
      }
",non-flaky,5
94680,square_okhttp,ThreadInterruptTest.run,"  @Test public void interruptReadingResponseBody() throws Exception {
      @Override public void run() {
        try {
          sleep(delayMillis);
          toInterrupt.interrupt();
        } catch (InterruptedException e) {
          throw new RuntimeException(e);
        }
      }
",non-flaky,5
94681,square_okhttp,ClientAuthTest.buildClient,"  @Test public void invalidClientAuthFails() throws Throwable {
  public OkHttpClient buildClient(HeldCertificate cert, HeldCertificate... chain) {
    SslClient.Builder sslClientBuilder = new SslClient.Builder()
        .addTrustedCertificate(serverRootCa.certificate);

    if (cert != null) {
      sslClientBuilder.certificateChain(cert, chain);
    }

    SslClient sslClient = sslClientBuilder.build();
    return new OkHttpClient.Builder()
        .sslSocketFactory(sslClient.socketFactory, sslClient.trustManager)
        .build();
  }
",non-flaky,5
94682,square_okhttp,DiskLruCacheTest.writeFile,"  @Test public void abortAfterDetach() throws Exception {
  public void writeFile(File file, String content) throws Exception {
    BufferedSink sink = Okio.buffer(fileSystem.sink(file));
    sink.writeUtf8(content);
    sink.close();
  }
",non-flaky,5
94683,square_okhttp,HttpResponseCacheTest.get,"  @Test public void getInstalledWithWrongTypeInstalled() {
      public CacheResponse get(URI uri, String requestMethod,
          Map<String, List<String>> requestHeaders) {
        return null;
      }
",non-flaky,5
94684,square_okhttp,CacheAdapterTest.get,"  @Test public void get_httpGet() throws Exception {
      @Override public CacheResponse get(
          URI uri, String method, Map<String, List<String>> headers) throws IOException {
        try {
          assertEquals(toUri(serverUrl), uri);
          assertEquals(""GET"", method);
          assertTrue(""Arbitrary standard header not present"", headers.containsKey(""User-Agent""));
          assertEquals(Collections.singletonList(""value1""), headers.get(""key1""));
          return null;
        } catch (Throwable t) {
          throw new IOException(""unexpected cache failure"", t);
        }
      }
",non-flaky,5
94685,square_okhttp,CacheAdapterTest.get,"  @Test public void get_httpsGet() throws Exception {
      @Override public CacheResponse get(URI uri, String method, Map<String, List<String>> headers)
          throws IOException {
        try {
          assertEquals(""https"", uri.getScheme());
          assertEquals(toUri(serverUrl), uri);
          assertEquals(""GET"", method);
          assertTrue(""Arbitrary standard header not present"", headers.containsKey(""User-Agent""));
          assertEquals(Collections.singletonList(""value1""), headers.get(""key1""));
          return null;
        } catch (Throwable t) {
          throw new IOException(""unexpected cache failure"", t);
        }
      }
",non-flaky,5
94686,square_okhttp,CacheAdapterTest.put,"  @Test public void put_httpGet() throws Exception {
      @Override public CacheRequest put(URI uri, URLConnection connection) throws IOException {
        try {
          assertTrue(connection instanceof HttpURLConnection);
          assertFalse(connection instanceof HttpsURLConnection);

          assertEquals(response.length, connection.getContentLength());

          HttpURLConnection httpUrlConnection = (HttpURLConnection) connection;
          assertEquals(""GET"", httpUrlConnection.getRequestMethod());
          assertTrue(httpUrlConnection.getDoInput());
          assertFalse(httpUrlConnection.getDoOutput());

          assertEquals(""Fantastic"", httpUrlConnection.getResponseMessage());
          assertEquals(toUri(serverUrl), uri);
          assertEquals(serverUrl, connection.getURL());
          assertEquals(""value"", connection.getRequestProperty(""key""));

          // Check retrieval by string key.
          assertEquals(statusLine, httpUrlConnection.getHeaderField(null));
          assertEquals(""c"", httpUrlConnection.getHeaderField(""A""));
          // The RI and OkHttp supports case-insensitive matching for this method.
          assertEquals(""c"", httpUrlConnection.getHeaderField(""a""));
          return null;
        } catch (Throwable t) {
          throw new IOException(""unexpected cache failure"", t);
        }
      }
",non-flaky,5
94687,square_okhttp,CacheAdapterTest.put,"  @Test public void put_httpPost() throws Exception {
      @Override public CacheRequest put(URI uri, URLConnection connection) throws IOException {
        try {
          assertTrue(connection instanceof HttpURLConnection);
          assertFalse(connection instanceof HttpsURLConnection);

          assertEquals(0, connection.getContentLength());

          HttpURLConnection httpUrlConnection = (HttpURLConnection) connection;
          assertEquals(""POST"", httpUrlConnection.getRequestMethod());
          assertTrue(httpUrlConnection.getDoInput());
          assertTrue(httpUrlConnection.getDoOutput());

          assertEquals(""Fantastic"", httpUrlConnection.getResponseMessage());
          assertEquals(toUri(serverUrl), uri);
          assertEquals(serverUrl, connection.getURL());
          assertEquals(""value"", connection.getRequestProperty(""key""));

          // Check retrieval by string key.
          assertEquals(statusLine, httpUrlConnection.getHeaderField(null));
          assertEquals(""c"", httpUrlConnection.getHeaderField(""A""));
          // The RI and OkHttp supports case-insensitive matching for this method.
          assertEquals(""c"", httpUrlConnection.getHeaderField(""a""));
          return null;
        } catch (Throwable t) {
          throw new IOException(""unexpected cache failure"", t);
        }
      }
",non-flaky,5
94688,square_okhttp,CacheAdapterTest.put,"  @Test public void put_httpsGet() throws Exception {
      @Override public CacheRequest put(URI uri, URLConnection connection) throws IOException {
        try {
          assertTrue(connection instanceof HttpsURLConnection);
          assertEquals(toUri(serverUrl), uri);
          assertEquals(serverUrl, connection.getURL());

          HttpsURLConnection cacheHttpsUrlConnection = (HttpsURLConnection) connection;
          HttpsURLConnection realHttpsUrlConnection =
              (HttpsURLConnection) CacheAdapterTest.this.connection;
          assertEquals(realHttpsUrlConnection.getCipherSuite(),
              cacheHttpsUrlConnection.getCipherSuite());
          assertEquals(realHttpsUrlConnection.getPeerPrincipal(),
              cacheHttpsUrlConnection.getPeerPrincipal());
          assertArrayEquals(realHttpsUrlConnection.getLocalCertificates(),
              cacheHttpsUrlConnection.getLocalCertificates());
          assertArrayEquals(realHttpsUrlConnection.getServerCertificates(),
              cacheHttpsUrlConnection.getServerCertificates());
          assertEquals(realHttpsUrlConnection.getLocalPrincipal(),
              cacheHttpsUrlConnection.getLocalPrincipal());
          return null;
        } catch (Throwable t) {
          throw new IOException(""unexpected cache failure"", t);
        }
      }
",non-flaky,5
94689,square_okhttp,ResponseCacheTest.assertCookies,"  @Test public void getHeadersRetainsCached200LevelWarnings() throws Exception {
  public void assertCookies(URL url, String... expectedCookies) throws Exception {
    List<String> actualCookies = new ArrayList<>();
    for (HttpCookie cookie : cookieManager.getCookieStore().get(url.toURI())) {
      actualCookies.add(cookie.toString());
    }
    assertEquals(Arrays.asList(expectedCookies), actualCookies);
  }
",non-flaky,5
94690,square_okhttp,ResponseCacheTest.gzip,"  @Test public void emptyResponseHeaderNameFromCacheIsLenient() throws Exception {
  public Buffer gzip(String data) throws IOException {
    Buffer result = new Buffer();
    BufferedSink sink = Okio.buffer(new GzipSink(result));
    sink.writeUtf8(data);
    sink.close();
    return result;
  }
",non-flaky,5
94691,square_okhttp,ResponseCacheTest.put,"  @Test public void responseCacheCallbackApis() throws Exception {
      @Override public CacheRequest put(URI uri, URLConnection connection) throws IOException {
        HttpURLConnection httpURLConnection = (HttpURLConnection) connection;
        assertEquals(server.url(""/"").url(), uri.toURL());
        assertEquals(200, httpURLConnection.getResponseCode());
        InputStream is = httpURLConnection.getInputStream();
        try {
          is.read();
          fail();
        } catch (UnsupportedOperationException expected) {
        }
        assertEquals(""5"", connection.getHeaderField(""Content-Length""));
        assertEquals(""text/plain"", connection.getHeaderField(""Content-Type""));
        assertEquals(""ijk"", connection.getHeaderField(""fgh""));
        cacheCount.incrementAndGet();
        return null;
      }
",non-flaky,5
94692,square_okhttp,ResponseCacheTest.abort,"  @Test public void responseCacheReturnsNullOutputStream() throws Exception {
      @Override public CacheRequest put(URI uri, URLConnection connection) {
        return new CacheRequest() {
          @Override public void abort() {
            aborted.set(true);
          }
",non-flaky,5
94693,square_okhttp,ResponseCacheTest.get,"  @Test public void responseCacheReturnsNullStatusLine() throws Exception {
      public CacheResponse get(URI uri, String requestMethod,
          Map<String, List<String>> requestHeaders)
",non-flaky,5
94694,square_okhttp,ResponseCacheTest.get,"  @Test public void responseCacheRequestHeaders() throws IOException, URISyntaxException {
      @Override public CacheResponse get(URI uri, String requestMethod,
          Map<String, List<String>> requestHeaders) throws IOException {
        requestHeadersRef.set(requestHeaders);
        return null;
      }
",non-flaky,5
94695,square_okhttp,JavaApiConverterTest.getBody,"  @Test public void createOkResponseForCacheGet() throws Exception {
      @Override public InputStream getBody() throws IOException {
        return new ByteArrayInputStream(""HelloWorld"".getBytes(StandardCharsets.UTF_8));
      }
",non-flaky,5
94696,square_okhttp,JavaApiConverterTest.getBody,"  @Test public void createOkResponseForCacheGet_withMissingStatusLine() throws Exception {
      @Override public InputStream getBody() throws IOException {
        return null; // Should never be called
      }
",non-flaky,5
94697,square_okhttp,JavaApiConverterTest.getBody,"  @Test public void createOkResponseForCacheGet_secure() throws Exception {
      @Override public InputStream getBody() throws IOException {
        return new ByteArrayInputStream(""HelloWorld"".getBytes(StandardCharsets.UTF_8));
      }
",non-flaky,5
94698,square_okhttp,JavaApiConverterTest.contentType,"  @Test public void extractStatusLine() throws Exception {
      @Override public MediaType contentType() {
        return MediaType.parse(""text/plain; charset=utf-8"");
      }
",non-flaky,5
94699,square_okhttp,RealWebSocketTest.contentType,"  @Test public void streamingMessage() throws IOException {
      @Override public MediaType contentType() {
        return TEXT;
      }
",non-flaky,5
94700,square_okhttp,RealWebSocketTest.contentType,"  @Test public void streamingMessageCanInterleavePing() throws IOException, InterruptedException {
      @Override public MediaType contentType() {
        return TEXT;
      }
",non-flaky,5
146,Alluxio_alluxio,FileSystemMasterIntegrationTest.lastModificationTimeAddCheckpointTest,"@Test
public void lastModificationTimeAddCheckpointTest() throws Exception {
    long fileId = mFsMaster.create(new TachyonURI(""/testFile""), CreateOptions.defaults());
    long opTimeMs = System.currentTimeMillis();
    mFsMaster.persistFileInternal(fileId, 1, opTimeMs);
    FileInfo fileInfo = mFsMaster.getFileInfo(fileId);
    Assert.assertEquals(opTimeMs, fileInfo.lastModificationTimeMs);
}",time,2
225,Alluxio_alluxio,BlockMasterJournalIntegrationTest.journalBlockDeletion,"@Test
public void journalBlockDeletion() throws Exception {
    FileSystem fs = mCluster.getClient();
    BlockMaster blockMaster = mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class);
    AlluxioURI file = new AlluxioURI(""/test"");
    FileSystemTestUtils.createByteFile(fs, file, MUST_CACHE, 10);
    URIStatus status = fs.getStatus(file);
    Long blockId = status.getBlockIds().get(0);
    assertNotNull(blockMaster.getBlockInfo(blockId));
    fs.delete(file);
    WorkerNetAddress workerAddress = mCluster.getWorkerAddress();
    try {
        blockMaster.getBlockInfo(blockId);
        fail(""Expected the block to be deleted"");
    } catch (BlockInfoException e) {
    }
    mCluster.stopMasters();
    mCluster.startMasters();
    AlluxioMasterProcess masterProcess = mCluster.getLocalAlluxioMaster().getMasterProcess();
    try {
        masterProcess.getMaster(BlockMaster.class).getBlockInfo(blockId);
        fail(""Expected the block to be deleted after restart"");
    } catch (BlockInfoException e) {
    }
}",async wait,0
292,Alluxio_alluxio,journalBlockCreation,"@Test
public void journalBlockCreation() throws Exception {
    FileSystem fs = mCluster.getClient();
    BlockMaster blockMaster =
    mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class);
    AlluxioURI file = new AlluxioURI(""/test"");
    FileSystemTestUtils.createByteFile(fs, file, WritePType.MUST_CACHE, 10);
    URIStatus status = fs.getStatus(file);
    Long blockId = status.getBlockIds().get(0);
    assertNotNull(blockMaster.getBlockInfo(blockId));
    mCluster.stopMasters();
    mCluster.startMasters();
    AlluxioMasterProcess masterProcess = mCluster.getLocalAlluxioMaster().getMasterProcess();
    assertNotNull(masterProcess.getMaster(BlockMaster.class).getBlockInfo(blockId));
}",async wait,0
106573,Alluxio_alluxio,UfsOperationsTest.ufsContractTest,"  @Test
  public void ufsContractTest() throws Exception {
    File ufsPath = mFolder.newFolder(""ufsContractTest"");

    try {
      UnderFileSystemContractTest
          .main(new String[] {""--path"", ""file://"" + ufsPath.getAbsolutePath()});
    } catch (Throwable e) {
      fail(""UFS contract failed: "" + e.getMessage());
    }
  }
",non-flaky,5
106574,Alluxio_alluxio,HdfsVersionValidationTaskTest.versionNotMatchedDefault,"  @Test
  public void versionNotMatchedDefault() throws Exception {
    PowerMockito.mockStatic(ShellUtils.class);
    String[] cmd = new String[]{""hadoop"", ""version""};
    BDDMockito.given(ShellUtils.execCommand(cmd)).willReturn(""Hadoop 2.2"");

    HdfsVersionValidationTask task = new HdfsVersionValidationTask(sConf);
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());
    assertEquals(ValidationUtils.State.FAILED, result.getState());
    assertThat(result.getResult(), containsString(""2.2 does not match alluxio.underfs.version""));
    assertThat(result.getAdvice(), containsString(""configure alluxio.underfs.version""));
  }
",non-flaky,5
106575,Alluxio_alluxio,HdfsVersionValidationTaskTest.versionNotMatched,"  @Test
  public void versionNotMatched() throws Exception {
    PowerMockito.mockStatic(ShellUtils.class);
    String[] cmd = new String[]{""hadoop"", ""version""};
    BDDMockito.given(ShellUtils.execCommand(cmd)).willReturn(""Hadoop 2.7"");
    sConf.set(PropertyKey.UNDERFS_VERSION, ""2.6"");

    HdfsVersionValidationTask task = new HdfsVersionValidationTask(sConf);
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());
    assertEquals(ValidationUtils.State.FAILED, result.getState());
    assertThat(result.getResult(), containsString(
            ""2.7 does not match alluxio.underfs.version=2.6""));
    assertThat(result.getAdvice(), containsString(""configure alluxio.underfs.version""));
  }
",non-flaky,5
106576,Alluxio_alluxio,HdfsVersionValidationTaskTest.versionMatched,"  @Test
  public void versionMatched() throws Exception {
    PowerMockito.mockStatic(ShellUtils.class);
    String[] cmd = new String[]{""hadoop"", ""version""};
    BDDMockito.given(ShellUtils.execCommand(cmd)).willReturn(""Hadoop 2.6"");
    sConf.set(PropertyKey.UNDERFS_VERSION, ""2.6"");

    HdfsVersionValidationTask task = new HdfsVersionValidationTask(sConf);
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());
    assertEquals(ValidationUtils.State.OK, result.getState());
  }
",non-flaky,5
106577,Alluxio_alluxio,HdfsVersionValidationTaskTest.minorVersionAccepted,"  @Test
  public void minorVersionAccepted() throws Exception {
    PowerMockito.mockStatic(ShellUtils.class);
    String[] cmd = new String[]{""hadoop"", ""version""};
    // The minor version is not defined in Alluxio, which should work
    BDDMockito.given(ShellUtils.execCommand(cmd)).willReturn(""Hadoop 2.6.2"");
    sConf.set(PropertyKey.UNDERFS_VERSION, ""2.6"");

    HdfsVersionValidationTask task = new HdfsVersionValidationTask(sConf);
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());
    assertEquals(ValidationUtils.State.OK, result.getState());
  }
",non-flaky,5
106578,Alluxio_alluxio,HdfsVersionValidationTaskTest.minorVersionConflict,"  @Test
  public void minorVersionConflict() throws Exception {
    PowerMockito.mockStatic(ShellUtils.class);
    String[] cmd = new String[]{""hadoop"", ""version""};
    // Alluxio defines a different minor version, which should not work
    BDDMockito.given(ShellUtils.execCommand(cmd)).willReturn(""Hadoop 2.6.2"");
    sConf.set(PropertyKey.UNDERFS_VERSION, ""2.6.3"");

    HdfsVersionValidationTask task = new HdfsVersionValidationTask(sConf);
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());
    assertEquals(ValidationUtils.State.FAILED, result.getState());
    assertThat(result.getResult(), containsString(
            ""Hadoop version 2.6.2 does not match alluxio.underfs.version=2.6.3""));
  }
",non-flaky,5
106579,Alluxio_alluxio,HdfsVersionValidationTaskTest.versionParsing,"  @Test
  public void versionParsing() {
    String versionStr = ""Hadoop 2.7.2\n""
            + ""Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git ""
            + ""-r b165c4fe8a74265c792ce23f546c64604acf0e41\n""
            + ""Compiled by jenkins on 2016-01-26T00:08Z\n""
            + ""Compiled with protoc 2.5.0\n""
            + ""From source with checksum d0fda26633fa762bff87ec759ebe689c\n""
            + ""This command was run using ""
            + ""/tmp/hadoop/share/hadoop/common/hadoop-common-2.7.2.jar"";

    HdfsVersionValidationTask task = new HdfsVersionValidationTask(sConf);
    String version = task.parseVersion(versionStr);
    assertEquals(""2.7.2"", version);
  }
",non-flaky,5
106580,Alluxio_alluxio,HdfsVersionValidationTaskTest.cdhVersionParsing,"  @Test
  public void cdhVersionParsing() {
    String versionStr = ""Hadoop 2.6.0-cdh5.16.2\n""
            + ""Subversion http://github.com/cloudera/hadoop -r ""
            + ""4f94d60caa4cbb9af0709a2fd96dc3861af9cf20\n""
            + ""Compiled by jenkins on 2019-06-03T10:41Z\n""
            + ""Compiled with protoc 2.5.0\n""
            + ""From source with checksum 79b9b24a29c6358b53597c3b49575e37\n""
            + ""This command was run using /usr/lib/hadoop/hadoop-common-2.6.0-cdh5.16.2.jar"";

    HdfsVersionValidationTask task = new HdfsVersionValidationTask(sConf);
    String version = task.parseVersion(versionStr);
    assertEquals(""cdh5.16.2"", version);
  }
",non-flaky,5
106581,Alluxio_alluxio,HdfsConfValidationTaskTest.loadedConf,"  @Test
  public void loadedConf() {
    String hdfsSite = Paths.get(sTestDir.toPath().toString(), ""hdfs-site.xml"").toString();
    ValidationTestUtils.writeXML(hdfsSite, ImmutableMap.of(""key2"", ""value2""));

    String coreSite = Paths.get(sTestDir.toPath().toString(), ""core-site.xml"").toString();
    ValidationTestUtils.writeXML(coreSite, ImmutableMap.of(""key1"", ""value1""));

    sConf.set(PropertyKey.UNDERFS_HDFS_CONFIGURATION,
            hdfsSite + HdfsConfValidationTask.SEPARATOR + coreSite);
    HdfsConfValidationTask task =
            new HdfsConfValidationTask(""hdfs://namenode:9000/alluxio"", sConf);
    ValidationTaskResult result = task.loadHdfsConfig();
    assertEquals(result.getState(), ValidationUtils.State.OK);
  }
",non-flaky,5
106582,Alluxio_alluxio,HdfsConfValidationTaskTest.missingCoreSiteXML,"  @Test
  public void missingCoreSiteXML() {
    // Only prepare hdfs-site.xml
    String hdfsSite = Paths.get(sTestDir.toPath().toString(), ""hdfs-site.xml"").toString();
    ValidationTestUtils.writeXML(hdfsSite, ImmutableMap.of(""key1"", ""value1""));

    sConf.set(PropertyKey.UNDERFS_HDFS_CONFIGURATION, hdfsSite);
    HdfsConfValidationTask task = new HdfsConfValidationTask(""hdfs://namenode:9000/alluxio"", sConf);
    ValidationTaskResult result = task.loadHdfsConfig();
    assertEquals(result.getState(), ValidationUtils.State.SKIPPED);
    assertThat(result.getResult(), containsString(""core-site.xml is not configured""));
    assertThat(result.getAdvice(), containsString(""core-site.xml""));
  }
",non-flaky,5
106583,Alluxio_alluxio,HdfsConfValidationTaskTest.missingHdfsSiteXML,"  @Test
  public void missingHdfsSiteXML() {
    // Only prepare core-site.xml
    String coreSite = Paths.get(sTestDir.toPath().toString(), ""core-site.xml"").toString();
    ValidationTestUtils.writeXML(coreSite, ImmutableMap.of(""key1"", ""value1""));

    sConf.set(PropertyKey.UNDERFS_HDFS_CONFIGURATION, coreSite);
    HdfsConfValidationTask task = new HdfsConfValidationTask(""hdfs://namenode:9000/alluxio"", sConf);
    ValidationTaskResult result = task.loadHdfsConfig();
    assertEquals(result.getState(), ValidationUtils.State.SKIPPED);
    assertThat(result.getResult(), containsString(""hdfs-site.xml is not configured""));
    assertThat(result.getAdvice(), containsString(""hdfs-site.xml""));
  }
",non-flaky,5
106584,Alluxio_alluxio,HdfsConfValidationTaskTest.missingBoth,"  @Test
  public void missingBoth() {
    sConf.set(PropertyKey.UNDERFS_HDFS_CONFIGURATION, ""/conf/"");
    HdfsConfValidationTask task = new HdfsConfValidationTask(""hdfs://namenode:9000/alluxio"", sConf);
    ValidationTaskResult result = task.loadHdfsConfig();
    assertEquals(result.getState(), ValidationUtils.State.SKIPPED);
    assertThat(result.getResult(), containsString(""hdfs-site.xml is not configured""));
    assertThat(result.getResult(), containsString(""core-site.xml is not configured""));
    assertThat(result.getAdvice(), containsString(""hdfs-site.xml""));
    assertThat(result.getAdvice(), containsString(""core-site.xml""));
  }
",non-flaky,5
106585,Alluxio_alluxio,HdfsConfValidationTaskTest.cannotParseCoreSiteXml,"  @Test
  public void cannotParseCoreSiteXml() throws IOException {
    String hdfsSite = Paths.get(sTestDir.toPath().toString(), ""hdfs-site.xml"").toString();
    ValidationTestUtils.writeXML(hdfsSite, ImmutableMap.of(""key2"", ""value2""));
    RandomAccessFile hdfsFile = new RandomAccessFile(hdfsSite, ""rw"");
    hdfsFile.setLength(hdfsFile.length() - 10);

    String coreSite = Paths.get(sTestDir.toPath().toString(), ""core-site.xml"").toString();
    ValidationTestUtils.writeXML(coreSite, ImmutableMap.of(""key1"", ""value1""));
    RandomAccessFile coreFile = new RandomAccessFile(coreSite, ""rw"");
    coreFile.setLength(coreFile.length() - 10);

    sConf.set(PropertyKey.UNDERFS_HDFS_CONFIGURATION,
            hdfsSite + HdfsConfValidationTask.SEPARATOR + coreSite);
    HdfsConfValidationTask task =
            new HdfsConfValidationTask(""hdfs://namenode:9000/alluxio"", sConf);
    ValidationTaskResult result = task.loadHdfsConfig();
    assertEquals(ValidationUtils.State.FAILED, result.getState());
    assertThat(result.getResult(),
        containsString(String.format(""Failed to parse %s"", hdfsSite)));
    assertThat(result.getResult(), containsString(String.format(""Failed to parse %s"", coreSite)));
    assertThat(result.getAdvice(), containsString(String.format(""Failed to parse %s"", hdfsSite)));
    assertThat(result.getAdvice(), containsString(String.format(""Failed to parse %s"", coreSite)));
  }
",non-flaky,5
106586,Alluxio_alluxio,HdfsConfValidationTaskTest.inconsistentConf,"  @Test
  public void inconsistentConf() {
    String hdfsSite = Paths.get(sTestDir.toPath().toString(), ""hdfs-site.xml"").toString();
    ValidationTestUtils.writeXML(hdfsSite, ImmutableMap.of(""key1"", ""value2""));

    String coreSite = Paths.get(sTestDir.toPath().toString(), ""core-site.xml"").toString();
    ValidationTestUtils.writeXML(coreSite, ImmutableMap.of(""key1"", ""value1""));

    sConf.set(PropertyKey.UNDERFS_HDFS_CONFIGURATION,
            hdfsSite + HdfsConfValidationTask.SEPARATOR + coreSite);
    HdfsConfValidationTask task =
            new HdfsConfValidationTask(""hdfs://namenode:9000/alluxio"", sConf);
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());

    assertEquals(ValidationUtils.State.FAILED, result.getState());
    assertThat(result.getResult(), containsString(""key1""));
    assertThat(result.getResult(), containsString(""value1 in core-site.xml""));
    assertThat(result.getResult(), containsString(""value2 in hdfs-site.xml""));
    assertThat(result.getAdvice(), containsString(""fix the inconsistency""));
  }
",non-flaky,5
106587,Alluxio_alluxio,HdfsConfValidationTaskTest.validConf,"  @Test
  public void validConf() {
    String hdfsSite = Paths.get(sTestDir.toPath().toString(), ""hdfs-site.xml"").toString();
    ValidationTestUtils.writeXML(hdfsSite, ImmutableMap.of(""key1"", ""value1"", ""key3"", ""value3""));

    String coreSite = Paths.get(sTestDir.toPath().toString(), ""core-site.xml"").toString();
    ValidationTestUtils.writeXML(coreSite, ImmutableMap.of(""key1"", ""value1"", ""key4"", ""value4""));

    sConf.set(PropertyKey.UNDERFS_HDFS_CONFIGURATION,
            hdfsSite + HdfsConfValidationTask.SEPARATOR + coreSite);
    HdfsConfValidationTask task =
            new HdfsConfValidationTask(""hdfs://namenode:9000/alluxio"", sConf);
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());

    assertEquals(ValidationUtils.State.OK, result.getState());
  }
",non-flaky,5
106588,Alluxio_alluxio,HdfsProxyUserValidationTaskTest.skipped,"  @Test
  public void skipped() {
    mConf.set(PropertyKey.SECURITY_AUTHENTICATION_TYPE, AuthType.NOSASL.getAuthName());
    HdfsProxyUserValidationTask task =
            new HdfsProxyUserValidationTask(""hdfs://namenode:9000/alluxio"", mConf);
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());
    assertEquals(ValidationUtils.State.SKIPPED, result.getState());
  }
",non-flaky,5
106589,Alluxio_alluxio,HdfsProxyUserValidationTaskTest.missingProxyUser,"  @Test
  public void missingProxyUser() {
    String userName = System.getProperty(""user.name"");

    // No proxy user definition in core-site.xml
    prepareHdfsConfFiles(ImmutableMap.of(""key1"", ""value1""));

    HdfsProxyUserValidationTask task =
            new HdfsProxyUserValidationTask(""hdfs://namenode:9000/alluxio"", mConf);
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());
    assertEquals(ValidationUtils.State.FAILED, result.getState());
    assertThat(result.getResult(), containsString(
            ""Alluxio is not able to perform impersonation.""));
    assertThat(result.getAdvice(), containsString(
            String.format(""Please enable Alluxio user %s to impersonate"", userName)));
  }
",non-flaky,5
106590,Alluxio_alluxio,HdfsProxyUserValidationTaskTest.proxyUserNotWildcard,"  @Test
  public void proxyUserNotWildcard() {
    String userName = System.getProperty(""user.name"");

    // Configured proxy users and groups, but not wildcard
    String proxyUserKey = String.format(""hadoop.proxyuser.%s.users"", userName);
    String proxyGroupKey = String.format(""hadoop.proxyuser.%s.groups"", userName);
    prepareHdfsConfFiles(ImmutableMap.of(proxyUserKey, ""user1,user2"", proxyGroupKey, ""groups""));

    HdfsProxyUserValidationTask task =
            new HdfsProxyUserValidationTask(""hdfs://namenode:9000/alluxio"", mConf);
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());
    assertEquals(ValidationUtils.State.WARNING, result.getState());
    assertThat(result.getResult(), containsString(
            String.format(""%s=user1,user2 and %s=groups"", proxyUserKey, proxyGroupKey)));
    assertThat(result.getAdvice(), containsString(
            ""Please make sure that includes all users/groups Alluxio needs to impersonate as.""));
  }
",non-flaky,5
106591,Alluxio_alluxio,HdfsProxyUserValidationTaskTest.proxyUsersAndGroupsAllMissing,"  @Test
  public void proxyUsersAndGroupsAllMissing() {
    String userName = System.getProperty(""user.name"");

    // Proxyuser configured for bob, not the running user
    prepareHdfsConfFiles(ImmutableMap.of(""hadoop.proxyuser.bob.users"", ""user1,user3"",
            ""hadoop.proxyuser.bob.groups"", ""*""));

    HdfsProxyUserValidationTask task =
            new HdfsProxyUserValidationTask(""hdfs://namenode:9000/alluxio"", mConf);
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());
    assertEquals(ValidationUtils.State.FAILED, result.getState());
    assertThat(result.getResult(), containsString(
            ""Alluxio is not able to perform impersonation.""));
    assertThat(result.getAdvice(), containsString(
            String.format(""Please enable Alluxio user %s to impersonate"", userName)));
  }
",non-flaky,5
106592,Alluxio_alluxio,HdfsProxyUserValidationTaskTest.wildcardProxyUsers,"  @Test
  public void wildcardProxyUsers() {
    String userName = System.getProperty(""user.name"");

    // Proxy users configured but not groups
    prepareHdfsConfFiles(ImmutableMap.of(
            String.format(""hadoop.proxyuser.%s.users"", userName), ""*""));

    HdfsProxyUserValidationTask task =
            new HdfsProxyUserValidationTask(""hdfs://namenode:9000/alluxio"", mConf);
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());
    assertEquals(ValidationUtils.State.OK, result.getState());
  }
",non-flaky,5
106593,Alluxio_alluxio,HdfsProxyUserValidationTaskTest.wildcardProxyGroups,"  @Test
  public void wildcardProxyGroups() {
    String userName = System.getProperty(""user.name"");

    // Proxy groups configured but not users
    prepareHdfsConfFiles(ImmutableMap.of(
            String.format(""hadoop.proxyuser.%s.groups"", userName), ""*""));

    HdfsProxyUserValidationTask task =
            new HdfsProxyUserValidationTask(""hdfs://namenode:9000/alluxio"", mConf);
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());
    assertEquals(ValidationUtils.State.OK, result.getState());
  }
",non-flaky,5
106594,Alluxio_alluxio,NativeLibValidationTaskTest.nativeLibPresent,"  @Test
  public void nativeLibPresent() throws Exception {
    File testLibDir = ValidationTestUtils.createTemporaryDirectory();
    String testLibPath = testLibDir.getPath();

    String libPath = testLibPath;
    System.setProperty(NativeLibValidationTask.NATIVE_LIB_PATH, libPath);

    NativeLibValidationTask task = new NativeLibValidationTask();
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());
    assertEquals(ValidationUtils.State.OK, result.getState());
  }
",non-flaky,5
106595,Alluxio_alluxio,NativeLibValidationTaskTest.nativeLibMissing,"  @Test
  public void nativeLibMissing() throws Exception {
    String libPath = ""/usr/missing"";
    System.setProperty(NativeLibValidationTask.NATIVE_LIB_PATH, libPath);

    NativeLibValidationTask task = new NativeLibValidationTask();
    ValidationTaskResult result = task.validateImpl(ImmutableMap.of());
    assertEquals(ValidationUtils.State.WARNING, result.getState());
    assertThat(result.getResult(), containsString(""Java native lib not found at /usr/missing""));
    assertThat(result.getAdvice(), containsString(""Please check your path /usr/missing""));
  }
",non-flaky,5
106596,Alluxio_alluxio,ContainerAllocatorTest.oneContainerPerHostFullAllocation,"  @Test(timeout = 10000)
  public void oneContainerPerHostFullAllocation() throws Exception {
    int numHosts = 10;
    int maxContainersPerHost = 1;
    testFullAllocation(numHosts, maxContainersPerHost);
  }
",non-flaky,5
106597,Alluxio_alluxio,ContainerAllocatorTest.fiveContainersPerHostFullAllocation,"  @Test(timeout = 10000)
  public void fiveContainersPerHostFullAllocation() throws Exception {
    int numHosts = 10;
    int maxContainersPerHost = 5;
    testFullAllocation(numHosts, maxContainersPerHost);
  }
",non-flaky,5
106598,Alluxio_alluxio,ContainerAllocatorTest.fiveContainersPerHostHalfAllocation,"  @Test(timeout = 10000)
  public void fiveContainersPerHostHalfAllocation() throws Exception {
    int numHosts = 10;
    int maxContainersPerHost = 5;
    int numContainers = numHosts * maxContainersPerHost / 2;
    ContainerAllocator containerAllocator =
        setup(numHosts, maxContainersPerHost, numContainers);
    List<Container> containers = containerAllocator.allocateContainers();

    assertEquals(numContainers, containers.size());
    checkMaxHostsLimitNotExceeded(containers, maxContainersPerHost);
  }
",non-flaky,5
106599,Alluxio_alluxio,ContainerAllocatorTest.notEnoughHosts,"  @Test(timeout = 10000)
  public void notEnoughHosts() throws Exception {
    int numHosts = 10;
    int maxContainersPerHost = 5;
    int numContainers = numHosts * maxContainersPerHost + 1; // one container too many
    ContainerAllocator containerAllocator =
        setup(numHosts, maxContainersPerHost, numContainers);
    mThrown.expect(RuntimeException.class);
    mThrown.expectMessage(
        ExceptionMessage.YARN_NOT_ENOUGH_HOSTS.getMessage(numContainers, CONTAINER_NAME, numHosts));
    containerAllocator.allocateContainers();
  }
",non-flaky,5
106600,Alluxio_alluxio,ContainerAllocatorTest.allocateMasterInAnyHost,"  @Test(timeout = 1000)
  public void allocateMasterInAnyHost() throws Exception {
    ContainerAllocator containerAllocator = new ContainerAllocator(CONTAINER_NAME, 1,
        1, mResource, mYarnClient, mRMClient, ""any"");
    doAnswer(allocateFirstHostAnswer(containerAllocator))
        .when(mRMClient).addContainerRequest(Matchers.argThat(request -> {
          if (request.getRelaxLocality() == true
              && request.getNodes().size() == 1
              && request.getNodes().get(0).equals(""any"")) {
            return true;
          }
          return false;
        }));
    containerAllocator.allocateContainers();
  }
",non-flaky,5
106601,Alluxio_alluxio,ClientTest.notEnoughMemoryForApplicationMaster,"  @Test
  public void notEnoughMemoryForApplicationMaster() throws Exception {
    int appMasterMem = 1024;
    Resource resource = Resource.newInstance(appMasterMem / 2, 4);
    generateMaxAllocation(resource);
    mThrown.expect(RuntimeException.class);
    mThrown.expectMessage(ExceptionMessage.YARN_NOT_ENOUGH_RESOURCES.getMessage(
        ""ApplicationMaster"", ""memory"", appMasterMem, resource.getMemory()));
    String[] args = new String[] {
        ""-resource_path"", ""test"",
        ""-am_memory"", Integer.toString(appMasterMem),
        ""-am_vcores"", ""2""
    };
    Client client = new Client(args, mConf);
    client.run();
  }
",non-flaky,5
106602,Alluxio_alluxio,ClientTest.notEnoughVCoreForApplicationMaster,"  @Test
  public void notEnoughVCoreForApplicationMaster() throws Exception {
    int appMasterMem = 1024;
    int appMasterCore = 2;
    Resource resource = Resource.newInstance(appMasterMem, appMasterCore / 2);
    generateMaxAllocation(resource);
    mThrown.expect(RuntimeException.class);
    mThrown.expectMessage(ExceptionMessage.YARN_NOT_ENOUGH_RESOURCES.getMessage(
        ""ApplicationMaster"", ""virtual cores"", appMasterCore, resource.getVirtualCores()));
    String[] args = new String[] {
        ""-resource_path"", ""test"",
        ""-am_memory"", Integer.toString(appMasterMem),
        ""-am_vcores"", Integer.toString(appMasterCore)
    };
    Client client = new Client(args, mConf);
    client.run();
  }
",non-flaky,5
106603,Alluxio_alluxio,ClientTest.notEnoughMemoryForAlluxioMaster,"  @Test
  public void notEnoughMemoryForAlluxioMaster() throws Exception {
    mConf.set(PropertyKey.INTEGRATION_MASTER_RESOURCE_MEM, ""2048.00MB"");
    mConf.set(PropertyKey.INTEGRATION_MASTER_RESOURCE_CPU, ""4"");
    int masterMemInMB = (int) (mConf.getBytes(
        PropertyKey.INTEGRATION_MASTER_RESOURCE_MEM) / Constants.MB);
    Resource resource = Resource.newInstance(masterMemInMB / 2, 4);
    generateMaxAllocation(resource);
    mThrown.expect(RuntimeException.class);
    mThrown.expectMessage(ExceptionMessage.YARN_NOT_ENOUGH_RESOURCES.getMessage(
        ""Alluxio Master"", ""memory"", masterMemInMB, resource.getMemory()));
    Client client = new Client(mConf);
    client.run();
  }
",non-flaky,5
106604,Alluxio_alluxio,ClientTest.notEnoughVCoreForAlluxioMaster,"  @Test
  public void notEnoughVCoreForAlluxioMaster() throws Exception {
    mConf.set(PropertyKey.INTEGRATION_MASTER_RESOURCE_MEM, ""2048.00MB"");
    mConf.set(PropertyKey.INTEGRATION_MASTER_RESOURCE_CPU, ""4"");
    int masterMemInMB = (int) (mConf.getBytes(
        PropertyKey.INTEGRATION_MASTER_RESOURCE_MEM) / Constants.MB);
    int masterVCores = mConf.getInt(PropertyKey.INTEGRATION_MASTER_RESOURCE_CPU);
    Resource resource = Resource.newInstance(masterMemInMB, 3);
    generateMaxAllocation(resource);
    mThrown.expect(RuntimeException.class);
    mThrown.expectMessage(ExceptionMessage.YARN_NOT_ENOUGH_RESOURCES.getMessage(
        ""Alluxio Master"", ""virtual cores"", masterVCores, resource.getVirtualCores()));
    Client client = new Client(mConf);
    client.run();
  }
",non-flaky,5
106605,Alluxio_alluxio,ClientTest.notEnoughMemoryForAlluxioWorker,"  @Test
  public void notEnoughMemoryForAlluxioWorker() throws Exception {
    mConf.set(PropertyKey.INTEGRATION_WORKER_RESOURCE_MEM, ""2048.00MB"");
    mConf.set(PropertyKey.WORKER_RAMDISK_SIZE, ""4096.00MB"");
    mConf.set(PropertyKey.INTEGRATION_WORKER_RESOURCE_CPU, ""8"");
    int workerMemInMB = (int) (mConf.getBytes(
        PropertyKey.INTEGRATION_WORKER_RESOURCE_MEM) / Constants.MB);
    int ramdiskMemInMB = (int) (mConf.getBytes(
        PropertyKey.WORKER_RAMDISK_SIZE) / Constants.MB);
    Resource resource = Resource.newInstance((workerMemInMB + ramdiskMemInMB) / 2, 4);
    generateMaxAllocation(resource);
    mThrown.expect(RuntimeException.class);
    mThrown.expectMessage(ExceptionMessage.YARN_NOT_ENOUGH_RESOURCES.getMessage(
        ""Alluxio Worker"", ""memory"", (workerMemInMB + ramdiskMemInMB), resource.getMemory()));
    Client client = new Client(mConf);
    client.run();
  }
",non-flaky,5
106606,Alluxio_alluxio,ClientTest.notEnoughVCoreForAlluxioWorker,"  @Test
  public void notEnoughVCoreForAlluxioWorker() throws Exception {
    mConf.set(PropertyKey.INTEGRATION_WORKER_RESOURCE_MEM, ""2048.00MB"");
    mConf.set(PropertyKey.WORKER_RAMDISK_SIZE, ""4096.00MB"");
    mConf.set(PropertyKey.INTEGRATION_WORKER_RESOURCE_CPU, ""8"");
    int workerMemInMB = (int) (mConf.getBytes(
        PropertyKey.INTEGRATION_WORKER_RESOURCE_MEM) / Constants.MB);
    int ramdiskMemInMB = (int) (mConf.getBytes(
        PropertyKey.WORKER_RAMDISK_SIZE) / Constants.MB);
    int workerVCore = mConf.getInt(PropertyKey.INTEGRATION_WORKER_RESOURCE_CPU);
    Resource resource = Resource.newInstance((workerMemInMB + ramdiskMemInMB), 4);
    generateMaxAllocation(resource);
    mThrown.expect(RuntimeException.class);
    mThrown.expectMessage(ExceptionMessage.YARN_NOT_ENOUGH_RESOURCES.getMessage(
        ""Alluxio Worker"", ""virtual cores"", workerVCore, resource.getVirtualCores()));
    Client client = new Client(mConf);
    client.run();
  }
",non-flaky,5
106607,Alluxio_alluxio,StatvfsTest.offset,"  @Test
  public void offset() {
    Statvfs jni = Statvfs.of(ByteBuffer.allocate(256));
    ru.serce.jnrfuse.struct.Statvfs jnr =
        ru.serce.jnrfuse.struct.Statvfs.of(Pointer.wrap(Runtime.getSystemRuntime(), 0x0));

    assertEquals(jnr.f_bsize.offset(), jni.f_bsize.offset());
    assertEquals(jnr.f_frsize.offset(), jni.f_frsize.offset());
    assertEquals(jnr.f_frsize.offset(), jni.f_frsize.offset());
    assertEquals(jnr.f_bfree.offset(), jni.f_bfree.offset());
    assertEquals(jnr.f_bavail.offset(), jni.f_bavail.offset());
    assertEquals(jnr.f_files.offset(), jni.f_files.offset());
    assertEquals(jnr.f_ffree.offset(), jni.f_ffree.offset());
    assertEquals(jnr.f_favail.offset(), jni.f_favail.offset());
    assertEquals(jnr.f_fsid.offset(), jni.f_fsid.offset());
    assertEquals(jnr.f_flag.offset(), jni.f_flag.offset());
    assertEquals(jnr.f_namemax.offset(), jni.f_namemax.offset());
  }
",non-flaky,5
106608,Alluxio_alluxio,FileStatTest.offset,"  @Test
  public void offset() {
    // allocate an enough large memory for jnistat
    FileStat jnistat = FileStat.of(ByteBuffer.allocate(256));
    ru.serce.jnrfuse.struct.FileStat jnrstat =
        new ru.serce.jnrfuse.struct.FileStat(Runtime.getSystemRuntime());

    assertEquals(jnrstat.st_dev.offset(), jnistat.st_dev.offset());
    assertEquals(jnrstat.st_ino.offset(), jnistat.st_ino.offset());
    assertEquals(jnrstat.st_nlink.offset(), jnistat.st_nlink.offset());
    assertEquals(jnrstat.st_mode.offset(), jnistat.st_mode.offset());
    assertEquals(jnrstat.st_uid.offset(), jnistat.st_uid.offset());
    assertEquals(jnrstat.st_gid.offset(), jnistat.st_gid.offset());
    assertEquals(jnrstat.st_rdev.offset(), jnistat.st_rdev.offset());
    assertEquals(jnrstat.st_size.offset(), jnistat.st_size.offset());
    assertEquals(jnrstat.st_blksize.offset(), jnistat.st_blksize.offset());
    assertEquals(jnrstat.st_blocks.offset(), jnistat.st_blocks.offset());
    assertEquals(jnrstat.st_atim.tv_sec.offset(), jnistat.st_atim.tv_sec.offset());
    assertEquals(jnrstat.st_atim.tv_nsec.offset(), jnistat.st_atim.tv_nsec.offset());
    assertEquals(jnrstat.st_mtim.tv_sec.offset(), jnistat.st_mtim.tv_sec.offset());
    assertEquals(jnrstat.st_mtim.tv_nsec.offset(), jnistat.st_mtim.tv_nsec.offset());
    assertEquals(jnrstat.st_ctim.tv_sec.offset(), jnistat.st_ctim.tv_sec.offset());
    assertEquals(jnrstat.st_ctim.tv_nsec.offset(), jnistat.st_ctim.tv_nsec.offset());
  }
",non-flaky,5
106609,Alluxio_alluxio,FileStatTest.dataConsistency,"  @Test
  public void dataConsistency() {
    FileStat stat = FileStat.of(ByteBuffer.allocateDirect(256));
    int mode = FileStat.ALL_READ | FileStat.ALL_WRITE | FileStat.S_IFDIR;
    long size = 0x123456789888721L;
    stat.st_mode.set(mode);
    stat.st_size.set(size);
    assertEquals(mode, stat.st_mode.intValue());
    assertEquals(size, stat.st_size.longValue());

    ByteBuffer buf = stat.getBuffer();
    assertEquals(mode, buf.getShort((int) stat.st_mode.offset()));
    assertEquals(size, buf.getLong((int) stat.st_size.offset()));
  }
",non-flaky,5
106610,Alluxio_alluxio,FuseFileInfoTest.offset,"  @Test
  public void offset() {
    FuseFileInfo jnifi = FuseFileInfo.of(ByteBuffer.allocate(256));
    ru.serce.jnrfuse.struct.FuseFileInfo jnrfi =
        ru.serce.jnrfuse.struct.FuseFileInfo.of(Pointer.wrap(Runtime.getSystemRuntime(), 0x0));
    assertEquals(jnrfi.flags.offset(), jnifi.flags.offset());
    assertEquals(jnrfi.fh.offset(), jnifi.fh.offset());
  }
",non-flaky,5
106611,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.chmod,"  @Test
  public void chmod() throws Exception {
    long mode = 123;
    mFuseFs.chmod(""/foo/bar"", mode);
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    SetAttributePOptions options =
        SetAttributePOptions.newBuilder().setMode(new Mode((short) mode).toProto()).build();
    verify(mFileSystem).setAttribute(expectedPath, options);
  }
",non-flaky,5
106612,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.chown,"  @Test
  public void chown() throws Exception {
    long uid = AlluxioFuseUtils.getUid(System.getProperty(""user.name""));
    long gid = AlluxioFuseUtils.getGid(System.getProperty(""user.name""));
    mFuseFs.chown(""/foo/bar"", uid, gid);
    String userName = System.getProperty(""user.name"");
    String groupName = AlluxioFuseUtils.getGroupName(gid);
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    SetAttributePOptions options =
        SetAttributePOptions.newBuilder().setGroup(groupName).setOwner(userName).build();
    verify(mFileSystem).setAttribute(expectedPath, options);
  }
",non-flaky,5
106613,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.chownWithoutValidGid,"  @Test
  public void chownWithoutValidGid() throws Exception {
    long uid = AlluxioFuseUtils.getUid(System.getProperty(""user.name""));
    long gid = AlluxioJniFuseFileSystem.ID_NOT_SET_VALUE;
    mFuseFs.chown(""/foo/bar"", uid, gid);
    String userName = System.getProperty(""user.name"");
    String groupName = AlluxioFuseUtils.getGroupName(userName);
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    SetAttributePOptions options =
        SetAttributePOptions.newBuilder().setGroup(groupName).setOwner(userName).build();
    verify(mFileSystem).setAttribute(expectedPath, options);

    gid = AlluxioJniFuseFileSystem.ID_NOT_SET_VALUE_UNSIGNED;
    mFuseFs.chown(""/foo/bar"", uid, gid);
    verify(mFileSystem, times(2)).setAttribute(expectedPath, options);
  }
",non-flaky,5
106614,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.chownWithoutValidUid,"  @Test
  public void chownWithoutValidUid() throws Exception {
    String userName = System.getProperty(""user.name"");
    long uid = AlluxioJniFuseFileSystem.ID_NOT_SET_VALUE;
    long gid = AlluxioFuseUtils.getGid(userName);
    mFuseFs.chown(""/foo/bar"", uid, gid);

    String groupName = AlluxioFuseUtils.getGroupName(userName);
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    SetAttributePOptions options = SetAttributePOptions.newBuilder().setGroup(groupName).build();
    verify(mFileSystem).setAttribute(expectedPath, options);

    uid = AlluxioJniFuseFileSystem.ID_NOT_SET_VALUE_UNSIGNED;
    mFuseFs.chown(""/foo/bar"", uid, gid);
    verify(mFileSystem, times(2)).setAttribute(expectedPath, options);
  }
",non-flaky,5
106615,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.chownWithoutValidUidAndGid,"  @Test
  public void chownWithoutValidUidAndGid() throws Exception {
    long uid = AlluxioJniFuseFileSystem.ID_NOT_SET_VALUE;
    long gid = AlluxioJniFuseFileSystem.ID_NOT_SET_VALUE;
    mFuseFs.chown(""/foo/bar"", uid, gid);
    verify(mFileSystem, never()).setAttribute(any());

    uid = AlluxioJniFuseFileSystem.ID_NOT_SET_VALUE_UNSIGNED;
    gid = AlluxioJniFuseFileSystem.ID_NOT_SET_VALUE_UNSIGNED;
    mFuseFs.chown(""/foo/bar"", uid, gid);
    verify(mFileSystem, never()).setAttribute(any());
  }
",non-flaky,5
106616,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.create,"  @Test
  public void create() throws Exception {
    mFileInfo.flags.set(O_WRONLY.intValue());
    mFuseFs.create(""/foo/bar"", 0, mFileInfo);
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    verify(mFileSystem).createFile(expectedPath, CreateFilePOptions.newBuilder()
        .setMode(new alluxio.security.authorization.Mode((short) 0).toProto())
        .build());
  }
",non-flaky,5
106617,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.createWithLengthLimit,"  @Test
  public void createWithLengthLimit() throws Exception {
    String c256 = String.join("""", Collections.nCopies(16, ""0123456789ABCDEF""));
    mFileInfo.flags.set(O_WRONLY.intValue());
    assertEquals(-ErrorCodes.ENAMETOOLONG(),
        mFuseFs.create(""/foo/"" + c256, 0, mFileInfo));
  }
",non-flaky,5
106618,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.flush,"  @Test
  public void flush() throws Exception {
    FileOutStream fos = mock(FileOutStream.class);
    AlluxioURI anyURI = any();
    CreateFilePOptions options = any();
    when(mFileSystem.createFile(anyURI, options)).thenReturn(fos);

    // open a file
    mFileInfo.flags.set(O_WRONLY.intValue());
    mFuseFs.create(""/foo/bar"", 0, mFileInfo);

    // then call flush into it
    mFuseFs.flush(""/foo/bar"", mFileInfo);
    verify(fos).flush();
  }
",non-flaky,5
106619,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.getattr,"  @Test
  public void getattr() throws Exception {
    // set up status
    FileInfo info = new FileInfo();
    info.setLength(4 * Constants.KB + 1);
    info.setLastModificationTimeMs(1000);
    String userName = System.getProperty(""user.name"");
    info.setOwner(userName);
    info.setGroup(AlluxioFuseUtils.getGroupName(userName));
    info.setFolder(true);
    info.setMode(123);
    info.setCompleted(true);
    URIStatus status = new URIStatus(info);

    // mock fs
    when(mFileSystem.getStatus(any(AlluxioURI.class))).thenReturn(status);

    FileStat stat = FileStat.of(ByteBuffer.allocateDirect(256));
    assertEquals(0, mFuseFs.getattr(""/foo"", stat));
    assertEquals(status.getLength(), stat.st_size.longValue());
    assertEquals(9, stat.st_blocks.intValue());
    assertEquals(status.getLastModificationTimeMs() / 1000, stat.st_ctim.tv_sec.get());
    assertEquals((status.getLastModificationTimeMs() % 1000) * 1000,
        stat.st_ctim.tv_nsec.longValue());
    assertEquals(status.getLastModificationTimeMs() / 1000, stat.st_mtim.tv_sec.get());
    assertEquals((status.getLastModificationTimeMs() % 1000) * 1000,
        stat.st_mtim.tv_nsec.longValue());
    assertEquals(AlluxioFuseUtils.getUid(System.getProperty(""user.name"")), stat.st_uid.get());
    assertEquals(AlluxioFuseUtils.getGid(System.getProperty(""user.name"")), stat.st_gid.get());
    assertEquals(123 | FileStat.S_IFDIR, stat.st_mode.intValue());
  }
",non-flaky,5
106620,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.getattrWithDelay,"  @Test
  public void getattrWithDelay() throws Exception {
    String path = ""/foo/bar"";
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");

    // set up status
    FileInfo info = new FileInfo();
    info.setLength(0);
    info.setCompleted(false);
    URIStatus status = new URIStatus(info);

    // mock fs
    when(mFileSystem.getStatus(any(AlluxioURI.class))).thenReturn(status);

    FileStat stat = FileStat.of(ByteBuffer.allocateDirect(256));

    // Use another thread to open file so that
    // we could change the file status when opening it
    Thread t = new Thread(() -> mFuseFs.getattr(path, stat));
    t.start();
    Thread.sleep(1000);

    // If the file is not being written and is not completed,
    // we will wait for the file to complete
    verify(mFileSystem, atLeast(10)).getStatus(expectedPath);
    assertEquals(0, stat.st_size.longValue());

    info.setCompleted(true);
    info.setLength(1000);

    t.join();

    assertEquals(1000, stat.st_size.longValue());
  }
",non-flaky,5
106621,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.getattrWhenWriting,"  @Test
  public void getattrWhenWriting() throws Exception {
    String path = ""/foo/bar"";
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(path);

    FileOutStream fos = mock(FileOutStream.class);
    when(mFileSystem.createFile(expectedPath)).thenReturn(fos);

    mFuseFs.create(path, 0, mFileInfo);

    // Prepare file status
    FileInfo info = new FileInfo();
    info.setLength(0);
    info.setCompleted(false);
    URIStatus status = new URIStatus(info);

    when(mFileSystem.exists(any(AlluxioURI.class))).thenReturn(true);
    when(mFileSystem.getStatus(any(AlluxioURI.class))).thenReturn(status);

    FileStat stat = FileStat.of(ByteBuffer.allocateDirect(256));

    // getattr() will not be blocked when writing
    mFuseFs.getattr(path, stat);
    // If getattr() is blocking, it will continuously get status of the file
    verify(mFileSystem, atMost(300)).getStatus(expectedPath);
    assertEquals(0, stat.st_size.longValue());

    mFuseFs.release(path, mFileInfo);

    // getattr() will be blocked waiting for the file to be completed
    // If release() is called (returned) but does not finished
    Thread t = new Thread(() -> mFuseFs.getattr(path, stat));
    t.start();
    Thread.sleep(1000);
    verify(mFileSystem, atLeast(10)).getStatus(expectedPath);
    assertEquals(0, stat.st_size.longValue());

    info.setCompleted(true);
    info.setLength(1000);

    t.join();

    // getattr() completed and set the file size
    assertEquals(1000, stat.st_size.longValue());
  }
",non-flaky,5
106622,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.mkDir,"  @Test
  public void mkDir() throws Exception {
    long mode = 0755L;
    mFuseFs.mkdir(""/foo/bar"", mode);
    verify(mFileSystem).createDirectory(BASE_EXPECTED_URI.join(""/foo/bar""),
        CreateDirectoryPOptions.newBuilder()
            .setMode(new alluxio.security.authorization.Mode((short) mode).toProto())
            .build());
  }
",non-flaky,5
106623,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.mkDirWithLengthLimit,"  @Test
  public void mkDirWithLengthLimit() throws Exception {
    long mode = 0755L;
    String c256 = String.join("""", Collections.nCopies(16, ""0123456789ABCDEF""));
    assertEquals(-ErrorCodes.ENAMETOOLONG(),
        mFuseFs.mkdir(""/foo/"" + c256, mode));
  }
",non-flaky,5
106624,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.openWithoutDelay,"  @Test
  public void openWithoutDelay() throws Exception {
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    setUpOpenMock(expectedPath);

    FileInStream is = mock(FileInStream.class);
    when(mFileSystem.openFile(expectedPath)).thenReturn(is);
    mFuseFs.open(""/foo/bar"", mFileInfo);
    verify(mFileSystem).openFile(expectedPath);
  }
",non-flaky,5
106625,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.incompleteFileCannotOpen,"  @Test
  public void incompleteFileCannotOpen() throws Exception {
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    FileInfo fi = setUpOpenMock(expectedPath);
    fi.setCompleted(false);

    when(mFileSystem.openFile(expectedPath)).thenThrow(new FileIncompleteException(expectedPath));
    assertEquals(-ErrorCodes.EFAULT(), mFuseFs.open(""/foo/bar"", mFileInfo));
  }
",non-flaky,5
106626,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.openWithDelay,"  @Test
  public void openWithDelay() throws Exception {
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    FileInfo fi = setUpOpenMock(expectedPath);
    fi.setCompleted(false);
    when(mFileSystem.openFile(expectedPath)).thenThrow(new FileIncompleteException(expectedPath));

    // Use another thread to open file so that
    // we could change the file status when opening it
    Thread t = new Thread(() -> mFuseFs.open(""/foo/bar"", mFileInfo));
    t.start();
    Thread.sleep(1000);
    // If the file exists but is not completed, we will wait for the file to complete
    verify(mFileSystem, atLeast(10)).getStatus(expectedPath);

    fi.setCompleted(true);
    t.join();
    verify(mFileSystem, times(2)).openFile(expectedPath);
  }
",non-flaky,5
106627,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.read,"  @Test
  public void read() throws Exception {
    // mocks set-up
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    setUpOpenMock(expectedPath);

    FileInStream fakeInStream = mock(FileInStream.class);
    when(fakeInStream.read(any(byte[].class),
        anyInt(), anyInt())).then((Answer<Integer>) invocationOnMock -> {
          byte[] myDest = (byte[]) invocationOnMock.getArguments()[0];
          for (byte i = 0; i < 4; i++) {
            myDest[i] = i;
          }
          return 4;
        });

    when(mFileSystem.openFile(expectedPath)).thenReturn(fakeInStream);
    mFileInfo.flags.set(O_RDONLY.intValue());

    // prepare something to read to it
    ByteBuffer ptr = ByteBuffer.allocateDirect(4);
    assertEquals(4, ptr.limit());

    // actual test
    mFuseFs.open(""/foo/bar"", mFileInfo);

    mFuseFs.read(""/foo/bar"", ptr, 4, 0, mFileInfo);
    ptr.flip();
    final byte[] dst = new byte[4];
    ptr.get(dst, 0, 4);
    final byte[] expected = new byte[] {0, 1, 2, 3};

    assertArrayEquals(""Source and dst data should be equal"", expected, dst);
  }
",non-flaky,5
106628,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.rename,"  @Test
  public void rename() throws Exception {
    AlluxioURI oldPath = BASE_EXPECTED_URI.join(""/old"");
    AlluxioURI newPath = BASE_EXPECTED_URI.join(""/new"");
    doNothing().when(mFileSystem).rename(oldPath, newPath);
    mFuseFs.rename(""/old"", ""/new"");
    verify(mFileSystem).rename(oldPath, newPath);
  }
",non-flaky,5
106629,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.renameOldNotExist,"  @Test
  public void renameOldNotExist() throws Exception {
    AlluxioURI oldPath = BASE_EXPECTED_URI.join(""/old"");
    AlluxioURI newPath = BASE_EXPECTED_URI.join(""/new"");
    doThrow(new FileDoesNotExistException(""File /old does not exist""))
        .when(mFileSystem).rename(oldPath, newPath);
    assertEquals(-ErrorCodes.ENOENT(), mFuseFs.rename(""/old"", ""/new""));
  }
",non-flaky,5
106630,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.renameNewExist,"  @Test
  public void renameNewExist() throws Exception {
    AlluxioURI oldPath = BASE_EXPECTED_URI.join(""/old"");
    AlluxioURI newPath = BASE_EXPECTED_URI.join(""/new"");
    doThrow(new FileAlreadyExistsException(""File /new already exists""))
        .when(mFileSystem).rename(oldPath, newPath);
    assertEquals(-ErrorCodes.EEXIST(), mFuseFs.rename(""/old"", ""/new""));
  }
",non-flaky,5
106631,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.renameWithLengthLimit,"  @Test
  public void renameWithLengthLimit() throws Exception {
    String c256 = String.join("""", Collections.nCopies(16, ""0123456789ABCDEF""));
    AlluxioURI oldPath = BASE_EXPECTED_URI.join(""/old"");
    AlluxioURI newPath = BASE_EXPECTED_URI.join(""/"" + c256);
    doNothing().when(mFileSystem).rename(oldPath, newPath);
    assertEquals(-ErrorCodes.ENAMETOOLONG(),
        mFuseFs.rename(""/old"", ""/"" + c256));
  }
",non-flaky,5
106632,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.rmdir,"  @Test
  public void rmdir() throws Exception {
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    doNothing().when(mFileSystem).delete(expectedPath);
    mFuseFs.rmdir(""/foo/bar"");
    verify(mFileSystem).delete(expectedPath);
  }
",non-flaky,5
106633,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.write,"  @Test
  public void write() throws Exception {
    FileOutStream fos = mock(FileOutStream.class);
    AlluxioURI anyURI = any();
    CreateFilePOptions options = any();
    when(mFileSystem.createFile(anyURI, options)).thenReturn(fos);

    // open a file
    mFileInfo.flags.set(O_WRONLY.intValue());
    mFuseFs.create(""/foo/bar"", 0, mFileInfo);

    // prepare something to write into it
    ByteBuffer ptr = ByteBuffer.allocateDirect(4);
    byte[] expected = {42, -128, 1, 3};
    ptr.put(expected, 0, 4);
    ptr.flip();

    mFuseFs.write(""/foo/bar"", ptr, 4, 0, mFileInfo);
    verify(fos).write(expected);

    // the second write is no-op because the writes must be sequential and overwriting is supported
    mFuseFs.write(""/foo/bar"", ptr, 4, 0, mFileInfo);
    verify(fos, times(1)).write(expected);
  }
",non-flaky,5
106634,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.unlink,"  @Test
  public void unlink() throws Exception {
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    doNothing().when(mFileSystem).delete(expectedPath);
    mFuseFs.unlink(""/foo/bar"");
    verify(mFileSystem).delete(expectedPath);
  }
",non-flaky,5
106635,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.pathTranslation,"  @Test
  public void pathTranslation() throws Exception {
    final LoadingCache<String, AlluxioURI> resolver = mFuseFs.getPathResolverCache();

    AlluxioURI expected = new AlluxioURI(TEST_ROOT_PATH);
    AlluxioURI actual = resolver.apply(""/"");
    assertEquals(""/ should resolve to "" + expected, expected, actual);

    expected = new AlluxioURI(TEST_ROOT_PATH + ""/home/foo"");
    actual = resolver.apply(""/home/foo"");
    assertEquals(""/home/foo should resolve to "" + expected, expected, actual);
  }
",non-flaky,5
106636,Alluxio_alluxio,AlluxioJniFuseFileSystemTest.statfs,"  @Test
  public void statfs() throws Exception {
    ByteBuffer buffer = ByteBuffer.allocateDirect(4 * Constants.KB);
    buffer.clear();
    Statvfs stbuf = Statvfs.of(buffer);

    int blockSize = 4 * Constants.KB;
    int totalBlocks = 4;
    int freeBlocks = 3;

    BlockMasterClient blockMasterClient = PowerMockito.mock(BlockMasterClient.class);
    PowerMockito.mockStatic(BlockMasterClient.Factory.class);
    when(BlockMasterClient.Factory.create(any())).thenReturn(blockMasterClient);

    BlockMasterInfo blockMasterInfo = new BlockMasterInfo();
    blockMasterInfo.setCapacityBytes(totalBlocks * blockSize);
    blockMasterInfo.setFreeBytes(freeBlocks * blockSize);
    when(blockMasterClient.getBlockMasterInfo(any())).thenReturn(blockMasterInfo);

    assertEquals(0, mFuseFs.statfs(""/"", stbuf));

    assertEquals(blockSize, stbuf.f_bsize.intValue());
    assertEquals(blockSize, stbuf.f_frsize.intValue());
    assertEquals(totalBlocks, stbuf.f_blocks.longValue());
    assertEquals(freeBlocks, stbuf.f_bfree.longValue());
    assertEquals(freeBlocks, stbuf.f_bavail.longValue());

    assertEquals(AlluxioJniFuseFileSystem.UNKNOWN_INODES, stbuf.f_files.intValue());
    assertEquals(AlluxioJniFuseFileSystem.UNKNOWN_INODES, stbuf.f_ffree.intValue());
    assertEquals(AlluxioJniFuseFileSystem.UNKNOWN_INODES, stbuf.f_favail.intValue());
    assertEquals(AlluxioJniFuseFileSystem.MAX_NAME_LENGTH, stbuf.f_namemax.intValue());
  }
",non-flaky,5
106637,Alluxio_alluxio,AlluxioFuseFileSystemTest.chmod,"  @Test
  public void chmod() throws Exception {
    long mode = 123;
    mFuseFs.chmod(""/foo/bar"", mode);
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    SetAttributePOptions options =
        SetAttributePOptions.newBuilder().setMode(new Mode((short) mode).toProto()).build();
    verify(mFileSystem).setAttribute(expectedPath, options);
  }
",non-flaky,5
106638,Alluxio_alluxio,AlluxioFuseFileSystemTest.chown,"  @Test
  public void chown() throws Exception {
    long uid = AlluxioFuseUtils.getUid(System.getProperty(""user.name""));
    long gid = AlluxioFuseUtils.getGid(System.getProperty(""user.name""));
    mFuseFs.chown(""/foo/bar"", uid, gid);
    String userName = System.getProperty(""user.name"");
    String groupName = AlluxioFuseUtils.getGroupName(gid);
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    SetAttributePOptions options =
        SetAttributePOptions.newBuilder().setGroup(groupName).setOwner(userName).build();
    verify(mFileSystem).setAttribute(expectedPath, options);
  }
",non-flaky,5
106639,Alluxio_alluxio,AlluxioFuseFileSystemTest.chownWithoutValidGid,"  @Test
  public void chownWithoutValidGid() throws Exception {
    long uid = AlluxioFuseUtils.getUid(System.getProperty(""user.name""));
    long gid = AlluxioFuseFileSystem.ID_NOT_SET_VALUE;
    mFuseFs.chown(""/foo/bar"", uid, gid);
    String userName = System.getProperty(""user.name"");
    String groupName = AlluxioFuseUtils.getGroupName(userName);
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    SetAttributePOptions options =
        SetAttributePOptions.newBuilder().setGroup(groupName).setOwner(userName).build();
    verify(mFileSystem).setAttribute(expectedPath, options);

    gid = AlluxioFuseFileSystem.ID_NOT_SET_VALUE_UNSIGNED;
    mFuseFs.chown(""/foo/bar"", uid, gid);
    verify(mFileSystem, times(2)).setAttribute(expectedPath, options);
  }
",non-flaky,5
106640,Alluxio_alluxio,AlluxioFuseFileSystemTest.chownWithoutValidUid,"  @Test
  public void chownWithoutValidUid() throws Exception {
    String userName = System.getProperty(""user.name"");
    long uid = AlluxioFuseFileSystem.ID_NOT_SET_VALUE;
    long gid = AlluxioFuseUtils.getGid(userName);
    mFuseFs.chown(""/foo/bar"", uid, gid);

    String groupName = AlluxioFuseUtils.getGroupName(userName);
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    SetAttributePOptions options = SetAttributePOptions.newBuilder().setGroup(groupName).build();
    verify(mFileSystem).setAttribute(expectedPath, options);

    uid = AlluxioFuseFileSystem.ID_NOT_SET_VALUE_UNSIGNED;
    mFuseFs.chown(""/foo/bar"", uid, gid);
    verify(mFileSystem, times(2)).setAttribute(expectedPath, options);
  }
",non-flaky,5
106641,Alluxio_alluxio,AlluxioFuseFileSystemTest.chownWithoutValidUidAndGid,"  @Test
  public void chownWithoutValidUidAndGid() throws Exception {
    long uid = AlluxioFuseFileSystem.ID_NOT_SET_VALUE;
    long gid = AlluxioFuseFileSystem.ID_NOT_SET_VALUE;
    mFuseFs.chown(""/foo/bar"", uid, gid);
    verify(mFileSystem, never()).setAttribute(any());

    uid = AlluxioFuseFileSystem.ID_NOT_SET_VALUE_UNSIGNED;
    gid = AlluxioFuseFileSystem.ID_NOT_SET_VALUE_UNSIGNED;
    mFuseFs.chown(""/foo/bar"", uid, gid);
    verify(mFileSystem, never()).setAttribute(any());
  }
",non-flaky,5
106642,Alluxio_alluxio,AlluxioFuseFileSystemTest.create,"  @Test
  public void create() throws Exception {
    mFileInfo.flags.set(O_WRONLY.intValue());
    mFuseFs.create(""/foo/bar"", 0, mFileInfo);
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    verify(mFileSystem).createFile(expectedPath, CreateFilePOptions.newBuilder()
        .setMode(new alluxio.security.authorization.Mode((short) 0).toProto())
        .build());
  }
",non-flaky,5
106643,Alluxio_alluxio,AlluxioFuseFileSystemTest.createWithLengthLimit,"  @Test
  public void createWithLengthLimit() throws Exception {
    String c256 = String.join("""", Collections.nCopies(16, ""0123456789ABCDEF""));
    mFileInfo.flags.set(O_WRONLY.intValue());
    assertEquals(-ErrorCodes.ENAMETOOLONG(),
        mFuseFs.create(""/foo/"" + c256, 0, mFileInfo));
  }
",non-flaky,5
106644,Alluxio_alluxio,AlluxioFuseFileSystemTest.flush,"  @Test
  public void flush() throws Exception {
    FileOutStream fos = mock(FileOutStream.class);
    AlluxioURI anyURI = any();
    CreateFilePOptions options = any();
    when(mFileSystem.createFile(anyURI, options)).thenReturn(fos);

    // open a file
    mFileInfo.flags.set(O_WRONLY.intValue());
    mFuseFs.create(""/foo/bar"", 0, mFileInfo);

    // then call flush into it
    mFuseFs.flush(""/foo/bar"", mFileInfo);
    verify(fos).flush();
  }
",non-flaky,5
106645,Alluxio_alluxio,AlluxioFuseFileSystemTest.getattr,"  @Test
  public void getattr() throws Exception {
    // set up status
    FileInfo info = new FileInfo();
    info.setLength(4 * Constants.KB + 1);
    info.setLastModificationTimeMs(1000);
    String userName = System.getProperty(""user.name"");
    info.setOwner(userName);
    info.setGroup(AlluxioFuseUtils.getGroupName(userName));
    info.setFolder(true);
    info.setMode(123);
    info.setCompleted(true);
    URIStatus status = new URIStatus(info);

    // mock fs
    when(mFileSystem.getStatus(any(AlluxioURI.class))).thenReturn(status);

    FileStat stat = new FileStat(Runtime.getSystemRuntime());
    assertEquals(0, mFuseFs.getattr(""/foo"", stat));
    assertEquals(status.getLength(), stat.st_size.longValue());
    assertEquals(9, stat.st_blocks.intValue());
    assertEquals(status.getLastModificationTimeMs() / 1000, stat.st_ctim.tv_sec.get());
    assertEquals((status.getLastModificationTimeMs() % 1000) * 1000,
        stat.st_ctim.tv_nsec.longValue());
    assertEquals(status.getLastModificationTimeMs() / 1000, stat.st_mtim.tv_sec.get());
    assertEquals((status.getLastModificationTimeMs() % 1000) * 1000,
        stat.st_mtim.tv_nsec.longValue());
    assertEquals(AlluxioFuseUtils.getUid(System.getProperty(""user.name"")), stat.st_uid.get());
    assertEquals(AlluxioFuseUtils.getGid(System.getProperty(""user.name"")), stat.st_gid.get());
    assertEquals(123 | FileStat.S_IFDIR, stat.st_mode.intValue());
  }
",non-flaky,5
106646,Alluxio_alluxio,AlluxioFuseFileSystemTest.getattrWithDelay,"  @Test
  public void getattrWithDelay() throws Exception {
    String path = ""/foo/bar"";
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");

    // set up status
    FileInfo info = new FileInfo();
    info.setLength(0);
    info.setCompleted(false);
    URIStatus status = new URIStatus(info);

    // mock fs
    when(mFileSystem.getStatus(any(AlluxioURI.class))).thenReturn(status);

    FileStat stat = new FileStat(Runtime.getSystemRuntime());

    // Use another thread to open file so that
    // we could change the file status when opening it
    Thread t = new Thread(() -> mFuseFs.getattr(path, stat));
    t.start();
    Thread.sleep(1000);

    // If the file is not being written and is not completed,
    // we will wait for the file to complete
    verify(mFileSystem, atLeast(10)).getStatus(expectedPath);
    assertEquals(0, stat.st_size.longValue());

    info.setCompleted(true);
    info.setLength(1000);

    t.join();

    assertEquals(1000, stat.st_size.longValue());
  }
",non-flaky,5
106647,Alluxio_alluxio,AlluxioFuseFileSystemTest.getattrWhenWriting,"  @Test
  public void getattrWhenWriting() throws Exception {
    String path = ""/foo/bar"";
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(path);

    FileOutStream fos = mock(FileOutStream.class);
    when(mFileSystem.createFile(expectedPath)).thenReturn(fos);

    mFuseFs.create(path, 0, mFileInfo);

    // Prepare file status
    FileInfo info = new FileInfo();
    info.setLength(0);
    info.setCompleted(false);
    URIStatus status = new URIStatus(info);

    when(mFileSystem.exists(any(AlluxioURI.class))).thenReturn(true);
    when(mFileSystem.getStatus(any(AlluxioURI.class))).thenReturn(status);

    FileStat stat = new FileStat(Runtime.getSystemRuntime());

    // getattr() will not be blocked when writing
    mFuseFs.getattr(path, stat);
    // If getattr() is blocking, it will continuously get status of the file
    verify(mFileSystem, atMost(300)).getStatus(expectedPath);
    assertEquals(0, stat.st_size.longValue());

    mFuseFs.release(path, mFileInfo);

    // getattr() will be blocked waiting for the file to be completed
    // If release() is called (returned) but does not finished
    Thread t = new Thread(() -> mFuseFs.getattr(path, stat));
    t.start();
    Thread.sleep(1000);
    verify(mFileSystem, atLeast(10)).getStatus(expectedPath);
    assertEquals(0, stat.st_size.longValue());

    info.setCompleted(true);
    info.setLength(1000);

    t.join();

    // getattr() completed and set the file size
    assertEquals(1000, stat.st_size.longValue());
  }
",non-flaky,5
106648,Alluxio_alluxio,AlluxioFuseFileSystemTest.mkDir,"  @Test
  public void mkDir() throws Exception {
    long mode = 0755L;
    mFuseFs.mkdir(""/foo/bar"", mode);
    verify(mFileSystem).createDirectory(BASE_EXPECTED_URI.join(""/foo/bar""),
        CreateDirectoryPOptions.newBuilder()
            .setMode(new alluxio.security.authorization.Mode((short) mode).toProto())
            .build());
  }
",non-flaky,5
106649,Alluxio_alluxio,AlluxioFuseFileSystemTest.mkDirWithLengthLimit,"  @Test
  public void mkDirWithLengthLimit() throws Exception {
    long mode = 0755L;
    String c256 = String.join("""", Collections.nCopies(16, ""0123456789ABCDEF""));
    assertEquals(-ErrorCodes.ENAMETOOLONG(),
        mFuseFs.mkdir(""/foo/"" + c256, mode));
  }
",non-flaky,5
106650,Alluxio_alluxio,AlluxioFuseFileSystemTest.openWithoutDelay,"  @Test
  public void openWithoutDelay() throws Exception {
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    setUpOpenMock(expectedPath);

    FileInStream is = mock(FileInStream.class);
    when(mFileSystem.openFile(expectedPath)).thenReturn(is);
    mFuseFs.open(""/foo/bar"", mFileInfo);
    verify(mFileSystem).openFile(expectedPath);
  }
",non-flaky,5
106651,Alluxio_alluxio,AlluxioFuseFileSystemTest.incompleteFileCannotOpen,"  @Test
  public void incompleteFileCannotOpen() throws Exception {
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    FileInfo fi = setUpOpenMock(expectedPath);
    fi.setCompleted(false);

    when(mFileSystem.openFile(expectedPath)).thenThrow(new FileIncompleteException(expectedPath));
    assertEquals(-ErrorCodes.EFAULT(), mFuseFs.open(""/foo/bar"", mFileInfo));
  }
",non-flaky,5
106652,Alluxio_alluxio,AlluxioFuseFileSystemTest.openWithDelay,"  @Test
  public void openWithDelay() throws Exception {
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    FileInfo fi = setUpOpenMock(expectedPath);
    fi.setCompleted(false);
    when(mFileSystem.openFile(expectedPath)).thenThrow(new FileIncompleteException(expectedPath));

    // Use another thread to open file so that
    // we could change the file status when opening it
    Thread t = new Thread(() -> mFuseFs.open(""/foo/bar"", mFileInfo));
    t.start();
    Thread.sleep(1000);
    // If the file exists but is not completed, we will wait for the file to complete
    verify(mFileSystem, atLeast(10)).getStatus(expectedPath);

    fi.setCompleted(true);
    t.join();
    verify(mFileSystem, times(2)).openFile(expectedPath);
  }
",non-flaky,5
106653,Alluxio_alluxio,AlluxioFuseFileSystemTest.read,"  @Test
  public void read() throws Exception {
    // mocks set-up
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    setUpOpenMock(expectedPath);

    FileInStream fakeInStream = mock(FileInStream.class);
    when(fakeInStream.read(any(byte[].class),
        anyInt(), anyInt())).then((Answer<Integer>) invocationOnMock -> {
          byte[] myDest = (byte[]) invocationOnMock.getArguments()[0];
          for (byte i = 0; i < 4; i++) {
            myDest[i] = i;
          }
          return 4;
        });
    when(fakeInStream.remaining()).thenReturn(4L);

    when(mFileSystem.openFile(expectedPath)).thenReturn(fakeInStream);
    mFileInfo.flags.set(O_RDONLY.intValue());

    // prepare something to read to it
    Runtime r = Runtime.getSystemRuntime();
    Pointer ptr = r.getMemoryManager().allocateTemporary(4, true);

    // actual test
    mFuseFs.open(""/foo/bar"", mFileInfo);

    mFuseFs.read(""/foo/bar"", ptr, 4, 0, mFileInfo);
    final byte[] dst = new byte[4];
    ptr.get(0, dst, 0, 4);
    final byte[] expected = new byte[] {0, 1, 2, 3};

    assertArrayEquals(""Source and dst data should be equal"", expected, dst);
  }
",non-flaky,5
106654,Alluxio_alluxio,AlluxioFuseFileSystemTest.readOffset,"  @Test
  public void readOffset() throws Exception {
    // mocks set-up
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    setUpOpenMock(expectedPath);

    FileInStream fakeInStream = mock(FileInStream.class);
    when(fakeInStream.read(any(byte[].class),
        anyInt(), anyInt())).then((Answer<Integer>) invocationOnMock -> {
          byte[] myDest = (byte[]) invocationOnMock.getArguments()[0];
          for (byte i = 0; i < (int) invocationOnMock.getArgument(2); i++) {
            myDest[i] = (byte) (i + 1);
          }
          return myDest.length;
        });
    AtomicInteger callCounter = new AtomicInteger();
    when(fakeInStream.remaining()).then((Answer<Long>) invocationOnMock -> {
      if (callCounter.getAndIncrement() == 0) {
        return 4L;
      } else {
        return 3L;
      }
    });

    when(mFileSystem.openFile(expectedPath)).thenReturn(fakeInStream);
    mFileInfo.flags.set(O_RDONLY.intValue());

    // prepare something to read to it
    Runtime r = Runtime.getSystemRuntime();
    Pointer ptr = r.getMemoryManager().allocateTemporary(2, true);

    // actual test
    mFuseFs.open(""/foo/bar"", mFileInfo);

    mFuseFs.read(""/foo/bar"", ptr, 2, 1, mFileInfo);
    final byte[] dst = new byte[2];
    ptr.get(0, dst, 0, 2);
    final byte[] expected = new byte[] {1, 2};

    assertArrayEquals(""Source and dst data should be equal"", expected, dst);
  }
",non-flaky,5
106655,Alluxio_alluxio,AlluxioFuseFileSystemTest.readOffset2,"  @Test
  public void readOffset2() throws Exception {
    // mocks set-up
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    setUpOpenMock(expectedPath);

    FileInStream fakeInStream = mock(FileInStream.class);
    when(fakeInStream.read(any(byte[].class),
        anyInt(), anyInt())).then((Answer<Integer>) invocationOnMock -> {
          byte[] myDest = (byte[]) invocationOnMock.getArguments()[0];
          for (byte i = 0; i < (int) invocationOnMock.getArgument(2); i++) {
            myDest[i] = i;
          }
          return myDest.length;
        });
    AtomicInteger callCounter = new AtomicInteger();
    when(fakeInStream.remaining()).then((Answer<Long>) invocationOnMock -> {
      if (callCounter.getAndIncrement() == 0) {
        return 4L;
      } else {
        return 3L;
      }
    });

    when(mFileSystem.openFile(expectedPath)).thenReturn(fakeInStream);
    mFileInfo.flags.set(O_RDONLY.intValue());

    // prepare something to read to it
    Runtime r = Runtime.getSystemRuntime();
    Pointer ptr = r.getMemoryManager().allocateTemporary(4, true);

    // actual test
    mFuseFs.open(""/foo/bar"", mFileInfo);

    mFuseFs.read(""/foo/bar"", ptr, 4, 4, mFileInfo);
    final byte[] dst = new byte[0];
    ptr.get(0, dst, 0, 0);
    final byte[] expected = new byte[0];

    assertArrayEquals(""Source and dst data should be equal"", expected, dst);
  }
",non-flaky,5
106656,Alluxio_alluxio,AlluxioFuseFileSystemTest.rename,"  @Test
  public void rename() throws Exception {
    AlluxioURI oldPath = BASE_EXPECTED_URI.join(""/old"");
    AlluxioURI newPath = BASE_EXPECTED_URI.join(""/new"");
    doNothing().when(mFileSystem).rename(oldPath, newPath);
    mFuseFs.rename(""/old"", ""/new"");
    verify(mFileSystem).rename(oldPath, newPath);
  }
",non-flaky,5
106657,Alluxio_alluxio,AlluxioFuseFileSystemTest.renameOldNotExist,"  @Test
  public void renameOldNotExist() throws Exception {
    AlluxioURI oldPath = BASE_EXPECTED_URI.join(""/old"");
    AlluxioURI newPath = BASE_EXPECTED_URI.join(""/new"");
    doThrow(new FileDoesNotExistException(""File /old does not exist""))
        .when(mFileSystem).rename(oldPath, newPath);
    assertEquals(-ErrorCodes.ENOENT(), mFuseFs.rename(""/old"", ""/new""));
  }
",non-flaky,5
106658,Alluxio_alluxio,AlluxioFuseFileSystemTest.renameNewExist,"  @Test
  public void renameNewExist() throws Exception {
    AlluxioURI oldPath = BASE_EXPECTED_URI.join(""/old"");
    AlluxioURI newPath = BASE_EXPECTED_URI.join(""/new"");
    doThrow(new FileAlreadyExistsException(""File /new already exists""))
        .when(mFileSystem).rename(oldPath, newPath);
    assertEquals(-ErrorCodes.EEXIST(), mFuseFs.rename(""/old"", ""/new""));
  }
",non-flaky,5
106659,Alluxio_alluxio,AlluxioFuseFileSystemTest.renameWithLengthLimit,"  @Test
  public void renameWithLengthLimit() throws Exception {
    String c256 = String.join("""", Collections.nCopies(16, ""0123456789ABCDEF""));
    AlluxioURI oldPath = BASE_EXPECTED_URI.join(""/old"");
    AlluxioURI newPath = BASE_EXPECTED_URI.join(""/"" + c256);
    doNothing().when(mFileSystem).rename(oldPath, newPath);
    assertEquals(-ErrorCodes.ENAMETOOLONG(),
        mFuseFs.rename(""/old"", ""/"" + c256));
  }
",non-flaky,5
106660,Alluxio_alluxio,AlluxioFuseFileSystemTest.rmdir,"  @Test
  public void rmdir() throws Exception {
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    doNothing().when(mFileSystem).delete(expectedPath);
    mFuseFs.rmdir(""/foo/bar"");
    verify(mFileSystem).delete(expectedPath);
  }
",non-flaky,5
106661,Alluxio_alluxio,AlluxioFuseFileSystemTest.write,"  @Test
  public void write() throws Exception {
    FileOutStream fos = mock(FileOutStream.class);
    AlluxioURI anyURI = any();
    CreateFilePOptions options = any();
    when(mFileSystem.createFile(anyURI, options)).thenReturn(fos);

    // open a file
    mFileInfo.flags.set(O_WRONLY.intValue());
    mFuseFs.create(""/foo/bar"", 0, mFileInfo);

    // prepare something to write into it
    Runtime r = Runtime.getSystemRuntime();
    Pointer ptr = r.getMemoryManager().allocateTemporary(4, true);
    byte[] expected = {42, -128, 1, 3};
    ptr.put(0, expected, 0, 4);

    mFuseFs.write(""/foo/bar"", ptr, 4, 0, mFileInfo);
    verify(fos).write(expected);

    // the second write is no-op because the writes must be sequential and overwriting is supported
    mFuseFs.write(""/foo/bar"", ptr, 4, 0, mFileInfo);
    verify(fos, times(1)).write(expected);
  }
",non-flaky,5
106662,Alluxio_alluxio,AlluxioFuseFileSystemTest.unlink,"  @Test
  public void unlink() throws Exception {
    AlluxioURI expectedPath = BASE_EXPECTED_URI.join(""/foo/bar"");
    doNothing().when(mFileSystem).delete(expectedPath);
    mFuseFs.unlink(""/foo/bar"");
    verify(mFileSystem).delete(expectedPath);
  }
",non-flaky,5
106663,Alluxio_alluxio,AlluxioFuseFileSystemTest.pathTranslation,"  @Test
  public void pathTranslation() throws Exception {
    final LoadingCache<String, AlluxioURI> resolver = mFuseFs.getPathResolverCache();

    AlluxioURI expected = new AlluxioURI(TEST_ROOT_PATH);
    AlluxioURI actual = resolver.apply(""/"");
    assertEquals(""/ should resolve to "" + expected, expected, actual);

    expected = new AlluxioURI(TEST_ROOT_PATH + ""/home/foo"");
    actual = resolver.apply(""/home/foo"");
    assertEquals(""/home/foo should resolve to "" + expected, expected, actual);
  }
",non-flaky,5
106664,Alluxio_alluxio,AlluxioFuseFileSystemTest.statfs,"  @Test
  public void statfs() throws Exception {
    Runtime runtime = Runtime.getSystemRuntime();
    Pointer pointer = runtime.getMemoryManager().allocateTemporary(4 * Constants.KB, true);
    Statvfs stbuf = Statvfs.of(pointer);

    int blockSize = 4 * Constants.KB;
    int totalBlocks = 4;
    int freeBlocks = 3;

    BlockMasterClient blockMasterClient = PowerMockito.mock(BlockMasterClient.class);
    PowerMockito.mockStatic(BlockMasterClient.Factory.class);
    when(BlockMasterClient.Factory.create(any())).thenReturn(blockMasterClient);

    BlockMasterInfo blockMasterInfo = new BlockMasterInfo();
    blockMasterInfo.setCapacityBytes(totalBlocks * blockSize);
    blockMasterInfo.setFreeBytes(freeBlocks * blockSize);
    when(blockMasterClient.getBlockMasterInfo(any())).thenReturn(blockMasterInfo);

    assertEquals(0, mFuseFs.statfs(""/"", stbuf));

    assertEquals(blockSize, stbuf.f_bsize.intValue());
    assertEquals(blockSize, stbuf.f_frsize.intValue());
    assertEquals(totalBlocks, stbuf.f_blocks.longValue());
    assertEquals(freeBlocks, stbuf.f_bfree.longValue());
    assertEquals(freeBlocks, stbuf.f_bavail.longValue());

    assertEquals(AlluxioFuseFileSystem.UNKNOWN_INODES, stbuf.f_files.intValue());
    assertEquals(AlluxioFuseFileSystem.UNKNOWN_INODES, stbuf.f_ffree.intValue());
    assertEquals(AlluxioFuseFileSystem.UNKNOWN_INODES, stbuf.f_favail.intValue());
    assertEquals(AlluxioFuseFileSystem.MAX_NAME_LENGTH, stbuf.f_namemax.intValue());
  }
",non-flaky,5
106665,Alluxio_alluxio,BaseFileSystemTest.createFile,"  @Test
  public void createFile() throws Exception {
    URIStatus status = new URIStatus(new FileInfo());
    AlluxioURI file = new AlluxioURI(""/file"");
    when(mFileSystemMasterClient.createFile(any(AlluxioURI.class), any(CreateFilePOptions.class)))
        .thenReturn(status);
    mFileSystem.createFile(file, CreateFilePOptions.getDefaultInstance());
    verify(mFileSystemMasterClient).createFile(file, FileSystemOptions.createFileDefaults(mConf)
            .toBuilder().mergeFrom(CreateFilePOptions.getDefaultInstance()).build());

    verifyFilesystemContextAcquiredAndReleased();
  }
",non-flaky,5
106666,Alluxio_alluxio,BaseFileSystemTest.createException,"  @Test
  public void createException() throws Exception {
    doThrow(EXCEPTION).when(mFileSystemMasterClient)
        .createFile(any(AlluxioURI.class), any(CreateFilePOptions.class));
    try {
      mFileSystem.createFile(new AlluxioURI(""/""), CreateFilePOptions.getDefaultInstance());
      fail(SHOULD_HAVE_PROPAGATED_MESSAGE);
    } catch (Exception e) {
      assertSame(EXCEPTION, e);
    }

    verifyFilesystemContextAcquiredAndReleased();
  }
",non-flaky,5
106667,Alluxio_alluxio,BaseFileSystemTest.delete,"  @Test
  public void delete() throws Exception {
    AlluxioURI file = new AlluxioURI(""/file"");
    DeletePOptions deleteOptions = DeletePOptions.newBuilder().setRecursive(true).build();
    mFileSystem.delete(file, deleteOptions);
    verify(mFileSystemMasterClient).delete(file,
        FileSystemOptions.deleteDefaults(mConf).toBuilder().mergeFrom(deleteOptions).build());

    verifyFilesystemContextAcquiredAndReleased();
  }
",non-flaky,5
106668,Alluxio_alluxio,BaseFileSystemTest.deleteException,"  @Test
  public void deleteException() throws Exception {
    AlluxioURI file = new AlluxioURI(""/file"");
    DeletePOptions deleteOptions = DeletePOptions.newBuilder().setRecursive(true).build();
    doThrow(EXCEPTION).when(mFileSystemMasterClient).delete(file,
        FileSystemOptions.deleteDefaults(mConf)
            .toBuilder().mergeFrom(deleteOptions).build());
    try {
      mFileSystem.delete(file, deleteOptions);
      fail(SHOULD_HAVE_PROPAGATED_MESSAGE);
    } catch (Exception e) {
      assertSame(EXCEPTION, e);
    }

    verifyFilesystemContextAcquiredAndReleased();
  }
",non-flaky,5
106669,Alluxio_alluxio,BaseFileSystemTest.free,"  @Test
  public void free() throws Exception {
    AlluxioURI file = new AlluxioURI(""/file"");
    FreePOptions freeOptions = FreePOptions.newBuilder().setRecursive(true).build();
    mFileSystem.free(file, freeOptions);
    verify(mFileSystemMasterClient).free(file, FileSystemOptions.freeDefaults(mConf)
        .toBuilder().mergeFrom(freeOptions).build());

    verifyFilesystemContextAcquiredAndReleased();
  }
",non-flaky,5
106670,Alluxio_alluxio,BaseFileSystemTest.freeException,"  @Test
  public void freeException() throws Exception {
    AlluxioURI file = new AlluxioURI(""/file"");
    FreePOptions freeOptions = FreePOptions.newBuilder().setRecursive(true).build();
    doThrow(EXCEPTION).when(mFileSystemMasterClient).free(file,
        FileSystemOptions.freeDefaults(mConf).toBuilder().mergeFrom(freeOptions).build());
    try {
      mFileSystem.free(file, freeOptions);
      fail(SHOULD_HAVE_PROPAGATED_MESSAGE);
    } catch (Exception e) {
      assertSame(EXCEPTION, e);
    }

    verifyFilesystemContextAcquiredAndReleased();
  }
",non-flaky,5
106671,Alluxio_alluxio,BaseFileSystemTest.getStatus,"  @Test
  public void getStatus() throws Exception {
    AlluxioURI file = new AlluxioURI(""/file"");
    URIStatus status = new URIStatus(new FileInfo());
    GetStatusPOptions getStatusOptions = GetStatusPOptions.getDefaultInstance();
    when(mFileSystemMasterClient.getStatus(file, FileSystemOptions.getStatusDefaults(mConf)
        .toBuilder().mergeFrom(getStatusOptions).build())).thenReturn(status);
    assertSame(status, mFileSystem.getStatus(file, getStatusOptions));
    verify(mFileSystemMasterClient).getStatus(file, FileSystemOptions.getStatusDefaults(mConf)
        .toBuilder().mergeFrom(getStatusOptions).build());

    verifyFilesystemContextAcquiredAndReleased();
  }
",non-flaky,5
106672,Alluxio_alluxio,BaseFileSystemTest.getStatusException,"  @Test
  public void getStatusException() throws Exception {
    AlluxioURI file = new AlluxioURI(""/file"");
    GetStatusPOptions getStatusOptions = GetStatusPOptions.getDefaultInstance();
    when(mFileSystemMasterClient.getStatus(file, FileSystemOptions.getStatusDefaults(mConf)
        .toBuilder().mergeFrom(getStatusOptions).build())).thenThrow(EXCEPTION);
    try {
      mFileSystem.getStatus(file, getStatusOptions);
      fail(SHOULD_HAVE_PROPAGATED_MESSAGE);
    } catch (Exception e) {
      assertSame(EXCEPTION, e);
    }

    verifyFilesystemContextAcquiredAndReleased();
  }
",non-flaky,5
174,hwang-pku_ormlite-core,DatabaseFieldConfigTest.testFromDbField,"@Test
public void testFromDbField() throws Exception {
    Field[] fields = Foo.class.getDeclaredFields();
    assertTrue(fields.length >= 1);
    DatabaseFieldConfig config = DatabaseFieldConfig.fromField(databaseType, ""foo"", fields[0]);
    assertNotNull(config);
    assertTrue(config.isCanBeNull());
    assertEquals(fields[0].getName(), config.getFieldName());
}",unordered collections,3
326,hwang-pku_ormlite-core,QueryBuilderTest.testQueryRaw,"@Test
public void testQueryRaw() throws Exception {
    Dao<Foo, Integer> dao = createDao(Foo.class, true);
    Foo foo = new Foo();
    foo.stringField = ""zipper"";
    dao.create(foo);
    QueryBuilder<Foo, Integer> qb = dao.queryBuilder();
    assertEquals(1, qb.countOf());
    GenericRawResults<String[]> results = qb.queryRaw();
    List<String[]> stringResults = results.getResults();
    assertEquals(1, stringResults.size());
    assertEquals(Integer.toString(foo.id), stringResults.get(0)[0]);
    assertEquals(foo.stringField, stringResults.get(0)[3]);
}",unordered collections,3
112671,hwang-pku_ormlite-core,VersionUtilsTest.testCheckCoreVersusJdbcVersionsGood,"	@Test
	public void testCheckCoreVersusJdbcVersionsGood() {
		VersionUtils.setThrownOnErrors(true);
		VersionUtils.checkCoreVersusJdbcVersions(VersionUtils.getCoreVersion());
	}
",non-flaky,5
112672,hwang-pku_ormlite-core,VersionUtilsTest.testCheckCoreVersusJdbcVersionsBad,"	@Test(expected = IllegalStateException.class)
	public void testCheckCoreVersusJdbcVersionsBad() {
		VersionUtils.setThrownOnErrors(true);
		VersionUtils.checkCoreVersusJdbcVersions(""xxx"");
	}
",non-flaky,5
112673,hwang-pku_ormlite-core,VersionUtilsTest.testCheckCoreVersusAndroidVersionsGood,"	@Test
	public void testCheckCoreVersusAndroidVersionsGood() {
		VersionUtils.setThrownOnErrors(true);
		VersionUtils.checkCoreVersusAndroidVersions(VersionUtils.getCoreVersion());
	}
",non-flaky,5
112674,hwang-pku_ormlite-core,VersionUtilsTest.testCheckCoreVersusAndroidVersionsBad,"	@Test(expected = IllegalStateException.class)
	public void testCheckCoreVersusAndroidVersionsBad() {
		VersionUtils.setThrownOnErrors(true);
		VersionUtils.checkCoreVersusAndroidVersions(""xxx"");
	}
",non-flaky,5
112675,hwang-pku_ormlite-core,JavaxPersistenceTest.testConversions,"	@Test
	public void testConversions() throws Exception {
		Field[] fields = Javax.class.getDeclaredFields();
		for (Field field : fields) {
			DatabaseFieldConfig config = new JavaxPersistenceImpl().createFieldConfig(databaseType, field);
			if (field.getName().equals(""generatedId"")) {
				assertFalse(config.isId());
				assertTrue(config.isGeneratedId());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertEquals(field.getName(), config.getFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""id"")) {
				assertTrue(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertEquals(field.getName(), config.getFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""stuff"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertEquals(field.getName(), config.getFieldName());
				assertEquals(STUFF_FIELD_NAME, config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""unknown"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getDataPersister());
				assertEquals(field.getName(), config.getFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""foreignManyToOne"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertTrue(config.isForeign());
				assertFalse(config.isForeignCollection());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getDataPersister());
				assertEquals(field.getName(), config.getFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""foreignOneToOne"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertTrue(config.isForeign());
				assertFalse(config.isForeignCollection());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getDataPersister());
				assertEquals(field.getName(), config.getFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""foreignOneToMany"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertTrue(config.isForeignCollection());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getDataPersister());
				assertEquals(field.getName(), config.getFieldName());
				assertNull(config.getForeignCollectionForeignFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""mappedByField"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertTrue(config.isForeignCollection());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getDataPersister());
				assertEquals(field.getName(), config.getFieldName());
				assertEquals(MAPPED_BY_FIELD_NAME, config.getForeignCollectionForeignFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""joinFieldName"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertTrue(config.isForeign());
				assertFalse(config.isForeignCollection());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getDataPersister());
				assertEquals(field.getName(), config.getFieldName());
				assertEquals(JOIN_FIELD_NAME, config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""columnDefinition"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertFalse(config.isVersion());
				assertTrue(config.isCanBeNull());
				assertEquals(COLUMN_DEFINITION, config.getColumnDefinition());
			} else if (field.getName().equals(""uniqueColumn"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertTrue(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""nullableColumn"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertFalse(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""uniqueJoinColumn"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertTrue(config.isForeign());
				assertFalse(config.isForeignCollection());
				assertTrue(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""nullableJoinColumn"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertTrue(config.isForeign());
				assertFalse(config.isForeignCollection());
				assertFalse(config.isUnique());
				assertFalse(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""ourEnumOrdinal"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertFalse(config.isVersion());
				assertTrue(config.isCanBeNull());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
				assertTrue(config.getDataPersister() instanceof EnumIntegerType);
			} else if (field.getName().equals(""ourEnumString"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertFalse(config.isVersion());
				assertTrue(config.isCanBeNull());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
				assertTrue(config.getDataPersister() instanceof EnumStringType);
			} else if (field.getName().equals(""version"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertTrue(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""basic"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""basicNotOptional"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertFalse(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else {
				System.err.println(""\n\n\nUnknown field: "" + field.getName());
			}
		}
	}
",non-flaky,5
112676,hwang-pku_ormlite-core,JavaxPersistenceTest.testTableName,"	@Test
	public void testTableName() {
		JavaxPersistenceConfigurer configurer = new JavaxPersistenceImpl();
		assertEquals(JAVAX_ENTITY_NAME, configurer.getEntityName(Javax.class));
		assertNull(configurer.getEntityName(EntityNoName.class));
	}
",non-flaky,5
112677,hwang-pku_ormlite-core,JavaxPersistenceTest.testUpperCaseFieldNames,"	@Test
	public void testUpperCaseFieldNames() throws Exception {
		Field[] fields = Javax.class.getDeclaredFields();
		UpperCaseFieldDatabaseType ucDatabaseType = new UpperCaseFieldDatabaseType();
		for (Field field : fields) {
			DatabaseFieldConfig config = new JavaxPersistenceImpl().createFieldConfig(ucDatabaseType, field);
			if (field.getName().equals(""id"")) {
				assertTrue(config.isId());
				assertFalse(config.isGeneratedId());
				assertEquals(""ID"", config.getFieldName());
			}
		}
	}
",non-flaky,5
112678,hwang-pku_ormlite-core,JavaxPersistenceTest.testSerializableClass,"	@Test
	public void testSerializableClass() throws SQLException {
		@SuppressWarnings(""unused"")
		Dao<SerializableWrapper, Integer> dao = createDao(SerializableWrapper.class, true);
		SerializableStuff stuff = new SerializableStuff();
		stuff.field1 = 12345;
		stuff.field2 = ""oejwepfjw"";
		SerializableWrapper wrapper = new SerializableWrapper();
		wrapper.stuff = stuff;

		assertEquals(1, dao.create(wrapper));

		SerializableWrapper result = dao.queryForId(wrapper.id);
		assertNotNull(result);
		assertEquals(wrapper.id, result.id);
		assertEquals(wrapper.stuff, result.stuff);
	}
",non-flaky,5
112679,hwang-pku_ormlite-core,BaseDaoEnabledTest.testCreate,"	@Test
	public void testCreate() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff = ""fewpfjewfew"";
		one.stuff = stuff;
		one.setDao(dao);
		assertEquals(1, one.create());
	}
",non-flaky,5
112680,hwang-pku_ormlite-core,BaseDaoEnabledTest.testCreateNoDao,"	@Test(expected = SQLException.class)
	public void testCreateNoDao() throws Exception {
		One one = new One();
		String stuff = ""fewpfjewfew"";
		one.stuff = stuff;
		one.create();
	}
",non-flaky,5
112681,hwang-pku_ormlite-core,BaseDaoEnabledTest.testUpdate,"	@Test
	public void testUpdate() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		assertEquals(1, dao.create(one));
		String stuff2 = ""fjpfejpwewpfjewfew"";
		one.stuff = stuff2;
		assertEquals(1, one.update());
		One one2 = dao.queryForId(one.id);
		assertEquals(stuff2, one2.stuff);
	}
",non-flaky,5
112682,hwang-pku_ormlite-core,BaseDaoEnabledTest.testUpdateId,"	@Test
	public void testUpdateId() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		assertEquals(1, dao.create(one));
		int id = one.id;
		assertNotNull(dao.queryForId(id));
		assertEquals(1, one.updateId(id + 1));
		assertNull(dao.queryForId(id));
		assertNotNull(dao.queryForId(id + 1));
	}
",non-flaky,5
112683,hwang-pku_ormlite-core,BaseDaoEnabledTest.testDelete,"	@Test
	public void testDelete() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		assertEquals(1, dao.create(one));
		assertNotNull(dao.queryForId(one.id));
		assertEquals(1, one.delete());
		assertNull(dao.queryForId(one.id));
	}
",non-flaky,5
112684,hwang-pku_ormlite-core,BaseDaoEnabledTest.testToString,"	@Test
	public void testToString() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		assertEquals(1, dao.create(one));
		String str = one.objectToString();
		assertTrue(str.contains(""id="" + one.id));
		assertTrue(str.contains(""stuff="" + stuff1));
	}
",non-flaky,5
112685,hwang-pku_ormlite-core,BaseDaoEnabledTest.testObjectEquals,"	@Test
	public void testObjectEquals() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		assertEquals(1, dao.create(one));
		assertTrue(one.objectsEqual(one));
	}
",non-flaky,5
112686,hwang-pku_ormlite-core,BaseDaoEnabledTest.testObjectEqualsNoDao,"	@Test(expected = IllegalArgumentException.class)
	public void testObjectEqualsNoDao() {
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		one.objectToString();
	}
",non-flaky,5
112687,hwang-pku_ormlite-core,BaseDaoEnabledTest.testExtractId,"	@Test
	public void testExtractId() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		assertEquals(1, dao.create(one));
		assertEquals(one.id, (int) one.extractId());
	}
",non-flaky,5
112688,hwang-pku_ormlite-core,BaseDaoEnabledTest.testForeign,"	@Test
	public void testForeign() throws Exception {
		Dao<One, Integer> oneDao = createDao(One.class, true);
		Dao<ForeignDaoEnabled, Integer> foreignDao = createDao(ForeignDaoEnabled.class, true);

		One one = new One();
		String stuff = ""fewpfjewfew"";
		one.stuff = stuff;
		one.setDao(oneDao);
		assertEquals(1, one.create());

		ForeignDaoEnabled foreign = new ForeignDaoEnabled();
		foreign.one = one;
		foreign.setDao(foreignDao);
		assertEquals(1, foreign.create());

		ForeignDaoEnabled foreign2 = foreignDao.queryForId(foreign.id);
		assertNotNull(foreign2);
		assertEquals(one.id, foreign2.one.id);
		assertNull(foreign2.one.stuff);
		assertEquals(1, foreign2.one.refresh());
		assertEquals(stuff, foreign2.one.stuff);
	}
",non-flaky,5
112689,hwang-pku_ormlite-core,SqlExceptionUtilTest.testException,"	@Test
	public void testException() {
		Throwable cause = new Throwable();
		String msg = ""hello"";
		SQLException e = SqlExceptionUtil.create(msg, cause);
		assertEquals(msg, e.getMessage());
		assertEquals(cause, e.getCause());
	}
",non-flaky,5
112690,hwang-pku_ormlite-core,SqlExceptionUtilTest.testExceptionWithSQLException,"	@Test
	public void testExceptionWithSQLException() {
		String sqlReason = ""sql exception message"";
		String sqlState = ""sql exception state"";
		Throwable cause = new SQLException(sqlReason, sqlState);
		String msg = ""hello"";
		SQLException e = SqlExceptionUtil.create(msg, cause);
		assertEquals(msg, e.getMessage());
		assertEquals(sqlState, e.getSQLState());
		assertEquals(cause, e.getCause());
	}
",non-flaky,5
112691,hwang-pku_ormlite-core,SqlExceptionUtilTest.testConstructor,"	@Test
	public void testConstructor() throws Exception {
		@SuppressWarnings({ ""rawtypes"" })
		Constructor[] constructors = SqlExceptionUtil.class.getDeclaredConstructors();
		assertEquals(1, constructors.length);
		constructors[0].setAccessible(true);
		constructors[0].newInstance();
	}
",non-flaky,5
112692,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManager() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(false);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint);
		conn.commit(savePoint);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn, savePoint);
		TransactionManager tm = new TransactionManager(connectionSource);
		tm.callInTransaction(new Callable<Void>() {
			@Override
			public Void call() {
				return null;
			}
",non-flaky,5
112693,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerTableName() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(false);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint);
		conn.commit(savePoint);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(FOO_TABLE_NAME)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn, savePoint);
		TransactionManager tm = new TransactionManager(connectionSource);
		tm.callInTransaction(FOO_TABLE_NAME, new Callable<Void>() {
			@Override
			public Void call() {
				return null;
			}
",non-flaky,5
112694,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerSavePointNull() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(false);
		expect(conn.setSavePoint(isA(String.class))).andReturn(null);
		conn.commit(null);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn);
		TransactionManager tm = new TransactionManager(connectionSource);
		tm.callInTransaction(new Callable<Void>() {
			@Override
			public Void call() {
				return null;
			}
",non-flaky,5
112695,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerRollback() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(false);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint);
		conn.rollback(savePoint);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn, savePoint);
		TransactionManager tm = new TransactionManager(connectionSource);
		try {
			tm.callInTransaction(new Callable<Void>() {
				@Override
				public Void call() throws Exception {
					throw new SQLException(""you better roll back!!"");
				}
",non-flaky,5
112696,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerRollbackNullSavePoint() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(false);
		expect(conn.setSavePoint(isA(String.class))).andReturn(null);
		conn.rollback(null);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn);
		TransactionManager tm = new TransactionManager(connectionSource);
		try {
			tm.callInTransaction(new Callable<Void>() {
				@Override
				public Void call() throws Exception {
					throw new SQLException(""you better roll back!!"");
				}
",non-flaky,5
112697,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerRollbackOtherException() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(false);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint);
		conn.rollback(savePoint);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn, savePoint);
		TransactionManager tm = new TransactionManager(connectionSource);
		try {
			tm.callInTransaction(new Callable<Void>() {
				@Override
				public Void call() throws Exception {
					throw new Exception(""you better roll back!!"");
				}
",non-flaky,5
112698,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerAutoCommitSupported() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(true);
		expect(conn.isAutoCommit()).andReturn(false);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint);
		conn.commit(savePoint);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn, savePoint);
		TransactionManager tm = new TransactionManager(connectionSource);
		tm.callInTransaction(new Callable<Void>() {
			@Override
			public Void call() {
				return null;
			}
",non-flaky,5
112699,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerAutoCommitOn() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(true);
		expect(conn.isAutoCommit()).andReturn(true);
		conn.setAutoCommit(false);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint);
		conn.commit(savePoint);
		conn.setAutoCommit(true);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn, savePoint);
		TransactionManager tm = new TransactionManager(connectionSource);
		tm.callInTransaction(new Callable<Void>() {
			@Override
			public Void call() {
				return null;
			}
",non-flaky,5
112700,hwang-pku_ormlite-core,TransactionManagerTest.testTransactionManagerSpringWiring,"	@Test
	public void testTransactionManagerSpringWiring() {
		TransactionManager tm = new TransactionManager();
		tm.setConnectionSource(connectionSource);
		tm.initialize();
	}
",non-flaky,5
112701,hwang-pku_ormlite-core,TransactionManagerTest.testTransactionManagerNoSet,"	@Test(expected = IllegalStateException.class)
	public void testTransactionManagerNoSet() {
		TransactionManager tm = new TransactionManager();
		tm.initialize();
	}
",non-flaky,5
112702,hwang-pku_ormlite-core,TransactionManagerTest.testDaoTransactionManagerCommitted,"	@Test
	public void testDaoTransactionManagerCommitted() throws Exception {
		if (connectionSource == null) {
			return;
		}
		TransactionManager mgr = new TransactionManager(connectionSource);
		final Dao<Foo, Integer> fooDao = createDao(Foo.class, true);
		testTransactionManager(mgr, null, fooDao);
	}
",non-flaky,5
112703,hwang-pku_ormlite-core,TransactionManagerTest.testRollBack,"	@Test
	public void testRollBack() throws Exception {
		if (connectionSource == null) {
			return;
		}
		TransactionManager mgr = new TransactionManager(connectionSource);
		final Dao<Foo, Integer> fooDao = createDao(Foo.class, true);
		testTransactionManager(mgr, new RuntimeException(""What!!  I protest!!""), fooDao);
	}
",non-flaky,5
112704,hwang-pku_ormlite-core,TransactionManagerTest.testSpringWiredRollBack,"	@Test
	public void testSpringWiredRollBack() throws Exception {
		if (connectionSource == null) {
			return;
		}
		TransactionManager mgr = new TransactionManager();
		mgr.setConnectionSource(connectionSource);
		mgr.initialize();
		final Dao<Foo, Integer> fooDao = createDao(Foo.class, true);
		testTransactionManager(mgr, new RuntimeException(""What!!  I protest!!""), fooDao);
	}
",non-flaky,5
112705,hwang-pku_ormlite-core,TransactionManagerTest.testNonRuntimeExceptionWiredRollBack,"	@Test
	public void testNonRuntimeExceptionWiredRollBack() throws Exception {
		if (connectionSource == null) {
			return;
		}
		TransactionManager mgr = new TransactionManager();
		mgr.setConnectionSource(connectionSource);
		mgr.initialize();
		final Dao<Foo, Integer> dao = createDao(Foo.class, true);
		testTransactionManager(mgr, new Exception(""What!!  I protest via an Exception!!""), dao);
	}
",non-flaky,5
112706,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionWithinTransaction() throws Exception {
		if (connectionSource == null) {
			return;
		}
		final TransactionManager mgr = new TransactionManager(connectionSource);
		final Dao<Foo, Integer> dao = createDao(Foo.class, true);
		mgr.callInTransaction(new Callable<Void>() {
			@Override
			public Void call() throws Exception {
				testTransactionManager(mgr, null, dao);
				return null;
			}
",non-flaky,5
112707,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionWithinTransactionFails() throws Exception {
		if (connectionSource == null) {
			return;
		}
		final TransactionManager mgr = new TransactionManager(connectionSource);
		final Dao<Foo, Integer> dao = createDao(Foo.class, true);
		try {
			mgr.callInTransaction(new Callable<Void>() {
				@Override
				public Void call() throws Exception {
					dao.create(new Foo());
					mgr.callInTransaction(new Callable<Void>() {
						@Override
						public Void call() throws Exception {
							dao.create(new Foo());
							throw new SQLException(""Exception ahoy!"");
						}
",non-flaky,5
112708,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testConnectionLeakCreateList() throws Exception {
		final Dao<Foo, Integer> dao = createDao(Foo.class, true);
		final List<Foo> list = new ArrayList<Foo>();
		Foo foo1 = new Foo();
		foo1.val = 1;
		list.add(foo1);
		Foo foo2 = new Foo();
		foo2.val = 2;
		list.add(foo2);
		Foo foo3 = new Foo();
		foo3.val = 3;
		list.add(foo3);
		assertTrue(connectionSource.isOkay());
		assertEquals(0, connectionSource.getConnectionCount());
		TransactionManager.callInTransaction(connectionSource, new Callable<Boolean>() {
			@Override
			public Boolean call() throws Exception {
				return dao.create(list) >= 0;
			}
",non-flaky,5
112709,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testNestedTransactions() throws Exception {
		final Dao<Foo, Integer> dao = createDao(Foo.class, true);
		final Foo foo = new Foo();
		assertEquals(1, dao.create(foo));

		Foo result = dao.queryForId(foo.id);
		assertNotNull(result);

		try {
			TransactionManager.callInTransaction(connectionSource, new Callable<Void>() {
				@Override
				public Void call() throws Exception {
					TransactionManager.callInTransaction(connectionSource, new Callable<Void>() {
						@Override
						public Void call() throws Exception {
							dao.delete(foo);
							return null;
						}
",non-flaky,5
112710,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testNestedTransactionsReleaseFails() throws Exception {
		final ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(true).times(2);
		expect(conn.isAutoCommit()).andReturn(true).times(2);
		conn.setAutoCommit(false);
		expectLastCall().times(2);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint).times(2);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType).times(2);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn).times(2);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(false);
		// should only get one of these because we only returned save once
		connectionSource.clearSpecialConnection(conn);
		conn.releaseSavePoint(savePoint);
		expectLastCall().andThrow(new SQLException(""testing the release to fail""));
		conn.rollback(savePoint);
		expectLastCall().times(2);
		connectionSource.releaseConnection(conn);
		expectLastCall().times(2);
		conn.setAutoCommit(true);
		expectLastCall().times(2);

		replay(connectionSource, conn, savePoint);
		try {
			TransactionManager.callInTransaction(connectionSource, new Callable<Void>() {
				@Override
				public Void call() throws SQLException {
					TransactionManager.callInTransaction(connectionSource, new Callable<Void>() {
						@Override
						public Void call() {
							return null;
						}
",non-flaky,5
112711,hwang-pku_ormlite-core,BaseConnectionSourceTest.testBasicStuff,"	@Test
	public void testBasicStuff() throws Exception {
		OurConnectionSource cs = new OurConnectionSource();
		assertFalse(cs.isSavedConnection(createMock(DatabaseConnection.class)));
		DatabaseConnection conn = cs.getReadOnlyConnection(null);
		assertNotNull(conn);
		assertNull(cs.getSpecialConnection(null));
		cs.saveSpecialConnection(conn);
		assertSame(conn, cs.getSpecialConnection(null));
		assertTrue(cs.isSavedConnection(conn));
		assertFalse(cs.isSavedConnection(createMock(DatabaseConnection.class)));
		DatabaseConnection conn2 = cs.getReadOnlyConnection(null);
		assertSame(conn, conn2);
		assertNotNull(conn2);
		cs.clearSpecialConnection(conn);
		assertNull(cs.getSpecialConnection(null));
		assertFalse(cs.isSavedConnection(conn));
		assertNull(cs.getSavedConnection());
		cs.close();
	}
",non-flaky,5
112712,hwang-pku_ormlite-core,BaseConnectionSourceTest.testNestedSave,"	@Test
	public void testNestedSave() throws Exception {
		OurConnectionSource cs = new OurConnectionSource();
		DatabaseConnection conn = cs.getReadOnlyConnection(null);
		cs.saveSpecialConnection(conn);
		cs.saveSpecialConnection(conn);
		cs.clearSpecialConnection(conn);
		assertEquals(conn, cs.getSpecialConnection(null));
		cs.close();
	}
",non-flaky,5
112713,hwang-pku_ormlite-core,BaseConnectionSourceTest.testSaveDifferentConnection,"	@Test(expected = SQLException.class)
	public void testSaveDifferentConnection() throws Exception {
		OurConnectionSource cs = new OurConnectionSource();
		DatabaseConnection conn = cs.getReadOnlyConnection(null);
		cs.saveSpecialConnection(conn);
		cs.saveSpecialConnection(createMock(DatabaseConnection.class));
		cs.close();
	}
",non-flaky,5
112714,hwang-pku_ormlite-core,BaseConnectionSourceTest.testClearNone,"	@Test
	public void testClearNone() {
		OurConnectionSource cs = new OurConnectionSource();
		cs.clearSpecialConnection(createMock(DatabaseConnection.class));
		cs.close();
	}
",non-flaky,5
112715,hwang-pku_ormlite-core,BaseConnectionSourceTest.testClearDifferentConnection,"	@Test
	public void testClearDifferentConnection() throws Exception {
		OurConnectionSource cs = new OurConnectionSource();
		DatabaseConnection conn = cs.getReadOnlyConnection(null);
		cs.saveSpecialConnection(conn);
		cs.clearSpecialConnection(createMock(DatabaseConnection.class));
		cs.close();
	}
",non-flaky,5
112716,hwang-pku_ormlite-core,ReflectionDatabaseConnectionProxyFactoryTest.testBasic,"	@Test
	public void testBasic() throws Exception {
		Dao<Foo, Object> dao = createDao(Foo.class, true);
		Foo foo = new Foo();
		foo.val = 1131233;

		assertEquals(0, OurConnectionProxy.insertCount);
		assertEquals(1, dao.create(foo));
		assertEquals(1, OurConnectionProxy.insertCount);

		Foo result = dao.queryForId(foo.id);
		assertEquals(foo.val + VALUE_INCREMENT, result.val);
	}
",non-flaky,5
112717,hwang-pku_ormlite-core,DatabaseConnectionProxyFactoryTest.testBasic,"	@Test
	public void testBasic() throws Exception {
		Dao<Foo, Object> dao = createDao(Foo.class, true);
		Foo foo = new Foo();
		foo.val = 100;

		ConnectionProxy.lastValue = 0;
		assertEquals(1, dao.create(foo));
		/*
		 * After we create an instance of foo, we check to see that our proxy was able to intercept the val argument.
		 */
		assertEquals(foo.val, ConnectionProxy.lastValue);
	}
",non-flaky,5
112718,hwang-pku_ormlite-core,DatabaseConnectionProxyFactoryTest.testChangeInsertValue,"	@Test
	public void testChangeInsertValue() throws Exception {
		Dao<Foo, Object> dao = createDao(Foo.class, true);
		Foo foo = new Foo();
		foo.val = TEST_CHANGE_FROM;

		ConnectionProxy.lastValue = 0;
		assertEquals(1, dao.create(foo));
		/*
		 * After we create an instance of foo, we check to see that our proxy was able to intercept the val argument.
		 */
		assertEquals(foo.val, ConnectionProxy.lastValue);

		Foo result = dao.queryForId(foo.id);
		assertNotNull(result);
		assertEquals(TEST_CHANGE_TO, result.val);
		assertTrue(result.val != TEST_CHANGE_FROM);
	}
",non-flaky,5
112719,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsAutoCommitSupported,"	@Test
	public void testIsAutoCommitSupported() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		boolean supported = true;
		expect(conn.isAutoCommitSupported()).andReturn(supported);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(supported, proxy.isAutoCommitSupported());
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112720,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsAutoCommitSupportedNull,"	@Test
	public void testIsAutoCommitSupportedNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertFalse(proxy.isAutoCommitSupported());
		proxy.close();
	}
",non-flaky,5
112721,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsAutoCommit,"	@Test
	public void testIsAutoCommit() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		boolean autoCommit = false;
		expect(conn.isAutoCommit()).andReturn(autoCommit);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(autoCommit, proxy.isAutoCommit());
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112722,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsAutoCommitNull,"	@Test
	public void testIsAutoCommitNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertFalse(proxy.isAutoCommit());
		proxy.close();
	}
",non-flaky,5
112723,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testSetAutoCommit,"	@Test
	public void testSetAutoCommit() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		boolean autoCommit = false;
		conn.setAutoCommit(autoCommit);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.setAutoCommit(autoCommit);
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112724,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testSetAutoCommitNull,"	@Test
	public void testSetAutoCommitNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		proxy.setAutoCommit(false);
		proxy.close();
	}
",non-flaky,5
112725,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testSetSavePoint,"	@Test
	public void testSetSavePoint() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String name = ""savepoint"";
		expect(conn.setSavePoint(name)).andReturn(null);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.setSavePoint(name);
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112726,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testSetSavePointNull,"	@Test
	public void testSetSavePointNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertNull(proxy.setSavePoint(""name""));
		proxy.close();
	}
",non-flaky,5
112727,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCommit,"	@Test
	public void testCommit() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		conn.commit(null);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.commit(null);
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112728,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCommitNull,"	@Test
	public void testCommitNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		proxy.commit(null);
		proxy.close();
	}
",non-flaky,5
112729,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testRollback,"	@Test
	public void testRollback() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		conn.rollback(null);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.rollback(null);
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112730,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testRollbackNull,"	@Test
	public void testRollbackNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		proxy.rollback(null);
		proxy.close();
	}
",non-flaky,5
112731,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testExecuteStatement,"	@Test
	public void testExecuteStatement() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""select foo from bar"";
		int result = 1312321;
		expect(conn.executeStatement(statement, 0)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.executeStatement(statement, 0));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112732,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testExecuteStatementNull,"	@Test
	public void testExecuteStatementNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertEquals(0, proxy.executeStatement(""statment"", 0));
		proxy.close();
	}
",non-flaky,5
112733,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCompileStatementStringStatementTypeFieldTypeArrayInt,"	@Test
	public void testCompileStatementStringStatementTypeFieldTypeArrayInt() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""select foo from bar"";
		StatementType type = StatementType.DELETE;
		int flags = 11253123;
		expect(conn.compileStatement(statement, type, null, flags, false)).andReturn(null);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.compileStatement(statement, type, null, flags, false);
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112734,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCompileStatementStringStatementTypeFieldTypeArrayIntNull,"	@Test
	public void testCompileStatementStringStatementTypeFieldTypeArrayIntNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertNull(proxy.compileStatement(""statment"", StatementType.DELETE, null, 0, false));
		proxy.close();
	}
",non-flaky,5
112735,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testInsert,"	@Test
	public void testInsert() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""insert bar"";
		int result = 13712321;
		expect(conn.insert(statement, null, null, null)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.insert(statement, null, null, null));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112736,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testInsertNull,"	@Test
	public void testInsertNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertEquals(0, proxy.insert(""statment"", null, null, null));
		proxy.close();
	}
",non-flaky,5
112737,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testUpdate,"	@Test
	public void testUpdate() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""insert bar"";
		int result = 13212321;
		expect(conn.update(statement, null, null)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.update(statement, null, null));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112738,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testUpdateNull,"	@Test
	public void testUpdateNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertEquals(0, proxy.update(""statment"", null, null));
		proxy.close();
	}
",non-flaky,5
112739,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testDelete,"	@Test
	public void testDelete() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""insert bar"";
		int result = 13872321;
		expect(conn.delete(statement, null, null)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.delete(statement, null, null));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112740,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testDeleteNull,"	@Test
	public void testDeleteNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertEquals(0, proxy.delete(""statment"", null, null));
		proxy.close();
	}
",non-flaky,5
112741,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testQueryForOne,"	@Test
	public void testQueryForOne() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""insert bar"";
		Object result = new Object();
		expect(conn.queryForOne(statement, null, null, null, null)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.queryForOne(statement, null, null, null, null));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112742,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testQueryForOneNull,"	@Test
	public void testQueryForOneNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertNull(proxy.queryForOne(""statment"", null, null, null, null));
		proxy.close();
	}
",non-flaky,5
112743,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testQueryForLongString,"	@Test
	public void testQueryForLongString() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""select stuff from foo"";
		long result = 31231231241414L;
		expect(conn.queryForLong(statement)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.queryForLong(statement));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112744,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testQueryForLongStringNull,"	@Test
	public void testQueryForLongStringNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertEquals(0, proxy.queryForLong(""statment""));
		proxy.close();
	}
",non-flaky,5
112745,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testQueryForLongStringObjectArrayFieldTypeArray,"	@Test
	public void testQueryForLongStringObjectArrayFieldTypeArray() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""select stuff from foo"";
		long result = 3123123124141413L;
		expect(conn.queryForLong(statement, null, null)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.queryForLong(statement, null, null));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112746,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testQueryForLongStringObjectArrayFieldTypeArrayNull,"	@Test
	public void testQueryForLongStringObjectArrayFieldTypeArrayNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertEquals(0, proxy.queryForLong(""statment"", null, null));
		proxy.close();
	}
",non-flaky,5
112747,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testClose,"	@Test
	public void testClose() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112748,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCloseNull,"	@Test
	public void testCloseNull() throws Exception {
		new DatabaseConnectionProxy(null).close();
	}
",non-flaky,5
112749,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCloseQuietly,"	@Test
	public void testCloseQuietly() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		conn.closeQuietly();
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.closeQuietly();
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112750,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCloseQuietlyNull,"	@Test
	public void testCloseQuietlyNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		proxy.closeQuietly();
		proxy.close();
	}
",non-flaky,5
112751,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsClosed,"	@Test
	public void testIsClosed() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		boolean closed = true;
		expect(conn.isClosed()).andReturn(closed);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(closed, proxy.isClosed());
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112752,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsClosedNull,"	@Test
	public void testIsClosedNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertTrue(proxy.isClosed());
		proxy.close();
	}
",non-flaky,5
112753,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsTableExists,"	@Test
	public void testIsTableExists() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		boolean tableExists = true;
		String tableName = ""fjewfjwef"";
		expect(conn.isTableExists(tableName)).andReturn(tableExists);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(tableExists, proxy.isTableExists(tableName));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112754,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsTableExistsNull,"	@Test
	public void testIsTableExistsNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertFalse(proxy.isTableExists(""foo""));
		proxy.close();
	}
",non-flaky,5
112755,hwang-pku_ormlite-core,ThreadLocalSelectArgTest.testStuff,"	@Test
	public void testStuff() {
		ThreadLocalSelectArg arg = new ThreadLocalSelectArg();
		assertNull(arg.getValue());
		assertFalse(arg.isValueSet());
		arg.setValue(null);
		assertNull(arg.getValue());
		assertTrue(arg.isValueSet());
	}
",non-flaky,5
112756,hwang-pku_ormlite-core,ThreadLocalSelectArgTest.testValueConst,"	@Test
	public void testValueConst() {
		int val = 12;
		ThreadLocalSelectArg arg = new ThreadLocalSelectArg(val);
		assertTrue(arg.isValueSet());
		assertEquals(val, arg.getValue());
	}
",non-flaky,5
112757,hwang-pku_ormlite-core,ThreadLocalSelectArgTest.testSqlTypeValueConst,"	@Test
	public void testSqlTypeValueConst() {
		int val = 12;
		SqlType type = SqlType.INTEGER;
		ThreadLocalSelectArg arg = new ThreadLocalSelectArg(type, val);
		assertTrue(arg.isValueSet());
		assertEquals(val, arg.getValue());
		assertEquals(type, arg.getSqlType());
	}
",non-flaky,5
112758,hwang-pku_ormlite-core,ThreadLocalSelectArgTest.testColumnNameTypeValueConst,"	@Test
	public void testColumnNameTypeValueConst() {
		int val = 12;
		String columnName = ""fewopjfewpfjwe"";
		ThreadLocalSelectArg arg = new ThreadLocalSelectArg(columnName, val);
		assertTrue(arg.isValueSet());
		assertEquals(val, arg.getValue());
		assertEquals(columnName, arg.getColumnName());
	}
",non-flaky,5
112759,hwang-pku_ormlite-core,RawResultsImplTest.testQueryRaw,"	@Test
	public void testQueryRaw() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		Foo foo = new Foo();
		foo.val = 1;
		foo.equal = 10;
		assertEquals(1, dao.create(foo));
		QueryBuilder<Foo, Integer> qb = dao.queryBuilder();
		qb.where().eq(Foo.VAL_COLUMN_NAME, new SelectArg());
		GenericRawResults<String[]> rawResults = dao.queryRaw(qb.prepareStatementString(), Integer.toString(foo.val));
		List<String[]> results = rawResults.getResults();
		assertEquals(1, results.size());
		boolean found = false;
		String[] columnNames = rawResults.getColumnNames();
		for (int i = 0; i < rawResults.getNumberColumns(); i++) {
			if (columnNames[i].equalsIgnoreCase(Foo.ID_COLUMN_NAME)) {
				assertEquals(Integer.toString(foo.id), results.get(0)[0]);
				found = true;
			}
		}
		assertTrue(found);
	}
",non-flaky,5
112760,hwang-pku_ormlite-core,RawResultsImplTest.testQueryRawColumns,"	@Test
	public void testQueryRawColumns() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		Foo foo1 = new Foo();
		foo1.val = 1;
		foo1.equal = 10;
		assertEquals(1, dao.create(foo1));
		Foo foo2 = new Foo();
		foo2.val = 10;
		foo2.equal = 5;
		assertEquals(1, dao.create(foo2));
		QueryBuilder<Foo, Integer> qb = dao.queryBuilder();
		qb.selectRaw(""COUNT(*)"");
		GenericRawResults<String[]> rawResults = dao.queryRaw(qb.prepareStatementString());
		List<String[]> results = rawResults.getResults();
		assertEquals(1, results.size());
		// 2 rows inserted
		assertEquals(""2"", results.get(0)[0]);

		qb = dao.queryBuilder();
		qb.selectRaw(""MIN(val)"", ""MAX(val)"");
		rawResults = dao.queryRaw(qb.prepareStatementString());
		results = rawResults.getResults();
		assertEquals(1, results.size());
		String[] result = results.get(0);
		assertEquals(2, result.length);
		// foo1 has the maximum value
		assertEquals(Integer.toString(foo1.val), result[0]);
		// foo2 has the maximum value
		assertEquals(Integer.toString(foo2.val), result[1]);
	}
",non-flaky,5
112761,hwang-pku_ormlite-core,RawResultsImplTest.testHaving,"	@Test
	public void testHaving() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);

		Foo foo = new Foo();
		int val1 = 243342;
		foo.val = val1;
		assertEquals(1, dao.create(foo));
		foo = new Foo();
		foo.val = val1;
		assertEquals(1, dao.create(foo));
		foo = new Foo();
		// only one of these
		int val2 = 6543;
		foo.val = val2;
		assertEquals(1, dao.create(foo));

		QueryBuilder<Foo, Integer> qb = dao.queryBuilder();
		qb.selectColumns(Foo.VAL_COLUMN_NAME);
		qb.groupBy(Foo.VAL_COLUMN_NAME);
		qb.having(""COUNT(VAL) > 1"");
		GenericRawResults<String[]> results = dao.queryRaw(qb.prepareStatementString());
		List<String[]> list = results.getResults();
		// only val2 has 2 of them
		assertEquals(1, list.size());
		assertEquals(String.valueOf(val1), list.get(0)[0]);

		qb.having(""COUNT(VAL) > 2"");
		results = dao.queryRaw(qb.prepareStatementString());
		list = results.getResults();
		assertEquals(0, list.size());
	}
",non-flaky,5
112762,hwang-pku_ormlite-core,RawResultsImplTest.testGetFirstResult,"	@Test
	public void testGetFirstResult() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		Foo foo1 = new Foo();
		foo1.val = 342;
		assertEquals(1, dao.create(foo1));
		Foo foo2 = new Foo();
		foo2.val = 9045342;
		assertEquals(1, dao.create(foo2));

		QueryBuilder<Foo, Integer> qb = dao.queryBuilder();
		qb.selectRaw(""MAX("" + Foo.VAL_COLUMN_NAME + "")"");
		GenericRawResults<String[]> results = dao.queryRaw(qb.prepareStatementString());
		String[] result = results.getFirstResult();
		int max = Integer.parseInt(result[0]);
		if (foo1.val > foo2.val) {
			assertEquals(foo1.val, max);
		} else {
			assertEquals(foo2.val, max);
		}
	}
",non-flaky,5
112763,hwang-pku_ormlite-core,RawResultsImplTest.mapRow,"	@Test
	public void testCustomColumnNames() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		Foo foo = new Foo();
		foo.val = 1213213;
		assertEquals(1, dao.create(foo));
		final String idName = ""SOME_ID"";
		final String valName = ""SOME_VAL"";
		final AtomicBoolean gotResult = new AtomicBoolean(false);
		GenericRawResults<Object> results =
				dao.queryRaw(""select id as "" + idName + "", val as "" + valName + "" from foo"",
						new RawRowMapper<Object>() {
							@Override
							public Object mapRow(String[] columnNames, String[] resultColumns) {
								assertEquals(idName, columnNames[0]);
								assertEquals(valName, columnNames[1]);
								gotResult.set(true);
								return new Object();
							}
",non-flaky,5
112764,hwang-pku_ormlite-core,DeleteBuilderTest.testDeleteAll,"	@Test
	public void testDeleteAll() throws Exception {
		DeleteBuilder<Foo, Integer> stmtb = new DeleteBuilder<Foo, Integer>(databaseType, baseFooTableInfo, null);
		StringBuilder sb = new StringBuilder();
		sb.append(""DELETE FROM "");
		databaseType.appendEscapedEntityName(sb, baseFooTableInfo.getTableName());
		assertEquals(sb.toString(), stmtb.prepareStatementString());
	}
",non-flaky,5
112765,hwang-pku_ormlite-core,DeleteBuilderTest.testDeleteMethod,"	@Test
	public void testDeleteMethod() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		Foo foo = new Foo();
		foo.val = 123123;
		assertEquals(1, dao.create(foo));

		assertNotNull(dao.queryForId(foo.id));
		DeleteBuilder<Foo, Integer> db = dao.deleteBuilder();
		// no match
		db.where().eq(Foo.VAL_COLUMN_NAME, foo.val + 1);
		assertEquals(0, db.delete());
		assertNotNull(dao.queryForId(foo.id));

		db.where().reset();
		db.where().eq(Foo.VAL_COLUMN_NAME, foo.val);
		assertEquals(1, db.delete());
		assertNull(dao.queryForId(foo.id));
	}
",non-flaky,5
112766,hwang-pku_ormlite-core,DeleteBuilderTest.testUpdateLimit,"	@Test
	public void testUpdateLimit() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		int num = 3;
		for (int i = 0; i < num; i++) {
			dao.create(new Foo());
		}
		long limit = 2;
		assertEquals(limit, dao.deleteBuilder().limit(limit).delete());
		int count = (int) dao.countOf();
		assertEquals(num - limit, count);
		assertNotEquals(num, count);
	}
",non-flaky,5
112767,hwang-pku_ormlite-core,SelectIteratorTest.testIterator,"	@Test
	public void testIterator() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		CloseableIterator<Foo> iterator = dao.iterator();
		assertFalse(iterator.hasNext());

		Foo foo1 = new Foo();
		assertEquals(1, dao.create(foo1));

		Foo foo2 = new Foo();
		assertEquals(1, dao.create(foo2));

		iterator = dao.iterator();
		assertTrue(iterator.hasNext());
		Foo result = iterator.next();
		assertEquals(foo1.id, result.id);
		assertTrue(iterator.hasNext());

		result = iterator.next();
		assertEquals(foo2.id, result.id);

		assertFalse(iterator.hasNext());
		assertNull(iterator.nextThrow());
	}
",non-flaky,5
112768,hwang-pku_ormlite-core,SelectIteratorTest.testIteratorPrepared,"	@Test
	public void testIteratorPrepared() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		Foo foo1 = new Foo();
		assertEquals(1, dao.create(foo1));

		Foo foo2 = new Foo();
		assertEquals(1, dao.create(foo2));

		PreparedQuery<Foo> query = dao.queryBuilder().where().eq(Foo.ID_COLUMN_NAME, foo2.id).prepare();
		CloseableIterator<Foo> iterator = dao.iterator(query);
		assertTrue(iterator.hasNext());
		Foo result = iterator.next();
		assertEquals(foo2.id, result.id);
		assertFalse(iterator.hasNext());
		assertNull(iterator.nextThrow());
	}
",non-flaky,5
112769,hwang-pku_ormlite-core,SelectIteratorTest.testIteratorRemoveNoNext,"	@Test(expected = IllegalStateException.class)
	public void testIteratorRemoveNoNext() throws Exception {
		Dao<Foo, Object> dao = createDao(Foo.class, true);
		CloseableIterator<Foo> iterator = dao.iterator();
		try {
			iterator.remove();
		} finally {
			iterator.close();
		}
	}
",non-flaky,5
112770,hwang-pku_ormlite-core,SelectIteratorTest.testIteratorNextRemoveRemoveNoNext,"	@Test(expected = IllegalStateException.class)
	public void testIteratorNextRemoveRemoveNoNext() throws Exception {
		Dao<Foo, Object> dao = createDao(Foo.class, true);
		Foo foo1 = new Foo();
		assertEquals(1, dao.create(foo1));
		Foo foo2 = new Foo();
		assertEquals(1, dao.create(foo2));
		CloseableIterator<Foo> iterator = dao.iterator();
		try {
			iterator.next();
			iterator.remove();
			iterator.remove();
		} finally {
			iterator.close();
		}
	}
",non-flaky,5
32,apache_druid,ResponseContextTest.serializeWithTruncateArrayTest,"@Test
public void serializeWithTruncateArrayTest() throws IOException {
    final ResponseContext ctx = ResponseContext.createEmpty();
    ctx.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3), interval(4), interval(5), interval(6)));
    ctx.put(EXTN_STRING_KEY, Strings.repeat(""x"", INTERVAL_LEN * 7));
    final DefaultObjectMapper objectMapper = new DefaultObjectMapper();
    final String fullString = objectMapper.writeValueAsString(ctx.getDelegate());
    final ResponseContext.SerializationResult res1 = ctx.serializeWith(objectMapper, Integer.MAX_VALUE);
    Assert.assertEquals(fullString, res1.getResult());
    final int maxLen = ((((INTERVAL_LEN * 4) + UNCOVERED_INTERVALS.getName().length()) + 4) + TRUNCATED.getName().length()) + 6;
    final ResponseContext.SerializationResult res2 = ctx.serializeWith(objectMapper, maxLen);
    final ResponseContext ctxCopy = ResponseContext.createEmpty();
    ctxCopy.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3)));
    ctxCopy.put(TRUNCATED, true);
    Assert.assertEquals(ctxCopy.getDelegate(), deserializeContext(res2.getResult(), objectMapper));
}",unordered collections,3
317,apache_druid,KafkaLookupExtractorFactoryTest.testStartStop,"@Test
public void testStartStop() {
    final KafkaStream<String, String> kafkaStream = PowerMock.createStrictMock(KafkaStream.class);
    final ConsumerIterator<String, String> consumerIterator = PowerMock.createStrictMock(ConsumerIterator.class);
    final ConsumerConnector consumerConnector = PowerMock.createStrictMock(ConsumerConnector.class);
    EasyMock.expect(consumerConnector.createMessageStreamsByFilter(EasyMock.anyObject(TopicFilter.class), EasyMock.anyInt(), EasyMock.eq(DEFAULT_STRING_DECODER), EasyMock.eq(DEFAULT_STRING_DECODER))).andReturn(ImmutableList.of(kafkaStream)).once();
    EasyMock.expect(kafkaStream.iterator()).andReturn(consumerIterator).anyTimes();
    EasyMock.expect(consumerIterator.hasNext()).andAnswer(getBlockingAnswer()).anyTimes();
    EasyMock.expect(cacheManager.createCache()).andReturn(cacheHandler).once();
    EasyMock.expect(cacheHandler.getCache()).andReturn(new ConcurrentHashMap<String, String>()).once();
    cacheHandler.close();
    EasyMock.expectLastCall();
    final AtomicBoolean threadWasInterrupted = new AtomicBoolean(false);
    consumerConnector.shutdown();
    EasyMock.expectLastCall().andAnswer(new IAnswer<Object>() {
        @Override
        public Object answer() {
            threadWasInterrupted.set(Thread.currentThread().isInterrupted());
            return null;
        }
    }).times(2);
    PowerMock.replay(cacheManager, cacheHandler, kafkaStream, consumerConnector, consumerIterator);
    final KafkaLookupExtractorFactory factory = new KafkaLookupExtractorFactory(cacheManager, TOPIC, ImmutableMap.of(""zookeeper.connect"", ""localhost""), 10000L, false) {
        @Override
        ConsumerConnector buildConnector(Properties properties) {
            return consumerConnector;
        }
    };
    Assert.assertTrue(factory.start());
    Assert.assertTrue(factory.close());
    Assert.assertTrue(factory.getFuture().isDone());
    Assert.assertFalse(threadWasInterrupted.get());
    PowerMock.verify(cacheManager, cacheHandler);
}",concurrency,1
60862,apache_druid,DistinctCountTopNQueryTest.testTopNWithDistinctCountAgg,"  @Test
  public void testTopNWithDistinctCountAgg() throws Exception
  {
    TopNQueryEngine engine = new TopNQueryEngine(pool);

    IncrementalIndex index = new OnheapIncrementalIndex.Builder()
        .setIndexSchema(
            new IncrementalIndexSchema.Builder()
                .withQueryGranularity(Granularities.SECOND)
                .withMetrics(new CountAggregatorFactory(""cnt""))
                .build()
        )
        .setMaxRowCount(1000)
        .build();

    String visitor_id = ""visitor_id"";
    String client_type = ""client_type"";
    DateTime time = DateTimes.of(""2016-03-04T00:00:00.000Z"");
    long timestamp = time.getMillis();
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""0"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""1"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""2"", client_type, ""android"")
        )
    );

    TopNQuery query = new TopNQueryBuilder().dataSource(QueryRunnerTestHelper.DATA_SOURCE)
                          .granularity(QueryRunnerTestHelper.ALL_GRAN)
                          .intervals(QueryRunnerTestHelper.FULL_ON_INTERVAL_SPEC)
                          .dimension(client_type)
                          .metric(""UV"")
                          .threshold(10)
                          .aggregators(
                              QueryRunnerTestHelper.ROWS_COUNT,
                              new DistinctCountAggregatorFactory(""UV"", visitor_id, null)
                          )
                          .build();

    final Iterable<Result<TopNResultValue>> results =
        engine.query(query, new IncrementalIndexStorageAdapter(index), null).toList();

    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(
        new Result<>(
            time,
            new TopNResultValue(
                Arrays.<Map<String, Object>>asList(
                    ImmutableMap.of(
                        client_type, ""iphone"",
                        ""UV"", 2L,
                        ""rows"", 2L
                    ),
                    ImmutableMap.of(
                        client_type, ""android"",
                        ""UV"", 1L,
                        ""rows"", 1L
                    )
                )
            )
        )
    );
    TestHelper.assertExpectedResults(expectedResults, results);
  }
",non-flaky,5
60863,apache_druid,DistinctCountTimeseriesQueryTest.testTimeseriesWithDistinctCountAgg,"  @Test
  public void testTimeseriesWithDistinctCountAgg() throws Exception
  {
    TimeseriesQueryEngine engine = new TimeseriesQueryEngine();

    IncrementalIndex index = new OnheapIncrementalIndex.Builder()
        .setIndexSchema(
            new IncrementalIndexSchema.Builder()
                .withQueryGranularity(Granularities.SECOND)
                .withMetrics(new CountAggregatorFactory(""cnt""))
                .build()
        )
        .setMaxRowCount(1000)
        .build();

    String visitor_id = ""visitor_id"";
    String client_type = ""client_type"";
    DateTime time = DateTimes.of(""2016-03-04T00:00:00.000Z"");
    long timestamp = time.getMillis();
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""0"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""1"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""2"", client_type, ""android"")
        )
    );

    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()
                                  .dataSource(QueryRunnerTestHelper.DATA_SOURCE)
                                  .granularity(QueryRunnerTestHelper.ALL_GRAN)
                                  .intervals(QueryRunnerTestHelper.FULL_ON_INTERVAL_SPEC)
                                  .aggregators(
                                      Lists.newArrayList(
                                          QueryRunnerTestHelper.ROWS_COUNT,
                                          new DistinctCountAggregatorFactory(""UV"", visitor_id, null)
                                      )
                                  )
                                  .build();

    final Iterable<Result<TimeseriesResultValue>> results =
        engine.process(query, new IncrementalIndexStorageAdapter(index)).toList();

    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(
        new Result<>(
            time,
            new TimeseriesResultValue(
                ImmutableMap.of(""UV"", 3, ""rows"", 3L)
            )
        )
    );
    TestHelper.assertExpectedResults(expectedResults, results);
  }
",non-flaky,5
60864,apache_druid,DistinctCountGroupByQueryTest.testGroupByWithDistinctCountAgg,"  @Test
  public void testGroupByWithDistinctCountAgg() throws Exception
  {
    IncrementalIndex index = new OnheapIncrementalIndex.Builder()
        .setIndexSchema(
            new IncrementalIndexSchema.Builder()
                .withQueryGranularity(Granularities.SECOND)
                .withMetrics(new CountAggregatorFactory(""cnt""))
                .build()
        )
        .setConcurrentEventAdd(true)
        .setMaxRowCount(1000)
        .build();

    String visitor_id = ""visitor_id"";
    String client_type = ""client_type"";
    long timestamp = DateTimes.of(""2010-01-01"").getMillis();
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""0"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp + 1,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""1"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp + 2,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""2"", client_type, ""android"")
        )
    );

    GroupByQuery query = new GroupByQuery.Builder()
        .setDataSource(QueryRunnerTestHelper.DATA_SOURCE)
        .setGranularity(QueryRunnerTestHelper.ALL_GRAN)
        .setDimensions(new DefaultDimensionSpec(
            client_type,
            client_type
        ))
        .setInterval(QueryRunnerTestHelper.FULL_ON_INTERVAL_SPEC)
        .setLimitSpec(
            new DefaultLimitSpec(
                Collections.singletonList(new OrderByColumnSpec(client_type, OrderByColumnSpec.Direction.DESCENDING)),
                10
            )
        )
        .setAggregatorSpecs(QueryRunnerTestHelper.ROWS_COUNT, new DistinctCountAggregatorFactory(""UV"", visitor_id, null))
        .build();
    final Segment incrementalIndexSegment = new IncrementalIndexSegment(index, null);

    Iterable<ResultRow> results = GroupByQueryRunnerTestHelper.runQuery(
        factory,
        factory.createRunner(incrementalIndexSegment),
        query
    );

    List<ResultRow> expectedResults = Arrays.asList(
        GroupByQueryRunnerTestHelper.createExpectedRow(
            query,
            ""1970-01-01T00:00:00.000Z"",
            client_type, ""iphone"",
            ""UV"", 2L,
            ""rows"", 2L
        ),
        GroupByQueryRunnerTestHelper.createExpectedRow(
            query,
            ""1970-01-01T00:00:00.000Z"",
            client_type, ""android"",
            ""UV"", 1L,
            ""rows"", 1L
        )
    );
    TestHelper.assertExpectedObjects(expectedResults, results, ""distinct-count"");
  }
",non-flaky,5
60865,apache_druid,RedisCacheConfigTest.testClusterPriority,"  @Test
  public void testClusterPriority() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(""{\""expiration\"": 1000,""
                                                 + ""\""cluster\"": {""
                                                 + ""\""nodes\"": \""127.0.0.1:6379\""""
                                                 + ""},""
                                                 + ""\""host\"": \""127.0.0.1\"",""
                                                 + ""\""port\"": 6379""
                                                 + ""}"", RedisCacheConfig.class);

    try (Cache cache = RedisCacheFactory.create(fromJson)) {
      Assert.assertTrue(cache instanceof RedisClusterCache);
    }
  }
",non-flaky,5
60866,apache_druid,RedisCacheConfigTest.testClusterInvalidNode,"  @Test
  public void testClusterInvalidNode() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(
        ""{\""expiration\"": 1000,""
        + ""\""cluster\"": {""
        + ""\""nodes\"": \""127.0.0.1\"""" //<===Invalid Node
        + ""}""
        + ""}"",
        RedisCacheConfig.class
    );

    expectedException.expect(new ExceptionMatcher(
        IAE.class,
        new StartWithMatcher(""Invalid redis cluster"")
    ));
    RedisCacheFactory.create(fromJson);
  }
",non-flaky,5
60867,apache_druid,RedisCacheConfigTest.testClusterLackOfPort,"  @Test
  public void testClusterLackOfPort() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(
        ""{\""expiration\"":1000,""
        + ""\""cluster\"": {""
        + ""\""nodes\"": \""127.0.0.1:\""""
        + ""}""
        + ""}"",
        RedisCacheConfig.class
    );

    expectedException.expect(new ExceptionMatcher(
        IAE.class,
        new StartWithMatcher(""Invalid port"")
    ));
    RedisCacheFactory.create(fromJson);
  }
",non-flaky,5
60868,apache_druid,RedisCacheConfigTest.testInvalidClusterNodePort0,"  @Test
  public void testInvalidClusterNodePort0() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(
        ""{\""expiration\"": 1000,""
        + ""\""cluster\"": {""
        + ""\""nodes\"": \""127.0.0.1:0\"""" //<===Invalid Port
        + ""}""
        + ""}"",
        RedisCacheConfig.class
    );

    expectedException.expect(new ExceptionMatcher(
        IAE.class,
        new ContainsMatcher(""Invalid port"")
    ));
    RedisCacheFactory.create(fromJson);
  }
",non-flaky,5
60869,apache_druid,RedisCacheConfigTest.testInvalidClusterNodePort65536,"  @Test
  public void testInvalidClusterNodePort65536() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(
        ""{\""expiration\"": 1000,""
        + ""\""cluster\"": {""
        + ""\""nodes\"": \""127.0.0.1:65536\"""" //<===Invalid Port
        + ""}""
        + ""}"",
        RedisCacheConfig.class
    );

    expectedException.expect(new ExceptionMatcher(
        IAE.class,
        new ContainsMatcher(""Invalid port"")
    ));
    RedisCacheFactory.create(fromJson);
  }
",non-flaky,5
60870,apache_druid,RedisCacheConfigTest.testNoClusterAndHost,"  @Test
  public void testNoClusterAndHost() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(
        ""{\""expiration\"": 1000""
        + ""}"",
        RedisCacheConfig.class
    );

    expectedException.expect(new ExceptionMatcher(
        IAE.class,
        new ContainsMatcher(""no redis server"")
    ));
    RedisCacheFactory.create(fromJson);
  }
",non-flaky,5
60871,apache_druid,RedisClusterCacheTest.testConfig,"  @Test
  public void testConfig() throws JsonProcessingException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(""{\""expiration\"": 1000}"", RedisCacheConfig.class);
    Assert.assertEquals(1, fromJson.getExpiration().getSeconds());

    fromJson = mapper.readValue(""{\""expiration\"": \""PT1H\""}"", RedisCacheConfig.class);
    Assert.assertEquals(3600, fromJson.getExpiration().getSeconds());
  }
",non-flaky,5
60872,apache_druid,RedisClusterCacheTest.testCache,"  @Test
  public void testCache()
  {
    Assert.assertNull(cache.get(new Cache.NamedKey(""the"", HI)));

    Cache.NamedKey key1 = new Cache.NamedKey(""the"", HI);
    Cache.NamedKey key2 = new Cache.NamedKey(""the"", HO);
    Cache.NamedKey key3 = new Cache.NamedKey(""a"", HI);
    Cache.NamedKey notExist = new Cache.NamedKey(""notExist"", HI);

    //test put and get
    cache.put(key1, new byte[]{1, 2, 3, 4});
    cache.put(key2, new byte[]{2, 3, 4, 5});
    cache.put(key3, new byte[]{3, 4, 5, 6});
    Assert.assertEquals(0x01020304, Ints.fromByteArray(cache.get(key1)));
    Assert.assertEquals(0x02030405, Ints.fromByteArray(cache.get(key2)));
    Assert.assertEquals(0x03040506, Ints.fromByteArray(cache.get(key3)));
    Assert.assertEquals(0x03040506, Ints.fromByteArray(cache.get(key3)));
    Assert.assertNull(cache.get(notExist));

    this.mgetCount.set(0);

    //test multi get
    Map<Cache.NamedKey, byte[]> result = cache.getBulk(
        Lists.newArrayList(
            key1,
            key2,
            key3,
            notExist
        )
    );

    // these 4 keys are distributed among different nodes, so there should be 4 times call of MGET
    Assert.assertEquals(mgetCount.get(), 4);
    Assert.assertEquals(result.size(), 3);
    Assert.assertEquals(0x01020304, Ints.fromByteArray(result.get(key1)));
    Assert.assertEquals(0x02030405, Ints.fromByteArray(result.get(key2)));
    Assert.assertEquals(0x03040506, Ints.fromByteArray(result.get(key3)));
  }
",non-flaky,5
60873,apache_druid,RedisStandaloneCacheTest.testBasicInjection,"  @Test
  public void testBasicInjection() throws Exception
  {
    String json = ""{ \""host\"": \""localhost\"", \""port\"": 6379, \""expiration\"": 3600}"";
    final RedisCacheConfig config = new ObjectMapper().readValue(json, RedisCacheConfig.class);

    Injector injector = Initialization.makeInjectorWithModules(
        GuiceInjectors.makeStartupInjector(), ImmutableList.of(
            binder -> {
              binder.bindConstant().annotatedWith(Names.named(""serviceName"")).to(""druid/test/redis"");
              binder.bindConstant().annotatedWith(Names.named(""servicePort"")).to(0);
              binder.bindConstant().annotatedWith(Names.named(""tlsServicePort"")).to(-1);

              binder.bindConstant().annotatedWith(Names.named(""host"")).to(""localhost"");
              binder.bindConstant().annotatedWith(Names.named(""port"")).to(6379);

              binder.bind(RedisCacheConfig.class).toInstance(config);
              binder.bind(Cache.class).toProvider(RedisCacheProviderWithConfig.class).in(ManageLifecycle.class);
            }
        )
    );
    Lifecycle lifecycle = injector.getInstance(Lifecycle.class);
    lifecycle.start();
    try {
      Cache cache = injector.getInstance(Cache.class);
      Assert.assertEquals(RedisStandaloneCache.class, cache.getClass());
    }
    finally {
      lifecycle.stop();
    }
  }
",non-flaky,5
60874,apache_druid,RedisStandaloneCacheTest.testSimpleInjection,"  @Test
  public void testSimpleInjection()
  {
    final String uuid = UUID.randomUUID().toString();
    System.setProperty(uuid + "".type"", ""redis"");
    final Injector injector = Initialization.makeInjectorWithModules(
        GuiceInjectors.makeStartupInjector(), ImmutableList.of(
            binder -> {
              binder.bindConstant().annotatedWith(Names.named(""serviceName"")).to(""druid/test/redis"");
              binder.bindConstant().annotatedWith(Names.named(""servicePort"")).to(0);
              binder.bindConstant().annotatedWith(Names.named(""tlsServicePort"")).to(-1);

              binder.bind(Cache.class).toProvider(CacheProvider.class);
              JsonConfigProvider.bind(binder, uuid, CacheProvider.class);
            }
        )
    );
    final CacheProvider cacheProvider = injector.getInstance(CacheProvider.class);
    Assert.assertNotNull(cacheProvider);
    Assert.assertEquals(RedisCacheProvider.class, cacheProvider.getClass());
  }
",non-flaky,5
60875,apache_druid,RedisStandaloneCacheTest.testSanity,"  @Test
  public void testSanity()
  {
    Assert.assertNull(cache.get(new Cache.NamedKey(""a"", HI)));
    put(cache, ""a"", HI, 0);
    Assert.assertEquals(0, get(cache, ""a"", HI));
    Assert.assertNull(cache.get(new Cache.NamedKey(""the"", HI)));

    put(cache, ""the"", HI, 1);
    Assert.assertEquals(0, get(cache, ""a"", HI));
    Assert.assertEquals(1, get(cache, ""the"", HI));

    put(cache, ""the"", HO, 10);
    Assert.assertEquals(0, get(cache, ""a"", HI));
    Assert.assertNull(cache.get(new Cache.NamedKey(""a"", HO)));
    Assert.assertEquals(1, get(cache, ""the"", HI));
    Assert.assertEquals(10, get(cache, ""the"", HO));

    cache.close(""the"");
    Assert.assertEquals(0, get(cache, ""a"", HI));
    Assert.assertNull(cache.get(new Cache.NamedKey(""a"", HO)));
  }
",non-flaky,5
60876,apache_druid,RedisStandaloneCacheTest.testGetBulk,"  @Test
  public void testGetBulk()
  {
    Assert.assertNull(cache.get(new Cache.NamedKey(""the"", HI)));

    put(cache, ""the"", HI, 1);
    put(cache, ""the"", HO, 10);

    Cache.NamedKey key1 = new Cache.NamedKey(""the"", HI);
    Cache.NamedKey key2 = new Cache.NamedKey(""the"", HO);
    Cache.NamedKey key3 = new Cache.NamedKey(""a"", HI);

    Map<Cache.NamedKey, byte[]> result = cache.getBulk(
        Lists.newArrayList(
            key1,
            key2,
            key3
        )
    );

    Assert.assertEquals(1, Ints.fromByteArray(result.get(key1)));
    Assert.assertEquals(10, Ints.fromByteArray(result.get(key2)));
    Assert.assertEquals(null, result.get(key3));
  }
",non-flaky,5
60877,apache_druid,InfluxParserTest.testParse,"  @Test
  public void testParse(String name, String input, Parsed expected)
  {
    Parser<String, Object> parser = new InfluxParser(null);
    Map<String, Object> parsed = parser.parseToMap(input);
    MatcherAssert.assertThat(
        ""correct measurement name"",
        parsed.get(""measurement""),
        Matchers.equalTo(expected.measurement)
    );
    MatcherAssert.assertThat(
        ""correct timestamp"",
        parsed.get(InfluxParser.TIMESTAMP_KEY),
        Matchers.equalTo(expected.timestamp)
    );
    expected.kv.forEach((k, v) -> MatcherAssert.assertThat(""correct field "" + k, parsed.get(k), Matchers.equalTo(v)));
    parsed.remove(""measurement"");
    parsed.remove(InfluxParser.TIMESTAMP_KEY);
    MatcherAssert.assertThat(""No extra keys in parsed data"", parsed.keySet(), Matchers.equalTo(expected.kv.keySet()));
  }
",non-flaky,5
60878,apache_druid,InfluxParserTest.testParseWhitelistPass,"  @Test
  public void testParseWhitelistPass()
  {
    Parser<String, Object> parser = new InfluxParser(Sets.newHashSet(""cpu""));
    String input = ""cpu,host=foo.bar.baz,region=us-east,application=echo pct_idle=99.3,pct_user=88.8,m1_load=2 1465839830100400200"";
    Map<String, Object> parsed = parser.parseToMap(input);
    MatcherAssert.assertThat(parsed.get(""measurement""), Matchers.equalTo(""cpu""));
  }
",non-flaky,5
60879,apache_druid,InfluxParserTest.testParseWhitelistFail,"  @Test
  public void testParseWhitelistFail()
  {
    Parser<String, Object> parser = new InfluxParser(Sets.newHashSet(""mem""));
    String input = ""cpu,host=foo.bar.baz,region=us-east,application=echo pct_idle=99.3,pct_user=88.8,m1_load=2 1465839830100400200"";
    try {
      parser.parseToMap(input);
    }
    catch (ParseException t) {
      MatcherAssert.assertThat(t, Matchers.isA(ParseException.class));
      return;
    }

    Assert.fail(""Exception not thrown"");
  }
",non-flaky,5
60880,apache_druid,InfluxParserTest.testParseFailures,"  @Test
  public void testParseFailures(Pair<String, String> testCase)
  {
    Parser<String, Object> parser = new InfluxParser(null);
    try {
      parser.parseToMap(testCase.rhs);
    }
    catch (ParseException t) {
      MatcherAssert.assertThat(t, Matchers.isA(ParseException.class));
      return;
    }

    Assert.fail(testCase.rhs + "": exception not thrown"");
  }
",non-flaky,5
60881,apache_druid,MaterializedViewSupervisorTest.testCheckSegments,"  @Test
  public void testCheckSegments() throws IOException
  {
    Set<DataSegment> baseSegments = Sets.newHashSet(
        new DataSegment(
            ""base"",
            Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""),
            ""2015-01-02"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        ),
        new DataSegment(
            ""base"",
            Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
            ""2015-01-03"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        ),
        new DataSegment(
            ""base"",
            Intervals.of(""2015-01-03T00Z/2015-01-04T00Z""),
            ""2015-01-04"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        )
    );
    Set<DataSegment> derivativeSegments = Sets.newHashSet(
        new DataSegment(
            derivativeDatasourceName,
            Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""),
            ""2015-01-02"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        ),
        new DataSegment(
            derivativeDatasourceName,
            Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
            ""3015-01-01"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        )
    );
    indexerMetadataStorageCoordinator.announceHistoricalSegments(baseSegments);
    indexerMetadataStorageCoordinator.announceHistoricalSegments(derivativeSegments);
    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();
    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.absent()).anyTimes();
    EasyMock.expect(taskStorage.getActiveTasks()).andReturn(ImmutableList.of()).anyTimes();
    Pair<SortedMap<Interval, String>, Map<Interval, List<DataSegment>>> toBuildInterval = supervisor.checkSegments();
    Set<Interval> expectedToBuildInterval = Sets.newHashSet(Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""));
    Map<Interval, List<DataSegment>> expectedSegments = new HashMap<>();
    expectedSegments.put(
        Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""),
        Collections.singletonList(
            new DataSegment(
                ""base"",
                Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""),
                ""2015-01-02"",
                ImmutableMap.of(),
                ImmutableList.of(""dim1"", ""dim2""),
                ImmutableList.of(""m1""),
                new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
                9,
                1024
            )
        )
    );
    expectedSegments.put(
        Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
        Collections.singletonList(
            new DataSegment(
                ""base"",
                Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
                ""2015-01-03"",
                ImmutableMap.of(),
                ImmutableList.of(""dim1"", ""dim2""),
                ImmutableList.of(""m1""),
                new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
                9,
                1024
            )
        )
    );
    Assert.assertEquals(expectedToBuildInterval, toBuildInterval.lhs.keySet());
    Assert.assertEquals(expectedSegments, toBuildInterval.rhs);
  }
",non-flaky,5
60882,apache_druid,MaterializedViewSupervisorTest.testCheckSegmentsAndSubmitTasks,"  @Test
  public void testCheckSegmentsAndSubmitTasks() throws IOException
  {
    Set<DataSegment> baseSegments = Sets.newHashSet(
        new DataSegment(
            ""base"",
            Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
            ""2015-01-03"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        )
    );
    indexerMetadataStorageCoordinator.announceHistoricalSegments(baseSegments);
    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();
    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.absent()).anyTimes();
    EasyMock.expect(taskStorage.getActiveTasks()).andReturn(ImmutableList.of()).anyTimes();
    EasyMock.expect(taskStorage.getStatus(""test_task1""))
            .andReturn(Optional.of(TaskStatus.failure(""test_task1"", ""Dummy task status failure err message"")))
            .anyTimes();
    EasyMock.expect(taskStorage.getStatus(""test_task2""))
            .andReturn(Optional.of(TaskStatus.running(""test_task2"")))
            .anyTimes();
    EasyMock.replay(taskStorage);

    Pair<Map<Interval, HadoopIndexTask>, Map<Interval, String>> runningTasksPair = supervisor.getRunningTasks();
    Map<Interval, HadoopIndexTask> runningTasks = runningTasksPair.lhs;
    Map<Interval, String> runningVersion = runningTasksPair.rhs;

    DataSchema dataSchema = new DataSchema(
        ""test_datasource"",
        null,
        null,
        null,
        TransformSpec.NONE,
        objectMapper
    );
    HadoopIOConfig hadoopIOConfig = new HadoopIOConfig(new HashMap<>(), null, null);
    HadoopIngestionSpec spec = new HadoopIngestionSpec(dataSchema, hadoopIOConfig, null);
    HadoopIndexTask task1 = new HadoopIndexTask(
        ""test_task1"",
        spec,
        null,
        null,
        null,
        objectMapper,
        null,
        null,
        null
    );
    runningTasks.put(Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""), task1);
    runningVersion.put(Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""), ""test_version1"");

    HadoopIndexTask task2 = new HadoopIndexTask(
        ""test_task2"",
        spec,
        null,
        null,
        null,
        objectMapper,
        null,
        null,
        null
    );
    runningTasks.put(Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""), task2);
    runningVersion.put(Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""), ""test_version2"");

    supervisor.checkSegmentsAndSubmitTasks();

    Map<Interval, HadoopIndexTask> expectedRunningTasks = new HashMap<>();
    Map<Interval, String> expectedRunningVersion = new HashMap<>();
    expectedRunningTasks.put(Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""), task2);
    expectedRunningVersion.put(Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""), ""test_version2"");

    Assert.assertEquals(expectedRunningTasks, runningTasks);
    Assert.assertEquals(expectedRunningVersion, runningVersion);

  }
",non-flaky,5
60883,apache_druid,MaterializedViewSupervisorTest.testCreateTask,"  @Test
  public void testCreateTask()
  {
    List<DataSegment> baseSegments = Collections.singletonList(
        new DataSegment(
            ""base"",
            Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
            ""2015-01-03"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        )
    );

    HadoopIndexTask task = spec.createTask(
        Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
        ""2015-01-03"",
        baseSegments
    );

    Assert.assertNotNull(task);
  }
",non-flaky,5
60884,apache_druid,MaterializedViewSupervisorTest.testSuspendedDoesntRun,"  @Test
  public void testSuspendedDoesntRun()
  {
    MaterializedViewSupervisorSpec suspended = new MaterializedViewSupervisorSpec(
        ""base"",
        new DimensionsSpec(Collections.singletonList(new StringDimensionSchema(""dim"")), null, null),
        new AggregatorFactory[]{new LongSumAggregatorFactory(""m1"", ""m1"")},
        HadoopTuningConfig.makeDefaultTuningConfig(),
        null,
        null,
        null,
        null,
        null,
        true,
        objectMapper,
        taskMaster,
        taskStorage,
        metadataSupervisorManager,
        sqlSegmentsMetadataManager,
        indexerMetadataStorageCoordinator,
        new MaterializedViewTaskConfig(),
        EasyMock.createMock(AuthorizerMapper.class),
        EasyMock.createMock(ChatHandlerProvider.class),
        new SupervisorStateManagerConfig()
    );
    MaterializedViewSupervisor supervisor = (MaterializedViewSupervisor) suspended.createSupervisor();

    // mock IndexerSQLMetadataStorageCoordinator to ensure that retrieveDataSourceMetadata is not called
    // which will be true if truly suspended, since this is the first operation of the 'run' method otherwise
    IndexerSQLMetadataStorageCoordinator mock = EasyMock.createMock(IndexerSQLMetadataStorageCoordinator.class);
    EasyMock.expect(mock.retrieveDataSourceMetadata(suspended.getDataSourceName()))
            .andAnswer(() -> {
              Assert.fail();
              return null;
            })
            .anyTimes();

    EasyMock.replay(mock);
    supervisor.run();
  }
",non-flaky,5
60885,apache_druid,DerivativeDataSourceMetadataTest.testEmptyBaseDataSource,"  @Test
  public void testEmptyBaseDataSource()
  {
    expectedException.expect(CoreMatchers.instanceOf(IllegalArgumentException.class));
    expectedException.expectMessage(
        ""baseDataSource cannot be null or empty. Please provide a baseDataSource.""
    );
    String baseDataSource = """";
    Set<String> dims = Sets.newHashSet(""dim1"", ""dim2"", ""dim3"");
    Set<String> metrics = Sets.newHashSet(""cost"");
    DerivativeDataSourceMetadata metadata = new DerivativeDataSourceMetadata(baseDataSource, dims, metrics);
  }
",non-flaky,5
60886,apache_druid,DerivativeDataSourceMetadataTest.testNullBaseDataSource,"  @Test
  public void testNullBaseDataSource()
  {
    expectedException.expect(CoreMatchers.instanceOf(IllegalArgumentException.class));
    expectedException.expectMessage(
        ""baseDataSource cannot be null or empty. Please provide a baseDataSource.""
    );
    String baseDataSource = null;
    Set<String> dims = Sets.newHashSet(""dim1"", ""dim2"", ""dim3"");
    Set<String> metrics = Sets.newHashSet(""cost"");
    DerivativeDataSourceMetadata metadata = new DerivativeDataSourceMetadata(baseDataSource, dims, metrics);
  }
",non-flaky,5
60887,apache_druid,MaterializedViewSupervisorSpecTest.testSupervisorSerialization,"  @Test
  public void testSupervisorSerialization() throws IOException
  {
    String supervisorStr = ""{\n"" +
                           ""  \""type\"" : \""derivativeDataSource\"",\n"" +
                           ""  \""baseDataSource\"": \""wikiticker\"",\n"" +
                           ""  \""dimensionsSpec\"":{\n"" +
                           ""            \""dimensions\"" : [\n"" +
                           ""              \""isUnpatrolled\"",\n"" +
                           ""              \""metroCode\"",\n"" +
                           ""              \""namespace\"",\n"" +
                           ""              \""page\"",\n"" +
                           ""              \""regionIsoCode\"",\n"" +
                           ""              \""regionName\"",\n"" +
                           ""              \""user\""\n"" +
                           ""            ]\n"" +
                           ""          },\n"" +
                           ""    \""metricsSpec\"" : [\n"" +
                           ""        {\n"" +
                           ""          \""name\"" : \""count\"",\n"" +
                           ""          \""type\"" : \""count\""\n"" +
                           ""        },\n"" +
                           ""        {\n"" +
                           ""          \""name\"" : \""added\"",\n"" +
                           ""          \""type\"" : \""longSum\"",\n"" +
                           ""          \""fieldName\"" : \""added\""\n"" +
                           ""        }\n"" +
                           ""      ],\n"" +
                           ""  \""tuningConfig\"": {\n"" +
                           ""      \""type\"" : \""hadoop\""\n"" +
                           ""  }\n"" +
                           ""}"";
    MaterializedViewSupervisorSpec expected = new MaterializedViewSupervisorSpec(
        ""wikiticker"",
        new DimensionsSpec(
            Lists.newArrayList(
                new StringDimensionSchema(""isUnpatrolled""),
                new StringDimensionSchema(""metroCode""),
                new StringDimensionSchema(""namespace""),
                new StringDimensionSchema(""page""),
                new StringDimensionSchema(""regionIsoCode""),
                new StringDimensionSchema(""regionName""),
                new StringDimensionSchema(""user"")
            ),
            null,
            null
        ),
        new AggregatorFactory[]{
            new CountAggregatorFactory(""count""),
            new LongSumAggregatorFactory(""added"", ""added"")
        },
        HadoopTuningConfig.makeDefaultTuningConfig(),
        null,
        null,
        null,
        null,
        null,
        false,
        objectMapper,
        null,
        null,
        null,
        null,
        null,
        new MaterializedViewTaskConfig(),
        EasyMock.createMock(AuthorizerMapper.class),
        new NoopChatHandlerProvider(),
        new SupervisorStateManagerConfig()
    );
    MaterializedViewSupervisorSpec spec = objectMapper.readValue(supervisorStr, MaterializedViewSupervisorSpec.class);
    Assert.assertEquals(expected.getBaseDataSource(), spec.getBaseDataSource());
    Assert.assertEquals(expected.getId(), spec.getId());
    Assert.assertEquals(expected.getDataSourceName(), spec.getDataSourceName());
    Assert.assertEquals(expected.getDimensions(), spec.getDimensions());
    Assert.assertEquals(expected.getMetrics(), spec.getMetrics());
  }
",non-flaky,5
60888,apache_druid,MaterializedViewSupervisorSpecTest.call,"  @Test
  public void testMaterializedViewSupervisorSpecCreated()
  {
    Exception ex = null;

    try {
      MaterializedViewSupervisorSpec spec = new MaterializedViewSupervisorSpec(
              ""wikiticker"",
              new DimensionsSpec(
                      Lists.newArrayList(
                              new StringDimensionSchema(""isUnpatrolled""),
                              new StringDimensionSchema(""metroCode""),
                              new StringDimensionSchema(""namespace""),
                              new StringDimensionSchema(""page""),
                              new StringDimensionSchema(""regionIsoCode""),
                              new StringDimensionSchema(""regionName""),
                              new StringDimensionSchema(""user"")
                      ),
                      null,
                      null
              ),
              new AggregatorFactory[]{
                  new CountAggregatorFactory(""count""),
                  new LongSumAggregatorFactory(""added"", ""added"")
              },
              HadoopTuningConfig.makeDefaultTuningConfig(),
              null,
              null,
              null,
              null,
              null,
              false,
              objectMapper,
              null,
              null,
              null,
              null,
              null,
              new MaterializedViewTaskConfig(),
              EasyMock.createMock(AuthorizerMapper.class),
              new NoopChatHandlerProvider(),
              new SupervisorStateManagerConfig()
      );
      Supervisor supervisor = spec.createSupervisor();
      Assert.assertTrue(supervisor instanceof MaterializedViewSupervisor);

      SupervisorTaskAutoScaler autoscaler = spec.createAutoscaler(supervisor);
      Assert.assertNull(autoscaler);

      try {
        supervisor.computeLagStats();
      }
      catch (Exception e) {
        Assert.assertTrue(e instanceof UnsupportedOperationException);
      }

      try {
        int count = supervisor.getActiveTaskGroupsCount();
      }
      catch (Exception e) {
        Assert.assertTrue(e instanceof UnsupportedOperationException);
      }

      Callable<Integer> noop = new Callable<Integer>() {
        @Override
        public Integer call()
        {
          return -1;
        }
",non-flaky,5
60889,apache_druid,MaterializedViewSupervisorSpecTest.testSuspendResuume,"  @Test
  public void testSuspendResuume() throws IOException
  {
    String supervisorStr = ""{\n"" +
                           ""  \""type\"" : \""derivativeDataSource\"",\n"" +
                           ""  \""baseDataSource\"": \""wikiticker\"",\n"" +
                           ""  \""dimensionsSpec\"":{\n"" +
                           ""            \""dimensions\"" : [\n"" +
                           ""              \""isUnpatrolled\"",\n"" +
                           ""              \""metroCode\"",\n"" +
                           ""              \""namespace\"",\n"" +
                           ""              \""page\"",\n"" +
                           ""              \""regionIsoCode\"",\n"" +
                           ""              \""regionName\"",\n"" +
                           ""              \""user\""\n"" +
                           ""            ]\n"" +
                           ""          },\n"" +
                           ""    \""metricsSpec\"" : [\n"" +
                           ""        {\n"" +
                           ""          \""name\"" : \""count\"",\n"" +
                           ""          \""type\"" : \""count\""\n"" +
                           ""        },\n"" +
                           ""        {\n"" +
                           ""          \""name\"" : \""added\"",\n"" +
                           ""          \""type\"" : \""longSum\"",\n"" +
                           ""          \""fieldName\"" : \""added\""\n"" +
                           ""        }\n"" +
                           ""      ],\n"" +
                           ""  \""tuningConfig\"": {\n"" +
                           ""      \""type\"" : \""hadoop\""\n"" +
                           ""  }\n"" +
                           ""}"";

    MaterializedViewSupervisorSpec spec = objectMapper.readValue(supervisorStr, MaterializedViewSupervisorSpec.class);
    Assert.assertFalse(spec.isSuspended());

    String suspendedSerialized = objectMapper.writeValueAsString(spec.createSuspendedSpec());
    MaterializedViewSupervisorSpec suspendedSpec = objectMapper.readValue(
        suspendedSerialized,
        MaterializedViewSupervisorSpec.class
    );
    Assert.assertTrue(suspendedSpec.isSuspended());

    String runningSerialized = objectMapper.writeValueAsString(spec.createRunningSpec());
    MaterializedViewSupervisorSpec runningSpec = objectMapper.readValue(
        runningSerialized,
        MaterializedViewSupervisorSpec.class
    );
    Assert.assertFalse(runningSpec.isSuspended());
  }
",non-flaky,5
60890,apache_druid,MaterializedViewSupervisorSpecTest.testEmptyBaseDataSource,"  @Test
  public void testEmptyBaseDataSource()
  {
    expectedException.expect(CoreMatchers.instanceOf(IllegalArgumentException.class));
    expectedException.expectMessage(
        ""baseDataSource cannot be null or empty. Please provide a baseDataSource.""
    );
    //noinspection ResultOfObjectAllocationIgnored (this method call will trigger the expected exception)
    new MaterializedViewSupervisorSpec(
        """",
        new DimensionsSpec(
            Lists.newArrayList(
                new StringDimensionSchema(""isUnpatrolled""),
                new StringDimensionSchema(""metroCode""),
                new StringDimensionSchema(""namespace""),
                new StringDimensionSchema(""page""),
                new StringDimensionSchema(""regionIsoCode""),
                new StringDimensionSchema(""regionName""),
                new StringDimensionSchema(""user"")
            ),
            null,
            null
        ),
        new AggregatorFactory[]{
            new CountAggregatorFactory(""count""),
            new LongSumAggregatorFactory(""added"", ""added"")
        },
        HadoopTuningConfig.makeDefaultTuningConfig(),
        null,
        null,
        null,
        null,
        null,
        false,
        objectMapper,
        null,
        null,
        null,
        null,
        null,
        new MaterializedViewTaskConfig(),
        EasyMock.createMock(AuthorizerMapper.class),
        new NoopChatHandlerProvider(),
        new SupervisorStateManagerConfig()
    );
  }
",non-flaky,5
60891,apache_druid,MaterializedViewSupervisorSpecTest.testNullBaseDataSource,"  @Test
  public void testNullBaseDataSource()
  {
    expectedException.expect(CoreMatchers.instanceOf(IllegalArgumentException.class));
    expectedException.expectMessage(
        ""baseDataSource cannot be null or empty. Please provide a baseDataSource.""
    );
    //noinspection ResultOfObjectAllocationIgnored (this method call will trigger the expected exception)
    new MaterializedViewSupervisorSpec(
        null,
        new DimensionsSpec(
            Lists.newArrayList(
                new StringDimensionSchema(""isUnpatrolled""),
                new StringDimensionSchema(""metroCode""),
                new StringDimensionSchema(""namespace""),
                new StringDimensionSchema(""page""),
                new StringDimensionSchema(""regionIsoCode""),
                new StringDimensionSchema(""regionName""),
                new StringDimensionSchema(""user"")
            ),
            null,
            null
        ),
        new AggregatorFactory[]{
            new CountAggregatorFactory(""count""),
            new LongSumAggregatorFactory(""added"", ""added"")
        },
        HadoopTuningConfig.makeDefaultTuningConfig(),
        null,
        null,
        null,
        null,
        null,
        false,
        objectMapper,
        null,
        null,
        null,
        null,
        null,
        new MaterializedViewTaskConfig(),
        EasyMock.createMock(AuthorizerMapper.class),
        new NoopChatHandlerProvider(),
        new SupervisorStateManagerConfig()
    );
  }
",non-flaky,5
60892,apache_druid,KafkaEmitterTest.testKafkaEmitter,"  @Test(timeout = 15_000)
  public void testKafkaEmitter() throws InterruptedException
  {
    final List<ServiceMetricEvent> serviceMetricEvents = ImmutableList.of(
        ServiceMetricEvent.builder().build(""m1"", 1).build(""service"", ""host"")
    );

    final List<AlertEvent> alertEvents = ImmutableList.of(
        new AlertEvent(""service"", ""host"", ""description"")
    );

    final List<RequestLogEvent> requestLogEvents = ImmutableList.of(
        DefaultRequestLogEventBuilderFactory.instance().createRequestLogEventBuilder(""requests"",
            RequestLogLine.forSql("""", null, DateTimes.nowUtc(), null, new QueryStats(ImmutableMap.of()))
        ).build(""service"", ""host"")
    );

    int totalEvents = serviceMetricEvents.size() + alertEvents.size() + requestLogEvents.size();
    int totalEventsExcludingRequestLogEvents = totalEvents - requestLogEvents.size();

    final CountDownLatch countDownSentEvents = new CountDownLatch(
        requestTopic == null ? totalEventsExcludingRequestLogEvents : totalEvents);
    final KafkaProducer<String, String> producer = EasyMock.createStrictMock(KafkaProducer.class);
    final KafkaEmitter kafkaEmitter = new KafkaEmitter(
        new KafkaEmitterConfig("""", ""metrics"", ""alerts"", requestTopic, ""test-cluster"", null),
        new ObjectMapper()
    )
    {
      @Override
      protected Producer<String, String> setKafkaProducer()
      {
        return producer;
      }

      @Override
      protected void sendToKafka(final String topic, MemoryBoundLinkedBlockingQueue<String> recordQueue,
          Callback callback
      )
      {
        countDownSentEvents.countDown();
        super.sendToKafka(topic, recordQueue, callback);
      }
    };

    EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(null)
        .times(requestTopic == null ? totalEventsExcludingRequestLogEvents : totalEvents);
    EasyMock.replay(producer);
    kafkaEmitter.start();

    for (Event event : serviceMetricEvents) {
      kafkaEmitter.emit(event);
    }
    for (Event event : alertEvents) {
      kafkaEmitter.emit(event);
    }
    for (Event event : requestLogEvents) {
      kafkaEmitter.emit(event);
    }
    countDownSentEvents.await();

    Assert.assertEquals(0, kafkaEmitter.getMetricLostCount());
    Assert.assertEquals(0, kafkaEmitter.getAlertLostCount());
    Assert.assertEquals(requestTopic == null ? requestLogEvents.size() : 0, kafkaEmitter.getRequestLostCount());
    Assert.assertEquals(0, kafkaEmitter.getInvalidLostCount());

    while (true) {
      try {
        EasyMock.verify(producer);
        break;
      }
      catch (Throwable e) {
        // although the latch may have count down, producer.send may not have been called yet in KafkaEmitter
        // so wait for sometime before verifying the mock
        Thread.sleep(100);
        // just continue
      }
    }
  }
",non-flaky,5
60893,apache_druid,KafkaEmitterConfigTest.testSerDeserKafkaEmitterConfig,"  @Test
  public void testSerDeserKafkaEmitterConfig() throws IOException
  {
    KafkaEmitterConfig kafkaEmitterConfig = new KafkaEmitterConfig(""hostname"", ""metricTest"",
        ""alertTest"", ""requestTest"",
        ""clusterNameTest"", ImmutableMap.<String, String>builder()
        .put(""testKey"", ""testValue"").build()
    );
    String kafkaEmitterConfigString = mapper.writeValueAsString(kafkaEmitterConfig);
    KafkaEmitterConfig kafkaEmitterConfigExpected = mapper.readerFor(KafkaEmitterConfig.class)
        .readValue(kafkaEmitterConfigString);
    Assert.assertEquals(kafkaEmitterConfigExpected, kafkaEmitterConfig);
  }
",non-flaky,5
60894,apache_druid,KafkaEmitterConfigTest.testSerDeserKafkaEmitterConfigNullRequestTopic,"  @Test
  public void testSerDeserKafkaEmitterConfigNullRequestTopic() throws IOException
  {
    KafkaEmitterConfig kafkaEmitterConfig = new KafkaEmitterConfig(""hostname"", ""metricTest"",
        ""alertTest"", null,
        ""clusterNameTest"", ImmutableMap.<String, String>builder()
        .put(""testKey"", ""testValue"").build()
    );
    String kafkaEmitterConfigString = mapper.writeValueAsString(kafkaEmitterConfig);
    KafkaEmitterConfig kafkaEmitterConfigExpected = mapper.readerFor(KafkaEmitterConfig.class)
        .readValue(kafkaEmitterConfigString);
    Assert.assertEquals(kafkaEmitterConfigExpected, kafkaEmitterConfig);
  }
",non-flaky,5
60895,apache_druid,KafkaEmitterConfigTest.testSerDeNotRequiredKafkaProducerConfig,"  @Test
  public void testSerDeNotRequiredKafkaProducerConfig()
  {
    KafkaEmitterConfig kafkaEmitterConfig = new KafkaEmitterConfig(""localhost:9092"", ""metricTest"",
        ""alertTest"", null,
        ""clusterNameTest"", null
    );
    try {
      @SuppressWarnings(""unused"")
      KafkaEmitter emitter = new KafkaEmitter(kafkaEmitterConfig, mapper);
    }
    catch (NullPointerException e) {
      Assert.fail();
    }
  }
",non-flaky,5
60896,apache_druid,KafkaEmitterConfigTest.testJacksonModules,"  @Test
  public void testJacksonModules()
  {
    Assert.assertTrue(new KafkaEmitterModule().getJacksonModules().isEmpty());
  }
",non-flaky,5
60897,apache_druid,ThriftInputRowParserTest.testGetThriftClass,"  @Test
  public void testGetThriftClass() throws Exception
  {
    ThriftInputRowParser parser1 = new ThriftInputRowParser(
        parseSpec,
        ""example/book.jar"",
        ""org.apache.druid.data.input.thrift.Book""
    );
    Assert.assertEquals(""org.apache.druid.data.input.thrift.Book"", parser1.getThriftClass().getName());

    ThriftInputRowParser parser2 = new ThriftInputRowParser(parseSpec, null, ""org.apache.druid.data.input.thrift.Book"");
    Assert.assertEquals(""org.apache.druid.data.input.thrift.Book"", parser2.getThriftClass().getName());
  }
",non-flaky,5
60898,apache_druid,ThriftInputRowParserTest.testParse,"  @Test
  public void testParse() throws Exception
  {
    ThriftInputRowParser parser = new ThriftInputRowParser(
        parseSpec,
        ""example/book.jar"",
        ""org.apache.druid.data.input.thrift.Book""
    );
    Book book = new Book().setDate(""2016-08-29"").setPrice(19.9).setTitle(""title"")
                          .setAuthor(new Author().setFirstName(""first"").setLastName(""last""));

    TSerializer serializer;
    byte[] bytes;

    // 1. compact
    serializer = new TSerializer(new TCompactProtocol.Factory());
    bytes = serializer.serialize(book);
    serializationAndTest(parser, bytes);

    // 2. binary + base64
    serializer = new TSerializer(new TBinaryProtocol.Factory());
    serializationAndTest(parser, StringUtils.encodeBase64(serializer.serialize(book)));

    // 3. json
    serializer = new TSerializer(new TJSONProtocol.Factory());
    bytes = serializer.serialize(book);
    serializationAndTest(parser, bytes);
  }
",non-flaky,5
60899,apache_druid,ThriftInputRowParserTest.testDisableJavaScript,"  @Test
  public void testDisableJavaScript()
  {
    final JavaScriptParseSpec parseSpec = new JavaScriptParseSpec(
        new TimestampSpec(""timestamp"", ""auto"", null),
        new DimensionsSpec(
            DimensionsSpec.getDefaultSchemas(
                ImmutableList.of(
                    ""dim1"",
                    ""dim2""
                )
            ),
            null,
            null
        ),
        ""func"",
        new JavaScriptConfig(false)
    );
    ThriftInputRowParser parser = new ThriftInputRowParser(
        parseSpec,
        ""example/book.jar"",
        ""org.apache.druid.data.input.thrift.Book""
    );

    expectedException.expect(CoreMatchers.instanceOf(IllegalStateException.class));
    expectedException.expectMessage(""JavaScript is disabled"");

    //noinspection ResultOfMethodCallIgnored (this method call will trigger the expected exception)
    parser.parseBatch(ByteBuffer.allocate(1)).get(0);
  }
",non-flaky,5
60900,apache_druid,MovingAverageIterableTest.testNext,"  @Test
  public void testNext()
  {

    List<DimensionSpec> dims = Arrays.asList(
        new DefaultDimensionSpec(GENDER, GENDER),
        new DefaultDimensionSpec(AGE, AGE),
        new DefaultDimensionSpec(COUNTRY, COUNTRY)
    );

    Sequence<RowBucket> dayBuckets = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Arrays.asList(
            new MapBasedRow(JAN_1, DIMS1),
            new MapBasedRow(JAN_1, DIMS2)
        )),
        new RowBucket(JAN_2, Collections.singletonList(
            new MapBasedRow(JAN_2, DIMS1)
        )),
        new RowBucket(JAN_3, Collections.emptyList()),
        new RowBucket(JAN_4, Arrays.asList(
            new MapBasedRow(JAN_4, DIMS2),
            new MapBasedRow(JAN_4, DIMS3)
        ))
    ));

    Iterable<Row> iterable = new MovingAverageIterable(
        dayBuckets,
        dims,
        Collections.singletonList(new ConstantAveragerFactory(""noop"", 1, 1.1f)),
        Collections.emptyList(),
        Collections.emptyList()
    );

    Iterator<Row> iter = iterable.iterator();

    Assert.assertTrue(iter.hasNext());
    Row r = iter.next();
    Assert.assertEquals(JAN_1, r.getTimestamp());
    Assert.assertEquals(""m"", r.getRaw(GENDER));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_1, r.getTimestamp());
    Assert.assertEquals(""f"", r.getRaw(GENDER));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_2, r.getTimestamp());
    Assert.assertEquals(""m"", r.getRaw(GENDER));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_2, r.getTimestamp());
    Assert.assertEquals(""f"", r.getRaw(GENDER));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Row r2 = r;
    Assert.assertEquals(JAN_3, r.getTimestamp());
    Assert.assertEquals(""US"", r.getRaw(COUNTRY));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_3, r.getTimestamp());
    Assert.assertEquals(""US"", r.getRaw(COUNTRY));
    Assert.assertThat(r.getRaw(AGE), CoreMatchers.not(CoreMatchers.equalTo(r2.getRaw(AGE))));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_4, r.getTimestamp());
    Assert.assertEquals(""f"", r.getRaw(GENDER));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_4, r.getTimestamp());
    Assert.assertEquals(""u"", r.getRaw(GENDER));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_4, r.getTimestamp());
    Assert.assertEquals(""m"", r.getRaw(GENDER));

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60901,apache_druid,MovingAverageIterableTest.testAveraging,"  @Test
  public void testAveraging()
  {

    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();
    Map<String, Object> event3 = new HashMap<>();
    Map<String, Object> event4 = new HashMap<>();

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    Row row1 = new MapBasedRow(JAN_1, event1);

    event2.put(""gender"", ""m"");
    event2.put(""pageViews"", 20L);
    Row row2 = new MapBasedRow(JAN_2, event2);

    event3.put(""gender"", ""m"");
    event3.put(""pageViews"", 30L);
    Row row3 = new MapBasedRow(JAN_3, event3);

    event4.put(""gender"", ""f"");
    event4.put(""pageViews"", 40L);
    Row row4 = new MapBasedRow(JAN_3, event4);

    float retval = 14.5f;

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.singletonList(row1)),
        new RowBucket(JAN_2, Collections.singletonList(row2)),
        new RowBucket(JAN_3, Arrays.asList(row3, row4))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Arrays.asList(
            new ConstantAveragerFactory(""costPageViews"", 7, retval),
            new LongMeanAveragerFactory(""movingAvgPageViews"", 7, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row caResult = iter.next();

    Assert.assertEquals(JAN_1, caResult.getTimestamp());
    Assert.assertEquals(""m"", (caResult.getDimension(""gender"")).get(0));
    Assert.assertEquals(retval, caResult.getMetric(""costPageViews"").floatValue(), 0.0f);
    Assert.assertEquals(1.4285715f, caResult.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    caResult = iter.next();
    Assert.assertEquals(""m"", (caResult.getDimension(""gender"")).get(0));
    Assert.assertEquals(4.285714f, caResult.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    caResult = iter.next();
    Assert.assertEquals(""m"", (caResult.getDimension(""gender"")).get(0));
    Assert.assertEquals(8.571428f, caResult.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    caResult = iter.next();
    Assert.assertEquals(""f"", (caResult.getDimension(""gender"")).get(0));
    Assert.assertEquals(5.714285850f, caResult.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertFalse(iter.hasNext());

  }
",non-flaky,5
60902,apache_druid,MovingAverageIterableTest.testCompleteData,"  @Test
  public void testCompleteData()
  {

    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();
    Map<String, Object> event3 = new HashMap<>();

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    event2.put(""gender"", ""f"");
    event2.put(""pageViews"", 20L);
    event3.put(""gender"", ""u"");
    event3.put(""pageViews"", 30L);

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    Row jan1Row1 = new MapBasedRow(JAN_1, event1);
    Row jan1Row2 = new MapBasedRow(JAN_1, event2);
    Row jan1Row3 = new MapBasedRow(JAN_1, event3);

    Row jan2Row1 = new MapBasedRow(JAN_2, event1);
    Row jan2Row2 = new MapBasedRow(JAN_2, event2);
    Row jan2Row3 = new MapBasedRow(JAN_2, event3);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Arrays.asList(jan1Row1, jan1Row2, jan1Row3)),
        new RowBucket(JAN_2, Arrays.asList(jan2Row1, jan2Row2, jan2Row3))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 2, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertFalse(iter.hasNext());

  }
",non-flaky,5
60903,apache_druid,MovingAverageIterableTest.testMissingDataAtBeginning,"  @Test
  public void testMissingDataAtBeginning()
  {

    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();
    Map<String, Object> event3 = new HashMap<>();

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    event2.put(""gender"", ""f"");
    event2.put(""pageViews"", 20L);
    event3.put(""gender"", ""u"");
    event3.put(""pageViews"", 30L);

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    Row jan1Row1 = new MapBasedRow(JAN_1, event1);

    Row jan2Row1 = new MapBasedRow(JAN_2, event1);
    Row jan2Row2 = new MapBasedRow(JAN_2, event2);
    Row jan2Row3 = new MapBasedRow(JAN_2, event3);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.singletonList(jan1Row1)),
        new RowBucket(JAN_2, Arrays.asList(jan2Row1, jan2Row2, jan2Row3))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 2, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60904,apache_druid,MovingAverageIterableTest.testMissingDataAtTheEnd,"  @Test
  public void testMissingDataAtTheEnd()
  {

    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();
    Map<String, Object> event3 = new HashMap<>();

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    event2.put(""gender"", ""f"");
    event2.put(""pageViews"", 20L);
    event3.put(""gender"", ""u"");
    event3.put(""pageViews"", 30L);

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    Row jan1Row1 = new MapBasedRow(JAN_1, event1);
    Row jan1Row2 = new MapBasedRow(JAN_1, event2);
    Row jan1Row3 = new MapBasedRow(JAN_1, event3);
    Row jan2Row1 = new MapBasedRow(JAN_2, event1);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Arrays.asList(jan1Row1, jan1Row2, jan1Row3)),
        new RowBucket(JAN_2, Collections.singletonList(jan2Row1))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 2, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60905,apache_druid,MovingAverageIterableTest.testMissingDataAtMiddle,"  @Test
  public void testMissingDataAtMiddle()
  {

    Map<String, Object> eventM = new HashMap<>();
    Map<String, Object> eventF = new HashMap<>();
    Map<String, Object> eventU = new HashMap<>();

    eventM.put(""gender"", ""m"");
    eventM.put(""pageViews"", 10L);
    eventF.put(""gender"", ""f"");
    eventF.put(""pageViews"", 20L);
    eventU.put(""gender"", ""u"");
    eventU.put(""pageViews"", 30L);

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    Row jan1Row1M = new MapBasedRow(JAN_1, eventM);
    Row jan1Row2F = new MapBasedRow(JAN_1, eventF);
    Row jan1Row3U = new MapBasedRow(JAN_1, eventU);
    Row jan2Row1M = new MapBasedRow(JAN_2, eventM);
    Row jan3Row1M = new MapBasedRow(JAN_3, eventM);
    Row jan3Row2F = new MapBasedRow(JAN_3, eventF);
    Row jan3Row3U = new MapBasedRow(JAN_3, eventU);
    Row jan4Row1M = new MapBasedRow(JAN_4, eventM);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Arrays.asList(jan1Row1M, jan1Row2F, jan1Row3U)),
        new RowBucket(JAN_2, Collections.singletonList(jan2Row1M)),
        new RowBucket(JAN_3, Arrays.asList(jan3Row1M, jan3Row2F, jan3Row3U)),
        new RowBucket(JAN_4, Collections.singletonList(jan4Row1M))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 3, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    // Jan 1
    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    // Jan 2
    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    // Jan 3
    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_3, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_3, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_3, (result.getTimestamp()));

    // Jan 4
    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_4, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_4, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_4, (result.getTimestamp()));

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60906,apache_druid,MovingAverageIterableTest.testMissingDaysAtBegining,"  @Test
  public void testMissingDaysAtBegining()
  {

    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    Row row1 = new MapBasedRow(JAN_3, event1);

    event2.put(""gender"", ""m"");
    event2.put(""pageViews"", 20L);
    Row row2 = new MapBasedRow(JAN_4, event2);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.emptyList()),
        new RowBucket(JAN_2, Collections.emptyList()),
        new RowBucket(JAN_3, Collections.singletonList(row1)),
        new RowBucket(JAN_4, Collections.singletonList(row2))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 4, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(7.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60907,apache_druid,MovingAverageIterableTest.testMissingDaysInMiddle,"  @Test
  public void testMissingDaysInMiddle()
  {
    System.setProperty(""druid.generic.useDefaultValueForNull"", ""true"");
    NullHandling.initializeForTests();
    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    Row row1 = new MapBasedRow(JAN_1, event1);

    event2.put(""gender"", ""m"");
    event2.put(""pageViews"", 20L);
    Row row2 = new MapBasedRow(JAN_4, event2);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.singletonList(row1)),
        new RowBucket(JAN_2, Collections.emptyList()),
        new RowBucket(JAN_3, Collections.emptyList()),
        new RowBucket(JAN_4, Collections.singletonList(row2))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 4, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(7.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60908,apache_druid,MovingAverageIterableTest.testWithFilteredAggregation,"  @Test
  public void testWithFilteredAggregation()
  {

    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    Row row1 = new MapBasedRow(JAN_1, event1);

    event2.put(""gender"", ""m"");
    event2.put(""pageViews"", 20L);
    Row row2 = new MapBasedRow(JAN_4, event2);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.singletonList(row1)),
        new RowBucket(JAN_2, Collections.emptyList()),
        new RowBucket(JAN_3, Collections.emptyList()),
        new RowBucket(JAN_4, Collections.singletonList(row2))
    ));

    AveragerFactory averagerfactory = new LongMeanAveragerFactory(""movingAvgPageViews"", 4, 1, ""pageViews"");
    AggregatorFactory aggregatorFactory = new LongSumAggregatorFactory(""pageViews"", ""pageViews"");
    DimFilter filter = new SelectorDimFilter(""gender"", ""m"", null);
    FilteredAggregatorFactory filteredAggregatorFactory = new FilteredAggregatorFactory(aggregatorFactory, filter);

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(averagerfactory),
        Collections.emptyList(),
        Collections.singletonList(filteredAggregatorFactory)
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(7.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60909,apache_druid,MovingAverageIterableTest.testMissingDaysAtEnd,"  @Test
  public void testMissingDaysAtEnd()
  {
    System.setProperty(""druid.generic.useDefaultValueForNull"", ""true"");
    NullHandling.initializeForTests();
    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    Row row1 = new MapBasedRow(JAN_1, event1);

    event2.put(""gender"", ""m"");
    event2.put(""pageViews"", 20L);
    Row row2 = new MapBasedRow(JAN_2, event2);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.singletonList(row1)),
        new RowBucket(JAN_2, Collections.singletonList(row2)),
        new RowBucket(JAN_3, Collections.emptyList()),
        new RowBucket(JAN_4, Collections.emptyList()),
        new RowBucket(JAN_5, Collections.emptyList()),
        new RowBucket(JAN_6, Collections.emptyList())
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 4, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();

    Assert.assertEquals(JAN_1, result.getTimestamp());
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(JAN_2, result.getTimestamp());
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(7.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(JAN_3, result.getTimestamp());
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(7.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(JAN_4, result.getTimestamp());
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(7.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(JAN_5, result.getTimestamp());
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(5.0f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(JAN_6, result.getTimestamp());
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(0.0f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60910,apache_druid,PostAveragerAggregatorCalculatorTest.testApply,"  @Test
  public void testApply()
  {
    event.put(""count"", 10.0);
    event.put(""avgCount"", 12.0);

    Row result = pac.apply(row);

    Assert.assertEquals(10.0f / 12.0f, result.getMetric(""avgCountRatio"").floatValue(), 0.0);
  }
",non-flaky,5
60911,apache_druid,PostAveragerAggregatorCalculatorTest.testApplyMissingColumn,"  @Test
  public void testApplyMissingColumn()
  {
    event.put(""count"", 10.0);

    Row result = pac.apply(row);

    Assert.assertEquals(0.0, result.getMetric(""avgCountRatio"").floatValue(), 0.0);
    Assert.assertNull(result.getRaw(""avgCountRatio""));
  }
",non-flaky,5
60912,apache_druid,DoubleMaxAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new DoubleMaxAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), CoreMatchers.instanceOf(DoubleMaxAverager.class));
  }
",non-flaky,5
60913,apache_druid,DoubleMinAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new DoubleMinAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(DoubleMinAverager.class));
  }
",non-flaky,5
60914,apache_druid,DoubleSumAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new DoubleSumAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(DoubleSumAverager.class));
  }
",non-flaky,5
60915,apache_druid,LongMaxAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new LongMaxAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(LongMaxAverager.class));
  }
",non-flaky,5
60916,apache_druid,LongMeanNoNullAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new LongMeanNoNullAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(LongMeanNoNullAverager.class));
  }
",non-flaky,5
60917,apache_druid,LongMinAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new LongMinAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(LongMinAverager.class));
  }
",non-flaky,5
60918,apache_druid,DoubleSumAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new DoubleSumAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(0.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(6.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", new Integer(0)), new HashMap<>());
    Assert.assertEquals(6.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 2.5), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    Assert.assertEquals(6.5, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(4.0, avg.computeResult(), 0.0);

  }
",non-flaky,5
60919,apache_druid,LongMeanNoNullAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new LongMeanNoNullAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(Double.NaN, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);
  }
",non-flaky,5
60920,apache_druid,DoubleMaxAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new DoubleMaxAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(Double.NEGATIVE_INFINITY, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", -1.1e100), new HashMap<>());
    Assert.assertEquals(-1.1e100, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    Assert.assertEquals(1.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 1), new HashMap<>());
    Assert.assertEquals(1.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 5.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    Assert.assertEquals(5.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);
  }
",non-flaky,5
60921,apache_druid,DoubleMeanAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new DoubleMeanAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(0.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(1.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(4.0 / 3, avg.computeResult(), 0.0);
  }
",non-flaky,5
60922,apache_druid,DoubleMeanNoNullAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new DoubleMeanNoNullAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(DoubleMeanNoNullAverager.class));
  }
",non-flaky,5
60923,apache_druid,BaseAveragerFactoryTest.testGetDependentFields,"  @Test
  public void testGetDependentFields()
  {
    List<String> dependentFields = fac.getDependentFields();
    Assert.assertEquals(1, dependentFields.size());
    Assert.assertEquals(""field"", dependentFields.get(0));
  }
",non-flaky,5
60924,apache_druid,BaseAveragerFactoryTest.testFinalization,"  @Test
  public void testFinalization()
  {
    Long input = 5L;
    Assert.assertEquals(input, fac.finalizeComputation(input));
  }
",non-flaky,5
60925,apache_druid,DoubleMeanNoNullAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new DoubleMeanNoNullAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(Double.NaN, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    // testing cycleSize functionality
    BaseAverager<Number, Double> averager = new DoubleMeanNoNullAverager(14, ""test"", ""field"", 7);

    averager.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    Assert.assertEquals(2.0, averager.computeResult(), 0.0);

    averager.addElement(Collections.singletonMap(""field"", 4.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 5.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 6.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 7.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 8.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 9.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", null), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 11.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 12.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 13.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 14.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 15.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 16.0), new HashMap<>());

    Assert.assertEquals(7.5, averager.computeResult(), 0.0);

    averager.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(8.5, averager.computeResult(), 0.0);
  }
",non-flaky,5
60926,apache_druid,LongSumAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Long> avg = new LongSumAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(0.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(6.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3), new HashMap<>());
    Assert.assertEquals(9.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    Assert.assertEquals(6.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(4.0, avg.computeResult(), 0.0);
  }
",non-flaky,5
60927,apache_druid,LongMeanAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new LongMeanAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(LongMeanAverager.class));
  }
",non-flaky,5
60928,apache_druid,LongSumAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new LongSumAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(LongSumAverager.class));
  }
",non-flaky,5
60929,apache_druid,DoubleMeanAveragerWithPeriodTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> averager = new DoubleMeanAverager(14, ""test"", ""field"", 7);

    averager.addElement(Collections.singletonMap(""field"", 7.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 4.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 5.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 6.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 7.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 4.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 5.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 6.0), new HashMap<>());

    Assert.assertEquals(7, averager.computeResult(), 0.0); // (7+7)/2

    averager.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(1, averager.computeResult(), 0.0); // (1+1)/2

    BaseAverager<Number, Double> averager1 = new DoubleMeanAverager(14, ""test"", ""field"", 3);

    averager1.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());

    Assert.assertEquals(1, averager1.computeResult(), 0.0); // (1+1+1+1+1)/5

    Assert.assertEquals(2, averager1.computeResult(), 0.0); // (2+2+2+2+2)/5

    Assert.assertEquals(13.0 / 5, averager1.computeResult(), 0.0); // (3+3+3+3+1)/5
  }
",non-flaky,5
60930,apache_druid,BaseAveragerTest.testBaseAverager,"  @Test
  public void testBaseAverager()
  {
    BaseAverager<Integer, Integer> avg = new TestAverager(Integer.class, 5, ""test"", ""field"", 1);

    Assert.assertEquals(""test"", avg.getName());
    Assert.assertEquals(5, avg.getNumBuckets());
    Assert.assertEquals(5, avg.getBuckets().length);
    Assert.assertTrue(avg.getBuckets().getClass().isArray());
  }
",non-flaky,5
60931,apache_druid,BaseAveragerTest.testAddElement,"  @Test
  public void testAddElement()
  {
    BaseAverager<Integer, Integer> avg = new TestAverager(Integer.class, 3, ""test"", ""field"", 1);
    Object[] buckets = avg.getBuckets();

    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());
    Assert.assertEquals(1, buckets[0]);
    Assert.assertNull(buckets[1]);
    Assert.assertNull(buckets[2]);

    avg.addElement(Collections.singletonMap(""field"", 2), Collections.emptyMap());
    Assert.assertEquals(1, buckets[0]);
    Assert.assertEquals(2, buckets[1]);
    Assert.assertNull(buckets[2]);

    avg.addElement(Collections.singletonMap(""field"", 3), Collections.emptyMap());
    Assert.assertEquals(1, buckets[0]);
    Assert.assertEquals(2, buckets[1]);
    Assert.assertEquals(3, buckets[2]);

    avg.addElement(Collections.singletonMap(""field"", 4), Collections.emptyMap());
    Assert.assertEquals(4, buckets[0]);
    Assert.assertEquals(2, buckets[1]);
    Assert.assertEquals(3, buckets[2]);
  }
",non-flaky,5
60932,apache_druid,BaseAveragerTest.testSkip,"  @Test
  public void testSkip()
  {
    BaseAverager<Integer, Integer> avg = new TestAverager(Integer.class, 3, ""test"", ""field"", 1);
    Object[] buckets = avg.getBuckets();

    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());
    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());
    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());

    Assert.assertEquals(1, buckets[0]);
    Assert.assertEquals(1, buckets[1]);
    Assert.assertEquals(1, buckets[2]);

    avg.skip();
    Assert.assertNull(buckets[0]);
    Assert.assertNotNull(buckets[1]);
    Assert.assertNotNull(buckets[2]);

    avg.skip();
    Assert.assertNull(buckets[0]);
    Assert.assertNull(buckets[1]);
    Assert.assertNotNull(buckets[2]);

    avg.skip();
    Assert.assertNull(buckets[0]);
    Assert.assertNull(buckets[1]);
    Assert.assertNull(buckets[2]);

    // poke some test data into the array
    buckets[0] = 1;

    avg.skip();
    Assert.assertNull(buckets[0]);
    Assert.assertNull(buckets[1]);
    Assert.assertNull(buckets[2]);
  }
",non-flaky,5
60933,apache_druid,BaseAveragerTest.testHasData,"  @Test
  public void testHasData()
  {
    BaseAverager<Integer, Integer> avg = new TestAverager(Integer.class, 3, ""test"", ""field"", 1);

    Assert.assertFalse(avg.hasData());

    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());
    Assert.assertTrue(avg.hasData());

    avg.skip();
    avg.skip();
    avg.skip();

    Assert.assertFalse(avg.hasData());
  }
",non-flaky,5
60934,apache_druid,BaseAveragerTest.testGetResult,"  @Test
  public void testGetResult()
  {
    BaseAverager<Integer, Integer> avg = new TestAverager(Integer.class, 3, ""test"", ""field"", 1);

    Assert.assertNull(avg.getResult());

    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());
    Assert.assertEquals(Integer.valueOf(1), avg.getResult());
  }
",non-flaky,5
60935,apache_druid,DoubleMeanAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new DoubleMeanAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(DoubleMeanAverager.class));
  }
",non-flaky,5
60936,apache_druid,DoubleMinAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new DoubleMinAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(Double.POSITIVE_INFINITY, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", -1.1e100), new HashMap<>());
    Assert.assertEquals(-1.1e100, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    Assert.assertEquals(-1.1e100, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", new Integer(1)), new HashMap<>());
    Assert.assertEquals(-1.1e100, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 5.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.skip();
    avg.skip();
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);
  }
",non-flaky,5
60937,apache_druid,LongMeanAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new LongMeanAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(0.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(1.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(4.0 / 3, avg.computeResult(), 0.0);
  }
",non-flaky,5
60938,apache_druid,LongMaxAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Long> avg = new LongMaxAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(Long.MIN_VALUE, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", -1000000L), new HashMap<>());
    Assert.assertEquals(-1000000, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", 1L), new HashMap<>());
    Assert.assertEquals(1, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", 1), new HashMap<>());
    Assert.assertEquals(1, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", 5L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    Assert.assertEquals(5, (long) avg.computeResult());

    avg.skip();
    Assert.assertEquals(3, (long) avg.computeResult());
  }
",non-flaky,5
60939,apache_druid,LongMinAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Long> avg = new LongMinAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(Long.MAX_VALUE, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", -10000L), new HashMap<>());
    Assert.assertEquals(-10000, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", 1L), new HashMap<>());
    Assert.assertEquals(-10000, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", 1000), new HashMap<>());
    Assert.assertEquals(-10000, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", 5L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(2, (long) avg.computeResult());

    avg.skip();
    avg.skip();
    Assert.assertEquals(3, (long) avg.computeResult());
  }
",non-flaky,5
60940,apache_druid,MovingAverageQueryTest.getDruidServers,"  @Test
  public void testQuery() throws IOException
  {
    Query<?> query = jsonMapper.readValue(getQueryString(), Query.class);
    Assert.assertThat(query, IsInstanceOf.instanceOf(getExpectedQueryType()));

    List<MapBasedRow> expectedResults = jsonMapper.readValue(getExpectedResultString(), getExpectedResultType());
    Assert.assertNotNull(expectedResults);
    Assert.assertThat(expectedResults, IsInstanceOf.instanceOf(List.class));

    CachingClusteredClient baseClient = new CachingClusteredClient(
        warehouse,
        new TimelineServerView()
        {
          @Override
          public Optional<? extends TimelineLookup<String, ServerSelector>> getTimeline(DataSourceAnalysis analysis)
          {
            return Optional.empty();
          }

          @Override
          public List<ImmutableDruidServer> getDruidServers()
          {
            return null;
          }
",non-flaky,5
60941,apache_druid,RowBucketIterableTest.testCompleteData,"  @Test
  public void testCompleteData()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_M_10);
    rows.add(JAN_4_M_10);

    List<Row> expectedDay1 = Collections.singletonList(JAN_1_M_10);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_M_10);
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60942,apache_druid,RowBucketIterableTest.testApplyLastDaySingleRow,"  @Test
  public void testApplyLastDaySingleRow()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    List<Row> expectedDay1 = Arrays.asList(JAN_1_M_10, JAN_1_F_20);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_F_20);
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_1_F_20);
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_F_20);
    rows.add(JAN_4_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60943,apache_druid,RowBucketIterableTest.testApplyLastDayMultipleRows,"  @Test
  public void testApplyLastDayMultipleRows()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    List<Row> expectedDay1 = Arrays.asList(JAN_1_M_10, JAN_1_F_20);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_F_20);
    List<Row> expectedDay4 = Arrays.asList(JAN_4_M_10, JAN_4_F_20, JAN_4_U_30);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_1_F_20);
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_F_20);
    rows.add(JAN_4_M_10);
    rows.add(JAN_4_F_20);
    rows.add(JAN_4_U_30);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60944,apache_druid,RowBucketIterableTest.testSingleDaySingleRow,"  @Test
  public void testSingleDaySingleRow()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_1);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);

    List<Row> expectedDay1 = Collections.singletonList(JAN_1_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());
    Assert.assertEquals(JAN_1, actual.getDateTime());
  }
",non-flaky,5
60945,apache_druid,RowBucketIterableTest.testSingleDayMultipleRow,"  @Test
  public void testSingleDayMultipleRow()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_1);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_1_F_20);
    rows.add(JAN_1_U_30);

    List<Row> expectedDay1 = Arrays.asList(JAN_1_M_10, JAN_1_F_20, JAN_1_U_30);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());
  }
",non-flaky,5
60946,apache_druid,RowBucketIterableTest.testMissingDaysAtBegining,"  @Test
  public void testMissingDaysAtBegining()
  {
    List<Row> expectedDay1 = Collections.emptyList();
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_2);

    rows = new ArrayList<>();
    rows.add(JAN_2_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());
  }
",non-flaky,5
60947,apache_druid,RowBucketIterableTest.testMissingDaysAtBeginingFollowedByMultipleRow,"  @Test
  public void testMissingDaysAtBeginingFollowedByMultipleRow()
  {
    List<Row> expectedDay1 = Collections.emptyList();
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_M_10);
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    rows = new ArrayList<>();
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_M_10);
    rows.add(JAN_4_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60948,apache_druid,RowBucketIterableTest.testMissingDaysAtBeginingAndAtTheEnd,"  @Test
  public void testMissingDaysAtBeginingAndAtTheEnd()
  {
    List<Row> expectedDay1 = Collections.emptyList();
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_M_10);
    List<Row> expectedDay4 = Collections.emptyList();

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    rows = new ArrayList<>();
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60949,apache_druid,RowBucketIterableTest.testMultipleMissingDays,"  @Test
  public void testMultipleMissingDays()
  {
    List<Row> expectedDay1 = Collections.emptyList();
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.emptyList();
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    rows = new ArrayList<>();
    rows.add(JAN_2_M_10);
    rows.add(JAN_4_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60950,apache_druid,RowBucketIterableTest.testMultipleMissingDaysMultipleRowAtTheEnd,"  @Test
  public void testMultipleMissingDaysMultipleRowAtTheEnd()
  {
    List<Row> expectedDay1 = Collections.emptyList();
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.emptyList();
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);
    List<Row> expectedDay5 = Collections.singletonList(JAN_5_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_5);

    rows = new ArrayList<>();
    rows.add(JAN_2_M_10);
    rows.add(JAN_4_M_10);
    rows.add(JAN_5_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_5, actual.getDateTime());
    Assert.assertEquals(expectedDay5, actual.getRows());
  }
",non-flaky,5
60951,apache_druid,RowBucketIterableTest.testMissingDaysInMiddleOneRow,"  @Test
  public void testMissingDaysInMiddleOneRow()
  {
    List<Row> expectedDay1 = Collections.singletonList(JAN_1_M_10);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.emptyList();
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_2_M_10);
    rows.add(JAN_4_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60952,apache_druid,RowBucketIterableTest.testMissingDaysInMiddleMultipleRow,"  @Test
  public void testMissingDaysInMiddleMultipleRow()
  {
    List<Row> expectedDay1 = Collections.singletonList(JAN_1_M_10);
    List<Row> expectedDay2 = Collections.emptyList();
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_M_10);
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_3_M_10);
    rows.add(JAN_4_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60953,apache_druid,RowBucketIterableTest.testApplyLastDayNoRows,"  @Test
  public void testApplyLastDayNoRows()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    List<Row> expectedDay1 = Arrays.asList(JAN_1_M_10, JAN_1_F_20);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_F_20);
    List<Row> expectedDay4 = Collections.emptyList();

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_1_F_20);
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_F_20);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60954,apache_druid,RowBucketIterableTest.testApplyLastTwoDayNoRows,"  @Test
  public void testApplyLastTwoDayNoRows()
  {
    List<Row> expectedDay1 = Arrays.asList(JAN_1_M_10, JAN_1_F_20);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.emptyList();
    List<Row> expectedDay4 = Collections.emptyList();

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_1_F_20);
    rows.add(JAN_2_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60955,apache_druid,RowBucketIterableTest.testApplyMultipleInterval,"  @Test
  public void testApplyMultipleInterval()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);
    intervals.add(INTERVAL_JAN_6_8);

    List<Row> expectedDay1 = Arrays.asList(JAN_1_M_10, JAN_1_F_20);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_F_20);
    List<Row> expectedDay4 = Arrays.asList(JAN_4_M_10, JAN_4_F_20, JAN_4_U_30);
    List<Row> expectedDay6 = Collections.singletonList(JAN_6_M_10);
    List<Row> expectedDay7 = Collections.singletonList(JAN_7_F_20);
    List<Row> expectedDay8 = Collections.singletonList(JAN_8_U_30);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_1_F_20);
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_F_20);
    rows.add(JAN_4_M_10);
    rows.add(JAN_4_F_20);
    rows.add(JAN_4_U_30);
    rows.add(JAN_6_M_10);
    rows.add(JAN_7_F_20);
    rows.add(JAN_8_U_30);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay4, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay6, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay7, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay8, actual.getRows());
  }
",non-flaky,5
60956,apache_druid,RowBucketIterableTest.testNodata,"  @Test
  public void testNodata()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);
    intervals.add(INTERVAL_JAN_6_8);

    rows = new ArrayList<>();

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    Assert.assertTrue(iter.hasNext());
    RowBucket actual = iter.next();
    Assert.assertEquals(Collections.emptyList(), actual.getRows());
  }
",non-flaky,5
60957,apache_druid,TDigestSketchAggregatorFactoryTest.testResultArraySignature,"  @Test
  public void testResultArraySignature()
  {
    final TimeseriesQuery query =
        Druids.newTimeseriesQueryBuilder()
              .dataSource(""dummy"")
              .intervals(""2000/3000"")
              .granularity(Granularities.HOUR)
              .aggregators(
                  new CountAggregatorFactory(""count""),
                  new TDigestSketchAggregatorFactory(""tdigest"", ""col"", null)
              )
              .postAggregators(
                  new FieldAccessPostAggregator(""tdigest-access"", ""tdigest""),
                  new FinalizingFieldAccessPostAggregator(""tdigest-finalize"", ""tdigest"")
              )
              .build();

    Assert.assertEquals(
        RowSignature.builder()
                    .addTimeColumn()
                    .add(""count"", ColumnType.LONG)
                    .add(""tdigest"", TDigestSketchAggregatorFactory.TYPE)
                    .add(""tdigest-access"", TDigestSketchAggregatorFactory.TYPE)
                    .add(""tdigest-finalize"", TDigestSketchAggregatorFactory.TYPE)
                    .build(),
        new TimeseriesQueryQueryToolChest().resultArraySignature(query)
    );
  }
",non-flaky,5
60958,apache_druid,TDigestSketchToQuantilePostAggregatorTest.testSerde,"  @Test
  public void testSerde() throws Exception
  {
    TDigestSketchToQuantilePostAggregator there =
        new TDigestSketchToQuantilePostAggregator(""post"", new ConstantPostAggregator("""", 100), 0.5);

    DefaultObjectMapper mapper = new DefaultObjectMapper();
    TDigestSketchToQuantilePostAggregator andBackAgain = mapper.readValue(
        mapper.writeValueAsString(there),
        TDigestSketchToQuantilePostAggregator.class
    );

    Assert.assertEquals(there, andBackAgain);
    Assert.assertArrayEquals(there.getCacheKey(), andBackAgain.getCacheKey());
    Assert.assertEquals(there.getDependentFields(), andBackAgain.getDependentFields());
  }
",non-flaky,5
60959,apache_druid,TDigestSketchToQuantilePostAggregatorTest.testToString,"  @Test
  public void testToString()
  {
    PostAggregator postAgg =
        new TDigestSketchToQuantilePostAggregator(""post"", new ConstantPostAggregator("""", 100), 0.5);

    Assert.assertEquals(
        ""TDigestSketchToQuantilePostAggregator{name='post', field=ConstantPostAggregator{name='', constantValue=100}, fraction=0.5}"",
        postAgg.toString()
    );
  }
",non-flaky,5
60960,apache_druid,TDigestSketchToQuantilePostAggregatorTest.testEquals,"  @Test
  public void testEquals()
  {
    EqualsVerifier.forClass(TDigestSketchToQuantilePostAggregator.class)
                  .withNonnullFields(""name"", ""field"", ""fraction"")
                  .usingGetClass()
                  .verify();
  }
",non-flaky,5
60961,apache_druid,TDigestSketchToQuantilesPostAggregatorTest.testSerde,"  @Test
  public void testSerde() throws Exception
  {
    TDigestSketchToQuantilesPostAggregator there =
        new TDigestSketchToQuantilesPostAggregator(""post"", new ConstantPostAggregator("""", 100), new double[]{0.25, 0.75});

    DefaultObjectMapper mapper = new DefaultObjectMapper();
    TDigestSketchToQuantilesPostAggregator andBackAgain = mapper.readValue(
        mapper.writeValueAsString(there),
        TDigestSketchToQuantilesPostAggregator.class
    );

    Assert.assertEquals(there, andBackAgain);
    Assert.assertArrayEquals(there.getCacheKey(), andBackAgain.getCacheKey());
    Assert.assertEquals(there.getDependentFields(), andBackAgain.getDependentFields());
  }
",non-flaky,5
3,eclipse_xtext-core,RequestManagerTest.testRunWriteAfterRead,"@Test
public void testRunWriteAfterRead() {
    final Function1<CancelIndicator, Integer> _function = (CancelIndicator it) -> {
        return Integer.valueOf(this.sharedState.incrementAndGet());
    };
    this.requestManager.<Integer>runRead(_function);
    final Function0<Object> _function_1 = () -> {
        return null;
    };
    final Function2<CancelIndicator, Object, Integer> _function_2 = (CancelIndicator $0,Object $1) -> {
        int _xblockexpression = ((int) (0));
        {
            Assert.assertEquals(1, this.sharedState.get());
            _xblockexpression = this.sharedState.incrementAndGet();
        }
        return Integer.valueOf(_xblockexpression);
    };
    this.requestManager.<Object, Integer>runWrite(_function_1, _function_2).join();
    Assert.assertEquals(2, this.sharedState.get());
}",concurrency,1
19420,eclipse_xtext-core,DeclarativeQualifiedNameConverterTest.getDelimiter,"	@Test public void testQualifiedNameConverter() throws Exception {
			public String getDelimiter() {
				return ""!"";
			}
",non-flaky,5
19421,eclipse_xtext-core,DeclarativeQualifiedNameConverterTest.getDelimiter,"	@Test public void testQualifiedNameConverter_emptyDelimiter() throws Exception {
			public String getDelimiter() {
				return """";
			}
",non-flaky,5
19422,eclipse_xtext-core,DeclarativeQualifiedNameConverterTest.getDelimiter,"	@Test public void testQualifiedNameConverter_nullDelimiter() throws Exception {
			public String getDelimiter() {
				return null;
			}
",non-flaky,5
19423,eclipse_xtext-core,QualifiedNameTest.testAppendNull,"	@Test public void testCreateNull() {
	public void testAppendNull() {
		try {
			QualifiedName.create().append((String) null);
			fail(""Exception expected"");
		} catch (IllegalArgumentException e) {}
	}
",non-flaky,5
19424,eclipse_xtext-core,QualifiedNameTest.apply,"	@Test public void testWrapper() throws Exception {
			public String apply(String from) {
				return from;
			}
",non-flaky,5
19425,eclipse_xtext-core,GenericModuleTest.bindDate,"	@Test public void testInstanceBinding() throws Exception {
			public Date bindDate() {
				return date;
			}
",non-flaky,5
19426,eclipse_xtext-core,GenericModuleTest.get,"	@Test public void testProviderClassDeactivation() throws Exception {
		public String get() {
			 return ""foo"";
		}
",non-flaky,5
19427,eclipse_xtext-core,GenericModuleTest.get,"	@Test public void testProviderInstanceBinding() throws Exception {
			public Date get() {
				return null;
			}
",non-flaky,5
19428,eclipse_xtext-core,GenericModuleTest.bindFoo,"	@Test public void testSingletonBinding() throws Exception {
			public Class<Foo> bindFoo() {
				return Foo.class;
			}
",non-flaky,5
19429,eclipse_xtext-core,GenericModuleTest.bindFoo,"	@Test public void testEagerSingletonBinding() throws Exception {
			public Class<Foo> bindFoo() {
				return Foo.class;
			}
",non-flaky,5
19430,eclipse_xtext-core,SerializationTest._testSerialize_03,"	@Test public void testSerialize_02() throws Exception {
	public void _testSerialize_03() throws Exception {
		model.setGenerated(GeneratedEnum.DIFFERENT_NAME);
		String result = serialize(model);
		assertEquals(""generated DifferentLiteral"", result);
	}
",non-flaky,5
19431,eclipse_xtext-core,AllContentsPerformanceTest.exec,"	@Test public void testXtextGrammarUoW() throws Exception {
			public Boolean exec(EObject state) throws Exception {
				callCount[0]++;
				return false;
			}
",non-flaky,5
19432,eclipse_xtext-core,XtextValidationTest.testBug322875_01,"	@Test
	public void testBug322875_01() throws Exception {
		String testGrammar = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'classpath:/org/eclipse/xtext/xtext/XtextValidationTest.ecore'  "" +
				"" import 'http://www.eclipse.org/2008/Xtext' as xtext\n"" +
				""Bug322875 returns Bug322875: referencesETypeFromClasspathPackage=[xtext::Grammar];"";
		XtextResource resource = getResourceFromStringAndExpect(testGrammar,1);
		assertFalse(resource.getErrors().toString(), resource.getErrors().isEmpty());
		assertBug322875(resource);
	}
",non-flaky,5
19433,eclipse_xtext-core,XtextValidationTest.testBug322875_01_b,"	@Test
	public void testBug322875_01_b() throws Exception {
		String testGrammar = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'http://www.eclipse.org/2008/Xtext' as xtext\n"" +
				"" import 'classpath:/org/eclipse/xtext/xtext/XtextValidationTest.ecore'  "" +
				""Bug322875 returns Bug322875: referencesETypeFromClasspathPackage=[xtext::Grammar];"";
		XtextResource resource = getResourceFromStringAndExpect(testGrammar,1);
		assertFalse(resource.getErrors().toString(), resource.getErrors().isEmpty());
		assertBug322875(resource);
	}
",non-flaky,5
19434,eclipse_xtext-core,XtextValidationTest.testBug322875_02,"	@Test
	public void testBug322875_02() throws Exception {
		URIConverter.URI_MAP.put(URI.createURI(""platform:/plugin/org.eclipse.emf.ecore/model/Ecore.ecore""), URI.createURI(getClass().getResource(""/model/Ecore.ecore"").toExternalForm()));
		String testGrammar = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'platform:/plugin/org.eclipse.emf.ecore/model/Ecore.ecore'  "" +
				""Model returns EClass: name=ID;"";
		XtextResource resource = getResourceFromString(testGrammar);
		Diagnostic diag = Diagnostician.INSTANCE.validate(resource.getContents().get(0));
		assertNotNull(""diag"", diag);
		assertEquals(diag.toString(), 0, diag.getChildren().size());
		assertEquals(""diag.isOk"", Diagnostic.OK, diag.getSeverity());
	}
",non-flaky,5
19435,eclipse_xtext-core,XtextValidationTest.testBug322875_04,"	@Test
	public void testBug322875_04() throws Exception {
		String testGrammarNsURI = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'http://www.eclipse.org/emf/2002/Ecore'  "" +
				""Model returns EClass: name=ID;"";
		String testGrammarPlatformPlugin = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'platform:/plugin/org.eclipse.emf.ecore/model/Ecore.ecore'  "" +
				""Model returns EClass: name=ID;"";
		XtextResource resourceOk = getResourceFromString(testGrammarNsURI);
		XtextResource resourceOk2 = (XtextResource) resourceOk.getResourceSet().createResource(URI.createURI(""unused.xtext""));
		resourceOk2.load(new StringInputStream(testGrammarPlatformPlugin), null);
		Diagnostic diagOK = Diagnostician.INSTANCE.validate(resourceOk.getContents().get(0));
		assertNotNull(""diag"", diagOK);
		assertEquals(diagOK.toString(), 0, diagOK.getChildren().size());
		diagOK = Diagnostician.INSTANCE.validate(resourceOk2.getContents().get(0));
		assertNotNull(""diag"", diagOK);
		assertEquals(diagOK.toString(), 0, diagOK.getChildren().size());
	}
",non-flaky,5
19436,eclipse_xtext-core,XtextValidationTest.testBug_280413_03,"	@Test
	public void testBug_280413_03() throws Exception {
		XtextResource resource = getResourceFromString(
				""grammar org.foo.Bar with org.eclipse.xtext.common.Terminals\n"" +
				""import 'classpath:/org/eclipse/xtext/Xtext.ecore' as xtext\n"" +
				""ParserRule returns xtext::ParserRule: name = ID;"");
		assertTrue(resource.getErrors().toString(), resource.getErrors().isEmpty());
		assertTrue(resource.getWarnings().toString(), resource.getWarnings().isEmpty());

		Diagnostic diag = Diagnostician.INSTANCE.validate(resource.getContents().get(0));
		assertNotNull(""diag"", diag);
		assertEquals(diag.getSeverity(), Diagnostic.OK);
		assertTrue(diag.getChildren().toString(), diag.getChildren().isEmpty());
	}
",non-flaky,5
19437,eclipse_xtext-core,XtextValidationTest.expectedContext,"	@Test public void testNegatedTokenNotEOF_2() throws Exception {
		String grammarAsText =
				""grammar test with org.eclipse.xtext.common.Terminals\n"" +
						""generate test 'http://test'\n"" +
						""A: foo=DUMMY;\n"" +
						""terminal DUMMY: !(EOF | ID);"";
		Grammar grammar = (Grammar) getModel(grammarAsText);
		XtextValidator validator = get(XtextValidator.class);
		ValidatingMessageAcceptor messageAcceptor = new ValidatingMessageAcceptor(null, true, false);
		TerminalRule terminal = (TerminalRule) grammar.getRules().get(1);
		NegatedToken token = (NegatedToken)terminal.getAlternatives();
		messageAcceptor.expectedContext(((Alternatives)token.getTerminal()).getElements().get(0));
		configureValidator(validator, messageAcceptor, token);
		validator.checkNegatedTokenNotEOF(token);
		messageAcceptor.validate();
	}

	public class ValidatingMessageAcceptor extends AbstractValidationMessageAcceptor {

		private final Set<EObject> contexts;
		private boolean error;
		private boolean warning;
		private boolean info;

		public ValidatingMessageAcceptor(EObject context, boolean error, boolean warning) {
			this.contexts = Sets.newHashSet();
			if (context != null)
				contexts.add(context);
			this.error = error;
			this.warning = warning;
		}
		
		public void expectedContext(EObject... contexts) {
			this.contexts.addAll(Arrays.asList(contexts));
		}
",non-flaky,5
19438,eclipse_xtext-core,TypeHierarchyHelperTest.testSimpeCase01,"	@Test
	public void testSimpeCase01() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		b.addSupertype(a);
		c.addSupertype(a);
		addAttribute(b, INT, ""f1"");
		addAttribute(c, INT, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19439,eclipse_xtext-core,TypeHierarchyHelperTest.testSimpeCase02,"	@Test
	public void testSimpeCase02() throws Exception {
		// no uplift for less than two children
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		b.addSupertype(a);
		addAttribute(b, INT, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19440,eclipse_xtext-core,TypeHierarchyHelperTest.testRecursiveUplift01,"	@Test
	public void testRecursiveUplift01() throws Exception {
		// no uplift for less than two children
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		EClassInfo d = addClass(""d"");
		EClassInfo e = addClass(""e"");
		b.addSupertype(a);
		c.addSupertype(a);
		d.addSupertype(c);
		e.addSupertype(c);

		addAttribute(b, INT, ""f1"");
		addAttribute(d, INT, ""f1"");
		addAttribute(e, INT, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
		assertEquals(1, d.getEClass().getEStructuralFeatures().size());
		assertEquals(1, e.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
		assertEquals(0, d.getEClass().getEStructuralFeatures().size());
		assertEquals(0, e.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19441,eclipse_xtext-core,TypeHierarchyHelperTest.testNikolaus,"	@Test
	public void testNikolaus() throws Exception {
		// no uplift for less than two children
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		EClassInfo d = addClass(""d"");
		EClassInfo e = addClass(""e"");
		b.addSupertype(a);
		c.addSupertype(a);
		d.addSupertype(b);
		d.addSupertype(c);
		e.addSupertype(b);
		e.addSupertype(c);

		addAttribute(b, STRING, ""f2"");
		addAttribute(c, STRING, ""f2"");
		addAttribute(d, INT, ""f1"");
		addAttribute(e, INT, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());
		assertEquals(1, d.getEClass().getEStructuralFeatures().size());
		assertEquals(1, e.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
		assertEquals(1, d.getEClass().getEStructuralFeatures().size());
		assertEquals(1, e.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19442,eclipse_xtext-core,TypeHierarchyHelperTest.testImcompatipleFeatures,"	@Test
	public void testImcompatipleFeatures() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		b.addSupertype(a);
		c.addSupertype(a);
		addAttribute(b, INT, ""f1"");
		addAttribute(c, STRING, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19443,eclipse_xtext-core,TypeHierarchyHelperTest.testReferences,"	@Test
	public void testReferences() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		EClassInfo d = addClass(""d"");
		b.addSupertype(a);
		c.addSupertype(a);
		addReference(b, d, ""r1"");
		addReference(c, d, ""r1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19444,eclipse_xtext-core,TypeHierarchyHelperTest.testConfigurationOfLiftedReference,"	@Test
	public void testConfigurationOfLiftedReference() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");

		b.addSupertype(a);
		c.addSupertype(a);
		EReference refB = addReference(b, a, ""ref"");
		refB.setContainment(true);
		EReference refC = addReference(c, a, ""ref"");
		refC.setContainment(true);

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());

		EReference refA = (EReference) a.getEClass().getEStructuralFeatures().get(0);
		assertTrue(refA.isContainment());
	}
",non-flaky,5
19445,eclipse_xtext-core,TypeHierarchyHelperTest.testDublicateDerivedFeature,"	@Test
	public void testDublicateDerivedFeature() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		b.addSupertype(a);
		c.addSupertype(b);
		addAttribute(a, INT, ""f"");
		addAttribute(c, INT, ""f"");

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		initializeHelper();
		helper.removeDuplicateDerivedFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19446,eclipse_xtext-core,EClassInfoTest.testChangeable,"	@Test public void testContainsCompatibleFeature_01() throws Exception {
	public void testChangeable(){
		EcorePackage pack = EcorePackage.eINSTANCE;
		EClass eClass = pack.getEClass();
		EClassInfo objectUnderTest = new EClassifierInfo.EClassInfo(eClass, false, Collections.<String>emptySet(), null);
		EcoreFactory fac = EcoreFactory.eINSTANCE;
		EReference reference = fac.createEReference();
		reference.setName(""newReference"");
		reference.setEType(eClass);
		reference.setChangeable(true);
		reference.setContainment(true);
		eClass.getEStructuralFeatures().add(reference);
		assertEquals(true,objectUnderTest.containsCompatibleFeature(""newReference"", false, true, eClass, new StringBuilder()));
		reference.setChangeable(false);
		assertEquals(false,objectUnderTest.containsCompatibleFeature(""newReference"", false, true, eClass, new StringBuilder()));
	}
",non-flaky,5
19447,eclipse_xtext-core,PartialParserTest.performTest,"	@Test public void testEditGroupWithCardinality_03() throws Exception {
	public void performTest(String toBeDeleted) throws Exception {
		String grammarAsText = 
			""grammar TestLanguage with org.eclipse.xtext.common.Terminals\n"" +
			""generate test 'myEcoreModel'\n"" +
			""Root: value=Test;\n"" +
			""Test: ("" + toBeDeleted.trim() + "" 'foo')*;"";
		XtextResource resource = getResourceFromString(grammarAsText);
		Grammar g = (Grammar) resource.getContents().get(0);
		ParserRule rule = (ParserRule) g.getRules().get(1);
		assertEquals(""*"", rule.getAlternatives().getCardinality());
		resource.update(grammarAsText.indexOf(toBeDeleted), toBeDeleted.length(), """");
		// make sure we did a partial parse pass
		assertSame(rule, ((Grammar) resource.getContents().get(0)).getRules().get(1));
		assertEquals(""*"", rule.getAlternatives().getCardinality());
	}
",non-flaky,5
19448,eclipse_xtext-core,Bug287082Test.acceptWarning,"	@Test public void testBug285605() throws Exception {
	public void acceptWarning(String message, EObject object, EStructuralFeature feature, int index, String code,
			String... issueData) {
		if (code.equals(OverriddenValueInspector.ISSUE_CODE)) {
			String expectation = ""The assigned value of feature 'feature' will possibly override itself because it is used inside of a loop."";
			assertEquals(expectation, message);
		} else {
			super.acceptWarning(message, object, feature, index, code, issueData);
		}
	}
",non-flaky,5
19449,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testRelativeContext() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19450,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testRelativePath() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19451,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testReexports2() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19452,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testLocalElementsNotFromIndex() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19453,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testImportsWithoutWildcard() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19454,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testDuplicateImportsAreIgnored() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19455,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testUnambiguousImportAreShadowed_00() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19456,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testUnambiguousImportAreShadowed_01() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19457,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testUnambiguousImportAreShadowed_02() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19458,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testMultipleFiles() throws Exception {
			public Iterator<EObject> iterator() {
				return res1.getAllContents();
			}
",non-flaky,5
19459,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testResourceSetReferencingResourceSet() throws Exception {
			public Iterator<EObject> iterator() {
				return res1.getAllContents();
			}
",non-flaky,5
19460,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testResourceSetReferencingResourceSet2() throws Exception {
			public Iterator<EObject> iterator() {
				return res2.getAllContents();
			}
",non-flaky,5
19461,eclipse_xtext-core,ScopeTest.iterator,"	@Test public void testLaziness() throws Exception {
				public Iterator<IEObjectDescription> iterator() {
					numberOfCalls++;
					return singleton(
							(IEObjectDescription) new EObjectDescription(QualifiedName.create(name),
									EcorePackage.Literals.EATTRIBUTE, null)).iterator();
				}
",non-flaky,5
19462,eclipse_xtext-core,DelegatingScopeProviderTest.testNoSuitableDelegate,"	@Test
	public void testNoSuitableDelegate() {
		TestableDelegatingScopeProvider testMe = new TestableDelegatingScopeProvider();
		testMe.setWrapper(this);
		Assert.assertEquals(1, testMe.invocationCount);
		
		IDelegatingScopeProvider.setWrapper(testMe, null);
		Assert.assertEquals(2, testMe.invocationCount);
	}
",non-flaky,5
19463,eclipse_xtext-core,DelegatingScopeProviderTest.testOneSuitableDelegate_01,"	@Test
	public void testOneSuitableDelegate_01() {
		TestableDelegatingScopeProvider root = new TestableDelegatingScopeProvider();
		TestableDelegatingScopeProvider delegating = new TestableDelegatingScopeProvider(root);
		
		delegating.setWrapper(this);
		Assert.assertEquals(1, delegating.invocationCount);
		Assert.assertEquals(1, root.invocationCount);
		
		IDelegatingScopeProvider.setWrapper(delegating, null);
		Assert.assertEquals(2, delegating.invocationCount);
		Assert.assertEquals(2, root.invocationCount);
	}
",non-flaky,5
19464,eclipse_xtext-core,DelegatingScopeProviderTest.getScope,"	@Test
	public void testOneSuitableDelegate_02() {
		final int[] invocationCount = new int[] { 0 };
		AbstractGlobalScopeDelegatingScopeProvider root = new AbstractGlobalScopeDelegatingScopeProvider() {
			
			@Override
			public IScope getScope(EObject context, EReference reference) {
				return IScope.NULLSCOPE;
			}
",non-flaky,5
19465,eclipse_xtext-core,DelegatingScopeProviderTest.getScope,"	@Test
	public void testTwoSuitableDelegates_02() {
		final int[] invocationCount = new int[] { 0 };
		AbstractGlobalScopeDelegatingScopeProvider first = new AbstractGlobalScopeDelegatingScopeProvider() {
			
			@Override
			public IScope getScope(EObject context, EReference reference) {
				return IScope.NULLSCOPE;
			}
",non-flaky,5
19466,eclipse_xtext-core,ImportScopeTest.getEObjectOrProxy,"	@Test public void testGetByEObject_01() throws Exception {
		public EObject getEObjectOrProxy() {
			EObject element = super.getEObjectOrProxy();
			InternalEObject result = (InternalEObject) EcoreFactory.eINSTANCE.create(element.eClass());
			result.eSetProxyURI(EcoreUtil.getURI(element));
			return result;
		}
",non-flaky,5
19467,eclipse_xtext-core,ProfilingTest.createInjector,"	@Test public void testSimple() throws Exception {
			public Injector createInjector() {
				return Guice.createInjector(new org.eclipse.xtext.index.IndexTestLanguageRuntimeModule(){
					@Override
					public java.lang.Class<? extends org.eclipse.xtext.scoping.IScopeProvider> bindIScopeProvider() {
						return OptimizedScopeProvider.class;
					}
				}
				);
			}
",non-flaky,5
19468,eclipse_xtext-core,Bug318343Test.tearDown,"	@Test public void testScopeContainsNotT2() throws Exception {
	public void tearDown() throws Exception {
		resource1 = null;
		resource2 = null;
		globalScopeProvider = null;
		super.tearDown();
		
	}
",non-flaky,5
19469,eclipse_xtext-core,ParseErrorHandlingTest.apply,"	@Test public void testBug236425() throws Exception {
			public Iterator<INode> iterator() {
				return Iterators.filter(node.getAsTreeIterable().iterator(), new Predicate<INode>() {
					@Override
					public boolean apply(INode input) {
						return input.getSyntaxErrorMessage() != null;
					}
",non-flaky,5
19470,eclipse_xtext-core,UriBasedReaderTest.configureFileExtensions,"	@Test public void testIssuesInOtherResource() throws Exception {
			public Injector createInjector() {
				return Guice.createInjector(new org.eclipse.xtext.XtextRuntimeModule() {
					@Override
					public void configureFileExtensions(Binder binder) {
						binder.bind(String.class).annotatedWith(Names.named(Constants.FILE_EXTENSIONS)).toInstance(""xtexterror"");
					}
",non-flaky,5
19471,eclipse_xtext-core,ReaderTest.apply,"	@Test public void testShadowingPathes() throws Exception {
			public boolean apply(EObject input) {
				return input.eResource().getURI().toString().contains(""folder%20""+uriContains);
			}
",non-flaky,5
19472,eclipse_xtext-core,PathTraverserTest.testNoneExistingFile,"	@Test
	public void testNoneExistingFile() throws Exception {
		String path = ""fileNotExists"";
		Set<URI> uris = new PathTraverser().findAllResourceUris(path, everythingButDummy);
		assertTrue(uris.isEmpty());
	}
",non-flaky,5
19473,eclipse_xtext-core,PathTraverserTest.testEmptyFolder,"	@Test
	public void testEmptyFolder() throws Exception {
		String path = pathTo(""emptyFolder"");
		Set<URI> uris = new PathTraverser().findAllResourceUris(path, everythingButDummy);
		assertTrue(uris.isEmpty());
	}
",non-flaky,5
19474,eclipse_xtext-core,PathTraverserTest.testNonEmptyFolder,"	@Test
	public void testNonEmptyFolder() throws Exception {
		String path = pathTo(""nonemptyFolder"");
		Set<URI> uris = new PathTraverser().findAllResourceUris(path, everythingButDummy);
		assertEquals(2, uris.size());
	}
",non-flaky,5
19475,eclipse_xtext-core,PathTraverserTest.testArchive,"	@Test
	public void testArchive() throws Exception {
		String path = pathTo(""nonemptyJar.jar"");
		Set<URI> uris = new PathTraverser().findAllResourceUris(path, everythingButDummy);
		assertEquals(3, uris.size());
	}
",non-flaky,5
19476,eclipse_xtext-core,AbstractReaderTest.matches,"	@Test public void testLoadMatchNone() throws Exception {
			public boolean matches(URI uri) {
				return false;
			}
",non-flaky,5
19477,eclipse_xtext-core,AbstractReaderTest.matches,"	@Test public void testLoadMatchAll() throws Exception {
			public boolean matches(URI uri) {
				return true;
			}
",non-flaky,5
19478,eclipse_xtext-core,AbstractReaderTest.pathTo,"	@Test public void testParseClassPath() throws Exception {
	public String pathTo(String string) throws Exception {
//		URL resource = getClass().getClassLoader().getResource();
		File base = new File(""./src/""+getClass().getName().replace('.', '/') + "".java"");
		URI fileURI = URI.createFileURI(base.getAbsolutePath());
//		System.out.println(fileURI);
		// this is a hack used in order to get a file URI for a bundleresource:/ URL
//		File f = (File) get(resource,""handler.bundleEntry.file"");
//		if (f!=null)
//			fileURI = URI.createFileURI(f.getAbsolutePath());
		
		URI fileURI2 = URI.createURI(string);
		return fileURI2.resolve(fileURI).toFileString();
	}
",non-flaky,5
19479,eclipse_xtext-core,CompositeNodeTest.iterator,"	@Test public void testGetLeafNodes_01() {
			public Iterator<INode> iterator() {
				return new AbstractIterator<INode>() {

					private BidiTreeIterator<AbstractNode> delegate = node.basicIterator();
					
					@Override
					protected INode computeNext() {
						if (delegate.hasPrevious())
							return delegate.previous();
						return endOfData();
					}
				};
			}
",non-flaky,5
19480,eclipse_xtext-core,LineAndColumnTest.testEmptyText,"	@Test
	public void testEmptyText() {
		assertLineAndColumn("""", 0, 1, 1);
	}
",non-flaky,5
19481,eclipse_xtext-core,LineAndColumnTest.testExceedsOffset,"	@Test(expected=IndexOutOfBoundsException.class)
	public void testExceedsOffset() {
		assertLineAndColumn("""", 1, -1, -1);
	}
",non-flaky,5
19482,eclipse_xtext-core,LineAndColumnTest.testNegativeOffset,"	@Test(expected=IndexOutOfBoundsException.class)
	public void testNegativeOffset() {
		assertLineAndColumn("""", -1, -1, -1);
	}
",non-flaky,5
19483,eclipse_xtext-core,LineAndColumnTest.testSingleCharText,"	@Test
	public void testSingleCharText() {
		assertLineAndColumn(""a"", 0, 1, 1);
		assertLineAndColumn(""a"", 1, 1, 2);
	}
",non-flaky,5
19484,eclipse_xtext-core,LineAndColumnTest.testTwoCharsText,"	@Test
	public void testTwoCharsText() {
		assertLineAndColumn(""ab"", 0, 1, 1);
		assertLineAndColumn(""ab"", 1, 1, 2);
		assertLineAndColumn(""ab"", 2, 1, 3);
	}
",non-flaky,5
19485,eclipse_xtext-core,LineAndColumnTest.testPointsToLineBreak,"	@Test
	public void testPointsToLineBreak() {
		assertLineAndColumn(""\n"", 0, 1, 1);
		assertLineAndColumn(""\r\n"", 0, 1, 1);
	}
",non-flaky,5
19486,eclipse_xtext-core,LineAndColumnTest.testPointsToBackslashNInWindowsLineBreak,"	@Test
	public void testPointsToBackslashNInWindowsLineBreak() {
		assertLineAndColumn(""\r\n"", 1, 1, 2);
		assertLineAndColumn(""a\r\n"", 2, 1, 3);
		assertLineAndColumn(""a\r\n"", 3, 2, 1);
	}
",non-flaky,5
19487,eclipse_xtext-core,LengthOffsetLineTest.setUp,"	@Test public void testErrors1() throws Exception {
	public void setUp() throws Exception {
		super.setUp();
		with(DummyTestLanguageStandaloneSetup.class);
	}
",non-flaky,5
19488,eclipse_xtext-core,SerializationUtilTest.testFillIdToEObjectMap,"	@Test
	public void testFillIdToEObjectMap() {
		EPackage pack = EcoreFactory.eINSTANCE.createEPackage();
		EClass root = createEClass(pack, ""Root"");
		EClass someType = createEClass(pack, ""SomeType"");

		EReference ref1 = addEReference(root, someType, ""ref1"", false);
		EReference ref2 = addEReference(root, someType, ""ref2"", true);

		EFactory factory = pack.getEFactoryInstance();
		EObject rootObject = factory.create(root);
		EObject someTypeObject1 = factory.create(someType);
		EObject someTypeObject2 = factory.create(someType);
		rootObject.eSet(ref1, someTypeObject1);
		rootObject.eSet(ref2, someTypeObject2);

		List<EObject> map = new ArrayList<>();
		SerializationUtil.fillIdToEObjectMap(rootObject, map);
		assertTrue(map.contains(rootObject));
		assertTrue(map.contains(someTypeObject1));
		assertFalse(map.contains(someTypeObject2));
		assertEquals(2, map.size());
	}
",non-flaky,5
19489,eclipse_xtext-core,SerializationUtilTest.testSyntaxErrorMessage,"	@Test
	public void testSyntaxErrorMessage() throws IOException {
		final String message = ""hi"";
		String [] issueCodes = { null, ""issue"" };
		String [][] issueDatas = { null, {null}, {""issue data""}};
		
		for (String[] issueData : issueDatas) {
			for (String issueCode : issueCodes) {
				SyntaxErrorMessage sem = new SyntaxErrorMessage(message, issueCode, issueData);
				ByteArrayOutputStream out = new ByteArrayOutputStream ();
				DataOutputStream dout = new DataOutputStream(out);
				SerializationUtil.writeSyntaxErrorMessage(dout, null, sem);
				dout.close();
				byte[] array = out.toByteArray();
				ByteArrayInputStream in = new ByteArrayInputStream(array); 
				DataInputStream din = new DataInputStream(in);
				SyntaxErrorMessage sem2 = SerializationUtil.readSyntaxErrorMessage(din, null);
				assertEquals(sem, sem2); 
			}
		}
		ByteArrayOutputStream out = new ByteArrayOutputStream ();
		DataOutputStream dout = new DataOutputStream(out);
		SerializationUtil.writeSyntaxErrorMessage(dout, null, null);
		dout.close();
		byte[] array = out.toByteArray();
		ByteArrayInputStream in = new ByteArrayInputStream(array); 
		DataInputStream din = new DataInputStream(in);
		SyntaxErrorMessage readMessage = SerializationUtil.readSyntaxErrorMessage(din, null);
		assertNull(readMessage);
	}
",non-flaky,5
19490,eclipse_xtext-core,EcoreUtil2Test.testClone_2,"	@Test
	public void testClone_2() throws Exception {
		ResourceSetImpl sourceSet = new DerivedStateAwareResourceSet();
		DerivedStateAwareResource resource = (DerivedStateAwareResource) sourceSet.createResource(URI
				.createURI(""http://derived.res""));
		boolean stateToCheck = !resource.isFullyInitialized();
		resource.setFullyInitialized(stateToCheck);
		
		Resource targetRes = EcoreUtil2.clone(new DerivedStateAwareResourceSet(), sourceSet).getResources().get(0);
		
		assertTrue(targetRes instanceof DerivedStateAwareResource);
		assertEquals(""FullyInitialized flag not copied "", stateToCheck, ((DerivedStateAwareResource) targetRes).isFullyInitialized());
	}
",non-flaky,5
19491,eclipse_xtext-core,ReadWriteAccessTest.uncaughtException,"	@Test public void testModifyAndRead() throws Exception {
			public void uncaughtException(Thread t, Throwable e) {
				exceptions.add(e);
			}
",non-flaky,5
19492,eclipse_xtext-core,Bug367679Test.testValidatorExists_0,"	@Test 
	public void testValidatorExists_0() {
		assertValidatorExists();
	}
",non-flaky,5
19493,eclipse_xtext-core,Bug367679Test.testValidatorExists_1,"	@Test 
	public void testValidatorExists_1() {
		assertValidatorExists();
	}
",non-flaky,5
19494,eclipse_xtext-core,JavaIoFileSystemAccessTest.testDirsAndFilesAreCreated,"	@Test
	public void testDirsAndFilesAreCreated() throws Exception {
		File dir = null;
		File textFile = null;
		File binFile = null;
		try {
			JavaIoFileSystemAccess fileSystemAccess = new JavaIoFileSystemAccess(
					IResourceServiceProvider.Registry.INSTANCE, new IEncodingProvider.Runtime());

			File tmpDir = configureFileSystemAccess(fileSystemAccess);
			fileSystemAccess.generateFile(""tmp/X"", ""XX"");
			fileSystemAccess.generateFile(""tmp/Y"", new StringInputStream(""\1\2\3""));

			dir = new File(tmpDir, ""tmp"");
			assertTrue(dir.exists());
			assertTrue(dir.isDirectory());

			textFile = new File(dir, ""X"");
			assertTrue(textFile.exists());
			assertTrue(textFile.isFile());
			assertEquals(""XX"", fileSystemAccess.readTextFile(""tmp/X""));

			binFile = new File(dir, ""Y"");
			assertTrue(binFile.exists());
			assertFalse(fileSystemAccess.isFile(""tmp"", IFileSystemAccess.DEFAULT_OUTPUT)); // isFile evaluates to false for directories
			assertTrue(fileSystemAccess.isFile(""tmp/Y"", IFileSystemAccess.DEFAULT_OUTPUT));
			assertTrue(binFile.isFile());
			InputStream stream = fileSystemAccess.readBinaryFile(""tmp/Y"");
			try {
				assertEquals(""\1\2\3"", new String(ByteStreams.toByteArray(stream)));
			} finally {
				stream.close();
			}

		} finally {
			try {
				if (textFile != null)
					textFile.delete();
			} finally {
				try {
					if (binFile != null)
						binFile.delete();
				} finally {
					if (dir != null)
						dir.delete();
				}
			}
		}
	}
",non-flaky,5
19495,eclipse_xtext-core,JavaIoFileSystemAccessTest.testURI,"	@Test
	public void testURI() throws Exception {
		JavaIoFileSystemAccess fileSystemAccess = new JavaIoFileSystemAccess();
		fileSystemAccess.setOutputPath(""testOutput"", ""/testDir"");
		URI uri = fileSystemAccess.getURI(""testFile"", ""testOutput"");
		String expectedUri = new File(new File(File.separator + ""testDir""), ""testFile"").toURI().toString();
		assertEquals(expectedUri, uri.toString());
	}
",non-flaky,5
19496,eclipse_xtext-core,JavaIoFileSystemAccessTest.getEncoding,"	@Test
	public void testEncoding() throws Exception {
		File file = null;
		FileInputStream fileInputStream = null;
		try {
			JavaIoFileSystemAccess fileSystemAccess = new JavaIoFileSystemAccess(
					IResourceServiceProvider.Registry.INSTANCE, new IEncodingProvider() {
						@Override
						public String getEncoding(URI uri) {
							return ""ISO-8859-1"";
						}
",non-flaky,5
19497,eclipse_xtext-core,JavaIoFileSystemAccessTest.testTraceIsCreated,"	@Test
	public void testTraceIsCreated() throws Exception {
		File file = null;
		try {

			JavaIoFileSystemAccess fileSystemAccess = new JavaIoFileSystemAccess(
					IResourceServiceProvider.Registry.INSTANCE, new IEncodingProvider.Runtime(),
					new TraceFileNameProvider(), new TraceRegionSerializer());

			File tmpDir = configureFileSystemAccess(fileSystemAccess);
			SourceRelativeURI uri = new SourceRelativeURI(URI.createURI(""foo/bar""));
			CharSequenceTraceWrapper wrapper = new CharSequenceTraceWrapper();
			fileSystemAccess.generateFile(""tmp/X"", wrapper.wrapWithTraceData(""XX"", uri, 0, 10, 0, 1));

			file = new File(tmpDir, ""tmp/X"");
			assertTrue(file.exists());
			assertTrue(file.isFile());
			assertEquals(""XX"", fileSystemAccess.readTextFile(""tmp/X""));

			file = new File(tmpDir, ""tmp/.X._trace"");
			assertTrue(file.exists());
			assertTrue(file.isFile());

		} finally {
			if (file != null)
				file.delete();
		}
	}
",non-flaky,5
19498,eclipse_xtext-core,TraceRegionTest.testConstructor,"	@Test
	public void testConstructor() {
		TraceRegion region = new TraceRegion(0, 1, 0, 0, true, 2, 3, 0, 0, null, newURI());
		assertEquals(0, region.getMyOffset());
		assertEquals(1, region.getMyLength());
		assertEquals(2, region.getMergedAssociatedLocation().getOffset());
		assertEquals(3, region.getMergedAssociatedLocation().getLength());
		assertEquals(newURI(), region.getAssociatedSrcRelativePath());
		assertNull(region.getParent());
		assertTrue(region.getNestedRegions().isEmpty());
	}
",non-flaky,5
19499,eclipse_xtext-core,TraceRegionTest.testConstructorWithParent,"	@Test
	public void testConstructorWithParent() {
		TraceRegion parent = new TraceRegion(0, 1, 0, 0, true, 2, 3, 0, 0, null, newURI());
		TraceRegion region = new TraceRegion(0, 1, 0, 0, true, 2, 3, 0, 0, parent, null);
		assertEquals(newURI(), region.getAssociatedSrcRelativePath());
		assertEquals(parent, region.getParent());
	}
",non-flaky,5
19500,eclipse_xtext-core,TraceRegionTest.testConstructorInvalidArgs_01,"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_01() {
		new TraceRegion(-1, 0, 0, 0, true, 0, 0, 0, 0, null, newURI());
	}
",non-flaky,5
19501,eclipse_xtext-core,TraceRegionTest.testConstructorInvalidArgs_02,"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_02() {
		new TraceRegion(0, -1, 0, 0, true, 0, 0, 0, 0, null, newURI());
	}
",non-flaky,5
19502,eclipse_xtext-core,TraceRegionTest.testConstructorInvalidArgs_03,"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_03() {
		new TraceRegion(0, 0, -1, 0, true, 0, 0, 0, 0, null, newURI());
	}
",non-flaky,5
19503,eclipse_xtext-core,TraceRegionTest.testConstructorInvalidArgs_04,"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_04() {
		new TraceRegion(0, 0, 0, -1, true, 0, 0, 0, 0, null, newURI());
	}
",non-flaky,5
19504,eclipse_xtext-core,TraceRegionTest.testConstructorInvalidArgs_05,"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_05() {
		new TraceRegion(0, 0, 0, 0, true, 0, 0, 0, 0, null, null);
	}
",non-flaky,5
19505,eclipse_xtext-core,TraceRegionTest.testLeafIterator_NoChildren,"	@Test
	public void testLeafIterator_NoChildren() {
		TraceRegion region = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, null, newURI());
		Iterator<AbstractTraceRegion> iter = region.leafIterator();
		assertEquals(Collections.singleton(region).iterator(), iter);
	}
",non-flaky,5
19506,eclipse_xtext-core,TraceRegionTest.testLeafIterator_OneChild,"	@Test
	public void testLeafIterator_OneChild() {
		TraceRegion parent = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion region = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Collections.singleton(region).iterator(), iter);
	}
",non-flaky,5
19507,eclipse_xtext-core,TraceRegionTest.testLeafIterator_GrandChild,"	@Test
	public void testLeafIterator_GrandChild() {
		TraceRegion root = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion parent = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, root, null);
		TraceRegion region = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Collections.singleton(region).iterator(), iter);
	}
",non-flaky,5
19508,eclipse_xtext-core,TraceRegionTest.testLeafIterator_TwoChildren_NoGaps,"	@Test
	public void testLeafIterator_TwoChildren_NoGaps() {
		TraceRegion parent = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, parent, null);
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19509,eclipse_xtext-core,TraceRegionTest.testLeafIterator_OneChild_LeftGap,"	@Test
	public void testLeafIterator_OneChild_LeftGap() {
		final TraceRegion parent = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		AbstractTraceRegion first = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(0, 1, 0, 1), true, new LocationData(2, 3, 0, 0, null), parent) {};
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19510,eclipse_xtext-core,TraceRegionTest.testLeafIterator_OneChild_RightGap,"	@Test
	public void testLeafIterator_OneChild_RightGap() {
		final TraceRegion parent = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		AbstractTraceRegion first = new TraceRegion(0, 1, 0, 1, true, 3, 4, 0, 0, parent, null);
		AbstractTraceRegion second = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(1, 1, 1, 2), true, new LocationData(2, 3, 0, 0, null), parent) {};
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19511,eclipse_xtext-core,TraceRegionTest.testLeafIterator_OneGrandChild_LeftGap,"	@Test
	public void testLeafIterator_OneGrandChild_LeftGap() {
		final TraceRegion root = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		AbstractTraceRegion first = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(0, 1, 0, 1), true, new LocationData(2, 3, 0, 0, null), root) {};
		TraceRegion parent = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, root, null);
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19512,eclipse_xtext-core,TraceRegionTest.testLeafIterator_OneGrandChild_RightGap,"	@Test
	public void testLeafIterator_OneGrandChild_RightGap() {
		final TraceRegion root = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion parent = new TraceRegion(0, 1, 0, 1, true, 3, 4, 0, 0, root, null);
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 3, 4, 0, 0, parent, null);
		AbstractTraceRegion second = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(1, 1, 1, 2), true, new LocationData(2, 3, 0, 0, null), root) {};
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19513,eclipse_xtext-core,TraceRegionTest.testLeafIterator_TwoGrandChildren_NoGaps_01,"	@Test
	public void testLeafIterator_TwoGrandChildren_NoGaps_01() {
		TraceRegion root = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion parent = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, root, null);
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, parent, null);
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19514,eclipse_xtext-core,TraceRegionTest.testLeafIterator_TwoGrandChildren_NoGaps_02,"	@Test
	public void testLeafIterator_TwoGrandChildren_NoGaps_02() {
		TraceRegion root = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion firstParent = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, root, null);
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, firstParent, null);
		TraceRegion secondParent = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, root, null);
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, secondParent, null);
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19515,eclipse_xtext-core,TraceRegionTest.testLeafIterator_TwoChildren_WithGaps,"	@Test
	public void testLeafIterator_TwoChildren_WithGaps() {
		final TraceRegion parent = new TraceRegion(0, 3, 0, 3, true, 2, 3, 0, 0, null, newURI());
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, parent, null);
		AbstractTraceRegion second = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(1, 1, 1, 2), true, new LocationData(2, 3, 0, 0, null), parent) {};
		AbstractTraceRegion third = new TraceRegion(2, 1, 2, 3, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Arrays.asList(first, second, third).iterator(), iter);
	}
",non-flaky,5
19516,eclipse_xtext-core,TraceRegionTest.testAnnotate_01,"	@Test
	public void testAnnotate_01() {
		TraceRegion region = new TraceRegion(0, 1, 0, 0, true, 2, 3, 0, 0, null, newURI());
		assertEquals(""<2:3[a]"", region.getAnnotatedString(""a""));
	}
",non-flaky,5
19517,eclipse_xtext-core,TraceRegionTest.testAnnotate_02,"	@Test
	public void testAnnotate_02() {
		TraceRegion region = new TraceRegion(1, 1, 0, 0, true, 2, 3, 0, 0, null, newURI());
		assertEquals(""a<2:3[b]c"", region.getAnnotatedString(""abc""));
	}
",non-flaky,5
19518,eclipse_xtext-core,TraceRegionTest.testAnnotate_03,"	@Test
	public void testAnnotate_03() {
		TraceRegion parent = new TraceRegion(0, 4, 0, 0, true, 1, 2, 0, 0, null, newURI());
		new TraceRegion(0, 1, 0, 0, true, 3, 4, 0, 0, parent, null);
		new TraceRegion(2, 1, 0, 0, true, 5, 6, 0, 0, parent, null);
		new TraceRegion(3, 1, 0, 0, true, 7, 8, 0, 0, parent, null);
		assertEquals(""<1:2[<3:4[a]b<5:6[c]<7:8[d]]e"", parent.getAnnotatedString(""abcde""));
	}
",non-flaky,5
19519,eclipse_xtext-core,TraceRegionTest.testAnnotate_04,"	@Test
	public void testAnnotate_04() {
		TraceRegion root = new TraceRegion(0, 4, 0, 0, true, 1, 2, 0, 0, null, newURI());
		TraceRegion parent = new TraceRegion(1, 2, 0, 0, true, 3, 4, 0, 0, root, null);
		new TraceRegion(2, 1, 0, 0, true, 5, 6, 0, 0, parent, null);
		assertEquals(""<1:2[a<3:4[b<5:6[c]]d]e"", root.getAnnotatedString(""abcde""));
	}
",non-flaky,5
178,salesforce_reactive-grpc,ChainedCallIntegrationTest.servicesCanCallOtherServices,"@Test
public void servicesCanCallOtherServices() throws InterruptedException {
    ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
    Mono<String> chain =
    Mono.just(request(""X"")).compose(stub::sayHello).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).as(stub::sayHelloRespStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).compose(stub::sayHelloBothStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).as(stub::sayHelloReqStream).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).compose(stub::sayHello).map(HelloResponse::getMessage).doOnSuccess(System.out::println);
    StepVerifier.create(chain).expectNext(""[<{[X]}> :: </[X]/> :: <\\[X]\\> :: <([X])>]"").expectComplete().verify(Duration.ofSeconds(2));
}",concurrency,1
113698,salesforce_reactive-grpc,GradleProofTest.gradleProof,"    @Test
    public void gradleProof() throws Exception {
        GradleProof proof = new GradleProof();
        try {
            proof.startServer();
            String result = proof.doClient(""World"");
            assertEquals(""Hello World"", result);
        } finally {
            proof.stopServer();
        }
    }
",non-flaky,5
113699,salesforce_reactive-grpc,ExampleInstrumentedTest.useAppContext,"    @Test
    public void useAppContext() {
        // Context of the app under test.
        Context appContext = InstrumentationRegistry.getTargetContext();

        assertEquals(""demo.client.android"", appContext.getPackageName());
    }
",non-flaky,5
113700,salesforce_reactive-grpc,ExampleUnitTest.addition_isCorrect,"    @Test
    public void addition_isCorrect() {
        assertEquals(4, 2 + 2);
    }
",non-flaky,5
113701,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.clientCanCancelServerStreamExplicitly,"    @Test
    public void clientCanCancelServerStreamExplicitly() throws InterruptedException {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        AtomicInteger lastNumberConsumed = new AtomicInteger(Integer.MAX_VALUE);
        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());
        Flux<NumberProto.Number> test = Mono.just(Empty.getDefaultInstance()).as(stub::responsePressure)
                .doOnNext(number -> {lastNumberConsumed.set(number.getNumber(0)); System.out.println(""C: "" + number.getNumber(0));})
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""));

        Disposable subscription = test.publish().connect();

        Thread.sleep(1000);
        subscription.dispose();
        Thread.sleep(1000);

        // Cancellation may or may not deliver the last generated message due to delays in the gRPC processing thread
        assertThat(Math.abs(lastNumberConsumed.get() - svc.getLastNumberProduced())).isLessThanOrEqualTo(3);
        assertThat(svc.wasCanceled()).isTrue();
    }
",non-flaky,5
113702,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.clientCanCancelServerStreamImplicitly,"    @Test
    public void clientCanCancelServerStreamImplicitly() throws InterruptedException {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());
        Flux<NumberProto.Number> test = Mono.just(Empty.getDefaultInstance()).as(stub::responsePressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""))
                .take(10);

        Disposable subscription = test.publish().connect();

        Thread.sleep(1000);

        assertThat(svc.wasCanceled()).isTrue();
    }
",non-flaky,5
113703,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamImplicitly,"    @Test
    public void serverCanCancelClientStreamImplicitly() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        svc.setExplicitCancel(false);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flux<NumberProto.Number> request = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delayElements(Duration.ofMillis(SEQUENCE_DELAY_MILLIS))
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(x -> {
                    requestDidProduce.set(true);
                    System.out.println(""Produced: "" + x.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        Mono<NumberProto.Number> observer = request.as(stub::requestPressure)
                .doOnSuccess(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()));

        StepVerifier.create(observer)
                .expectNext(protoNum(9))
                .verifyComplete();

        await().atMost(org.awaitility.Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();
    }
",non-flaky,5
113704,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamExplicitly,"    @Test
    public void serverCanCancelClientStreamExplicitly() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        svc.setExplicitCancel(true);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flux<NumberProto.Number> request = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delayElements(Duration.ofMillis(SEQUENCE_DELAY_MILLIS))
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(n -> {
                    requestDidProduce.set(true);
                    System.out.println(""P: "" + n.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        Mono<NumberProto.Number> observer = request.as(stub::requestPressure)
                .doOnSuccess(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()));

        StepVerifier.create(observer)
                .expectNext(protoNum(-1))
                .verifyComplete();

        await().atMost(org.awaitility.Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();
    }
",non-flaky,5
113705,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamImplicitlyBidi,"    @Test
    public void serverCanCancelClientStreamImplicitlyBidi() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        svc.setExplicitCancel(false);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flux<NumberProto.Number> request = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delayElements(Duration.ofMillis(SEQUENCE_DELAY_MILLIS))
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(x -> {
                    requestDidProduce.set(true);
                    System.out.println(""Produced: "" + x.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        Flux<NumberProto.Number> observer = request.compose(stub::twoWayPressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()));

        StepVerifier.create(observer)
                .expectNext(protoNum(9))
                .verifyComplete();

        await().atMost(org.awaitility.Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();
    }
",non-flaky,5
113706,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamExplicitlyBidi,"    @Test
    public void serverCanCancelClientStreamExplicitlyBidi() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        svc.setExplicitCancel(true);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flux<NumberProto.Number> request = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delayElements(Duration.ofMillis(SEQUENCE_DELAY_MILLIS))
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(n -> {
                    requestDidProduce.set(true);
                    System.out.println(""P: "" + n.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        Flux<NumberProto.Number> observer = request.compose(stub::twoWayPressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()));

        StepVerifier.create(observer)
                .expectNext(protoNum(-1))
                .verifyComplete();

        await().atMost(org.awaitility.Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();
    }
",non-flaky,5
113707,salesforce_reactive-grpc,ServerErrorIntegrationTest.oneToOne,"    @Test
    public void oneToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloResponse> resp = Mono.just(HelloRequest.getDefaultInstance()).compose(stub::sayHello);

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
",non-flaky,5
113708,salesforce_reactive-grpc,ServerErrorIntegrationTest.oneToMany,"    @Test
    public void oneToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloResponse> resp = Mono.just(HelloRequest.getDefaultInstance()).as(stub::sayHelloRespStream);
        Flux<HelloResponse> test = resp
                .doOnNext(System.out::println)
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""));

        StepVerifier.create(test)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
",non-flaky,5
113709,salesforce_reactive-grpc,ServerErrorIntegrationTest.manyToOne,"    @Test
    public void manyToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloResponse> resp = Flux.just(HelloRequest.getDefaultInstance()).as(stub::sayHelloReqStream);
        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
",non-flaky,5
113710,salesforce_reactive-grpc,ServerErrorIntegrationTest.manyToMany,"    @Test
    public void manyToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloResponse> resp = Flux.just(HelloRequest.getDefaultInstance()).compose(stub::sayHelloBothStream);
        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
",non-flaky,5
113711,salesforce_reactive-grpc,BackpressureIntegrationTest.clientToServerBackpressure,"    @Test
    public void clientToServerBackpressure() {
        serverRule.getServiceRegistry().addService(new TestService());

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        Flux<NumberProto.Number> reactorRequest = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .doOnNext(i -> System.out.println(i + "" --> ""))
                .doOnNext(i -> updateNumberOfWaits(lastValueTime, numberOfWaits))
                .map(BackpressureIntegrationTest::protoNum);

        Mono<NumberProto.Number> reactorResponse = reactorRequest.as(stub::requestPressure);

        StepVerifier.create(reactorResponse)
                .expectNextMatches(v -> v.getNumber(0) == NUMBER_OF_STREAM_ELEMENTS - 1)
                .expectComplete()
                .verify(Duration.ofSeconds(5));

        assertThat(numberOfWaits.get()).isEqualTo(1);
    }
",non-flaky,5
113712,salesforce_reactive-grpc,BackpressureIntegrationTest.serverToClientBackpressure,"    @Test
    public void serverToClientBackpressure() {
        serverRule.getServiceRegistry().addService(new TestService());

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        Mono<Empty> reactorRequest = Mono.just(Empty.getDefaultInstance());

        Flux<NumberProto.Number> reactorResponse = reactorRequest.as(stub::responsePressure)
                .doOnNext(n -> System.out.println(n.getNumber(0) + ""  <--""))
                .doOnNext(n -> waitIfValuesAreEqual(n.getNumber(0), 3));

        StepVerifier.create(reactorResponse)
                .expectNextCount(NUMBER_OF_STREAM_ELEMENTS)
                .expectComplete()
                .verify(Duration.ofSeconds(5));

        assertThat(numberOfWaits.get()).isEqualTo(1);
    }
",non-flaky,5
113713,salesforce_reactive-grpc,BackpressureIntegrationTest.bidiResponseBackpressure,"    @Test
    public void bidiResponseBackpressure() {
        serverRule.getServiceRegistry().addService(new TestService());

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        Flux<NumberProto.Number> reactorRequest = Flux.empty();

        Flux<NumberProto.Number> reactorResponse = reactorRequest.compose(stub::twoWayResponsePressure)
                .doOnNext(n -> System.out.println(n.getNumber(0) + ""  <--""))
                .doOnNext(n -> waitIfValuesAreEqual(n.getNumber(0), 3));

        StepVerifier.create(reactorResponse)
                .expectNextCount(NUMBER_OF_STREAM_ELEMENTS)
                .expectComplete()
                .verify(Duration.ofSeconds(5));

        assertThat(numberOfWaits.get()).isEqualTo(1);
    }
",non-flaky,5
113714,salesforce_reactive-grpc,BackpressureIntegrationTest.bidiRequestBackpressure,"    @Test
    public void bidiRequestBackpressure() {
        serverRule.getServiceRegistry().addService(new TestService());

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        Flux<NumberProto.Number> reactorRequest = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .doOnNext(i -> System.out.println(i + "" --> ""))
                .doOnNext(i -> updateNumberOfWaits(lastValueTime, numberOfWaits))
                .map(BackpressureIntegrationTest::protoNum);

        Flux<NumberProto.Number> reactorResponse = reactorRequest.compose(stub::twoWayRequestPressure);

        StepVerifier.create(reactorResponse)
                .expectNextMatches(v -> v.getNumber(0) == NUMBER_OF_STREAM_ELEMENTS - 1)
                .expectComplete()
                .verify(Duration.ofSeconds(5));

        assertThat(numberOfWaits.get()).isEqualTo(1);
    }
",non-flaky,5
113715,salesforce_reactive-grpc,ServerErrorUpstreamCancellationIntegrationTest.serverErrorSignalsUpstreamCancellationManyToOne,"    @Test
    public void serverErrorSignalsUpstreamCancellationManyToOne() {
        serverRule.getServiceRegistry().addService(new ExplodeAfterFiveService());
        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        AtomicBoolean upstreamCancel = new AtomicBoolean(false);

        Mono<NumberProto.Number> observer = Flux.range(0, Integer.MAX_VALUE)
                .map(this::protoNum)
                .doOnCancel(() -> upstreamCancel.set(true))
                .as(stub::requestPressure)
                .doOnError(System.out::println)
                .doOnSuccess(i -> System.out.println(i.getNumber(0)));

        StepVerifier.create(observer)
                .verifyError(StatusRuntimeException.class);

        assertThat(upstreamCancel.get()).isTrue();
    }
",non-flaky,5
113716,salesforce_reactive-grpc,ServerErrorUpstreamCancellationIntegrationTest.serverErrorSignalsUpstreamCancellationBidi,"    @Test
    public void serverErrorSignalsUpstreamCancellationBidi() {
        serverRule.getServiceRegistry().addService(new ExplodeAfterFiveService());
        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        AtomicBoolean upstreamCancel = new AtomicBoolean(false);

        Flux<NumberProto.Number> subscriber = Flux.range(0, Integer.MAX_VALUE)
                .map(this::protoNum)
                .doOnCancel(() -> upstreamCancel.set(true))
                .compose(stub::twoWayPressure)
                .doOnNext(i -> System.out.println(i.getNumber(0)));

        StepVerifier.create(subscriber)
                .verifyError(StatusRuntimeException.class);
        assertThat(upstreamCancel.get()).isTrue();
    }
",non-flaky,5
113717,salesforce_reactive-grpc,UnexpectedServerErrorIntegrationTest.oneToOne,"    @Test
    public void oneToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloResponse> resp = Mono.just(HelloRequest.getDefaultInstance()).compose(stub::sayHello);

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus().getCode() == Status.Code.INTERNAL);
    }
",non-flaky,5
113718,salesforce_reactive-grpc,UnexpectedServerErrorIntegrationTest.oneToMany,"    @Test
    public void oneToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloResponse> resp = Mono.just(HelloRequest.getDefaultInstance()).as(stub::sayHelloRespStream);
        Flux<HelloResponse> test = resp
                .doOnNext(System.out::println)
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""));

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus().getCode() == Status.Code.INTERNAL);
    }
",non-flaky,5
113719,salesforce_reactive-grpc,UnexpectedServerErrorIntegrationTest.manyToOne,"    @Test
    public void manyToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(HelloRequest.getDefaultInstance());
        Mono<HelloResponse> resp = req.as(stub::sayHelloReqStream);

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus().getCode() == Status.Code.INTERNAL);
    }
",non-flaky,5
113720,salesforce_reactive-grpc,UnexpectedServerErrorIntegrationTest.manyToMany,"    @Test
    public void manyToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(HelloRequest.getDefaultInstance());
        Flux<HelloResponse> resp = req.compose(stub::sayHelloBothStream);

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus().getCode() == Status.Code.INTERNAL);
    }
",non-flaky,5
113721,salesforce_reactive-grpc,ClientThreadIntegrationTest.oneToOne,"    @Test
    public void oneToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloRequest> req = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Mono<HelloResponse> resp = req.compose(stub::sayHello);

        AtomicReference<String> clientThreadName = new AtomicReference<>();

        StepVerifier
                .create(resp
                        .map(HelloResponse::getMessage)
                        .doOnSuccess(x -> clientThreadName.set(Thread.currentThread().getName())))
                .expectNext(""Hello reactorjava"")
                .verifyComplete();

        assertThat(clientThreadName.get()).isEqualTo(""TheGrpcClient"");
        assertThat(serverThreadName.get()).isEqualTo(""TheGrpcServer"");
    }
",non-flaky,5
113722,salesforce_reactive-grpc,ClientThreadIntegrationTest.manyToMany,"    @Test
    public void manyToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build(),
                HelloRequest.newBuilder().setName(""d"").build(),
                HelloRequest.newBuilder().setName(""e"").build());

        Flux<HelloResponse> resp = req.compose(stub::sayHelloBothStream);

        AtomicReference<String> clientThreadName = new AtomicReference<>();

        StepVerifier
                .create(resp
                        .map(HelloResponse::getMessage)
                        .doOnNext(x -> clientThreadName.set(Thread.currentThread().getName())))
                .expectNext(""Hello a and b"", ""Hello c and d"", ""Hello e"")
                .verifyComplete();

        assertThat(clientThreadName.get()).isEqualTo(""TheGrpcClient"");
        assertThat(serverThreadName.get()).isEqualTo(""TheGrpcServer"");
    }
",non-flaky,5
113723,salesforce_reactive-grpc,UnimplementedMethodIntegrationTest.unimplementedMethodShouldFail,"    @Test
    public void unimplementedMethodShouldFail() {
        GreeterGrpc.GreeterBlockingStub stub = GreeterGrpc.newBlockingStub(channel);

        assertThatThrownBy(() -> stub.sayHello(HelloRequest.newBuilder().setName(""World"").build()))
                .isInstanceOf(StatusRuntimeException.class)
                .hasMessageContaining(""UNIMPLEMENTED"");
    }
",non-flaky,5
113724,salesforce_reactive-grpc,AbstractStubTest.getChannelWorks,"    @Test
    public void getChannelWorks() {
        ManagedChannel channel = serverRule.getChannel();
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);

        assertThat(stub.getChannel()).isEqualTo(channel);
    }
",non-flaky,5
113725,salesforce_reactive-grpc,AbstractStubTest.settingCallOptionsWorks,"    @Test
    public void settingCallOptionsWorks() {
        ManagedChannel channel = serverRule.getChannel();
        Deadline deadline = Deadline.after(42, TimeUnit.SECONDS);

        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel).withDeadline(deadline);

        assertThat(stub.getCallOptions().getDeadline()).isEqualTo(deadline);
    }
",non-flaky,5
113726,salesforce_reactive-grpc,StandardClientReactiveServerInteropTest.oneToOne,"    @Test
    public void oneToOne() {
        AtomicBoolean called = new AtomicBoolean(false);
        GreeterGrpc.GreeterStub stub = GreeterGrpc.newStub(channel);

        HelloRequest request = HelloRequest.newBuilder().setName(""World"").build();
        stub.sayHello(request, new LambdaStreamObserver<>(
                response -> {
                    assertThat(response.getMessage()).isEqualTo(""Hello World"");
                    called.set(true);
                }
        ));

        await().atMost(1, TimeUnit.SECONDS).untilTrue(called);
    }
",non-flaky,5
113727,salesforce_reactive-grpc,StandardClientReactiveServerInteropTest.oneToMany,"    @Test
    public void oneToMany() {
        AtomicInteger called = new AtomicInteger(0);
        GreeterGrpc.GreeterStub stub = GreeterGrpc.newStub(channel);

        HelloRequest request = HelloRequest.newBuilder().setName(""World"").build();
        stub.sayHelloRespStream(request, new LambdaStreamObserver<>(
                response -> {
                    assertThat(response.getMessage()).isIn(""Hello World"", ""Hi World"", ""Greetings World"");
                    called.incrementAndGet();
                }
        ));

        await().atMost(1, TimeUnit.SECONDS).untilAtomic(called, equalTo(3));
    }
",non-flaky,5
113728,salesforce_reactive-grpc,StandardClientReactiveServerInteropTest.manyToOne,"    @Test
    public void manyToOne() {
        AtomicBoolean called = new AtomicBoolean(false);
        GreeterGrpc.GreeterStub stub = GreeterGrpc.newStub(channel);

        StreamObserver<HelloRequest> requestStream = stub.sayHelloReqStream(new LambdaStreamObserver<>(
                response -> {
                    assertThat(response.getMessage()).isEqualTo(""Hello A and B and C"");
                    called.set(true);
                }
        ));

        requestStream.onNext(HelloRequest.newBuilder().setName(""A"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""B"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""C"").build());
        requestStream.onCompleted();

        await().atMost(1, TimeUnit.SECONDS).untilTrue(called);
    }
",non-flaky,5
113729,salesforce_reactive-grpc,StandardClientReactiveServerInteropTest.manyToMany,"    @Test
    public void manyToMany() {
        AtomicInteger called = new AtomicInteger(0);
        GreeterGrpc.GreeterStub stub = GreeterGrpc.newStub(channel);

        StreamObserver<HelloRequest> requestStream = stub.sayHelloBothStream(new LambdaStreamObserver<>(
                response -> {
                    assertThat(response.getMessage()).isIn(""Hello A and B"", ""Hello C and D"");
                    called.incrementAndGet();
                }
        ));

        requestStream.onNext(HelloRequest.newBuilder().setName(""A"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""B"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""C"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""D"").build());
        requestStream.onCompleted();

        await().atMost(1, TimeUnit.SECONDS).untilAtomic(called, equalTo(2));
    }
",non-flaky,5
113730,salesforce_reactive-grpc,EndToEndIntegrationTest.oneToOne,"    @Test
    public void oneToOne() throws IOException {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloRequest> req = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Mono<HelloResponse> resp = req.compose(stub::sayHello);

        StepVerifier.create(resp.map(HelloResponse::getMessage))
                .expectNext(""Hello reactorjava"")
                .verifyComplete();
    }
",non-flaky,5
113731,salesforce_reactive-grpc,EndToEndIntegrationTest.oneToMany,"    @Test
    public void oneToMany() throws IOException {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloRequest> req = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Flux<HelloResponse> resp = req.as(stub::sayHelloRespStream);

        StepVerifier.create(resp.map(HelloResponse::getMessage))
                .expectNext(""Hello reactorjava"", ""Hi reactorjava"", ""Greetings reactorjava"")
                .verifyComplete();
    }
",non-flaky,5
113732,salesforce_reactive-grpc,EndToEndIntegrationTest.manyToOne,"    @Test
    public void manyToOne() throws Exception {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build());

        Mono<HelloResponse> resp = req.as(stub::sayHelloReqStream);

        StepVerifier.create(resp.map(HelloResponse::getMessage))
                .expectNext(""Hello a and b and c"")
                .verifyComplete();
    }
",non-flaky,5
113733,salesforce_reactive-grpc,EndToEndIntegrationTest.manyToMany,"    @Test
    public void manyToMany() throws Exception {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build(),
                HelloRequest.newBuilder().setName(""d"").build(),
                HelloRequest.newBuilder().setName(""e"").build());

        Flux<HelloResponse> resp = req.compose(stub::sayHelloBothStream);

        StepVerifier.create(resp.map(HelloResponse::getMessage))
                .expectNext(""Hello a and b"", ""Hello c and d"", ""Hello e"")
                .verifyComplete();
    }
",non-flaky,5
113734,salesforce_reactive-grpc,ConcurrentRequestIntegrationTest.fourKindsOfRequestAtOnce,"    @Test
    public void fourKindsOfRequestAtOnce() throws Exception {
        StepVerifier.setDefaultTimeout(Duration.ofSeconds(3));

        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);

        // == MAKE REQUESTS ==
        // One to One
        Mono<HelloRequest> req1 = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Mono<HelloResponse> resp1 = req1.compose(stub::sayHello);

        // One to Many
        Mono<HelloRequest> req2 = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Flux<HelloResponse> resp2 = req2.as(stub::sayHelloRespStream);

        // Many to One
        Flux<HelloRequest> req3 = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build());

        Mono<HelloResponse> resp3 = req3.as(stub::sayHelloReqStream);

        // Many to Many
        Flux<HelloRequest> req4 = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build(),
                HelloRequest.newBuilder().setName(""d"").build(),
                HelloRequest.newBuilder().setName(""e"").build());

        Flux<HelloResponse> resp4 = req4.compose(stub::sayHelloBothStream);

        // == VERIFY RESPONSES ==
        ListeningExecutorService executorService = MoreExecutors.listeningDecorator(Executors.newCachedThreadPool());

        // Run all four verifications in parallel
        try {
            // One to One
            ListenableFuture<Boolean> oneToOne = executorService.submit(() -> {
                StepVerifier.create(resp1.map(HelloResponse::getMessage))
                        .expectNext(""Hello reactorjava"")
                        .verifyComplete();
                return true;
            });

            // One to Many
            ListenableFuture<Boolean> oneToMany = executorService.submit(() -> {
                StepVerifier.create(resp2.map(HelloResponse::getMessage))
                        .expectNext(""Hello reactorjava"", ""Hi reactorjava"", ""Greetings reactorjava"")
                        .verifyComplete();
                return true;
            });

            // Many to One
            ListenableFuture<Boolean> manyToOne = executorService.submit(() -> {
                StepVerifier.create(resp3.map(HelloResponse::getMessage))
                        .expectNext(""Hello a and b and c"")
                        .verifyComplete();
                return true;
            });

            // Many to Many
            ListenableFuture<Boolean> manyToMany = executorService.submit(() -> {
                StepVerifier.create(resp4.map(HelloResponse::getMessage))
                        .expectNext(""Hello a and b"", ""Hello c and d"", ""Hello e"")
                        .verifyComplete();
                return true;
            });

            ListenableFuture<List<Boolean>> allFutures = Futures.allAsList(Lists.newArrayList(oneToOne, oneToMany, manyToOne, manyToMany));
            // Block for response
            List<Boolean> results = allFutures.get(3, TimeUnit.SECONDS);
            assertThat(results).containsExactly(true, true, true, true);

        } finally {
            executorService.shutdown();
        }
    }
",non-flaky,5
113735,salesforce_reactive-grpc,ReactiveClientStandardServerInteropTest.oneToOne,"    @Test
    public void oneToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<String> reactorRequest = Mono.just(""World"");
        Mono<String> reactorResponse = reactorRequest.map(this::toRequest).compose(stub::sayHello).map(this::fromResponse);

        StepVerifier.create(reactorResponse)
                .expectNext(""Hello World"")
                .verifyComplete();
    }
",non-flaky,5
113736,salesforce_reactive-grpc,ReactiveClientStandardServerInteropTest.oneToMany,"    @Test
    public void oneToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<String> reactorRequest = Mono.just(""World"");
        Flux<String> reactorResponse = reactorRequest.map(this::toRequest).as(stub::sayHelloRespStream).map(this::fromResponse);

        StepVerifier.create(reactorResponse)
                .expectNext(""Hello World"", ""Hi World"", ""Greetings World"")
                .verifyComplete();
    }
",non-flaky,5
113737,salesforce_reactive-grpc,ReactiveClientStandardServerInteropTest.manyToOne,"    @Test
    public void manyToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<String> reactorRequest = Flux.just(""A"", ""B"", ""C"");
        Mono<String> reactorResponse = reactorRequest.map(this::toRequest).as(stub::sayHelloReqStream).map(this::fromResponse);

        StepVerifier.create(reactorResponse)
                .expectNext(""Hello A and B and C"")
                .verifyComplete();
    }
",non-flaky,5
113738,salesforce_reactive-grpc,ReactiveClientStandardServerInteropTest.manyToMany,"    @Test
    public void manyToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<String> reactorRequest = Flux.just(""A"", ""B"", ""C"", ""D"");
        Flux<String> reactorResponse = reactorRequest.map(this::toRequest).compose(stub::sayHelloBothStream).map(this::fromResponse);

        StepVerifier.create(reactorResponse)
                .expectNext(""Hello A and B"", ""Hello C and D"")
                .verifyComplete();
    }
",non-flaky,5
113739,salesforce_reactive-grpc,ContextPropagationIntegrationTest.ClientSendsContext,"    @Test
    public void ClientSendsContext() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Context.current()
                .withValue(ctxKey, ""ClientSendsContext"")
                .run(() -> StepVerifier.create(worldReq.compose(stub::sayHello).map(HelloResponse::getMessage))
                        .expectNext(""Hello World"")
                        .verifyComplete());

        assertThat(clientInterceptor.getSendMessageCtxValue()).isEqualTo(""ClientSendsContext"");
    }
",non-flaky,5
113740,salesforce_reactive-grpc,ContextPropagationIntegrationTest.ClientGetsContext,"    @Test
    public void ClientGetsContext() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);

        Mono<HelloResponse> test = worldReq.compose(stub::sayHello)
                .doOnSuccess(resp -> {
                    Context ctx = Context.current();
                    assertThat(ctxKey.get(ctx)).isEqualTo(""ClientGetsContext"");
                });

        StepVerifier.create(test.map(HelloResponse::getMessage))
                .expectNext(""Hello World"")
                .verifyComplete();
    }
",non-flaky,5
113741,salesforce_reactive-grpc,ContextPropagationIntegrationTest.ServerAcceptsContext,"    @Test
    public void ServerAcceptsContext() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);

        StepVerifier.create(worldReq.compose(stub::sayHello).map(HelloResponse::getMessage))
                .expectNext(""Hello World"")
                .verifyComplete();
        assertThat(svc.getReceivedCtxValue()).isEqualTo(""ServerAcceptsContext"");
    }
",non-flaky,5
113742,salesforce_reactive-grpc,UnaryZeroMessageResponseIntegrationTest.zeroMessageResponseOneToOne,"    @Test
    public void zeroMessageResponseOneToOne() {
        serverRule.getServiceRegistry().addService(new MissingUnaryResponseService());

        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(serverRule.getChannel());
        Mono<HelloRequest> req = Mono.just(HelloRequest.newBuilder().setName(""reactor"").build());
        Mono<HelloResponse> resp = req.compose(stub::sayHello);

        StepVerifier.create(resp).verifyErrorMatches(t ->
                t instanceof StatusRuntimeException &&
                ((StatusRuntimeException) t).getStatus().getCode() == Status.Code.CANCELLED);
    }
",non-flaky,5
113743,salesforce_reactive-grpc,UnaryZeroMessageResponseIntegrationTest.zeroMessageResponseManyToOne,"    @Test
    public void zeroMessageResponseManyToOne() {
        serverRule.getServiceRegistry().addService(new MissingUnaryResponseService());

        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(serverRule.getChannel());
        Flux<HelloRequest> req = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build());

        Mono<HelloResponse> resp = req.as(stub::sayHelloReqStream);

        StepVerifier.create(resp).verifyErrorMatches(t ->
                t instanceof StatusRuntimeException &&
                ((StatusRuntimeException) t).getStatus().getCode() == Status.Code.CANCELLED);
    }
",non-flaky,5
113744,salesforce_reactive-grpc,ReactorGrpcPublisherManyToManyVerificationTest.createPublisher,"@Test(timeOut = 3000)
    public Publisher<Message> createPublisher(long elements) {
        ReactorTckGrpc.ReactorTckStub stub = ReactorTckGrpc.newReactorStub(channel);
        Flux<Message> request = Flux.range(0, (int)elements).map(this::toMessage);
        Publisher<Message> publisher = stub.manyToMany(request).publishOn(Schedulers.immediate());

        return publisher;
    }
",non-flaky,5
113745,salesforce_reactive-grpc,ReactorGrpcPublisherManyToOneVerificationTest.maxElementsFromPublisher,"@Test(timeOut = 3000)
    public long maxElementsFromPublisher() {
        return 1;
    }
",non-flaky,5
113746,salesforce_reactive-grpc,ReactorGrpcPublisherOneToOneVerificationTest.maxElementsFromPublisher,"@Test(timeOut = 3000)
    public long maxElementsFromPublisher() {
        return 1;
    }
",non-flaky,5
113747,salesforce_reactive-grpc,ReactorGrpcPublisherOneToManyVerificationTest.createPublisher,"@Test(timeOut = 3000)
    public Publisher<Message> createPublisher(long elements) {
        ReactorTckGrpc.ReactorTckStub stub = ReactorTckGrpc.newReactorStub(channel);
        Mono<Message> request = Mono.just(toMessage((int) elements));
        Publisher<Message> publisher = stub.oneToMany(request).publishOn(Schedulers.immediate());

        return publisher;
    }
",non-flaky,5
113748,salesforce_reactive-grpc,ReactorGrpcSubscriberWhiteboxVerificationTest.triggerRequest,"@Test(timeOut = 3000)
    public Subscriber<Message> createSubscriber(WhiteboxSubscriberProbe<Message> probe) {
        return new ReactivePublisherBackpressureOnReadyHandlerClient<Message>(new StubServerCallStreamObserver()) {
            @Override
            public void onSubscribe(final Subscription s) {
                super.onSubscribe(s);

                // register a successful Subscription, and create a Puppet,
                // for the WhiteboxVerification to be able to drive its tests:
                probe.registerOnSubscribe(new SubscriberPuppet() {

                    @Override
                    public void triggerRequest(long elements) {
                        s.request(elements);
                    }
",non-flaky,5
113749,salesforce_reactive-grpc,SubscribeOnlyOnceTest.subscribeOnlyOnceLifterErrorsWhenMultipleSubscribe,"    @Test
    public void subscribeOnlyOnceLifterErrorsWhenMultipleSubscribe() throws Exception {
        SubscribeOnlyOnceLifter<Object> op = new SubscribeOnlyOnceLifter<>();
        CoreSubscriber<Object> innerSub = mock(CoreSubscriber.class);
        Subscription subscription = mock(Subscription.class);

        CoreSubscriber<Object> outerSub = op.apply(null, innerSub);

        outerSub.onSubscribe(subscription);
        assertThatThrownBy(() -> outerSub.onSubscribe(subscription))
                .isInstanceOf(NullPointerException.class)
                .hasMessageContaining(""cannot directly subscribe to a gRPC service multiple times"");

        verify(innerSub, times(1)).onSubscribe(subscription);
    }
",non-flaky,5
113750,salesforce_reactive-grpc,BackpressureChunkingTest.chunkOperatorCorrectlyChunks,"    @Test
    public void chunkOperatorCorrectlyChunks() {
        final List<Long> requests = new ArrayList<>();
        int chunkSize = ReactiveBackpressureChunker.DEFAULT_CHUNK_SIZE;

        Flux<Integer> chunked = Flux.range(0, chunkSize + 4)
                .doOnRequest(requests::add)
                .transform(Operators.lift(new BackpressureChunkingLifter<Integer>()));

        StepVerifier.create(chunked)
                .expectNext(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19)
                .verifyComplete();

        assertThat(requests).containsExactly((long) chunkSize, (long) chunkSize);
    }
",non-flaky,5
113751,salesforce_reactive-grpc,ReactorConsumerStreamObserverTest.rxConsumerIsSet,"    @Test
    public void rxConsumerIsSet() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        ReactorConsumerStreamObserver rxObs = new ReactorConsumerStreamObserver();

        rxObs.beforeStart(obs);

        assertThat(rxObs.getRxConsumer()).isNotNull();
    }
",non-flaky,5
113752,salesforce_reactive-grpc,ReactorConsumerStreamObserverTest.onNextDelegates,"    @Test
    public void onNextDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        ReactorConsumerStreamObserver rxObs = new ReactorConsumerStreamObserver();
        Subscriber<Object> sub = mock(Subscriber.class);

        rxObs.beforeStart(obs);
        rxObs.getRxConsumer().subscribe(sub);

        Object obj = new Object();
        StepVerifier.create(rxObs.getRxConsumer())
                .then(() -> rxObs.onNext(obj))
                .expectNext(obj)
                .then(rxObs::onCompleted)
                .expectComplete()
                .verify(Duration.ofSeconds(3));
    }
",non-flaky,5
113753,salesforce_reactive-grpc,ReactorConsumerStreamObserverTest.onErrorDelegates,"    @Test
    public void onErrorDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        ReactorConsumerStreamObserver rxObs = new ReactorConsumerStreamObserver();
        Subscriber<Object> sub = mock(Subscriber.class);

        rxObs.beforeStart(obs);
        rxObs.getRxConsumer().subscribe(sub);

        Throwable obj = new Exception(""test error"");
        StepVerifier.create(rxObs.getRxConsumer())
                .then(() -> rxObs.onError(obj))
                .expectErrorMessage(""test error"")
                .verify(Duration.ofSeconds(3));
    }
",non-flaky,5
113754,salesforce_reactive-grpc,GrpcRetryTest.noRetryMakesErrorFlowabable,"    @Test
    public void noRetryMakesErrorFlowabable() {
        Flux<Integer> test = newThreeErrorFlux()
                .as(flux -> flux);

        StepVerifier.create(test)
                .expectErrorMessage(""Not yet!"")
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113755,salesforce_reactive-grpc,GrpcRetryTest.noRetryMakesErrorSingle,"    @Test
    public void noRetryMakesErrorSingle() {
        Mono<Integer> test = newThreeErrorMono()
                .as(mono -> mono);

        StepVerifier.create(test)
                .expectErrorMessage(""Not yet!"")
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113756,salesforce_reactive-grpc,GrpcRetryTest.oneToManyRetryWhen,"    @Test
    public void oneToManyRetryWhen() {
        Flux<Integer> test = newThreeErrorMono()
                .<Flux<Integer>>as(GrpcRetry.OneToMany.retryWhen(Mono::flux, Retry.any().retryMax(4)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113757,salesforce_reactive-grpc,GrpcRetryTest.oneToManyRetryImmediately,"    @Test
    public void oneToManyRetryImmediately() {
        Flux<Integer> test = newThreeErrorMono()
                .<Flux<Integer>>as(GrpcRetry.OneToMany.retryImmediately(Mono::flux));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113758,salesforce_reactive-grpc,GrpcRetryTest.oneToManyRetryAfter,"    @Test
    public void oneToManyRetryAfter() {
        Flux<Integer> test = newThreeErrorMono()
                .<Flux<Integer>>as(GrpcRetry.OneToMany.retryAfter(Mono::flux, Duration.ofMillis(10)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113759,salesforce_reactive-grpc,GrpcRetryTest.manyToManyRetryWhen,"    @Test
    public void manyToManyRetryWhen() {
        Flux<Integer> test = newThreeErrorFlux()
                .<Integer>compose(GrpcRetry.ManyToMany.retryWhen(Function.identity(), Retry.any().retryMax(4)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113760,salesforce_reactive-grpc,GrpcRetryTest.manyToManyRetryImmediately,"    @Test
    public void manyToManyRetryImmediately() {
        Flux<Integer> test = newThreeErrorFlux()
                .<Integer>compose(GrpcRetry.ManyToMany.retryImmediately(Function.identity()));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113761,salesforce_reactive-grpc,GrpcRetryTest.manyToManyRetryAfter,"    @Test
    public void manyToManyRetryAfter() {
        Flux<Integer> test = newThreeErrorFlux()
                .<Integer>compose(GrpcRetry.ManyToMany.retryAfter(Function.identity(), Duration.ofMillis(10)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113762,salesforce_reactive-grpc,GrpcRetryTest.manyToOneRetryWhen,"    @Test
    public void manyToOneRetryWhen() {
        Mono<Integer> test = newThreeErrorFlux()
                .<Mono<Integer>>as(GrpcRetry.ManyToOne.retryWhen(Flux::single, Retry.any().retryMax(4)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113763,salesforce_reactive-grpc,GrpcRetryTest.manyToOneRetryImmediately,"    @Test
    public void manyToOneRetryImmediately() {
        Mono<Integer> test = newThreeErrorFlux()
                .<Mono<Integer>>as(GrpcRetry.ManyToOne.retryImmediately(Flux::single));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113764,salesforce_reactive-grpc,GrpcRetryTest.manyToOneRetryAfter,"    @Test
    public void manyToOneRetryAfter() {
        Mono<Integer> test = newThreeErrorFlux()
                .<Mono<Integer>>as(GrpcRetry.ManyToOne.retryAfter(Flux::single, Duration.ofMillis(10)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113765,salesforce_reactive-grpc,ReactiveStreamObserverPublisherServerTest.onNextDelegates,"    @Test
    public void onNextDelegates() {
        ServerCallStreamObserver<Object> obs = mock(ServerCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherServer<Object> pub = new ReactiveStreamObserverPublisherServer<Object>(obs);
        pub.subscribe(sub);

        Object obj = new Object();

        pub.onNext(obj);
        verify(sub).onNext(obj);
    }
",non-flaky,5
113766,salesforce_reactive-grpc,ReactiveStreamObserverPublisherServerTest.onErrorDelegates,"    @Test
    public void onErrorDelegates() {
        ServerCallStreamObserver<Object> obs = mock(ServerCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherServer<Object> pub = new ReactiveStreamObserverPublisherServer<Object>(obs);
        pub.subscribe(sub);

        Throwable obj = new Exception();

        pub.onError(obj);
        verify(sub).onError(obj);
    }
",non-flaky,5
113767,salesforce_reactive-grpc,ReactiveStreamObserverPublisherServerTest.onCompletedDelegates,"    @Test
    public void onCompletedDelegates() {
        ServerCallStreamObserver<Object> obs = mock(ServerCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherServer<Object> pub = new ReactiveStreamObserverPublisherServer<Object>(obs);
        pub.subscribe(sub);

        pub.onCompleted();
        verify(sub).onComplete();
    }
",non-flaky,5
113768,salesforce_reactive-grpc,ReactiveStreamObserverPublisherServerTest.answer,"    @Test
    public void requestDelegates() {
        ServerCallStreamObserver<Object> obs = mock(ServerCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        final AtomicReference<Subscription> subscription = new AtomicReference<Subscription>();
        doAnswer(new Answer() {
            @Override
            public Object answer(InvocationOnMock invocationOnMock) {
                subscription.set((Subscription) invocationOnMock.getArguments()[0]);
                return null;
            }
",non-flaky,5
113769,salesforce_reactive-grpc,ReactiveStreamObserverPublisherClientTest.onNextDelegates,"    @Test
    public void onNextDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherClient<Object> pub = new ReactiveStreamObserverPublisherClient<Object>(obs);
        pub.subscribe(sub);

        Object obj = new Object();

        pub.onNext(obj);
        verify(sub).onNext(obj);
    }
",non-flaky,5
113770,salesforce_reactive-grpc,ReactiveStreamObserverPublisherClientTest.onErrorDelegates,"    @Test
    public void onErrorDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherClient<Object> pub = new ReactiveStreamObserverPublisherClient<Object>(obs);
        pub.subscribe(sub);

        Throwable obj = new Exception();

        pub.onError(obj);
        verify(sub).onError(obj);
    }
",non-flaky,5
113771,salesforce_reactive-grpc,ReactiveStreamObserverPublisherClientTest.onCompletedDelegates,"    @Test
    public void onCompletedDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherClient<Object> pub = new ReactiveStreamObserverPublisherClient<Object>(obs);
        pub.subscribe(sub);

        pub.onCompleted();
        verify(sub).onComplete();
    }
",non-flaky,5
113772,salesforce_reactive-grpc,ReactiveStreamObserverPublisherClientTest.answer,"    @Test
    public void requestDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        final AtomicReference<Subscription> subscription = new AtomicReference<Subscription>();
        doAnswer(new Answer() {
            @Override
            public Object answer(InvocationOnMock invocationOnMock) {
                subscription.set((Subscription) invocationOnMock.getArguments()[0]);
                return null;
            }
",non-flaky,5
113773,salesforce_reactive-grpc,CancellableStreamObserverTest.run,"    @Test
    public void statusExceptionTriggersHandler() {
        ClientResponseObserver<Object, Object> delegate = mock(ClientResponseObserver.class);
        final AtomicBoolean called = new AtomicBoolean(false);

        CancellableStreamObserver<Object, Object> observer = new CancellableStreamObserver<Object, Object>(delegate, new Runnable() {
            @Override
            public void run() {
                called.set(true);
            }
",non-flaky,5
113774,salesforce_reactive-grpc,CancellableStreamObserverTest.run,"    @Test
    public void statusRuntimeExceptionTriggersHandler() {
        ClientResponseObserver<Object, Object> delegate = mock(ClientResponseObserver.class);
        final AtomicBoolean called = new AtomicBoolean(false);

        CancellableStreamObserver<Object, Object> observer = new CancellableStreamObserver<Object, Object>(delegate, new Runnable() {
            @Override
            public void run() {
                called.set(true);
            }
",non-flaky,5
113775,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.applySubscribes,"    @Test
    public void applySubscribes() {
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(16);

        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        assertThat(chunkSubscriber).isNotNull();

        chunkSubscriber.onSubscribe(upstreamSubscription);
        assertThat(downstreamSubscriber.upstreamSubscription).isNotNull();
    }
",non-flaky,5
113776,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.requestOneGetsAChunk,"    @Test
    public void requestOneGetsAChunk() {
        int chunkSize = 16;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.request(1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
    }
",non-flaky,5
113777,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.requestOneSupplyOneDoesntRequestAnother,"    @Test
    public void requestOneSupplyOneDoesntRequestAnother() {
        int chunkSize = 16;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.request(1);
        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(chunkSize);
    }
",non-flaky,5
113778,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.requestManyGetsAChunkFirst,"    @Test
    public void requestManyGetsAChunkFirst() {
        int chunkSize = 16;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.request(256);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
    }
",non-flaky,5
113779,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.requestManyChunksRequestsAsSatisfiedAndStopsWhenComplete,"    @Test
    public void requestManyChunksRequestsAsSatisfiedAndStopsWhenComplete() {
        int chunkSize = 3;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.request(9);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(chunkSize);

        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(3);
        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(3);
        send(chunkSubscriber, 1);
        // Chunk satisfied, request next chunk
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(6);

        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(6);
        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(6);
        send(chunkSubscriber, 1);
        // Chunk satisfied, request next chunk
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(9);

        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(9);
        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(9);
        send(chunkSubscriber, 1);
        // Requested satisfied, do not request any more
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(9);
    }
",non-flaky,5
113780,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.completePropagatesDown,"    @Test
    public void completePropagatesDown() {
        int chunkSize = 3;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        chunkSubscriber.onComplete();
        assertThat(downstreamSubscriber.isComplete).isTrue();
    }
",non-flaky,5
113781,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.errorPropagatesDown,"    @Test
    public void errorPropagatesDown() {
        int chunkSize = 3;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        Throwable t = new Throwable();
        chunkSubscriber.onError(t);
        assertThat(downstreamSubscriber.lastThrowable).isEqualTo(t);
    }
",non-flaky,5
113782,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.cancelPropagatesUp,"    @Test
    public void cancelPropagatesUp() {
        int chunkSize = 3;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.cancel();
        assertThat(upstreamSubscription.isCancelled).isTrue();
    }
",non-flaky,5
113783,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.runPrimesThePump,"    @Test
    public void runPrimesThePump() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        when(obs.isReady()).thenReturn(true);
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);

        handler.onSubscribe(sub);

        handler.run();
        verify(sub).request(1);
    }
",non-flaky,5
113784,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.onNextKeepsPumpRunning,"    @Test
    public void onNextKeepsPumpRunning() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        when(obs.isReady()).thenReturn(true);

        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);

        handler.onSubscribe(sub);

        Object obj = new Object();
        handler.onNext(obj);

        verify(obs).onNext(obj);
        verify(sub).request(1);
    }
",non-flaky,5
113785,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.onNextStopsPump,"    @Test
    public void onNextStopsPump() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        when(obs.isReady()).thenReturn(false);

        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);

        handler.onSubscribe(sub);

        Object obj = new Object();
        handler.onNext(obj);

        verify(obs).onNext(obj);
        verify(sub, never()).request(1);
    }
",non-flaky,5
113786,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.exceptionInOnNextCancelsUpstreamSubscription,"    @Test
    public void exceptionInOnNextCancelsUpstreamSubscription() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        doThrow(new IllegalStateException(""won't be propagated to handler caller"")).when(obs).onNext(any());
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);
        handler.onSubscribe(sub);
        
        handler.onNext(new Object());
        verify(obs).cancel(anyString(), any(Throwable.class));
        verify(obs).onError(any(Throwable.class));
    }
",non-flaky,5
113787,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.exceptionInOnOnErrorCancelsUpstreamSubscription,"    @Test
    public void exceptionInOnOnErrorCancelsUpstreamSubscription() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        doThrow(new IllegalStateException(""won't be propagated to handler caller"")).when(obs).onError(any(Throwable.class));
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);
        handler.onSubscribe(sub);
        
        handler.onError(new RuntimeException());
        verify(obs).cancel(anyString(), any(Throwable.class));
    }
",non-flaky,5
113788,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.exceptionInOnCompleteCancelsUpstreamSubscription,"    @Test
    public void exceptionInOnCompleteCancelsUpstreamSubscription() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        doThrow(new IllegalStateException(""won't be propagated to handler caller"")).when(obs).onCompleted();
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);
        handler.onSubscribe(sub);
        
        handler.onComplete();
        verify(obs).cancel(anyString(), any(Throwable.class));
        verify(obs).onError(any(Throwable.class));
    }
",non-flaky,5
113789,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.onSubscribeCancelsSecondSubscription,"    @Test
    public void onSubscribeCancelsSecondSubscription() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub1 = mock(Subscription.class);
        Subscription sub2 = mock(Subscription.class);

        handler.onSubscribe(sub1);
        handler.onSubscribe(sub2);
        
        verify(sub2).cancel();
    }
",non-flaky,5
113790,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.clientCanCancelServerStreamExplicitly,"    @Test
    public void clientCanCancelServerStreamExplicitly() throws InterruptedException {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());
        TestSubscriber<NumberProto.Number> subscription = Single.just(Empty.getDefaultInstance())
                .as(stub::responsePressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""))
                .test();

        Thread.sleep(250);
        subscription.dispose();
        Thread.sleep(250);

        subscription.awaitTerminalEvent(3, TimeUnit.SECONDS);
        // Cancellation may or may not deliver the last generated message due to delays in the gRPC processing thread
        assertThat(Math.abs(subscription.valueCount() - svc.getLastNumberProduced())).isLessThanOrEqualTo(3);
        assertThat(svc.wasCanceled()).isTrue();

        errorRule.verifyNoError();
    }
",non-flaky,5
113791,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.clientCanCancelServerStreamImplicitly,"    @Test
    public void clientCanCancelServerStreamImplicitly() throws InterruptedException {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());
        TestSubscriber<NumberProto.Number> subscription =  Single.just(Empty.getDefaultInstance())
                .as(stub::responsePressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""))
                .take(10)
                .test();

        // Consume some work
        Thread.sleep(TimeUnit.SECONDS.toMillis(1));
        subscription.dispose();

        subscription.awaitTerminalEvent(3, TimeUnit.SECONDS);
        subscription.assertValueCount(10);
        subscription.assertTerminated();
        assertThat(svc.wasCanceled()).isTrue();

        errorRule.verifyNoError();
    }
",non-flaky,5
113792,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamImplicitly,"    @Test
    public void serverCanCancelClientStreamImplicitly() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        svc.setExplicitCancel(false);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flowable<NumberProto.Number> request = Flowable
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delay(10, TimeUnit.MILLISECONDS)
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(x -> {
                    requestDidProduce.set(true);
                    System.out.println(""Produced: "" + x.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        TestObserver<NumberProto.Number> observer = request
                .as(stub::requestPressure)
                .doOnSuccess(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .test();

        observer.awaitTerminalEvent(3, TimeUnit.SECONDS);
        observer.assertComplete();
        observer.assertTerminated();

        await().atMost(Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();

        errorRule.verifyNoError();
    }
",non-flaky,5
113793,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamExplicitly,"    @Test
    public void serverCanCancelClientStreamExplicitly() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        svc.setExplicitCancel(true);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flowable<NumberProto.Number> request = Flowable
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delay(10, TimeUnit.MILLISECONDS)
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(n -> {
                    requestDidProduce.set(true);
                    System.out.println(""P: "" + n.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        TestObserver<NumberProto.Number> observer = request
                .as(stub::requestPressure)
                .doOnSuccess(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .test();

        observer.awaitTerminalEvent();
        observer.assertComplete();
        observer.assertTerminated();

        await().atMost(Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();

        errorRule.verifyNoError();
    }
",non-flaky,5
113794,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamImplicitlyBidi,"    @Test
    public void serverCanCancelClientStreamImplicitlyBidi() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        svc.setExplicitCancel(false);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flowable<NumberProto.Number> request = Flowable
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delay(10, TimeUnit.MILLISECONDS)
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(x -> {
                    requestDidProduce.set(true);
                    System.out.println(""Produced: "" + x.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        TestSubscriber<NumberProto.Number> observer = request
                .compose(stub::twoWayPressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .test();

        observer.awaitTerminalEvent(3, TimeUnit.SECONDS);
        observer.assertTerminated();
        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();

        errorRule.verifyNoError();
    }
",non-flaky,5
113795,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamExplicitlyBidi,"    @Test
    public void serverCanCancelClientStreamExplicitlyBidi() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        svc.setExplicitCancel(true);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flowable<NumberProto.Number> request = Flowable
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delay(10, TimeUnit.MILLISECONDS)
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(n -> {
                    requestDidProduce.set(true);
                    System.out.println(""P: "" + n.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        TestSubscriber<NumberProto.Number> observer = request
                .compose(stub::twoWayPressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .test();

        observer.awaitTerminalEvent();
        observer.assertTerminated();
        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();

        errorRule.verifyNoError();
    }
",non-flaky,5
113796,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.prematureResponseStreamDisposalShouldNotThrowUnhandledException,"    @Test
    public void prematureResponseStreamDisposalShouldNotThrowUnhandledException() throws Exception {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        // slowly process the response stream
        Disposable subscription = stub.responsePressure(Empty.getDefaultInstance()).subscribe(n -> {
            Thread.sleep(1000);
        });

        subscription.dispose();

        Thread.sleep(200);
        errorRule.verifyNoError();
    }
",non-flaky,5
113797,salesforce_reactive-grpc,ServerErrorIntegrationTest.oneToOne,"    @Test
    public void oneToOne() {
        RxGreeterGrpc.RxGreeterStub stub = RxGreeterGrpc.newRxStub(channel);
        Single<HelloResponse> resp = Single.just(HelloRequest.getDefaultInstance()).compose(stub::sayHello);
        TestObserver<HelloResponse> test = resp.test();

        test.awaitTerminalEvent(3, TimeUnit.SECONDS);
        test.assertError(t -> t instanceof StatusRuntimeException);
        test.assertError(t -> ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
",non-flaky,5
239,Netflix_Hystrix,HealthCountsStreamTest.testShortCircuited,"@Test
public void testShortCircuited() {
    HystrixCommandKey key = Factory.asKey(""CMD-Health-G"");
    stream = HealthCountsStream.getInstance(key, 10, 100);
    final CountDownLatch latch = new CountDownLatch(1);
    stream.observe().take(10).subscribe(getSubscriber(latch));
    CommandStreamTest.Command failure1 = Command.from(groupKey, key, FAILURE, 20);
    CommandStreamTest.Command failure2 = Command.from(groupKey, key, FAILURE, 20);
    CommandStreamTest.Command failure3 = Command.from(groupKey, key, FAILURE, 20);
    CommandStreamTest.Command shortCircuit1 = Command.from(groupKey, key, SUCCESS);
    CommandStreamTest.Command shortCircuit2 = Command.from(groupKey, key, SUCCESS);
    failure1.observe();
    failure2.observe();
    failure3.observe();
    try {
        Thread.sleep(100);
    } catch (InterruptedException ie) {
        fail(ie.getMessage());
    }
    shortCircuit1.observe();
    shortCircuit2.observe();
    try {
        assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
    } catch (InterruptedException ex) {
        fail(""Interrupted ex"");
    }
    assertTrue(shortCircuit1.isResponseShortCircuited());
    assertTrue(shortCircuit2.isResponseShortCircuited());
    System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
    assertEquals(3L, stream.getLatest().getErrorCount());
    assertEquals(3L, stream.getLatest().getTotalRequests());
}",async wait,0
135711,Netflix_Hystrix,HystrixSubclassCommandTest.testFallback,"    @Test
    public void testFallback() {
        HystrixCommand<Integer> superCmd = new SuperCommand(""cache"", false);
        assertEquals(2, superCmd.execute().intValue());

        HystrixCommand<Integer> subNoOverridesCmd = new SubCommandNoOverride(""cache"", false);
        assertEquals(2, subNoOverridesCmd.execute().intValue());

        HystrixCommand<Integer> subOverriddenFallbackCmd = new SubCommandOverrideFallback(""cache"", false);
        assertEquals(3, subOverriddenFallbackCmd.execute().intValue());
    }
",non-flaky,5
135712,Netflix_Hystrix,HystrixSubclassCommandTest.testRequestCacheSuperClass,"    @Test
    public void testRequestCacheSuperClass() {
        HystrixCommand<Integer> superCmd1 = new SuperCommand(""cache"", true);
        assertEquals(1, superCmd1.execute().intValue());
        HystrixCommand<Integer> superCmd2 = new SuperCommand(""cache"", true);
        assertEquals(1, superCmd2.execute().intValue());
        HystrixCommand<Integer> superCmd3 = new SuperCommand(""no-cache"", true);
        assertEquals(1, superCmd3.execute().intValue());
        System.out.println(""REQ LOG : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        HystrixRequestLog reqLog = HystrixRequestLog.getCurrentRequest();
        assertEquals(3, reqLog.getAllExecutedCommands().size());
        List<HystrixInvokableInfo<?>> infos = new ArrayList<HystrixInvokableInfo<?>>(reqLog.getAllExecutedCommands());
        HystrixInvokableInfo<?> info1 = infos.get(0);
        assertEquals(""SuperCommand"", info1.getCommandKey().name());
        assertEquals(1, info1.getExecutionEvents().size());
        HystrixInvokableInfo<?> info2 = infos.get(1);
        assertEquals(""SuperCommand"", info2.getCommandKey().name());
        assertEquals(2, info2.getExecutionEvents().size());
        assertEquals(HystrixEventType.RESPONSE_FROM_CACHE, info2.getExecutionEvents().get(1));
        HystrixInvokableInfo<?> info3 = infos.get(2);
        assertEquals(""SuperCommand"", info3.getCommandKey().name());
        assertEquals(1, info3.getExecutionEvents().size());
    }
",non-flaky,5
135713,Netflix_Hystrix,HystrixSubclassCommandTest.testRequestCacheSubclassNoOverrides,"    @Test
    public void testRequestCacheSubclassNoOverrides() {
        HystrixCommand<Integer> subCmd1 = new SubCommandNoOverride(""cache"", true);
        assertEquals(1, subCmd1.execute().intValue());
        HystrixCommand<Integer> subCmd2 = new SubCommandNoOverride(""cache"", true);
        assertEquals(1, subCmd2.execute().intValue());
        HystrixCommand<Integer> subCmd3 = new SubCommandNoOverride(""no-cache"", true);
        assertEquals(1, subCmd3.execute().intValue());
        System.out.println(""REQ LOG : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        HystrixRequestLog reqLog = HystrixRequestLog.getCurrentRequest();
        assertEquals(3, reqLog.getAllExecutedCommands().size());
        List<HystrixInvokableInfo<?>> infos = new ArrayList<HystrixInvokableInfo<?>>(reqLog.getAllExecutedCommands());
        HystrixInvokableInfo<?> info1 = infos.get(0);
        assertEquals(""SubCommandNoOverride"", info1.getCommandKey().name());
        assertEquals(1, info1.getExecutionEvents().size());
        HystrixInvokableInfo<?> info2 = infos.get(1);
        assertEquals(""SubCommandNoOverride"", info2.getCommandKey().name());
        assertEquals(2, info2.getExecutionEvents().size());
        assertEquals(HystrixEventType.RESPONSE_FROM_CACHE, info2.getExecutionEvents().get(1));
        HystrixInvokableInfo<?> info3 = infos.get(2);
        assertEquals(""SubCommandNoOverride"", info3.getCommandKey().name());
        assertEquals(1, info3.getExecutionEvents().size());
    }
",non-flaky,5
135714,Netflix_Hystrix,HystrixSubclassCommandTest.testRequestLogSuperClass,"    @Test
    public void testRequestLogSuperClass() {
        HystrixCommand<Integer> superCmd = new SuperCommand(""cache"", true);
        assertEquals(1, superCmd.execute().intValue());
        System.out.println(""REQ LOG : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        HystrixRequestLog reqLog = HystrixRequestLog.getCurrentRequest();
        assertEquals(1, reqLog.getAllExecutedCommands().size());
        HystrixInvokableInfo<?> info = reqLog.getAllExecutedCommands().iterator().next();
        assertEquals(""SuperCommand"", info.getCommandKey().name());
    }
",non-flaky,5
135715,Netflix_Hystrix,HystrixSubclassCommandTest.testRequestLogSubClassNoOverrides,"    @Test
    public void testRequestLogSubClassNoOverrides() {
        HystrixCommand<Integer> subCmd = new SubCommandNoOverride(""cache"", true);
        assertEquals(1, subCmd.execute().intValue());
        System.out.println(""REQ LOG : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        HystrixRequestLog reqLog = HystrixRequestLog.getCurrentRequest();
        assertEquals(1, reqLog.getAllExecutedCommands().size());
        HystrixInvokableInfo<?> info = reqLog.getAllExecutedCommands().iterator().next();
        assertEquals(""SubCommandNoOverride"", info.getCommandKey().name());
    }
",non-flaky,5
135716,Netflix_Hystrix,HystrixThreadPoolMetricsTest.shouldYieldNoExecutedTasksOnStartup,"	@Test
	public void shouldYieldNoExecutedTasksOnStartup() throws Exception {
		//given
		final Collection<HystrixThreadPoolMetrics> instances = HystrixThreadPoolMetrics.getInstances();

		//then
		assertEquals(0, instances.size());

	}
",non-flaky,5
135717,Netflix_Hystrix,HystrixThreadPoolMetricsTest.shouldReturnOneExecutedTask,"	@Test
	public void shouldReturnOneExecutedTask() throws Exception {
		//given
		final Collection<HystrixThreadPoolMetrics> instances = HystrixThreadPoolMetrics.getInstances();
		RollingThreadPoolEventCounterStream.getInstance(tpKey, 10, 100).startCachingStreamValuesIfUnstarted();

		//when
		new NoOpHystrixCommand().execute();

		//then
		Thread.sleep(100);
		assertEquals(1, instances.size());
		assertEquals(1, instances.iterator().next().getRollingCountThreadsExecuted());
	}
",non-flaky,5
135718,Netflix_Hystrix,CommonHystrixCommandTests.call,"    @Test
    public void testExecutionHookSemaphoreSuccess() {
        assertHooksOnSuccess(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, FallbackResult.SUCCESS);
                    }
",non-flaky,5
135719,Netflix_Hystrix,CommonHystrixCommandTests.call,"    @Test
    public void testExecutionHookSemaphoreBadRequestException() {
        assertHooksOnFailure(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.BAD_REQUEST, FallbackResult.SUCCESS);
                    }
",non-flaky,5
135720,Netflix_Hystrix,CommonHystrixCommandTests.call,"    @Test
    public void testExecutionHookSemaphoreExceptionNoFallback() {
        assertHooksOnFailure(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.FAILURE, FallbackResult.UNIMPLEMENTED);
                    }
",non-flaky,5
135721,Netflix_Hystrix,CommonHystrixCommandTests.call,"    @Test
    public void testExecutionHookSemaphoreExceptionSuccessfulFallback() {
        assertHooksOnSuccess(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.FAILURE, FallbackResult.SUCCESS);
                    }
",non-flaky,5
135722,Netflix_Hystrix,CommonHystrixCommandTests.call,"    @Test
    public void testExecutionHookSemaphoreExceptionUnsuccessfulFallback() {
        assertHooksOnFailure(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.FAILURE, FallbackResult.FAILURE);
                    }
",non-flaky,5
135723,Netflix_Hystrix,CommonHystrixCommandTests.run,"    @Test
    public void testExecutionHookSemaphoreRejectedNoFallback() {
        assertHooksOnFailFast(
                new Func0<C>() {
                    @Override
                    public C call() {
                        AbstractCommand.TryableSemaphore semaphore = new AbstractCommand.TryableSemaphoreActual(HystrixProperty.Factory.asProperty(2));

                        final C cmd1 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 500, FallbackResult.UNIMPLEMENTED, semaphore);
                        final C cmd2 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 500, FallbackResult.UNIMPLEMENTED, semaphore);

                        //saturate the semaphore
                        new Thread() {
                            @Override
                            public void run() {
                                cmd1.observe();
                            }
",non-flaky,5
135724,Netflix_Hystrix,CommonHystrixCommandTests.run,"    @Test
    public void testExecutionHookSemaphoreRejectedSuccessfulFallback() {
        assertHooksOnSuccess(
                new Func0<C>() {
                    @Override
                    public C call() {
                        AbstractCommand.TryableSemaphore semaphore = new AbstractCommand.TryableSemaphoreActual(HystrixProperty.Factory.asProperty(2));

                        final C cmd1 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 1500, FallbackResult.SUCCESS, semaphore);
                        final C cmd2 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 1500, FallbackResult.SUCCESS, semaphore);

                        //saturate the semaphore
                        new Thread() {
                            @Override
                            public void run() {
                                cmd1.observe();
                            }
",non-flaky,5
135725,Netflix_Hystrix,CommonHystrixCommandTests.run,"    @Test
    public void testExecutionHookSemaphoreRejectedUnsuccessfulFallback() {
        assertHooksOnFailFast(
                new Func0<C>() {
                    @Override
                    public C call() {
                        AbstractCommand.TryableSemaphore semaphore = new AbstractCommand.TryableSemaphoreActual(HystrixProperty.Factory.asProperty(2));

                        final C cmd1 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 500, FallbackResult.FAILURE, semaphore);
                        final C cmd2 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 500, FallbackResult.FAILURE, semaphore);

                        //saturate the semaphore
                        new Thread() {
                            @Override
                            public void run() {
                                cmd1.observe();
                            }
",non-flaky,5
135726,Netflix_Hystrix,CommonHystrixCommandTests.call,"    @Test
    public void testExecutionHookSemaphoreShortCircuitNoFallback() {
        assertHooksOnFailFast(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCircuitOpenCommand(ExecutionIsolationStrategy.SEMAPHORE, FallbackResult.UNIMPLEMENTED);
                    }
",non-flaky,5
135727,Netflix_Hystrix,CommonHystrixCommandTests.call,"    @Test
    public void testExecutionHookSemaphoreShortCircuitSuccessfulFallback() {
        assertHooksOnSuccess(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCircuitOpenCommand(ExecutionIsolationStrategy.SEMAPHORE, FallbackResult.SUCCESS);
                    }
",non-flaky,5
135728,Netflix_Hystrix,CommonHystrixCommandTests.call,"    @Test
    public void testExecutionHookSemaphoreShortCircuitUnsuccessfulFallback() {
        assertHooksOnFailFast(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCircuitOpenCommand(ExecutionIsolationStrategy.SEMAPHORE, FallbackResult.FAILURE);
                    }
",non-flaky,5
135729,Netflix_Hystrix,HystrixCommandMetricsTest.testGetErrorPercentage,"    @Test
    public void testGetErrorPercentage() {
        String key = ""cmd-metrics-A"";
        try {
            HystrixCommand<Boolean> cmd1 = new SuccessCommand(key, 1);
            HystrixCommandMetrics metrics = cmd1.metrics;
            cmd1.execute();
            Thread.sleep(100);
            assertEquals(0, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd2 = new FailureCommand(key, 1);
            cmd2.execute();
            Thread.sleep(100);
            assertEquals(50, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd3 = new SuccessCommand(key, 1);
            HystrixCommand<Boolean> cmd4 = new SuccessCommand(key, 1);
            cmd3.execute();
            cmd4.execute();
            Thread.sleep(100);
            assertEquals(25, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd5 = new TimeoutCommand(key);
            HystrixCommand<Boolean> cmd6 = new TimeoutCommand(key);
            cmd5.execute();
            cmd6.execute();
            Thread.sleep(100);
            assertEquals(50, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd7 = new SuccessCommand(key, 1);
            HystrixCommand<Boolean> cmd8 = new SuccessCommand(key, 1);
            HystrixCommand<Boolean> cmd9 = new SuccessCommand(key, 1);
            cmd7.execute();
            cmd8.execute();
            cmd9.execute();

            // latent
            HystrixCommand<Boolean> cmd10 = new SuccessCommand(key, 60);
            cmd10.execute();

            // 6 success + 1 latent success + 1 failure + 2 timeout = 10 total
            // latent success not considered error
            // error percentage = 1 failure + 2 timeout / 10
            Thread.sleep(100);
            assertEquals(30, metrics.getHealthCounts().getErrorPercentage());

        } catch (Exception e) {
            e.printStackTrace();
            fail(""Error occurred: "" + e.getMessage());
        }

    }
",non-flaky,5
135730,Netflix_Hystrix,HystrixCommandMetricsTest.testBadRequestsDoNotAffectErrorPercentage,"    @Test
    public void testBadRequestsDoNotAffectErrorPercentage() {
        String key = ""cmd-metrics-B"";
        try {

            HystrixCommand<Boolean> cmd1 = new SuccessCommand(key ,1);
            HystrixCommandMetrics metrics = cmd1.metrics;
            cmd1.execute();
            Thread.sleep(100);
            assertEquals(0, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd2 = new FailureCommand(key, 1);
            cmd2.execute();
            Thread.sleep(100);
            assertEquals(50, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd3 = new BadRequestCommand(key, 1);
            HystrixCommand<Boolean> cmd4 = new BadRequestCommand(key, 1);
            try {
                cmd3.execute();
            } catch (HystrixBadRequestException ex) {
                System.out.println(""Caught expected HystrixBadRequestException from cmd3"");
            }
            try {
                cmd4.execute();
            } catch (HystrixBadRequestException ex) {
                System.out.println(""Caught expected HystrixBadRequestException from cmd4"");
            }
            Thread.sleep(100);
            assertEquals(50, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd5 = new FailureCommand(key, 1);
            HystrixCommand<Boolean> cmd6 = new FailureCommand(key, 1);
            cmd5.execute();
            cmd6.execute();
            Thread.sleep(100);
            assertEquals(75, metrics.getHealthCounts().getErrorPercentage());
        } catch (Exception e) {
            e.printStackTrace();
            fail(""Error occurred : "" + e.getMessage());
        }
    }
",non-flaky,5
135731,Netflix_Hystrix,HystrixCommandMetricsTest.onCompleted,"    @Test
    public void testCurrentConcurrentExecutionCount() throws InterruptedException {
        String key = ""cmd-metrics-C"";

        HystrixCommandMetrics metrics = null;
        List<Observable<Boolean>> cmdResults = new ArrayList<Observable<Boolean>>();

        int NUM_CMDS = 8;
        for (int i = 0; i < NUM_CMDS; i++) {
            HystrixCommand<Boolean> cmd = new SuccessCommand(key, 900);
            if (metrics == null) {
                metrics = cmd.metrics;
            }
            Observable<Boolean> eagerObservable = cmd.observe();
            cmdResults.add(eagerObservable);
        }

        try {
            Thread.sleep(150);
        } catch (InterruptedException ie) {
            fail(ie.getMessage());
        }
        System.out.println(""ReqLog: "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertEquals(NUM_CMDS, metrics.getCurrentConcurrentExecutionCount());

        final CountDownLatch latch = new CountDownLatch(1);
        Observable.merge(cmdResults).subscribe(new Subscriber<Boolean>() {
            @Override
            public void onCompleted() {
                System.out.println(""All commands done"");
                latch.countDown();
            }
",non-flaky,5
135732,Netflix_Hystrix,HystrixCommandTestWithCustomConcurrencyStrategy.testCommandRequiresContextConcurrencyStrategyProvidesItContextSetUpCorrectly,"    @Test
    public void testCommandRequiresContextConcurrencyStrategyProvidesItContextSetUpCorrectly() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(true);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is set up properly
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute());
        printRequestLog();
        assertNotNull(HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertNotNull(cmd.currentRequestLog);
        context.shutdown();
    }
",non-flaky,5
135733,Netflix_Hystrix,HystrixCommandTestWithCustomConcurrencyStrategy.testCommandRequiresContextConcurrencyStrategyProvidesItContextLeftUninitialized,"    @Test
    public void testCommandRequiresContextConcurrencyStrategyProvidesItContextLeftUninitialized() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(true);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is not set up
        HystrixRequestContext.setContextOnCurrentThread(null);
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute()); //command execution not affected by missing context
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
    }
",non-flaky,5
135734,Netflix_Hystrix,HystrixCommandTestWithCustomConcurrencyStrategy.testCommandRequiresContextConcurrencyStrategyDoesNotProvideItContextSetUpCorrectly,"    @Test
    public void testCommandRequiresContextConcurrencyStrategyDoesNotProvideItContextSetUpCorrectly() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(false);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is set up properly
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute());
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
        context.shutdown();
    }
",non-flaky,5
135735,Netflix_Hystrix,HystrixCommandTestWithCustomConcurrencyStrategy.testCommandRequiresContextConcurrencyStrategyDoesNotProvideItContextLeftUninitialized,"    @Test
    public void testCommandRequiresContextConcurrencyStrategyDoesNotProvideItContextLeftUninitialized() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(false);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is not set up
        HystrixRequestContext.setContextOnCurrentThread(null);
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute()); //command execution not affected by missing context
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
    }
",non-flaky,5
135736,Netflix_Hystrix,HystrixCommandTestWithCustomConcurrencyStrategy.testCommandDoesNotRequireContextConcurrencyStrategyProvidesItContextSetUpCorrectly,"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyProvidesItContextSetUpCorrectly() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(true);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is set up properly
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        HystrixCommand<Boolean> cmd = new TestCommand(false, false);
        assertTrue(cmd.execute());
        printRequestLog();
        assertNotNull(HystrixRequestLog.getCurrentRequest());
        assertNotNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
        context.shutdown();
    }
",non-flaky,5
135737,Netflix_Hystrix,HystrixCommandTestWithCustomConcurrencyStrategy.testCommandDoesNotRequireContextConcurrencyStrategyProvidesItContextLeftUninitialized,"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyProvidesItContextLeftUninitialized() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(true);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is not set up
        HystrixRequestContext.setContextOnCurrentThread(null);
        HystrixCommand<Boolean> cmd = new TestCommand(false, false);
        assertTrue(cmd.execute()); //command execution not affected by missing context
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
    }
",non-flaky,5
135738,Netflix_Hystrix,HystrixCommandTestWithCustomConcurrencyStrategy.testCommandDoesNotRequireContextConcurrencyStrategyDoesNotProvideItContextSetUpCorrectly,"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyDoesNotProvideItContextSetUpCorrectly() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(false);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is set up properly
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute());
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
        context.shutdown();
    }
",non-flaky,5
135739,Netflix_Hystrix,HystrixCommandTestWithCustomConcurrencyStrategy.testCommandDoesNotRequireContextConcurrencyStrategyDoesNotProvideItContextLeftUninitialized,"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyDoesNotProvideItContextLeftUninitialized() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(false);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is not set up
        HystrixRequestContext.setContextOnCurrentThread(null);
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute()); //command execution unaffected by missing context
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
    }
",non-flaky,5
135740,Netflix_Hystrix,HystrixPropertyTest.testNested1,"    @Test
    public void testNested1() {
        HystrixProperty<String> a = Factory.asProperty(""a"");
        assertEquals(""a"", a.get());

        HystrixProperty<String> aWithDefault = Factory.asProperty(a, ""b"");
        assertEquals(""a"", aWithDefault.get());
    }
",non-flaky,5
135741,Netflix_Hystrix,HystrixPropertyTest.testNested2,"    @Test
    public void testNested2() {
        HystrixProperty<String> nullValue = Factory.nullProperty();

        HystrixProperty<String> withDefault = Factory.asProperty(nullValue, ""b"");
        assertEquals(""b"", withDefault.get());
    }
",non-flaky,5
135742,Netflix_Hystrix,HystrixPropertyTest.testNested3,"    @Test
    public void testNested3() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, ""a"");

        HystrixProperty<String> withDefault = Factory.asProperty(a, ""b"");
        assertEquals(""a"", withDefault.get());
    }
",non-flaky,5
135743,Netflix_Hystrix,HystrixPropertyTest.testNested4,"    @Test
    public void testNested4() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, null);

        HystrixProperty<String> withDefault = Factory.asProperty(a, ""b"");
        assertEquals(""b"", withDefault.get());
    }
",non-flaky,5
135744,Netflix_Hystrix,HystrixPropertyTest.testNested5,"    @Test
    public void testNested5() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, null);

        @SuppressWarnings(""unchecked"")
        HystrixProperty<String> withDefault = Factory.asProperty(a, Factory.asProperty(""b""));
        assertEquals(""b"", withDefault.get());
    }
",non-flaky,5
135745,Netflix_Hystrix,HystrixPropertyTest.testSeries1,"    @Test
    public void testSeries1() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, null);

        @SuppressWarnings(""unchecked"")
        HystrixProperty<String> withDefault = Factory.asProperty(a, nullValue, nullValue, Factory.asProperty(""b""));
        assertEquals(""b"", withDefault.get());
    }
",non-flaky,5
135746,Netflix_Hystrix,HystrixPropertyTest.testSeries2,"    @Test
    public void testSeries2() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, null);

        @SuppressWarnings(""unchecked"")
        HystrixProperty<String> withDefault = Factory.asProperty(a, nullValue, Factory.asProperty(""b""), nullValue, Factory.asProperty(""c""));
        assertEquals(""b"", withDefault.get());
    }
",non-flaky,5
135747,Netflix_Hystrix,HystrixPropertiesChainedArchaiusPropertyTest.testString,"    @Test
    public void testString() throws Exception {

        DynamicStringProperty pString = new DynamicStringProperty(""defaultString"", ""default-default"");
        HystrixPropertiesChainedArchaiusProperty.StringProperty fString = new HystrixPropertiesChainedArchaiusProperty.StringProperty(""overrideString"", pString);

        assertTrue(""default-default"".equals(fString.get()));

        ConfigurationManager.getConfigInstance().setProperty(""defaultString"", ""default"");
        assertTrue(""default"".equals(fString.get()));

        ConfigurationManager.getConfigInstance().setProperty(""overrideString"", ""override"");
        assertTrue(""override"".equals(fString.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""overrideString"");
        assertTrue(""default"".equals(fString.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""defaultString"");
        assertTrue(""default-default"".equals(fString.get()));
    }
",non-flaky,5
135748,Netflix_Hystrix,HystrixPropertiesChainedArchaiusPropertyTest.testInteger,"    @Test
    public void testInteger() throws Exception {

        DynamicIntegerProperty pInt = new DynamicIntegerProperty(""defaultInt"", -1);
        HystrixPropertiesChainedArchaiusProperty.IntegerProperty fInt = new HystrixPropertiesChainedArchaiusProperty.IntegerProperty(""overrideInt"", pInt);

        assertTrue(-1 == fInt.get());

        ConfigurationManager.getConfigInstance().setProperty(""defaultInt"", 10);
        assertTrue(10 == fInt.get());

        ConfigurationManager.getConfigInstance().setProperty(""overrideInt"", 11);
        assertTrue(11 == fInt.get());

        ConfigurationManager.getConfigInstance().clearProperty(""overrideInt"");
        assertTrue(10 == fInt.get());

        ConfigurationManager.getConfigInstance().clearProperty(""defaultInt"");
        assertTrue(-1 == fInt.get());
    }
",non-flaky,5
135749,Netflix_Hystrix,HystrixPropertiesChainedArchaiusPropertyTest.testBoolean,"    @Test
    public void testBoolean() throws Exception {

        DynamicBooleanProperty pBoolean = new DynamicBooleanProperty(""defaultBoolean"", true);
        HystrixPropertiesChainedArchaiusProperty.BooleanProperty fBoolean = new HystrixPropertiesChainedArchaiusProperty.BooleanProperty(""overrideBoolean"", pBoolean);

        System.out.println(""pBoolean: "" + pBoolean.get());
        System.out.println(""fBoolean: "" + fBoolean.get());

        assertTrue(fBoolean.get());

        ConfigurationManager.getConfigInstance().setProperty(""defaultBoolean"", Boolean.FALSE);

        System.out.println(""pBoolean: "" + pBoolean.get());
        System.out.println(""fBoolean: "" + fBoolean.get());

        assertFalse(fBoolean.get());

        ConfigurationManager.getConfigInstance().setProperty(""overrideBoolean"", Boolean.TRUE);
        assertTrue(fBoolean.get());

        ConfigurationManager.getConfigInstance().clearProperty(""overrideBoolean"");
        assertFalse(fBoolean.get());

        ConfigurationManager.getConfigInstance().clearProperty(""defaultBoolean"");
        assertTrue(fBoolean.get());
    }
",non-flaky,5
135750,Netflix_Hystrix,HystrixPropertiesChainedArchaiusPropertyTest.testChainingString,"    @Test
    public void testChainingString() throws Exception {

        DynamicStringProperty node1 = new DynamicStringProperty(""node1"", ""v1"");
        StringProperty node2 = new HystrixPropertiesChainedArchaiusProperty.StringProperty(""node2"", node1);

        HystrixPropertiesChainedArchaiusProperty.StringProperty node3 = new HystrixPropertiesChainedArchaiusProperty.StringProperty(""node3"", node2);

        assertTrue("""" + node3.get(), ""v1"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node1"", ""v11"");
        assertTrue(""v11"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node2"", ""v22"");
        assertTrue(""v22"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""node1"");
        assertTrue(""v22"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node3"", ""v33"");
        assertTrue(""v33"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""node2"");
        assertTrue(""v33"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node2"", ""v222"");
        assertTrue(""v33"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""node3"");
        assertTrue(""v222"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""node2"");
        assertTrue(""v1"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node2"", ""v2222"");
        assertTrue(""v2222"".equals(node3.get()));
    }
",non-flaky,5
135751,Netflix_Hystrix,HystrixPropertiesChainedArchaiusPropertyTest.testChainingInteger,"    @Test
    public void testChainingInteger() throws Exception {

        DynamicIntegerProperty node1 = new DynamicIntegerProperty(""node1"", 1);
        IntegerProperty node2 = new HystrixPropertiesChainedArchaiusProperty.IntegerProperty(""node2"", node1);

        HystrixPropertiesChainedArchaiusProperty.IntegerProperty node3 = new HystrixPropertiesChainedArchaiusProperty.IntegerProperty(""node3"", node2);

        assertTrue("""" + node3.get(), 1 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node1"", 11);
        assertTrue(11 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node2"", 22);
        assertTrue(22 == node3.get());

        ConfigurationManager.getConfigInstance().clearProperty(""node1"");
        assertTrue(22 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node3"", 33);
        assertTrue(33 == node3.get());

        ConfigurationManager.getConfigInstance().clearProperty(""node2"");
        assertTrue(33 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node2"", 222);
        assertTrue(33 == node3.get());

        ConfigurationManager.getConfigInstance().clearProperty(""node3"");
        assertTrue(222 == node3.get());

        ConfigurationManager.getConfigInstance().clearProperty(""node2"");
        assertTrue(1 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node2"", 2222);
        assertTrue(2222 == node3.get());
    }
",non-flaky,5
135752,Netflix_Hystrix,HystrixPropertiesChainedArchaiusPropertyTest.run,"    @Test
    public void testAddCallback() throws Exception {

        final DynamicStringProperty node1 = new DynamicStringProperty(""n1"", ""n1"");
        final HystrixPropertiesChainedArchaiusProperty.StringProperty node2 = new HystrixPropertiesChainedArchaiusProperty.StringProperty(""n2"", node1);

        final AtomicInteger callbackCount = new AtomicInteger(0);

        node2.addCallback(new Runnable() {
            @Override
            public void run() {
                callbackCount.incrementAndGet();
            }
",non-flaky,5
135753,Netflix_Hystrix,HystrixConcurrencyStrategyTest.call,"    @Test
    public void testRequestContextPropagatesAcrossObserveOnPool() {
        new SimpleCommand().execute();
        new SimpleCommand().observe().map(new Func1<String, String>() {

            @Override
            public String call(String s) {
                System.out.println(""Map => Commands: "" + HystrixRequestLog.getCurrentRequest().getAllExecutedCommands());
                return s;
            }
",non-flaky,5
135754,Netflix_Hystrix,HystrixConcurrencyStrategyTest.call,"    @Test
    public void testThreadContextOnTimeout() {
        final AtomicBoolean isInitialized = new AtomicBoolean();
        new TimeoutCommand().toObservable()
                .doOnError(new Action1<Throwable>() {
                    @Override
                    public void call(Throwable throwable) {
                        isInitialized.set(HystrixRequestContext.isCurrentThreadInitialized());
                    }
",non-flaky,5
135755,Netflix_Hystrix,HystrixConcurrencyStrategyTest.testNoRequestContextOnSimpleConcurencyStrategyWithoutException,"    @Test
    public void testNoRequestContextOnSimpleConcurencyStrategyWithoutException() throws Exception {
        shutdownContextIfExists();
        ConfigurationManager.getConfigInstance().setProperty(""hystrix.command.default.requestLog.enabled"", ""false"");

        new SimpleCommand().execute();

        assertTrue(""We are able to run the simple command without a context initialization error."", true);
    }
",non-flaky,5
135756,Netflix_Hystrix,HystrixContextSchedulerTest.call,"    @Test(timeout = 2500)
    public void testUnsubscribeWrappedScheduler() throws InterruptedException {
        Scheduler s = Schedulers.newThread();
        final AtomicBoolean interrupted = new AtomicBoolean();
        final CountDownLatch start = new CountDownLatch(1);
        final CountDownLatch end = new CountDownLatch(1);

        HystrixContextScheduler hcs = new HystrixContextScheduler(s);

        Scheduler.Worker w = hcs.createWorker();
        try {
            w.schedule(new Action0() {
                @Override
                public void call() {
                    start.countDown();
                    try {
                        try {
                            Thread.sleep(5000);
                        } catch (InterruptedException ex) {
                            interrupted.set(true);
                        }
                    } finally {
                        end.countDown();
                    }
                }
",non-flaky,5
135757,Netflix_Hystrix,HystrixMetricsPublisherFactoryTest.run,"    @Test
    public void testSingleInitializePerKey() {
        final TestHystrixMetricsPublisher publisher = new TestHystrixMetricsPublisher();
        HystrixPlugins.getInstance().registerMetricsPublisher(publisher);
        final HystrixMetricsPublisherFactory factory = new HystrixMetricsPublisherFactory();
        ArrayList<Thread> threads = new ArrayList<Thread>();
        for (int i = 0; i < 20; i++) {
            threads.add(new Thread(new Runnable() {

                @Override
                public void run() {
                    factory.getPublisherForCommand(TestCommandKey.TEST_A, null, null, null, null);
                    factory.getPublisherForCommand(TestCommandKey.TEST_B, null, null, null, null);
                    factory.getPublisherForThreadPool(TestThreadPoolKey.TEST_A, null, null);
                }
",non-flaky,5
135758,Netflix_Hystrix,HystrixMetricsPublisherFactoryTest.testMetricsPublisherReset,"    @Test
    public void testMetricsPublisherReset() {
        // precondition: HystrixMetricsPublisherFactory class is not loaded. Calling HystrixPlugins.reset() here should be good enough to run this with other tests.

        // set first custom publisher
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""key"");
        HystrixMetricsPublisherCommand firstCommand = new HystrixMetricsPublisherCommandDefault(key, null, null, null, null);
        HystrixMetricsPublisher firstPublisher = new CustomPublisher(firstCommand);
        HystrixPlugins.getInstance().registerMetricsPublisher(firstPublisher);

        // ensure that first custom publisher is used
        HystrixMetricsPublisherCommand cmd = HystrixMetricsPublisherFactory.createOrRetrievePublisherForCommand(key, null, null, null, null);
        assertSame(firstCommand, cmd);

        // reset, then change to second custom publisher
        HystrixPlugins.reset();
        HystrixMetricsPublisherCommand secondCommand = new HystrixMetricsPublisherCommandDefault(key, null, null, null, null);
        HystrixMetricsPublisher secondPublisher = new CustomPublisher(secondCommand);
        HystrixPlugins.getInstance().registerMetricsPublisher(secondPublisher);

        // ensure that second custom publisher is used
        cmd = HystrixMetricsPublisherFactory.createOrRetrievePublisherForCommand(key, null, null, null, null);
        assertNotSame(firstCommand, cmd);
        assertSame(secondCommand, cmd);
    }
",non-flaky,5
135759,Netflix_Hystrix,HystrixPluginsTest.testDynamicProperties,"    @Test
    public void testDynamicProperties() throws Exception {
        fakeServiceLoaderResource = 
                ""FAKE_META_INF_SERVICES/com.netflix.hystrix.strategy.properties.HystrixDynamicProperties"";
        HystrixPlugins plugins = setupMockServiceLoader();
        HystrixDynamicProperties properties = plugins.getDynamicProperties();
        plugins.getCommandExecutionHook();
        plugins.getPropertiesStrategy();
        assertTrue(properties instanceof MockHystrixDynamicPropertiesTest);

        assertEvents(
                ""[serviceloader: META-INF/services/com.netflix.hystrix.strategy.properties.HystrixDynamicProperties""
                        + "", debug: [Created HystrixDynamicProperties instance by loading from ServiceLoader. Using class: {}, com.netflix.hystrix.strategy.HystrixPluginsTest.MockHystrixDynamicPropertiesTest]""
                        + "", property: hystrix.plugin.HystrixCommandExecutionHook.implementation""
                        + "", serviceloader: META-INF/services/com.netflix.hystrix.strategy.executionhook.HystrixCommandExecutionHook""
                        + "", property: hystrix.plugin.HystrixPropertiesStrategy.implementation""
                        + "", serviceloader: META-INF/services/com.netflix.hystrix.strategy.properties.HystrixPropertiesStrategy]"");
    }
",non-flaky,5
135760,Netflix_Hystrix,HystrixPluginsTest.testDynamicPropertiesFailure,"    @Test(expected=ServiceConfigurationError.class)
    public void testDynamicPropertiesFailure() throws Exception {
        /*
         * James Bond: Do you expect me to talk?
         * Auric Goldfinger: No, Mr. Bond, I expect you to die!
         */
        fakeServiceLoaderResource = 
                ""FAKE_META_INF_SERVICES/com.netflix.hystrix.strategy.properties.HystrixDynamicPropertiesFail"";
        HystrixPlugins plugins = setupMockServiceLoader();
        plugins.getDynamicProperties();

    }
",non-flaky,5
135761,Netflix_Hystrix,HystrixPluginsTest.testDynamicSystemProperties,"    @Test
    public void testDynamicSystemProperties() throws Exception {
        //On the off chance this is the first test lets not screw up all the other tests
        HystrixPlugins.getInstance();
        
        System.setProperty(""hystrix.plugin.HystrixDynamicProperties.implementation"", 
                ""com.netflix.hystrix.strategy.properties.HystrixDynamicPropertiesSystemProperties"");
        
        HystrixPlugins plugins = setupMockServiceLoader();
        assertTrue(plugins.getDynamicProperties() instanceof HystrixDynamicPropertiesSystemProperties);
        
        HystrixDynamicProperties p = plugins.getDynamicProperties();
        //Some minimum testing of system properties wrapper
        //this probably should be in its own test class.
        assertTrue(p.getBoolean(""USE_DEFAULT"", true).get());
        assertEquals(""string"", p.getString(""USE_DEFAULT"", ""string"").get());
        assertEquals(1L, p.getLong(""USE_DEFAULT"", 1L).get().longValue());
        assertEquals(1, p.getInteger(""USE_DEFAULT"", 1).get().intValue());
        assertNotNull(p.getString(""path.separator"", null).get());
        
        assertEvents(""[debug: [Created HystrixDynamicProperties instance from System property named \""hystrix.plugin.HystrixDynamicProperties.implementation\"". Using class: {}, com.netflix.hystrix.strategy.properties.HystrixDynamicPropertiesSystemProperties]]"");

        System.clearProperty(""hystrix.plugin.HystrixDynamicProperties.implementation"");

    }
",non-flaky,5
135762,Netflix_Hystrix,HystrixPluginsTest.testCommandExecutionHookDefaultImpl,"    /*    @Test
    public void testCommandExecutionHookDefaultImpl() {
        HystrixCommandExecutionHook impl = HystrixPlugins.getInstance().getCommandExecutionHook();
        assertTrue(impl instanceof HystrixCommandExecutionHookDefault);
    }
",non-flaky,5
135763,Netflix_Hystrix,HystrixPluginsTest.testCommandExecutionHookViaRegisterMethod,"    @Test
    public void testCommandExecutionHookViaRegisterMethod() {
        HystrixPlugins.getInstance().registerCommandExecutionHook(new HystrixCommandExecutionHookTestImpl());
        HystrixCommandExecutionHook impl = HystrixPlugins.getInstance().getCommandExecutionHook();
        assertTrue(impl instanceof HystrixCommandExecutionHookTestImpl);
	}*/
",non-flaky,5
135764,Netflix_Hystrix,HystrixPluginsTest.testEventNotifierDefaultImpl,"    /*@Test
    public void testEventNotifierDefaultImpl() {
        HystrixEventNotifier impl = HystrixPlugins.getInstance().getEventNotifier();
        assertTrue(impl instanceof HystrixEventNotifierDefault);
    }
",non-flaky,5
135765,Netflix_Hystrix,HystrixPluginsTest.testEventNotifierViaRegisterMethod,"    @Test
    public void testEventNotifierViaRegisterMethod() {
        HystrixPlugins.getInstance().registerEventNotifier(new HystrixEventNotifierTestImpl());
        HystrixEventNotifier impl = HystrixPlugins.getInstance().getEventNotifier();
        assertTrue(impl instanceof HystrixEventNotifierTestImpl);
    }
",non-flaky,5
135766,Netflix_Hystrix,HystrixPluginsTest.testEventNotifierViaProperty,"    @Test
    public void testEventNotifierViaProperty() {
        try {
            String fullClass = HystrixEventNotifierTestImpl.class.getName();
            System.setProperty(""hystrix.plugin.HystrixEventNotifier.implementation"", fullClass);
            HystrixEventNotifier impl = HystrixPlugins.getInstance().getEventNotifier();
            assertTrue(impl instanceof HystrixEventNotifierTestImpl);
        } finally {
            System.clearProperty(""hystrix.plugin.HystrixEventNotifier.implementation"");
        }
	}*/
",non-flaky,5
135767,Netflix_Hystrix,HystrixPluginsTest.testConcurrencyStrategyDefaultImpl,"    /*@Test
    public void testConcurrencyStrategyDefaultImpl() {
        HystrixConcurrencyStrategy impl = HystrixPlugins.getInstance().getConcurrencyStrategy();
        assertTrue(impl instanceof HystrixConcurrencyStrategyDefault);
    }
",non-flaky,5
135768,Netflix_Hystrix,HystrixPluginsTest.testConcurrencyStrategyViaRegisterMethod,"    @Test
    public void testConcurrencyStrategyViaRegisterMethod() {
        HystrixPlugins.getInstance().registerConcurrencyStrategy(new HystrixConcurrencyStrategyTestImpl());
        HystrixConcurrencyStrategy impl = HystrixPlugins.getInstance().getConcurrencyStrategy();
        assertTrue(impl instanceof HystrixConcurrencyStrategyTestImpl);
    }
",non-flaky,5
135769,Netflix_Hystrix,HystrixPluginsTest.testConcurrencyStrategyViaProperty,"    @Test
    public void testConcurrencyStrategyViaProperty() {
        try {
            String fullClass = HystrixConcurrencyStrategyTestImpl.class.getName();
            System.setProperty(""hystrix.plugin.HystrixConcurrencyStrategy.implementation"", fullClass);
            HystrixConcurrencyStrategy impl = HystrixPlugins.getInstance().getConcurrencyStrategy();
            assertTrue(impl instanceof HystrixConcurrencyStrategyTestImpl);
        } finally {
            System.clearProperty(""hystrix.plugin.HystrixConcurrencyStrategy.implementation"");
        }
	}*/
",non-flaky,5
135770,Netflix_Hystrix,HystrixPluginsTest.testMetricsPublisherDefaultImpl,"    /*@Test
    public void testMetricsPublisherDefaultImpl() {
        HystrixMetricsPublisher impl = HystrixPlugins.getInstance().getMetricsPublisher();
        assertTrue(impl instanceof HystrixMetricsPublisherDefault);
    }
",non-flaky,5
135771,Netflix_Hystrix,HystrixPluginsTest.testMetricsPublisherViaRegisterMethod,"    @Test
    public void testMetricsPublisherViaRegisterMethod() {
        HystrixPlugins.getInstance().registerMetricsPublisher(new HystrixMetricsPublisherTestImpl());
        HystrixMetricsPublisher impl = HystrixPlugins.getInstance().getMetricsPublisher();
        assertTrue(impl instanceof HystrixMetricsPublisherTestImpl);
    }
",non-flaky,5
135772,Netflix_Hystrix,HystrixPluginsTest.testMetricsPublisherViaProperty,"    @Test
    public void testMetricsPublisherViaProperty() {
        try {
            String fullClass = HystrixMetricsPublisherTestImpl.class.getName();
            System.setProperty(""hystrix.plugin.HystrixMetricsPublisher.implementation"", fullClass);
            HystrixMetricsPublisher impl = HystrixPlugins.getInstance().getMetricsPublisher();
            assertTrue(impl instanceof HystrixMetricsPublisherTestImpl);
        } finally {
            System.clearProperty(""hystrix.plugin.HystrixMetricsPublisher.implementation"");
        }
	}*/
",non-flaky,5
135773,Netflix_Hystrix,HystrixPluginsTest.testPropertiesStrategyDefaultImpl,"    /*@Test
    public void testPropertiesStrategyDefaultImpl() {
        HystrixPropertiesStrategy impl = HystrixPlugins.getInstance().getPropertiesStrategy();
        assertTrue(impl instanceof HystrixPropertiesStrategyDefault);
    }
",non-flaky,5
135774,Netflix_Hystrix,HystrixPluginsTest.testPropertiesStrategyViaRegisterMethod,"    @Test
    public void testPropertiesStrategyViaRegisterMethod() {
        HystrixPlugins.getInstance().registerPropertiesStrategy(new HystrixPropertiesStrategyTestImpl());
        HystrixPropertiesStrategy impl = HystrixPlugins.getInstance().getPropertiesStrategy();
        assertTrue(impl instanceof HystrixPropertiesStrategyTestImpl);
    }
",non-flaky,5
135775,Netflix_Hystrix,HystrixPluginsTest.testPropertiesStrategyViaProperty,"    @Test
    public void testPropertiesStrategyViaProperty() {
        try {
            String fullClass = HystrixPropertiesStrategyTestImpl.class.getName();
            System.setProperty(""hystrix.plugin.HystrixPropertiesStrategy.implementation"", fullClass);
            HystrixPropertiesStrategy impl = HystrixPlugins.getInstance().getPropertiesStrategy();
            assertTrue(impl instanceof HystrixPropertiesStrategyTestImpl);
        } finally {
            System.clearProperty(""hystrix.plugin.HystrixPropertiesStrategy.implementation"");
        }
	}*/
",non-flaky,5
135776,Netflix_Hystrix,HystrixPluginsTest.call,"    /*@Test
    public void testRequestContextViaPluginInTimeout() {
        HystrixPlugins.getInstance().registerConcurrencyStrategy(new HystrixConcurrencyStrategy() {
            @Override
            public <T> Callable<T> wrapCallable(final Callable<T> callable) {
                return new RequestIdCallable<T>(callable);
            }
        });

        HystrixRequestContext context = HystrixRequestContext.initializeContext();

        testRequestIdThreadLocal.set(""foobar"");
        final AtomicReference<String> valueInTimeout = new AtomicReference<String>();

        new DummyCommand().toObservable()
                .doOnError(new Action1<Throwable>() {
                    @Override
                    public void call(Throwable throwable) {
                        System.out.println(""initialized = "" + HystrixRequestContext.isCurrentThreadInitialized());
                        System.out.println(""requestId (timeout) = "" + testRequestIdThreadLocal.get());
                        valueInTimeout.set(testRequestIdThreadLocal.get());
                    }
",non-flaky,5
135777,Netflix_Hystrix,CollapsedRequestSubjectTest.testSetResponseSuccess,"    @Test
    public void testSetResponseSuccess() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(""theResponse"");

        // fetch value
        assertEquals(""theResponse"", v.get());
    }
",non-flaky,5
135778,Netflix_Hystrix,CollapsedRequestSubjectTest.testSetNullResponseSuccess,"    @Test
    public void testSetNullResponseSuccess() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(null);

        // fetch value
        assertEquals(null, v.get());
    }
",non-flaky,5
135779,Netflix_Hystrix,CollapsedRequestSubjectTest.testSetException,"    @Test
    public void testSetException() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setException(new RuntimeException(""anException""));

        // fetch value
        try {
            v.get();
            fail(""expected exception"");
        } catch (ExecutionException e) {
            assertEquals(""anException"", e.getCause().getMessage());
        }
    }
",non-flaky,5
135780,Netflix_Hystrix,CollapsedRequestSubjectTest.testSetExceptionAfterResponse,"    @Test
    public void testSetExceptionAfterResponse() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(""theResponse"");

        try {
            cr.setException(new RuntimeException(""anException""));
            fail(""expected IllegalState"");
        } catch (IllegalStateException e) {

        }

        assertEquals(""theResponse"", v.get());
    }
",non-flaky,5
135781,Netflix_Hystrix,CollapsedRequestSubjectTest.testSetResponseAfterException,"    @Test
    public void testSetResponseAfterException() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setException(new RuntimeException(""anException""));

        try {
            cr.setResponse(""theResponse"");
            fail(""expected IllegalState"");
        } catch (IllegalStateException e) {

        }

        try {
            v.get();
            fail(""expected exception"");
        } catch (ExecutionException e) {
            assertEquals(""anException"", e.getCause().getMessage());
        }
    }
",non-flaky,5
135782,Netflix_Hystrix,CollapsedRequestSubjectTest.testSetResponseDuplicate,"    @Test
    public void testSetResponseDuplicate() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(""theResponse"");

        try {
            cr.setResponse(""theResponse2"");
            fail(""expected IllegalState"");
        } catch (IllegalStateException e) {

        }

        assertEquals(""theResponse"", v.get());
    }
",non-flaky,5
135783,Netflix_Hystrix,CollapsedRequestSubjectTest.testSetResponseAfterUnsubscribe,"    @Test(expected = CancellationException.class)
    public void testSetResponseAfterUnsubscribe() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> f = o.toBlocking().toFuture();

        // cancel/unsubscribe
        f.cancel(true);

        try {
            cr.setResponse(""theResponse"");
        } catch (IllegalStateException e) {
            fail(""this should have done nothing as it was unsubscribed already"");
        }

        // expect CancellationException after cancelling
        f.get();
    }
",non-flaky,5
135784,Netflix_Hystrix,CollapsedRequestSubjectTest.testSetExceptionAfterUnsubscribe,"    @Test(expected = CancellationException.class)
    public void testSetExceptionAfterUnsubscribe() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> f = o.toBlocking().toFuture();

        // cancel/unsubscribe
        f.cancel(true);

        try {
            cr.setException(new RuntimeException(""anException""));
        } catch (IllegalStateException e) {
            fail(""this should have done nothing as it was unsubscribed already"");
        }

        // expect CancellationException after cancelling
        f.get();
    }
",non-flaky,5
135785,Netflix_Hystrix,CollapsedRequestSubjectTest.testUnsubscribeAfterSetResponse,"    @Test
    public void testUnsubscribeAfterSetResponse() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(""theResponse"");

        // unsubscribe after the value is sent
        v.cancel(true);

        // still get value as it was set before canceling
        assertEquals(""theResponse"", v.get());
    }
",non-flaky,5
135786,Netflix_Hystrix,HystrixThreadPoolTest.testShutdown,"    @Test
    public void testShutdown() {
        // other unit tests will probably have run before this so get the count
        int count = Factory.threadPools.size();

        HystrixThreadPool pool = Factory.getInstance(HystrixThreadPoolKey.Factory.asKey(""threadPoolFactoryTest""),
                HystrixThreadPoolProperties.Setter.getUnitTestPropertiesBuilder());

        assertEquals(count + 1, Factory.threadPools.size());
        assertFalse(pool.getExecutor().isShutdown());

        Factory.shutdown();

        // ensure all pools were removed from the cache
        assertEquals(0, Factory.threadPools.size());
        assertTrue(pool.getExecutor().isShutdown());
    }
",non-flaky,5
135787,Netflix_Hystrix,HystrixThreadPoolTest.testShutdownWithWait,"    @Test
    public void testShutdownWithWait() {
        // other unit tests will probably have run before this so get the count
        int count = Factory.threadPools.size();

        HystrixThreadPool pool = Factory.getInstance(HystrixThreadPoolKey.Factory.asKey(""threadPoolFactoryTest""),
                HystrixThreadPoolProperties.Setter.getUnitTestPropertiesBuilder());

        assertEquals(count + 1, Factory.threadPools.size());
        assertFalse(pool.getExecutor().isShutdown());

        Factory.shutdown(1, TimeUnit.SECONDS);

        // ensure all pools were removed from the cache
        assertEquals(0, Factory.threadPools.size());
        assertTrue(pool.getExecutor().isShutdown());
    }
",non-flaky,5
135788,Netflix_Hystrix,HystrixThreadPoolTest.getMetricsPublisherForThreadPool,"    @Test
    public void ensureThreadPoolInstanceIsTheOneRegisteredWithMetricsPublisherAndThreadPoolCache() throws IllegalAccessException, NoSuchFieldException {
        HystrixPlugins.getInstance().registerMetricsPublisher(new HystrixMetricsPublisher() {
            @Override
            public HystrixMetricsPublisherThreadPool getMetricsPublisherForThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixThreadPoolMetrics metrics, HystrixThreadPoolProperties properties) {
                return new HystrixMetricsPublisherThreadPoolContainer(metrics);
            }
",non-flaky,5
135789,Netflix_Hystrix,HystrixThreadPoolTest.call,"    @Test(timeout = 2500)
    public void testUnsubscribeHystrixThreadPool() throws InterruptedException {
        // methods are package-private so can't test it somewhere else
        HystrixThreadPool pool = Factory.getInstance(HystrixThreadPoolKey.Factory.asKey(""threadPoolFactoryTest""),
                HystrixThreadPoolProperties.Setter.getUnitTestPropertiesBuilder());
        
        final AtomicBoolean interrupted = new AtomicBoolean();
        final CountDownLatch start = new CountDownLatch(1);
        final CountDownLatch end = new CountDownLatch(1);

        HystrixContextScheduler hcs = new HystrixContextScheduler(HystrixPlugins.getInstance().getConcurrencyStrategy(), pool);

        Scheduler.Worker w = hcs.createWorker();

        try {
            w.schedule(new Action0() {
                @Override
                public void call() {
                    start.countDown();
                    try {
                        try {
                            Thread.sleep(5000);
                        } catch (InterruptedException ex) {
                            interrupted.set(true);
                        }
                    } finally {
                        end.countDown();
                    }
                }
",non-flaky,5
135790,Netflix_Hystrix,HystrixCommandTimeoutConcurrencyTesting.testTimeoutRace,"    @Test
    public void testTimeoutRace() throws InterruptedException {
        final int NUM_TRIALS = 10;

        for (int i = 0; i < NUM_TRIALS; i++) {
            List<Observable<String>> observables = new ArrayList<Observable<String>>();
            HystrixRequestContext context = null;

            try {
                context = HystrixRequestContext.initializeContext();
                for (int j = 0; j < NUM_CONCURRENT_COMMANDS; j++) {
                    observables.add(new TestCommand().observe());
                }

                Observable<String> overall = Observable.merge(observables);

                List<String> results = overall.toList().toBlocking().first(); //wait for all commands to complete

                for (String s : results) {
                    if (s == null) {
                        System.err.println(""Received NULL!"");
                        throw new RuntimeException(""Received NULL"");
                    }
                }

                for (HystrixInvokableInfo<?> hi : HystrixRequestLog.getCurrentRequest().getAllExecutedCommands()) {
                    if (!hi.isResponseTimedOut()) {
                        System.err.println(""Timeout not found in executed command"");
                        throw new RuntimeException(""Timeout not found in executed command"");
                    }
                    if (hi.isResponseTimedOut() && hi.getExecutionEvents().size() == 1) {
                        System.err.println(""Missing fallback status!"");
                        throw new RuntimeException(""Missing fallback status on timeout."");
                    }
                }

            } catch (Exception e) {
                System.err.println(""Error: "" + e.getMessage());
                e.printStackTrace();
                throw new RuntimeException(e);
            } finally {
                System.out.println(HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
                if (context != null) {
                    context.shutdown();
                }
            }

            System.out.println(""*************** TRIAL "" + i + "" ******************"");
            System.out.println();
            Thread.sleep(50);
        }

        Hystrix.reset();
    }
",non-flaky,5
135791,Netflix_Hystrix,RollingCollapserBatchSizeDistributionStreamTest.onCompleted,"    @Test
    public void testEmptyStreamProducesEmptyDistributions() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""Collapser-Batch-Size-A"");
        stream = RollingCollapserBatchSizeDistributionStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().skip(10).take(10).subscribe(new Subscriber<CachedValuesHistogram>() {
            @Override
            public void onCompleted() {
                latch.countDown();
            }
",non-flaky,5
135792,Netflix_Hystrix,RollingCollapserBatchSizeDistributionStreamTest.onCompleted,"    @Test
    public void testBatches() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""Collapser-Batch-Size-B"");
        stream = RollingCollapserBatchSizeDistributionStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(10).subscribe(new Subscriber<CachedValuesHistogram>() {
            @Override
            public void onCompleted() {
                latch.countDown();
            }
",non-flaky,5
135793,Netflix_Hystrix,RollingCollapserBatchSizeDistributionStreamTest.onCompleted,"    @Test
    public void testBatchesAgeOut() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""Collapser-Batch-Size-B"");
        stream = RollingCollapserBatchSizeDistributionStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(30).subscribe(new Subscriber<CachedValuesHistogram>() {
            @Override
            public void onCompleted() {
                latch.countDown();
            }
",non-flaky,5
135794,Netflix_Hystrix,CumulativeCollapserEventCounterStreamTest.testEmptyStreamProducesZeros,"    @Test
    public void testEmptyStreamProducesZeros() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-A"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(10).subscribe(getSubscriber(latch));

        //no writes

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        assertEquals(0, stream.getLatest(HystrixEventType.Collapser.ADDED_TO_BATCH));
        assertEquals(0, stream.getLatest(HystrixEventType.Collapser.BATCH_EXECUTED));
        assertEquals(0, stream.getLatest(HystrixEventType.Collapser.RESPONSE_FROM_CACHE));
    }
",non-flaky,5
135795,Netflix_Hystrix,CumulativeCollapserEventCounterStreamTest.testCollapsed,"    @Test
    public void testCollapsed() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-B"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(10).subscribe(getSubscriber(latch));

        for (int i = 0; i < 3; i++) {
            CommandStreamTest.Collapser.from(key, i).observe();
        }

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.Collapser.values().length];
        expected[HystrixEventType.Collapser.BATCH_EXECUTED.ordinal()] = 1;
        expected[HystrixEventType.Collapser.ADDED_TO_BATCH.ordinal()] = 3;
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
135796,Netflix_Hystrix,CumulativeCollapserEventCounterStreamTest.testCollapsedAndResponseFromCache,"    @Test
    public void testCollapsedAndResponseFromCache() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-C"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(10).subscribe(getSubscriber(latch));

        for (int i = 0; i < 3; i++) {
            CommandStreamTest.Collapser.from(key, i).observe();
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
        }

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.Collapser.values().length];
        expected[HystrixEventType.Collapser.BATCH_EXECUTED.ordinal()] = 1;
        expected[HystrixEventType.Collapser.ADDED_TO_BATCH.ordinal()] = 3;
        expected[HystrixEventType.Collapser.RESPONSE_FROM_CACHE.ordinal()] = 6;
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
135797,Netflix_Hystrix,CumulativeCollapserEventCounterStreamTest.testCollapsedAndResponseFromCacheAgeOutOfCumulativeWindow,"    @Test
    public void testCollapsedAndResponseFromCacheAgeOutOfCumulativeWindow() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-D"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(30).subscribe(getSubscriber(latch));

        for (int i = 0; i < 3; i++) {
            CommandStreamTest.Collapser.from(key, i).observe();
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
        }

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.Collapser.values().length];
        expected[HystrixEventType.Collapser.BATCH_EXECUTED.ordinal()] = 1;
        expected[HystrixEventType.Collapser.ADDED_TO_BATCH.ordinal()] = 3;
        expected[HystrixEventType.Collapser.RESPONSE_FROM_CACHE.ordinal()] = 6;
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
135798,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testEmptyStreamProducesZeros,"    @Test
    public void testEmptyStreamProducesZeros() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-A"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //no writes

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        assertFalse(hasData(stream.getLatest()));
    }
",non-flaky,5
135799,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testSingleSuccess,"    @Test
    public void testSingleSuccess() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-B"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.SUCCESS, 20);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.SUCCESS.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
135800,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testSingleFailure,"    @Test
    public void testSingleFailure() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-C"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.FAILURE, 20);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 1;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
135801,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testSingleTimeout,"    @Test
    public void testSingleTimeout() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-D"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.TIMEOUT);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.TIMEOUT.ordinal()] = 1;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
135802,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testSingleBadRequest,"    @Test
    public void testSingleBadRequest() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-E"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.BAD_REQUEST);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.BAD_REQUEST.ordinal()] = 1;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
135803,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testRequestFromCache,"    @Test
    public void testRequestFromCache() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-F"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd1 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 20);
        Command cmd2 = Command.from(groupKey, key, HystrixEventType.RESPONSE_FROM_CACHE);
        Command cmd3 = Command.from(groupKey, key, HystrixEventType.RESPONSE_FROM_CACHE);

        cmd1.observe();
        cmd2.observe();
        cmd3.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }

        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.SUCCESS.ordinal()] = 1;
        expected[HystrixEventType.RESPONSE_FROM_CACHE.ordinal()] = 2;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
135804,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testShortCircuited,"    @Test
    public void testShortCircuited() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-G"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //3 failures in a row will trip circuit.  let bucket roll once then submit 2 requests.
        //should see 3 FAILUREs and 2 SHORT_CIRCUITs and then 5 FALLBACK_SUCCESSes

        Command failure1 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20);
        Command failure2 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20);
        Command failure3 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20);

        Command shortCircuit1 = Command.from(groupKey, key, HystrixEventType.SUCCESS);
        Command shortCircuit2 = Command.from(groupKey, key, HystrixEventType.SUCCESS);

        failure1.observe();
        failure2.observe();
        failure3.observe();

        try {
            Thread.sleep(500);
        } catch (InterruptedException ie) {
            fail(ie.getMessage());
        }

        shortCircuit1.observe();
        shortCircuit2.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }

        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertTrue(shortCircuit1.isResponseShortCircuited());
        assertTrue(shortCircuit2.isResponseShortCircuited());
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 3;
        expected[HystrixEventType.SHORT_CIRCUITED.ordinal()] = 2;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 5;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
135805,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.run,"    @Test
    public void testSemaphoreRejected() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-H"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //10 commands will saturate semaphore when called from different threads.
        //submit 2 more requests and they should be SEMAPHORE_REJECTED
        //should see 10 SUCCESSes, 2 SEMAPHORE_REJECTED and 2 FALLBACK_SUCCESSes

        List<Command> saturators = new ArrayList<Command>();

        for (int i = 0; i < 10; i++) {
            saturators.add(Command.from(groupKey, key, HystrixEventType.SUCCESS, 500, HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE));
        }

        Command rejected1 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0, HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE);
        Command rejected2 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0, HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE);

        for (final Command saturator : saturators) {
            new Thread(new HystrixContextRunnable(new Runnable() {
                @Override
                public void run() {
                    saturator.observe();
                }
",non-flaky,5
135806,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testThreadPoolRejected,"    @Test
    public void testThreadPoolRejected() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-I"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //10 commands will saturate threadpools when called concurrently.
        //submit 2 more requests and they should be THREADPOOL_REJECTED
        //should see 10 SUCCESSes, 2 THREADPOOL_REJECTED and 2 FALLBACK_SUCCESSes

        List<Command> saturators = new ArrayList<Command>();

        for (int i = 0; i < 10; i++) {
            saturators.add(Command.from(groupKey, key, HystrixEventType.SUCCESS, 500));
        }

        Command rejected1 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0);
        Command rejected2 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0);

        for (final Command saturator : saturators) {
            saturator.observe();
        }

        try {
            Thread.sleep(100);
        } catch (InterruptedException ie) {
            fail(ie.getMessage());
        }

        rejected1.observe();
        rejected2.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }

        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertTrue(rejected1.isResponseThreadPoolRejected());
        assertTrue(rejected2.isResponseThreadPoolRejected());
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.SUCCESS.ordinal()] = 10;
        expected[HystrixEventType.THREAD_POOL_REJECTED.ordinal()] = 2;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 2;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
135807,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testFallbackFailure,"    @Test
    public void testFallbackFailure() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-J"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_FAILURE);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 1;
        expected[HystrixEventType.FALLBACK_FAILURE.ordinal()] = 1;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
135808,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testFallbackMissing,"    @Test
    public void testFallbackMissing() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-K"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_MISSING);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 1;
        expected[HystrixEventType.FALLBACK_MISSING.ordinal()] = 1;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
135809,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testFallbackRejection,"    @Test
    public void testFallbackRejection() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-L"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //fallback semaphore size is 5.  So let 5 commands saturate that semaphore, then
        //let 2 more commands go to fallback.  they should get rejected by the fallback-semaphore

        List<Command> fallbackSaturators = new ArrayList<Command>();
        for (int i = 0; i < 5; i++) {
            fallbackSaturators.add(Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_SUCCESS, 400));
        }

        Command rejection1 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_SUCCESS, 0);
        Command rejection2 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_SUCCESS, 0);

        for (Command saturator: fallbackSaturators) {
            saturator.observe();
        }

        try {
            Thread.sleep(70);
        } catch (InterruptedException ex) {
            fail(ex.getMessage());
        }

        rejection1.observe();
        rejection2.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 7;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 5;
        expected[HystrixEventType.FALLBACK_REJECTION.ordinal()] = 2;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 2;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
135810,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.call,"    @Test
    public void testCancelled() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-M"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command toCancel = Command.from(groupKey, key, HystrixEventType.SUCCESS, 500);

        System.out.println(System.currentTimeMillis() + "" : "" + Thread.currentThread().getName() + "" : about to observe and subscribe"");
        Subscription s = toCancel.observe().
                doOnUnsubscribe(new Action0() {
                    @Override
                    public void call() {
                        System.out.println(System.currentTimeMillis() + "" : "" + Thread.currentThread().getName() + "" : UnSubscribe from command.observe()"");
                    }
",non-flaky,5
69,apache_samza,TestContainerAllocatorWithHostAffinity.testExpiredRequestAllocationOnAnyHost,"@Test
public void testExpiredRequestAllocationOnAnyHost() throws Exception {
    MockClusterResourceManager spyManager = spy(new MockClusterResourceManager(callback, state));
    ContainerManager spyContainerManager = spy(new ContainerManager(containerPlacementMetadataStore, state, spyManager, true, false, mock(LocalityManager.class), faultDomainManager, config));
    spyAllocator = Mockito.spy(new ContainerAllocator(spyManager, config, state, true, spyContainerManager));
    spyAllocator.requestResources(new HashMap<String, String>() {
        {
            put(""0"", ""hostname-0"");
            put(""1"", ""hostname-1"");
        }
    });
    spyAllocatorThread = new Thread(spyAllocator);
    spyAllocatorThread.start();
    Thread.sleep(1000);
    assertTrue(state.preferredHostRequests.get() == 2);
    assertTrue(state.expiredPreferredHostRequests.get() == 2);
    verify(spyContainerManager, times(1)).handleExpiredRequest(eq(""0""), eq(""hostname-0""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class));
    verify(spyContainerManager, times(1)).handleExpiredRequest(eq(""1""), eq(""hostname-1""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class));
    ArgumentCaptor<SamzaResourceRequest> cancelledRequestCaptor = ArgumentCaptor.forClass(SamzaResourceRequest.class);
    verify(spyManager, atLeast(2)).cancelResourceRequest(cancelledRequestCaptor.capture());
    assertTrue(cancelledRequestCaptor.getAllValues().stream().map(( resourceRequest) -> resourceRequest.getPreferredHost()).collect(Collectors.toSet()).size() > 2);
    assertTrue(state.matchedResourceRequests.get() == 0);
    assertTrue(state.anyHostRequests.get() > 2);
    spyAllocator.stop();
}",async wait,0
89274,apache_samza,TestSamzaRestService.testStartShouldStartTheMetricsReportersAndServer,"  @Test
  public void testStartShouldStartTheMetricsReportersAndServer() throws Exception {
    NetworkConnector connector = Mockito.mock(NetworkConnector.class);
    int testServerPort = 100;
    Mockito.doReturn(testServerPort).when(connector).getPort();
    Mockito.when(server.getConnectors()).thenReturn(new NetworkConnector[]{connector});
    Mockito.doNothing().when(server).start();
    samzaRestService.start();
    Mockito.verify(metricsReporter).start();
    Mockito.verify(metricsReporter).register(""SamzaRest"", metricsRegistry);
    Mockito.verify(server).start();
  }
",non-flaky,5
89275,apache_samza,TestSamzaRestService.testStopShouldStopTheMetricsReportersAndStopTheServer,"  @Test
  public void testStopShouldStopTheMetricsReportersAndStopTheServer() throws Exception {
    samzaRestService.stop();
    Mockito.verify(metricsReporter).stop();
    Mockito.verify(server).stop();
  }
",non-flaky,5
89276,apache_samza,TestYarnRestJobStatusProvider.testGetJobStatuses,"  @Test
  public void testGetJobStatuses() throws IOException, InterruptedException {
    doReturn(APPS_RESPONSE.getBytes()).when(provider).httpGet(anyString());

    List<Job> jobs = Lists.newArrayList(
        new Job(""job1"", ""1""),  // Job with multiple applications, 1 RUNNING
        new Job(""job2"", ""1""),  // Job with 1 KILLED application
        new Job(""job3"", ""1""),  // Job with 1 RUNNING application
        new Job(""job4"", ""1"")); // Job not found in YARN
    provider.getJobStatuses(jobs);

    Collections.sort(jobs, (o1, o2) -> o1.getJobName().compareTo(o2.getJobName()));

    assertEquals(4, jobs.size());
    verifyJobStatus(jobs.get(0), ""job1"", JobStatus.STARTED, ""RUNNING"");
    verifyJobStatus(jobs.get(1), ""job2"", JobStatus.STOPPED, ""KILLED"");
    verifyJobStatus(jobs.get(2), ""job3"", JobStatus.STARTED, ""RUNNING"");
    verifyJobStatus(jobs.get(3), ""job4"", JobStatus.UNKNOWN, null);
  }
",non-flaky,5
89277,apache_samza,TestJobsResource.testGetJobs,"  @Test
   public void testGetJobs()
      throws IOException {

    Response resp = target(""v1/jobs"").request().get();
    assertEquals(200, resp.getStatus());
    final Job[] jobs = objectMapper.readValue(resp.readEntity(String.class), Job[].class);
    assertEquals(4, jobs.length);

    assertEquals(MockJobProxy.JOB_INSTANCE_1_NAME, jobs[0].getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_1_ID, jobs[0].getJobId());
    assertStatusNotDefault(jobs[0]);
    assertEquals(MockJobProxy.JOB_INSTANCE_2_NAME, jobs[1].getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_2_ID, jobs[1].getJobId());
    assertStatusNotDefault(jobs[1]);
    assertEquals(MockJobProxy.JOB_INSTANCE_3_NAME, jobs[2].getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_3_ID, jobs[2].getJobId());
    assertStatusNotDefault(jobs[2]);
    assertEquals(MockJobProxy.JOB_INSTANCE_4_NAME, jobs[3].getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_4_ID, jobs[3].getJobId());
    assertStatusNotDefault(jobs[3]);
    resp.close();
  }
",non-flaky,5
89278,apache_samza,TestJobsResource.testPostJobs,"  @Test
   public void testPostJobs()
      throws IOException {
    Response resp = target(""v1/jobs"").request().post(Entity.text(""""));
    assertEquals(405, resp.getStatus());
    resp.close();
  }
",non-flaky,5
89279,apache_samza,TestJobsResource.testPutJobs,"  @Test
  public void testPutJobs()
      throws IOException {
    Response resp = target(""v1/jobs"").request().put(Entity.text(""""));
    assertEquals(405, resp.getStatus());
    resp.close();
  }
",non-flaky,5
89280,apache_samza,TestJobsResource.testGetJob,"  @Test
  public void testGetJob()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID)).request().get();
    assertEquals(200, resp.getStatus());
    final Job job2 = objectMapper.readValue(resp.readEntity(String.class), Job.class);

    assertEquals(MockJobProxy.JOB_INSTANCE_2_NAME, job2.getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_2_ID, job2.getJobId());
    assertStatusNotDefault(job2);
    resp.close();
  }
",non-flaky,5
89281,apache_samza,TestJobsResource.testPostJob,"  @Test
  public void testPostJob()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID)).request().post(
        Entity.text(""""));
    assertEquals(405, resp.getStatus());
    resp.close();
  }
",non-flaky,5
89282,apache_samza,TestJobsResource.testGetJobNameNotFound,"  @Test
  public void testGetJobNameNotFound()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", ""BadJobName"", MockJobProxy.JOB_INSTANCE_2_ID)).request().get();
    assertEquals(404, resp.getStatus());

    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message""), errorMessage.get(""message"").contains(""does not exist""));
    resp.close();
  }
",non-flaky,5
89283,apache_samza,TestJobsResource.testGetJobIdNotFound,"  @Test
  public void testGetJobIdNotFound()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, ""BadJobId"")).request().get();
    assertEquals(404, resp.getStatus());

    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message""), errorMessage.get(""message"").contains(""does not exist""));
    resp.close();
  }
",non-flaky,5
89284,apache_samza,TestJobsResource.testGetJobNameWithoutId,"  @Test
  public void testGetJobNameWithoutId()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s"", MockJobProxy.JOB_INSTANCE_2_NAME)).request().get();
    assertEquals(404, resp.getStatus());
    resp.close();
  }
",non-flaky,5
89285,apache_samza,TestJobsResource.testStartJob,"  @Test
  public void testStartJob()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID))
        .queryParam(""status"", ""started"").request().put(Entity.form(new Form()));
    assertEquals(202, resp.getStatus());

    final Job job2 = objectMapper.readValue(resp.readEntity(String.class), Job.class);
    assertEquals(MockJobProxy.JOB_INSTANCE_2_NAME, job2.getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_2_ID, job2.getJobId());
    assertStatusNotDefault(job2);
    resp.close();
  }
",non-flaky,5
89286,apache_samza,TestJobsResource.testStopJob,"  @Test
  public void testStopJob()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID))
        .queryParam(""status"", ""stopped"").request().put(Entity.form(new Form()));
    assertEquals(202, resp.getStatus());

    final Job job2 = objectMapper.readValue(resp.readEntity(String.class), Job.class);
    assertEquals(MockJobProxy.JOB_INSTANCE_2_NAME, job2.getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_2_ID, job2.getJobId());
    assertStatusNotDefault(job2);
    resp.close();
  }
",non-flaky,5
89287,apache_samza,TestJobsResource.testPutBadJobStatus,"  @Test
  public void testPutBadJobStatus()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID))
        .queryParam(""status"", ""BADSTATUS"").request().put(Entity.form(new Form()));
    assertEquals(400, resp.getStatus());

    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message"").contains(""BADSTATUS""));
    resp.close();
  }
",non-flaky,5
89288,apache_samza,TestJobsResource.testPutMissingStatus,"  @Test
  public void testPutMissingStatus()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID)).request()
        .put(Entity.form(new Form()));
    assertEquals(400, resp.getStatus());

    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message"").contains(""status""));
    resp.close();
  }
",non-flaky,5
89289,apache_samza,TestTasksResource.testGetTasks,"  @Test
  public void testGetTasks() throws IOException {
    String requestUrl = String.format(""v1/jobs/%s/%s/tasks"", ""testJobName"", ""testJobId"");
    Response response = target(requestUrl).request().get();
    assertEquals(200, response.getStatus());
    Task[] tasks = objectMapper.readValue(response.readEntity(String.class), Task[].class);
    assertEquals(2, tasks.length);

    assertEquals(MockTaskProxy.TASK_1_PREFERRED_HOST, tasks[0].getPreferredHost());
    assertEquals(MockTaskProxy.TASK_1_CONTAINER_ID, tasks[0].getContainerId());
    assertEquals(MockTaskProxy.TASK_1_NAME, tasks[0].getTaskName());
    assertEquals(MockTaskProxy.PARTITIONS, tasks[0].getPartitions());

    assertEquals(MockTaskProxy.TASK_2_PREFERRED_HOST, tasks[1].getPreferredHost());
    assertEquals(MockTaskProxy.TASK_2_CONTAINER_ID, tasks[1].getContainerId());
    assertEquals(MockTaskProxy.TASK_2_NAME, tasks[1].getTaskName());
    assertEquals(MockTaskProxy.PARTITIONS, tasks[1].getPartitions());
  }
",non-flaky,5
89290,apache_samza,TestTasksResource.testGetTasksWithInvalidJobName,"  @Test
  public void testGetTasksWithInvalidJobName() throws IOException {
    String requestUrl = String.format(""v1/jobs/%s/%s/tasks"", ""BadJobName"", MockJobProxy.JOB_INSTANCE_4_ID);
    Response resp = target(requestUrl).request().get();
    assertEquals(400, resp.getStatus());
    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message""), errorMessage.get(""message"").contains(""Invalid arguments for getTasks. ""));
    resp.close();
  }
",non-flaky,5
89291,apache_samza,TestTasksResource.testGetTasksWithInvalidJobId,"  @Test
  public void testGetTasksWithInvalidJobId() throws IOException {
    String requestUrl = String.format(""v1/jobs/%s/%s/tasks"", MockJobProxy.JOB_INSTANCE_1_NAME, ""BadJobId"");
    Response resp = target(requestUrl).request().get();
    assertEquals(400, resp.getStatus());
    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message""), errorMessage.get(""message"").contains(""Invalid arguments for getTasks. ""));
    resp.close();
  }
",non-flaky,5
89292,apache_samza,TestLocalStoreMonitor.shouldDeleteLocalTaskStoreWhenItHasNoOffsetFile,"  @Test
  public void shouldDeleteLocalTaskStoreWhenItHasNoOffsetFile() throws Exception {
    localStoreMonitor.monitor();
    assertTrue(""Task store directory should not exist."", !taskStoreDir.exists());
    assertEquals(taskStoreSize, localStoreMonitorMetrics.diskSpaceFreedInBytes.getCount());
    assertEquals(1, localStoreMonitorMetrics.noOfDeletedTaskPartitionStores.getCount());
  }
",non-flaky,5
89293,apache_samza,TestLocalStoreMonitor.shouldDeleteLocalStoreWhenLastModifiedTimeOfOffsetFileIsGreaterThanOffsetTTL,"  @Test
  public void shouldDeleteLocalStoreWhenLastModifiedTimeOfOffsetFileIsGreaterThanOffsetTTL() throws Exception {
    File offsetFile = createOffsetFile(taskStoreDir);
    offsetFile.setLastModified(0);
    localStoreMonitor.monitor();
    assertTrue(""Offset file should not exist."", !offsetFile.exists());
    assertEquals(0, localStoreMonitorMetrics.diskSpaceFreedInBytes.getCount());
  }
",non-flaky,5
89294,apache_samza,TestLocalStoreMonitor.shouldDeleteInActiveLocalStoresOfTheJob,"  @Test
  public void shouldDeleteInActiveLocalStoresOfTheJob() throws Exception {
    File inActiveStoreDir = new File(jobDir, ""inActiveStore"");
    FileUtils.forceMkdir(inActiveStoreDir);
    File inActiveTaskDir = new File(inActiveStoreDir, ""test-task"");
    FileUtils.forceMkdir(inActiveTaskDir);
    long inActiveTaskDirSize = inActiveTaskDir.getTotalSpace();
    localStoreMonitor.monitor();
    assertTrue(""Inactive task store directory should not exist."", !inActiveTaskDir.exists());
    assertEquals(taskStoreSize + inActiveTaskDirSize, localStoreMonitorMetrics.diskSpaceFreedInBytes.getCount());
    assertEquals(2, localStoreMonitorMetrics.noOfDeletedTaskPartitionStores.getCount());
    FileUtils.deleteDirectory(inActiveStoreDir);
  }
",non-flaky,5
89295,apache_samza,TestLocalStoreMonitor.shouldDoNothingWhenLastModifiedTimeOfOffsetFileIsLessThanOffsetTTL,"  @Test
  public void shouldDoNothingWhenLastModifiedTimeOfOffsetFileIsLessThanOffsetTTL() throws Exception {
    File offsetFile = createOffsetFile(taskStoreDir);
    localStoreMonitor.monitor();
    assertTrue(""Offset file should exist."", offsetFile.exists());
    assertEquals(0, localStoreMonitorMetrics.diskSpaceFreedInBytes.getCount());
  }
",non-flaky,5
89296,apache_samza,TestLocalStoreMonitor.shouldDoNothingWhenTheJobIsRunning,"  @Test
  public void shouldDoNothingWhenTheJobIsRunning() throws Exception {
    Mockito.when(jobsClientMock.getJobStatus(Mockito.any())).thenReturn(JobStatus.STARTED);
    File offsetFile = createOffsetFile(taskStoreDir);
    localStoreMonitor.monitor();
    assertTrue(""Offset file should exist."", offsetFile.exists());
    assertEquals(0, localStoreMonitorMetrics.diskSpaceFreedInBytes.getCount());
  }
",non-flaky,5
89297,apache_samza,TestLocalStoreMonitor.shouldDeleteTaskStoreWhenTaskPreferredStoreIsNotLocalHost,"  @Test
  public void shouldDeleteTaskStoreWhenTaskPreferredStoreIsNotLocalHost() throws Exception {
    Task task = new Task(""notLocalHost"", ""test-task"", ""0"", new ArrayList<>(), ImmutableList.of(""test-store""));
    Mockito.when(jobsClientMock.getTasks(Mockito.any())).thenReturn(ImmutableList.of(task));
    localStoreMonitor.monitor();
    assertTrue(""Task store directory should not exist."", !taskStoreDir.exists());
    assertEquals(taskStoreSize, localStoreMonitorMetrics.diskSpaceFreedInBytes.getCount());
    assertEquals(1, localStoreMonitorMetrics.noOfDeletedTaskPartitionStores.getCount());
  }
",non-flaky,5
89298,apache_samza,TestLocalStoreMonitor.shouldContinueLocalStoreCleanUpAfterFailureToCleanUpStoreOfAJob,"  @Test
  public void shouldContinueLocalStoreCleanUpAfterFailureToCleanUpStoreOfAJob() throws Exception {
    File testFailingJobDir = new File(localStoreDir, ""test-jobName-jobId-1"");

    File testFailingTaskStoreDir = new File(new File(testFailingJobDir, ""test-store""), ""test-task"");

    FileUtils.forceMkdir(testFailingTaskStoreDir);

    // For job: test-jobName-jobId-1, throw up in getTasks call and
    // expect the cleanup to succeed for other job: test-jobName-jobId.
    Mockito.doThrow(new RuntimeException(""Dummy exception message.""))
        .when(jobsClientMock)
        .getTasks(new JobInstance(""test-jobName"", ""jobId-1""));

    Task task = new Task(""notLocalHost"", ""test-task"", ""0"", new ArrayList<>(), ImmutableList.of(""test-store""));

    Mockito.when(jobsClientMock.getTasks(new JobInstance(""test-jobName"", ""jobId""))).thenReturn(ImmutableList.of(task));

    Map<String, String> configMap = new HashMap<>(config);
    configMap.put(LocalStoreMonitorConfig.CONFIG_IGNORE_FAILURES, ""true"");

    LocalStoreMonitor localStoreMonitor =
        new LocalStoreMonitor(new LocalStoreMonitorConfig(new MapConfig(configMap)), localStoreMonitorMetrics,
            jobsClientMock);

    localStoreMonitor.monitor();

    // Non failing job directory should be cleaned up.
    assertTrue(""Task store directory should not exist."", !taskStoreDir.exists());
    FileUtils.deleteDirectory(testFailingJobDir);
  }
",non-flaky,5
89299,apache_samza,TestMonitorService.testMonitorsShouldBeInstantiatedProperly,"  @Test
  public void testMonitorsShouldBeInstantiatedProperly() {
    // Test that a monitor should be instantiated properly by invoking
    // the appropriate factory method.
    Map<String, String> configMap = ImmutableMap.of(CONFIG_MONITOR_FACTORY_CLASS,
                                                    DummyMonitorFactory.class.getCanonicalName());
    Monitor monitor = null;
    try {
      monitor = MonitorLoader.instantiateMonitor(""testMonitor"", new MonitorConfig(new MapConfig(configMap)),
          METRICS_REGISTRY);
    } catch (InstantiationException e) {
      fail();
    }
    assertNotNull(monitor);
    // Object should implement the monitor().
    try {
      monitor.monitor();
    } catch (Exception e) {
      fail();
    }
  }
",non-flaky,5
89300,apache_samza,TestMonitorService.testShouldGroupRelevantMonitorConfigTogether,"  @Test
  public void testShouldGroupRelevantMonitorConfigTogether() {
    // Test that Monitor Loader groups relevant config together.
    Map<String, String> firstMonitorConfig = ImmutableMap.of(""monitor.monitor1.factory.class"",
                                                             ""org.apache.samza.monitor.DummyMonitor"",
                                                             ""monitor.monitor1.scheduling.interval.ms"",
                                                             ""100"");
    Map<String, String> secondMonitorConfig = ImmutableMap.of(""monitor.monitor2.factory.class"",
                                                              ""org.apache.samza.monitor.DummyMonitor"",
                                                              ""monitor.monitor2.scheduling.interval.ms"",
                                                              ""200"");
    MapConfig mapConfig = new MapConfig(ImmutableList.of(firstMonitorConfig, secondMonitorConfig));
    MonitorConfig expectedFirstConfig = new MonitorConfig(new MapConfig(firstMonitorConfig).subset(""monitor.monitor1.""));
    MonitorConfig expectedSecondConfig = new MonitorConfig(new MapConfig(secondMonitorConfig).subset(""monitor.monitor2.""));
    Map<String, MonitorConfig> expected = ImmutableMap.of(""monitor1"", expectedFirstConfig, ""monitor2"", expectedSecondConfig);
    assertEquals(expected, MonitorConfig.getMonitorConfigs(mapConfig));
  }
",non-flaky,5
89301,apache_samza,TestMonitorService.testMonitorExceptionIsolation,"  @Test
  public void testMonitorExceptionIsolation() {
    // Test that an exception from a monitor doesn't bubble up out of the scheduler.
    Map<String, String> configMap =
        ImmutableMap.of(String.format(""monitor.name.%s"", CONFIG_MONITOR_FACTORY_CLASS),
                        ExceptionThrowingMonitorFactory.class.getCanonicalName());
    SamzaRestConfig config = new SamzaRestConfig(new MapConfig(configMap));
    SamzaMonitorService monitorService = new SamzaMonitorService(config,
                                                                 METRICS_REGISTRY);

    // This will throw if the exception isn't caught within the provider.
    monitorService.start();
    monitorService.stop();
  }
",non-flaky,5
89302,apache_samza,TestMonitorService.createSchedulerAndScheduleMonitor,"  @Test
  public void testShouldNotFailWhenTheMonitorFactoryClassIsNotDefined()
      throws Exception {
    // Test that when MonitorFactoryClass is not defined in the config, monitor service
    // should not fail.
    Map<String, String> configMap = ImmutableMap.of(""monitor.monitor1.config.key1"", ""configValue1"",
                                                    ""monitor.monitor1.config.key2"", ""configValue2"",
                                                    String.format(""monitor.MOCK_MONITOR.%s"", CONFIG_MONITOR_FACTORY_CLASS),
                                                    MockMonitorFactory.class.getCanonicalName());

    SamzaRestConfig config = new SamzaRestConfig(new MapConfig(configMap));

    class SamzaMonitorServiceTest extends SamzaMonitorService {
      MetricsRegistry metricsRegistry;
      public SamzaMonitorServiceTest(SamzaRestConfig config, MetricsRegistry metricsRegistry) {
        super(config, metricsRegistry);
        this.metricsRegistry = metricsRegistry;
      }

      @Override
      public void createSchedulerAndScheduleMonitor(String monitorName, MonitorConfig monitorConfig, long schedulingIntervalInMs) {
        try {
          // immediately run monitor, without scheduling
          instantiateMonitor(monitorName, monitorConfig, metricsRegistry).monitor();
        } catch (Exception e) {
          fail();
        }
      }
",non-flaky,5
89303,apache_samza,TestMonitorService.testShouldFailWhenTheMonitorFactoryClassIsInvalid,"  @Test(expected = SamzaException.class)
  public void testShouldFailWhenTheMonitorFactoryClassIsInvalid() {
    // Test that when MonitorFactoryClass is defined in the config and is invalid,
    // monitor service should fail. Should throw back SamzaException.
    Map<String, String> configMap = ImmutableMap.of(String.format(""monitor.name.%s"", CONFIG_MONITOR_FACTORY_CLASS),
                                                    ""RandomClassName"");
    SamzaRestConfig config = new SamzaRestConfig(new MapConfig(configMap));
    SamzaMonitorService monitorService = new SamzaMonitorService(config,
                                                                 METRICS_REGISTRY);
    monitorService.start();
  }
",non-flaky,5
89304,apache_samza,TestMonitorService.monitor,"  @Test
  public void testScheduledExecutorSchedulingProvider() {
    // Test that the monitor is scheduled by the ScheduledExecutorSchedulingProvider
    ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1);

    // notifyingMonitor.monitor() should be called repeatedly.
    final CountDownLatch wasCalledLatch = new CountDownLatch(3);

    final Monitor notifyingMonitor = new Monitor() {
      @Override
      public void monitor() {
        wasCalledLatch.countDown();
      }
",non-flaky,5
89305,apache_samza,TestKafkaSystemConsumerMetrics.testKafkaSystemConsumerMetrics,"  @Test
  public void testKafkaSystemConsumerMetrics() {
    String systemName = ""system"";
    TopicPartition tp1 = new TopicPartition(""topic1"", 1);
    TopicPartition tp2 = new TopicPartition(""topic2"", 2);
    String clientName = ""clientName"";

    // record expected values for further comparison
    Map<String, String> expectedValues = new HashMap<>();

    ReadableMetricsRegistry registry = new MetricsRegistryMap();
    KafkaSystemConsumerMetrics metrics = new KafkaSystemConsumerMetrics(systemName, registry);

    // initialize the metrics for the partitions
    metrics.registerTopicPartition(tp1);
    metrics.registerTopicPartition(tp2);

    // initialize the metrics for the host:port
    metrics.registerClientProxy(clientName);

    metrics.setOffsets(tp1, 1001);
    metrics.setOffsets(tp2, 1002);
    expectedValues.put(metrics.offsets().get(tp1).getName(), ""1001"");
    expectedValues.put(metrics.offsets().get(tp2).getName(), ""1002"");

    metrics.incBytesReads(tp1, 10);
    metrics.incBytesReads(tp1, 5); // total 15
    expectedValues.put(metrics.bytesRead().get(tp1).getName(), ""15"");

    metrics.incReads(tp1);
    metrics.incReads(tp1); // total 2
    expectedValues.put(metrics.reads().get(tp1).getName(), ""2"");

    metrics.setHighWatermarkValue(tp2, 1000);
    metrics.setHighWatermarkValue(tp2, 1001); // final value 1001
    expectedValues.put(metrics.highWatermark().get(tp2).getName(), ""1001"");

    metrics.setLagValue(tp1, 200);
    metrics.setLagValue(tp1, 201); // final value 201
    expectedValues.put(metrics.lag().get(tp1).getName(), ""201"");

    metrics.incClientBytesReads(clientName, 100); // broker-bytes-read
    metrics.incClientBytesReads(clientName, 110); // total 210
    expectedValues.put(metrics.clientBytesRead().get(clientName).getName(), ""210"");

    metrics.incClientReads(clientName); // messages-read
    metrics.incClientReads(clientName); // total 2
    expectedValues.put(metrics.clientReads().get(clientName).getName(), ""2"");

    metrics.setNumTopicPartitions(clientName, 2); // ""topic-partitions""
    metrics.setNumTopicPartitions(clientName, 3); // final value 3
    expectedValues.put(metrics.topicPartitions().get(clientName).getName(), ""3"");


    String groupName = metrics.group();
    Assert.assertEquals(groupName, KafkaSystemConsumerMetrics.class.getName());
    Assert.assertEquals(metrics.systemName(), systemName);

    Map<String, Metric> metricMap = registry.getGroup(groupName);
    validate(metricMap, expectedValues);
  }
",non-flaky,5
89306,apache_samza,TestKafkaSystemAdminWithMock.testGetSystemStreamMetaDataWithValidTopic,"  @Test
  public void testGetSystemStreamMetaDataWithValidTopic() {
    System.out.println(""STARTING"");
    Map<String, SystemStreamMetadata> metadataMap =
        kafkaSystemAdmin.getSystemStreamMetadata(ImmutableSet.of(VALID_TOPIC));

    // verify metadata size
    assertEquals(""metadata should return for 1 topic"", metadataMap.size(), 1);
    System.out.println(""STARTING1"");
    // verify the metadata streamName
    assertEquals(""the stream name should be "" + VALID_TOPIC, metadataMap.get(VALID_TOPIC).getStreamName(), VALID_TOPIC);
    System.out.println(""STARTING2"");
    // verify the offset for each partition
    Map<Partition, SystemStreamMetadata.SystemStreamPartitionMetadata> systemStreamPartitionMetadata =
        metadataMap.get(VALID_TOPIC).getSystemStreamPartitionMetadata();
    assertEquals(""there are 2 partitions"", systemStreamPartitionMetadata.size(), 2);
    System.out.println(""STARTING3"");
    SystemStreamMetadata.SystemStreamPartitionMetadata partition0Metadata =
        systemStreamPartitionMetadata.get(new Partition(0));
    assertEquals(""oldest offset for partition 0"", partition0Metadata.getOldestOffset(),
        KAFKA_BEGINNING_OFFSET_FOR_PARTITION0.toString());
    assertEquals(""upcoming offset for partition 0"", partition0Metadata.getUpcomingOffset(),
        KAFKA_END_OFFSET_FOR_PARTITION0.toString());
    assertEquals(""newest offset for partition 0"", partition0Metadata.getNewestOffset(),
        Long.toString(KAFKA_END_OFFSET_FOR_PARTITION0 - 1));
    System.out.println(""STARTING4"");
    SystemStreamMetadata.SystemStreamPartitionMetadata partition1Metadata =
        systemStreamPartitionMetadata.get(new Partition(1));
    assertEquals(""oldest offset for partition 1"", partition1Metadata.getOldestOffset(),
        KAFKA_BEGINNING_OFFSET_FOR_PARTITION1.toString());
    assertEquals(""upcoming offset for partition 1"", partition1Metadata.getUpcomingOffset(),
        KAFKA_END_OFFSET_FOR_PARTITION1.toString());
    assertEquals(""newest offset for partition 1"", partition1Metadata.getNewestOffset(),
        Long.toString(KAFKA_END_OFFSET_FOR_PARTITION1 - 1));
  }
",non-flaky,5
89307,apache_samza,TestKafkaSystemAdminWithMock.testGetSystemStreamMetaDataWithInvalidTopic,"  @Test
  public void testGetSystemStreamMetaDataWithInvalidTopic() {
    Map<String, SystemStreamMetadata> metadataMap =
        kafkaSystemAdmin.getSystemStreamMetadata(ImmutableSet.of(INVALID_TOPIC));
    assertEquals(""empty metadata for invalid topic"", metadataMap.size(), 0);
  }
",non-flaky,5
89308,apache_samza,TestKafkaSystemAdminWithMock.testGetSystemStreamMetaDataWithNoTopic,"  @Test
  public void testGetSystemStreamMetaDataWithNoTopic() {
    Map<String, SystemStreamMetadata> metadataMap = kafkaSystemAdmin.getSystemStreamMetadata(Collections.emptySet());
    assertEquals(""empty metadata for no topic"", metadataMap.size(), 0);
  }
",non-flaky,5
89309,apache_samza,TestKafkaSystemAdminWithMock.testGetSystemStreamMetaDataForTopicWithNoMessage,"  @Test
  public void testGetSystemStreamMetaDataForTopicWithNoMessage() {
    // The topic with no messages will have beginningOffset = 0 and endOffset = 0
    when(mockKafkaConsumer.beginningOffsets(ImmutableList.of(testTopicPartition0, testTopicPartition1))).thenReturn(
        ImmutableMap.of(testTopicPartition0, 0L, testTopicPartition1, 0L));
    when(mockKafkaConsumer.endOffsets(ImmutableList.of(testTopicPartition0, testTopicPartition1))).thenReturn(
        ImmutableMap.of(testTopicPartition0, 0L, testTopicPartition1, 0L));

    Map<String, SystemStreamMetadata> metadataMap =
        kafkaSystemAdmin.getSystemStreamMetadata(ImmutableSet.of(VALID_TOPIC));
    assertEquals(""metadata should return for 1 topic"", metadataMap.size(), 1);

    // verify the metadata streamName
    assertEquals(""the stream name should be "" + VALID_TOPIC, metadataMap.get(VALID_TOPIC).getStreamName(), VALID_TOPIC);

    // verify the offset for each partition
    Map<Partition, SystemStreamMetadata.SystemStreamPartitionMetadata> systemStreamPartitionMetadata =
        metadataMap.get(VALID_TOPIC).getSystemStreamPartitionMetadata();
    assertEquals(""there are 2 partitions"", systemStreamPartitionMetadata.size(), 2);

    SystemStreamMetadata.SystemStreamPartitionMetadata partition0Metadata =
        systemStreamPartitionMetadata.get(new Partition(0));
    assertEquals(""oldest offset for partition 0"", partition0Metadata.getOldestOffset(), ""0"");
    assertEquals(""upcoming offset for partition 0"", partition0Metadata.getUpcomingOffset(), ""0"");
    assertEquals(""newest offset is not set due to abnormal upcoming offset"", partition0Metadata.getNewestOffset(),
        null);

    SystemStreamMetadata.SystemStreamPartitionMetadata partition1Metadata =
        systemStreamPartitionMetadata.get(new Partition(1));
    assertEquals(""oldest offset for partition 1"", partition1Metadata.getOldestOffset(), ""0"");
    assertEquals(""upcoming offset for partition 1"", partition1Metadata.getUpcomingOffset(), ""0"");
    assertEquals(""newest offset is not set due to abnormal upcoming offset"", partition1Metadata.getNewestOffset(),
        null);
  }
",non-flaky,5
89310,apache_samza,TestKafkaSystemAdminWithMock.testGetSSPMetadata,"  @Test
  public void testGetSSPMetadata() {
    SystemStreamPartition ssp = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    SystemStreamPartition otherSSP = new SystemStreamPartition(TEST_SYSTEM, ""otherTopic"", new Partition(1));
    TopicPartition topicPartition = new TopicPartition(VALID_TOPIC, 0);
    TopicPartition otherTopicPartition = new TopicPartition(""otherTopic"", 1);
    when(mockKafkaConsumer.beginningOffsets(ImmutableList.of(topicPartition, otherTopicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 1L, otherTopicPartition, 2L));
    when(mockKafkaConsumer.endOffsets(ImmutableList.of(topicPartition, otherTopicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 11L, otherTopicPartition, 12L));
    Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> expected =
        ImmutableMap.of(ssp, new SystemStreamMetadata.SystemStreamPartitionMetadata(""1"", ""10"", ""11""), otherSSP,
            new SystemStreamMetadata.SystemStreamPartitionMetadata(""2"", ""11"", ""12""));
    assertEquals(kafkaSystemAdmin.getSSPMetadata(ImmutableSet.of(ssp, otherSSP)), expected);
  }
",non-flaky,5
89311,apache_samza,TestKafkaSystemAdminWithMock.testGetSSPMetadataEmptyPartition,"  @Test
  public void testGetSSPMetadataEmptyPartition() {
    SystemStreamPartition ssp = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    SystemStreamPartition otherSSP = new SystemStreamPartition(TEST_SYSTEM, ""otherTopic"", new Partition(1));
    TopicPartition topicPartition = new TopicPartition(VALID_TOPIC, 0);
    TopicPartition otherTopicPartition = new TopicPartition(""otherTopic"", 1);
    when(mockKafkaConsumer.beginningOffsets(ImmutableList.of(topicPartition, otherTopicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 1L));
    when(mockKafkaConsumer.endOffsets(ImmutableList.of(topicPartition, otherTopicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 11L));

    Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> expected =
        ImmutableMap.of(ssp, new SystemStreamMetadata.SystemStreamPartitionMetadata(""1"", ""10"", ""11""), otherSSP,
            new SystemStreamMetadata.SystemStreamPartitionMetadata(null, null, null));
    assertEquals(expected, kafkaSystemAdmin.getSSPMetadata(ImmutableSet.of(ssp, otherSSP)));
  }
",non-flaky,5
89312,apache_samza,TestKafkaSystemAdminWithMock.testGetSSPMetadataEmptyUpcomingOffset,"  @Test
  public void testGetSSPMetadataEmptyUpcomingOffset() {
    SystemStreamPartition ssp = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    TopicPartition topicPartition = new TopicPartition(VALID_TOPIC, 0);
    when(mockKafkaConsumer.beginningOffsets(ImmutableList.of(topicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 0L));
    when(mockKafkaConsumer.endOffsets(ImmutableList.of(topicPartition))).thenReturn(ImmutableMap.of());
    Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> expected =
        ImmutableMap.of(ssp, new SystemStreamMetadata.SystemStreamPartitionMetadata(""0"", null, null));
    assertEquals(kafkaSystemAdmin.getSSPMetadata(ImmutableSet.of(ssp)), expected);
  }
",non-flaky,5
89313,apache_samza,TestKafkaSystemAdminWithMock.testGetSSPMetadataZeroUpcomingOffset,"  @Test
  public void testGetSSPMetadataZeroUpcomingOffset() {
    SystemStreamPartition ssp = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    TopicPartition topicPartition = new TopicPartition(VALID_TOPIC, 0);
    when(mockKafkaConsumer.beginningOffsets(ImmutableList.of(topicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, -1L));
    when(mockKafkaConsumer.endOffsets(ImmutableList.of(topicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 0L));
    Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> expected =
        ImmutableMap.of(ssp, new SystemStreamMetadata.SystemStreamPartitionMetadata(""0"", null, ""0""));
    assertEquals(kafkaSystemAdmin.getSSPMetadata(ImmutableSet.of(ssp)), expected);
  }
",non-flaky,5
89314,apache_samza,TestKafkaSystemAdminWithMock.testGetSystemStreamMetaDataWithRetry,"  @Test
  public void testGetSystemStreamMetaDataWithRetry() {
    final List<PartitionInfo> partitionInfosForTopic = ImmutableList.of(mockPartitionInfo0, mockPartitionInfo1);
    when(mockKafkaConsumer.partitionsFor(VALID_TOPIC)).thenThrow(new RuntimeException())
        .thenReturn(partitionInfosForTopic);

    Map<String, SystemStreamMetadata> metadataMap =
        kafkaSystemAdmin.getSystemStreamMetadata(ImmutableSet.of(VALID_TOPIC));
    assertEquals(""metadata should return for 1 topic"", metadataMap.size(), 1);

    // retried twice because the first fails and the second succeeds
    Mockito.verify(mockKafkaConsumer, Mockito.times(2)).partitionsFor(VALID_TOPIC);

    final List<TopicPartition> topicPartitions =
        Arrays.asList(new TopicPartition(mockPartitionInfo0.topic(), mockPartitionInfo0.partition()),
            new TopicPartition(mockPartitionInfo1.topic(), mockPartitionInfo1.partition()));
    // the following methods thereafter are only called once
    Mockito.verify(mockKafkaConsumer, Mockito.times(1)).beginningOffsets(topicPartitions);
    Mockito.verify(mockKafkaConsumer, Mockito.times(1)).endOffsets(topicPartitions);
  }
",non-flaky,5
89315,apache_samza,TestKafkaSystemAdminWithMock.testGetSystemStreamMetadataShouldTerminateAfterFiniteRetriesOnException,"  @Test(expected = SamzaException.class)
  public void testGetSystemStreamMetadataShouldTerminateAfterFiniteRetriesOnException() {
    when(mockKafkaConsumer.partitionsFor(VALID_TOPIC)).thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException());

    kafkaSystemAdmin.getSystemStreamMetadata(ImmutableSet.of(VALID_TOPIC));
  }
",non-flaky,5
89316,apache_samza,TestKafkaSystemAdminWithMock.testGetSystemStreamPartitionCountsShouldTerminateAfterFiniteRetriesOnException,"  @Test(expected = SamzaException.class)
  public void testGetSystemStreamPartitionCountsShouldTerminateAfterFiniteRetriesOnException() throws Exception {
    final Set<String> streamNames = ImmutableSet.of(VALID_TOPIC);
    final long cacheTTL = 100L;

    when(mockKafkaConsumer.partitionsFor(VALID_TOPIC)).thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException());

    kafkaSystemAdmin.getSystemStreamPartitionCounts(streamNames, cacheTTL);
  }
",non-flaky,5
89317,apache_samza,TestKafkaSystemAdminWithMock.testGetSSPMetadataWithRetry,"  @Test
  public void testGetSSPMetadataWithRetry() {
    SystemStreamPartition oneSSP = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    SystemStreamPartition otherSSP = new SystemStreamPartition(TEST_SYSTEM, ""otherTopic"", new Partition(1));
    ImmutableSet<SystemStreamPartition> ssps = ImmutableSet.of(oneSSP, otherSSP);
    List<TopicPartition> topicPartitions = ssps.stream()
        .map(ssp -> new TopicPartition(ssp.getStream(), ssp.getPartition().getPartitionId()))
        .collect(Collectors.toList());
    Map<TopicPartition, Long> testBeginningOffsets =
        ImmutableMap.of(testTopicPartition0, KAFKA_BEGINNING_OFFSET_FOR_PARTITION0, testTopicPartition1,
            KAFKA_BEGINNING_OFFSET_FOR_PARTITION1);

    when(mockKafkaConsumer.beginningOffsets(topicPartitions)).thenThrow(new RuntimeException())
        .thenReturn(testBeginningOffsets);
    Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> sspMetadata =
        kafkaSystemAdmin.getSSPMetadata(ssps, new ExponentialSleepStrategy(2,
            1, 1));

    assertEquals(""metadata should return for 2 topics"", sspMetadata.size(), 2);

    // retried twice because the first fails and the second succeeds
    Mockito.verify(mockKafkaConsumer, Mockito.times(2)).beginningOffsets(topicPartitions);
  }
",non-flaky,5
89318,apache_samza,TestKafkaSystemAdminWithMock.testGetSSPMetadataShouldTerminateAfterFiniteRetriesOnException,"  @Test(expected = SamzaException.class)
  public void testGetSSPMetadataShouldTerminateAfterFiniteRetriesOnException() throws Exception {
    SystemStreamPartition oneSSP = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    SystemStreamPartition otherSSP = new SystemStreamPartition(TEST_SYSTEM, ""otherTopic"", new Partition(1));

    ImmutableSet<SystemStreamPartition> ssps = ImmutableSet.of(oneSSP, otherSSP);
    List<TopicPartition> topicPartitions = ssps.stream()
        .map(ssp -> new TopicPartition(ssp.getStream(), ssp.getPartition().getPartitionId()))
        .collect(Collectors.toList());

    when(mockKafkaConsumer.beginningOffsets(topicPartitions)).thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException());

    kafkaSystemAdmin.getSSPMetadata(ssps, new ExponentialSleepStrategy(2,
        1, 1));
  }
",non-flaky,5
89319,apache_samza,TestKafkaSystemConsumer.testConfigValidations,"  @Test
  public void testConfigValidations() {

    final KafkaSystemConsumer consumer = createConsumer(FETCH_THRESHOLD_MSGS, FETCH_THRESHOLD_BYTES);

    consumer.start();
    // should be no failures
  }
",non-flaky,5
89320,apache_samza,TestKafkaSystemConsumer.testFetchThresholdShouldDivideEvenlyAmongPartitions,"  @Test
  public void testFetchThresholdShouldDivideEvenlyAmongPartitions() {
    final KafkaSystemConsumer consumer = createConsumer(FETCH_THRESHOLD_MSGS, FETCH_THRESHOLD_BYTES);
    final int partitionsNum = 50;
    for (int i = 0; i < partitionsNum; i++) {
      consumer.register(new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(i)), ""0"");
    }

    consumer.start();

    Assert.assertEquals(Long.valueOf(FETCH_THRESHOLD_MSGS) / partitionsNum, consumer.perPartitionFetchThreshold);
    Assert.assertEquals(Long.valueOf(FETCH_THRESHOLD_BYTES) / 2 / partitionsNum,
        consumer.perPartitionFetchThresholdBytes);

    consumer.stop();
  }
",non-flaky,5
89321,apache_samza,TestKafkaSystemConsumer.testConsumerRegisterOlderOffsetOfTheSamzaSSP,"  @Test
  public void testConsumerRegisterOlderOffsetOfTheSamzaSSP() {

    KafkaSystemConsumer consumer = createConsumer(FETCH_THRESHOLD_MSGS, FETCH_THRESHOLD_BYTES);

    SystemStreamPartition ssp0 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(0));
    SystemStreamPartition ssp1 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(1));
    SystemStreamPartition ssp2 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(2));

    consumer.register(ssp0, ""0"");
    consumer.register(ssp0, ""5"");
    consumer.register(ssp1, ""2"");
    consumer.register(ssp1, ""3"");
    consumer.register(ssp2, ""0"");

    assertEquals(""0"", consumer.topicPartitionsToOffset.get(KafkaSystemConsumer.toTopicPartition(ssp0)));
    assertEquals(""2"", consumer.topicPartitionsToOffset.get(KafkaSystemConsumer.toTopicPartition(ssp1)));
    assertEquals(""0"", consumer.topicPartitionsToOffset.get(KafkaSystemConsumer.toTopicPartition(ssp2)));
  }
",non-flaky,5
89322,apache_samza,TestKafkaSystemConsumer.testFetchThresholdBytes,"  @Test
  public void testFetchThresholdBytes() {

    SystemStreamPartition ssp0 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(0));
    SystemStreamPartition ssp1 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(1));
    int partitionsNum = 2;
    int ime0Size = Integer.valueOf(FETCH_THRESHOLD_MSGS) / partitionsNum; // fake size
    int ime1Size = Integer.valueOf(FETCH_THRESHOLD_MSGS) / partitionsNum - 1; // fake size
    int ime11Size = 20;
    ByteArraySerializer bytesSerde = new ByteArraySerializer();
    IncomingMessageEnvelope ime0 = new IncomingMessageEnvelope(ssp0, ""0"", bytesSerde.serialize("""", ""key0"".getBytes()),
        bytesSerde.serialize("""", ""value0"".getBytes()), ime0Size);
    IncomingMessageEnvelope ime1 = new IncomingMessageEnvelope(ssp1, ""0"", bytesSerde.serialize("""", ""key1"".getBytes()),
        bytesSerde.serialize("""", ""value1"".getBytes()), ime1Size);
    IncomingMessageEnvelope ime11 = new IncomingMessageEnvelope(ssp1, ""0"", bytesSerde.serialize("""", ""key11"".getBytes()),
        bytesSerde.serialize("""", ""value11"".getBytes()), ime11Size);
    KafkaSystemConsumer consumer = createConsumer(FETCH_THRESHOLD_MSGS, FETCH_THRESHOLD_BYTES);

    consumer.register(ssp0, ""0"");
    consumer.register(ssp1, ""0"");
    consumer.start();
    consumer.messageSink.addMessage(ssp0, ime0);
    // queue for ssp0 should be full now, because we added message of size FETCH_THRESHOLD_MSGS/partitionsNum
    Assert.assertFalse(consumer.messageSink.needsMoreMessages(ssp0));
    consumer.messageSink.addMessage(ssp1, ime1);
    // queue for ssp1 should be less then full now, because we added message of size (FETCH_THRESHOLD_MSGS/partitionsNum - 1)
    Assert.assertTrue(consumer.messageSink.needsMoreMessages(ssp1));
    consumer.messageSink.addMessage(ssp1, ime11);
    // queue for ssp1 should full now, because we added message of size 20 on top
    Assert.assertFalse(consumer.messageSink.needsMoreMessages(ssp1));

    Assert.assertEquals(1, consumer.getNumMessagesInQueue(ssp0));
    Assert.assertEquals(2, consumer.getNumMessagesInQueue(ssp1));
    Assert.assertEquals(ime0Size, consumer.getMessagesSizeInQueue(ssp0));
    Assert.assertEquals(ime1Size + ime11Size, consumer.getMessagesSizeInQueue(ssp1));

    consumer.stop();
  }
",non-flaky,5
89323,apache_samza,TestKafkaSystemConsumer.testFetchThresholdBytesDiabled,"  @Test
  public void testFetchThresholdBytesDiabled() {
    // Pass 0 as fetchThresholdByBytes, which disables checking for limit by size

    SystemStreamPartition ssp0 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(0));
    SystemStreamPartition ssp1 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(1));
    int partitionsNum = 2;
    int ime0Size = Integer.valueOf(FETCH_THRESHOLD_MSGS) / partitionsNum; // fake size, upto the limit
    int ime1Size = Integer.valueOf(FETCH_THRESHOLD_MSGS) / partitionsNum - 100; // fake size, below the limit
    int ime11Size = 20; // event with the second message still below the size limit
    ByteArraySerializer bytesSerde = new ByteArraySerializer();
    IncomingMessageEnvelope ime0 = new IncomingMessageEnvelope(ssp0, ""0"", bytesSerde.serialize("""", ""key0"".getBytes()),
        bytesSerde.serialize("""", ""value0"".getBytes()), ime0Size);
    IncomingMessageEnvelope ime1 = new IncomingMessageEnvelope(ssp1, ""0"", bytesSerde.serialize("""", ""key1"".getBytes()),
        bytesSerde.serialize("""", ""value1"".getBytes()), ime1Size);
    IncomingMessageEnvelope ime11 = new IncomingMessageEnvelope(ssp1, ""0"", bytesSerde.serialize("""", ""key11"".getBytes()),
        bytesSerde.serialize("""", ""value11"".getBytes()), ime11Size);

    // limit by number of messages 4/2 = 2 per partition
    // limit by number of bytes - disabled
    KafkaSystemConsumer consumer = createConsumer(""4"", ""0""); // should disable

    consumer.register(ssp0, ""0"");
    consumer.register(ssp1, ""0"");
    consumer.start();
    consumer.messageSink.addMessage(ssp0, ime0);
    // should be full by size, but not full by number of messages (1 of 2)
    Assert.assertTrue(consumer.messageSink.needsMoreMessages(ssp0));
    consumer.messageSink.addMessage(ssp1, ime1);
    // not full neither by size nor by messages
    Assert.assertTrue(consumer.messageSink.needsMoreMessages(ssp1));
    consumer.messageSink.addMessage(ssp1, ime11);
    // not full by size, but should be full by messages
    Assert.assertFalse(consumer.messageSink.needsMoreMessages(ssp1));

    Assert.assertEquals(1, consumer.getNumMessagesInQueue(ssp0));
    Assert.assertEquals(2, consumer.getNumMessagesInQueue(ssp1));
    Assert.assertEquals(ime0Size, consumer.getMessagesSizeInQueue(ssp0));
    Assert.assertEquals(ime1Size + ime11Size, consumer.getMessagesSizeInQueue(ssp1));

    consumer.stop();
  }
",non-flaky,5
89324,apache_samza,TestKafkaSystemConsumer.testStartConsumer,"  @Test
  public void testStartConsumer() {
    final Consumer consumer = Mockito.mock(Consumer.class);
    final KafkaConsumerProxyFactory kafkaConsumerProxyFactory = Mockito.mock(KafkaConsumerProxyFactory.class);

    final KafkaSystemConsumerMetrics kafkaSystemConsumerMetrics = new KafkaSystemConsumerMetrics(TEST_SYSTEM, new NoOpMetricsRegistry());
    final SystemStreamPartition testSystemStreamPartition1 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(0));
    final SystemStreamPartition testSystemStreamPartition2 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(1));
    final String testOffset = ""1"";
    final KafkaConsumerProxy kafkaConsumerProxy = Mockito.mock(KafkaConsumerProxy.class);

    Mockito.when(kafkaConsumerProxyFactory.create(Mockito.anyObject())).thenReturn(kafkaConsumerProxy);
    Mockito.doNothing().when(consumer).seek(new TopicPartition(TEST_STREAM, 0), 1);
    Mockito.doNothing().when(consumer).seek(new TopicPartition(TEST_STREAM, 1), 1);

    KafkaSystemConsumer kafkaSystemConsumer = new KafkaSystemConsumer(consumer, TEST_SYSTEM, new MapConfig(), TEST_CLIENT_ID, kafkaConsumerProxyFactory,
                                                                      kafkaSystemConsumerMetrics, new SystemClock());
    kafkaSystemConsumer.register(testSystemStreamPartition1, testOffset);
    kafkaSystemConsumer.register(testSystemStreamPartition2, testOffset);

    kafkaSystemConsumer.startConsumer();

    Mockito.verify(consumer).seek(new TopicPartition(TEST_STREAM, 0), 1);
    Mockito.verify(consumer).seek(new TopicPartition(TEST_STREAM, 1), 1);
    Mockito.verify(kafkaConsumerProxy).start();
    Mockito.verify(kafkaConsumerProxy).addTopicPartition(testSystemStreamPartition1, Long.valueOf(testOffset));
    Mockito.verify(kafkaConsumerProxy).addTopicPartition(testSystemStreamPartition2, Long.valueOf(testOffset));
  }
",non-flaky,5
89325,apache_samza,TestKafkaSystemAdminJava.testCreateStreamShouldCoordinatorStreamWithCorrectTopicProperties,"  @Test
  public void testCreateStreamShouldCoordinatorStreamWithCorrectTopicProperties() throws Exception {
    String coordinatorTopicName = String.format(""topic-name-%s"", RandomStringUtils.randomAlphabetic(5));
    StreamSpec coordinatorStreamSpec = KafkaStreamSpec.createCoordinatorStreamSpec(coordinatorTopicName, SYSTEM());

    boolean hasCreatedStream = systemAdmin().createStream(coordinatorStreamSpec);

    assertTrue(hasCreatedStream);

    Map<String, String> coordinatorTopicProperties = getTopicConfigFromKafkaBroker(coordinatorTopicName);

    assertEquals(""compact"", coordinatorTopicProperties.get(TopicConfig.CLEANUP_POLICY_CONFIG));
    assertEquals(""26214400"", coordinatorTopicProperties.get(TopicConfig.SEGMENT_BYTES_CONFIG));
    assertEquals(""86400000"", coordinatorTopicProperties.get(TopicConfig.DELETE_RETENTION_MS_CONFIG));
  }
",non-flaky,5
89326,apache_samza,TestKafkaSystemAdminJava.testGetOffsetsAfter,"  @Test
  public void testGetOffsetsAfter() {
    SystemStreamPartition ssp1 = new SystemStreamPartition(SYSTEM, TOPIC, new Partition(0));
    SystemStreamPartition ssp2 = new SystemStreamPartition(SYSTEM, TOPIC, new Partition(1));
    Map<SystemStreamPartition, String> offsets = new HashMap<>();
    offsets.put(ssp1, ""1"");
    offsets.put(ssp2, ""2"");

    offsets = systemAdmin().getOffsetsAfter(offsets);

    Assert.assertEquals(""2"", offsets.get(ssp1));
    Assert.assertEquals(""3"", offsets.get(ssp2));
  }
",non-flaky,5
89327,apache_samza,TestKafkaSystemAdminJava.testToKafkaSpecForCheckpointStreamShouldReturnTheCorrectStreamSpecByPreservingTheConfig,"  @Test
  public void testToKafkaSpecForCheckpointStreamShouldReturnTheCorrectStreamSpecByPreservingTheConfig() {
    String topicName = ""testStream"";
    String streamId = ""samza-internal-checkpoint-stream-id"";
    int partitionCount = 1;
    Map<String, String> map = new HashMap<>();
    map.put(""cleanup.policy"", ""compact"");
    map.put(""replication.factor"", ""3"");
    map.put(""segment.bytes"", ""536870912"");
    map.put(""delete.retention.ms"", ""86400000"");

    Config config = new MapConfig(map);

    StreamSpec spec = new StreamSpec(streamId, topicName, SYSTEM, partitionCount, config);
    KafkaSystemAdmin kafkaSystemAdmin = systemAdmin();
    KafkaStreamSpec kafkaStreamSpec = kafkaSystemAdmin.toKafkaSpec(spec);
    System.out.println(kafkaStreamSpec);
    assertEquals(streamId, kafkaStreamSpec.getId());
    assertEquals(topicName, kafkaStreamSpec.getPhysicalName());
    assertEquals(partitionCount, kafkaStreamSpec.getPartitionCount());
    assertEquals(3, kafkaStreamSpec.getReplicationFactor());
    assertEquals(""compact"", kafkaStreamSpec.getConfig().get(""cleanup.policy""));
    assertEquals(""536870912"", kafkaStreamSpec.getConfig().get(""segment.bytes""));
    assertEquals(""86400000"", kafkaStreamSpec.getConfig().get(""delete.retention.ms""));
  }
",non-flaky,5
89328,apache_samza,TestKafkaSystemAdminJava.testToKafkaSpec,"  @Test
  public void testToKafkaSpec() {
    String topicName = ""testStream"";

    int defaultPartitionCount = 2;
    int changeLogPartitionFactor = 5;
    Map<String, String> map = new HashMap<>();
    Config config = new MapConfig(map);
    StreamSpec spec = new StreamSpec(""id"", topicName, SYSTEM, defaultPartitionCount, config);

    KafkaSystemAdmin kafkaAdmin = systemAdmin();
    KafkaStreamSpec kafkaSpec = kafkaAdmin.toKafkaSpec(spec);

    Assert.assertEquals(""id"", kafkaSpec.getId());
    Assert.assertEquals(topicName, kafkaSpec.getPhysicalName());
    Assert.assertEquals(SYSTEM, kafkaSpec.getSystemName());
    Assert.assertEquals(defaultPartitionCount, kafkaSpec.getPartitionCount());

    // validate that conversion is using coordination metadata
    map.put(""job.coordinator.segment.bytes"", ""123"");
    map.put(""job.coordinator.cleanup.policy"", ""superCompact"");
    int coordReplicatonFactor = 4;
    map.put(org.apache.samza.config.KafkaConfig.JOB_COORDINATOR_REPLICATION_FACTOR(),
        String.valueOf(coordReplicatonFactor));

    KafkaSystemAdmin admin = Mockito.spy(createSystemAdmin(SYSTEM, map));
    spec = StreamSpec.createCoordinatorStreamSpec(topicName, SYSTEM);
    kafkaSpec = admin.toKafkaSpec(spec);
    Assert.assertEquals(coordReplicatonFactor, kafkaSpec.getReplicationFactor());
    Assert.assertEquals(""123"", kafkaSpec.getProperties().getProperty(""segment.bytes""));
    // cleanup policy is overridden in the KafkaAdmin
    Assert.assertEquals(""compact"", kafkaSpec.getProperties().getProperty(""cleanup.policy""));

    // validate that conversion is using changeLog metadata
    map = new HashMap<>();
    map.put(JobConfig.JOB_DEFAULT_SYSTEM, SYSTEM);

    map.put(String.format(""stores.%s.changelog"", ""fakeStore""), topicName);
    int changeLogReplicationFactor = 3;
    map.put(String.format(""stores.%s.changelog.replication.factor"", ""fakeStore""),
        String.valueOf(changeLogReplicationFactor));
    admin = Mockito.spy(createSystemAdmin(SYSTEM, map));
    spec = StreamSpec.createChangeLogStreamSpec(topicName, SYSTEM, changeLogPartitionFactor);
    kafkaSpec = admin.toKafkaSpec(spec);
    Assert.assertEquals(changeLogReplicationFactor, kafkaSpec.getReplicationFactor());

    // same, but with missing topic info
    try {
      admin = Mockito.spy(createSystemAdmin(SYSTEM, map));
      spec = StreamSpec.createChangeLogStreamSpec(""anotherTopic"", SYSTEM, changeLogPartitionFactor);
      kafkaSpec = admin.toKafkaSpec(spec);
      Assert.fail(""toKafkaSpec should've failed for missing topic"");
    } catch (StreamValidationException e) {
      // expected
    }

    // validate that conversion is using intermediate streams properties
    String interStreamId = ""isId"";

    Map<String, String> interStreamMap = new HashMap<>();
    interStreamMap.put(""app.mode"", ApplicationConfig.ApplicationMode.BATCH.toString());
    interStreamMap.put(String.format(""streams.%s.samza.intermediate"", interStreamId), ""true"");
    interStreamMap.put(String.format(""streams.%s.samza.system"", interStreamId), ""testSystem"");
    interStreamMap.put(String.format(""streams.%s.p1"", interStreamId), ""v1"");
    interStreamMap.put(String.format(""streams.%s.retention.ms"", interStreamId), ""123"");
    // legacy format
    interStreamMap.put(String.format(""systems.%s.streams.%s.p2"", ""testSystem"", interStreamId), ""v2"");

    admin = Mockito.spy(createSystemAdmin(SYSTEM, interStreamMap));
    spec = new StreamSpec(interStreamId, topicName, SYSTEM, defaultPartitionCount, config);
    kafkaSpec = admin.toKafkaSpec(spec);
    Assert.assertEquals(""v1"", kafkaSpec.getProperties().getProperty(""p1""));
    Assert.assertEquals(""v2"", kafkaSpec.getProperties().getProperty(""p2""));
    Assert.assertEquals(""123"", kafkaSpec.getProperties().getProperty(""retention.ms""));
    Assert.assertEquals(defaultPartitionCount, kafkaSpec.getPartitionCount());
  }
",non-flaky,5
89329,apache_samza,TestKafkaSystemAdminJava.testCreateCoordinatorStream,"  @Test
  public void testCreateCoordinatorStream() {
    SystemAdmin admin = Mockito.spy(systemAdmin());
    StreamSpec spec = StreamSpec.createCoordinatorStreamSpec(""testCoordinatorStream"", ""testSystem"");

    admin.createStream(spec);
    admin.validateStream(spec);
    Mockito.verify(admin).createStream(Mockito.any());
  }
",non-flaky,5
89330,apache_samza,TestKafkaSystemAdminJava.testCreateCoordinatorStreamWithSpecialCharsInTopicName,"  @Test
  public void testCreateCoordinatorStreamWithSpecialCharsInTopicName() {
    final String stream = ""test.coordinator_test.Stream"";

    Map<String, String> map = new HashMap<>();
    map.put(""job.coordinator.segment.bytes"", ""123"");
    map.put(""job.coordinator.cleanup.policy"", ""compact"");
    int coordReplicatonFactor = 2;
    map.put(org.apache.samza.config.KafkaConfig.JOB_COORDINATOR_REPLICATION_FACTOR(),
        String.valueOf(coordReplicatonFactor));

    KafkaSystemAdmin admin = Mockito.spy(createSystemAdmin(SYSTEM, map));
    StreamSpec spec = StreamSpec.createCoordinatorStreamSpec(stream, SYSTEM);

    Mockito.doAnswer(invocationOnMock -> {
      StreamSpec internalSpec = (StreamSpec) invocationOnMock.callRealMethod();
      assertTrue(internalSpec instanceof KafkaStreamSpec);  // KafkaStreamSpec is used to carry replication factor
      assertTrue(internalSpec.isCoordinatorStream());
      assertEquals(SYSTEM, internalSpec.getSystemName());
      assertEquals(stream, internalSpec.getPhysicalName());
      assertEquals(1, internalSpec.getPartitionCount());
      Assert.assertEquals(coordReplicatonFactor, ((KafkaStreamSpec) internalSpec).getReplicationFactor());
      Assert.assertEquals(""123"", ((KafkaStreamSpec) internalSpec).getProperties().getProperty(""segment.bytes""));
      // cleanup policy is overridden in the KafkaAdmin
      Assert.assertEquals(""compact"", ((KafkaStreamSpec) internalSpec).getProperties().getProperty(""cleanup.policy""));

      return internalSpec;
    }).when(admin).toKafkaSpec(Mockito.any());

    admin.createStream(spec);
    admin.validateStream(spec);
  }
",non-flaky,5
89331,apache_samza,TestKafkaSystemAdminJava.testCreateChangelogStreamHelp,"  @Test
  public void testCreateChangelogStreamHelp() {
    testCreateChangelogStreamHelp(""testChangeLogStream"");
  }
",non-flaky,5
89332,apache_samza,TestKafkaSystemAdminJava.testCreateChangelogStreamWithSpecialCharsInTopicName,"  @Test
  public void testCreateChangelogStreamWithSpecialCharsInTopicName() {
    // cannot contain period
    testCreateChangelogStreamHelp(""test-Change_Log-Stream"");
  }
",non-flaky,5
89333,apache_samza,TestKafkaSystemAdminJava.testCreateStream,"  @Test
  public void testCreateStream() {
    StreamSpec spec = new StreamSpec(""testId"", ""testStream"", ""testSystem"", 8);
    KafkaSystemAdmin admin = systemAdmin();
    assertTrue(""createStream should return true if the stream does not exist and then is created."",
        admin.createStream(spec));
    admin.validateStream(spec);

    assertFalse(""createStream should return false if the stream already exists."", systemAdmin().createStream(spec));
  }
",non-flaky,5
89334,apache_samza,TestKafkaSystemAdminJava.testValidateStreamDoesNotExist,"  @Test(expected = StreamValidationException.class)
  public void testValidateStreamDoesNotExist() {

    StreamSpec spec = new StreamSpec(""testId"", ""testStreamNameExist"", ""testSystem"", 8);

    systemAdmin().validateStream(spec);
  }
",non-flaky,5
89335,apache_samza,TestKafkaSystemAdminJava.testValidateStreamWrongPartitionCount,"  @Test(expected = StreamValidationException.class)
  public void testValidateStreamWrongPartitionCount() {
    StreamSpec spec1 = new StreamSpec(""testId"", ""testStreamPartition"", ""testSystem"", 8);
    StreamSpec spec2 = new StreamSpec(""testId"", ""testStreamPartition"", ""testSystem"", 4);

    assertTrue(""createStream should return true if the stream does not exist and then is created."",
        systemAdmin().createStream(spec1));

    systemAdmin().validateStream(spec2);
  }
",non-flaky,5
89336,apache_samza,TestKafkaSystemAdminJava.testValidateStreamWrongName,"  @Test(expected = StreamValidationException.class)
  public void testValidateStreamWrongName() {
    StreamSpec spec1 = new StreamSpec(""testId"", ""testStreamName1"", ""testSystem"", 8);
    StreamSpec spec2 = new StreamSpec(""testId"", ""testStreamName2"", ""testSystem"", 8);

    assertTrue(""createStream should return true if the stream does not exist and then is created."",
        systemAdmin().createStream(spec1));

    systemAdmin().validateStream(spec2);
  }
",non-flaky,5
89337,apache_samza,TestKafkaSystemAdminJava.testClearStream,"  @Test
  public void testClearStream() {
    StreamSpec spec = new StreamSpec(""testId"", ""testStreamClear"", ""testSystem"", 8);

    KafkaSystemAdmin admin = systemAdmin();
    String topicName = spec.getPhysicalName();

    assertTrue(""createStream should return true if the stream does not exist and then is created."", admin.createStream(spec));
    // validate topic exists
    assertTrue(admin.clearStream(spec));

    // validate that topic was removed
    DescribeTopicsResult dtr = admin.adminClient.describeTopics(ImmutableSet.of(topicName));
    try {
      TopicDescription td = dtr.all().get().get(topicName);
      Assert.fail(""topic "" + topicName + "" should've been removed. td="" + td);
    } catch (Exception e) {
      if (!(e.getCause() instanceof org.apache.kafka.common.errors.UnknownTopicOrPartitionException)) {
        Assert.fail(""topic "" + topicName + "" should've been removed. Expected UnknownTopicOrPartitionException."");
      }
    }
  }
",non-flaky,5
89338,apache_samza,TestKafkaSystemAdminJava.testShouldAssembleMetadata,"  @Test
  public void testShouldAssembleMetadata() {
    Map<SystemStreamPartition, String> oldestOffsets = new ImmutableMap.Builder<SystemStreamPartition, String>()
        .put(new SystemStreamPartition(SYSTEM, ""stream1"", new Partition(0)), ""o1"")
        .put(new SystemStreamPartition(SYSTEM, ""stream2"", new Partition(0)), ""o2"")
        .put(new SystemStreamPartition(SYSTEM, ""stream1"", new Partition(1)), ""o3"")
        .put(new SystemStreamPartition(SYSTEM, ""stream2"", new Partition(1)), ""o4"")
        .build();

    Map<SystemStreamPartition, String> newestOffsets = new ImmutableMap.Builder<SystemStreamPartition, String>()
        .put(new SystemStreamPartition(SYSTEM, ""stream1"", new Partition(0)), ""n1"")
        .put(new SystemStreamPartition(SYSTEM, ""stream2"", new Partition(0)), ""n2"")
        .put(new SystemStreamPartition(SYSTEM, ""stream1"", new Partition(1)), ""n3"")
        .put(new SystemStreamPartition(SYSTEM, ""stream2"", new Partition(1)), ""n4"")
        .build();

    Map<SystemStreamPartition, String> upcomingOffsets = new ImmutableMap.Builder<SystemStreamPartition, String>()
        .put(new SystemStreamPartition(SYSTEM, ""stream1"", new Partition(0)), ""u1"")
        .put(new SystemStreamPartition(SYSTEM, ""stream2"", new Partition(0)), ""u2"")
        .put(new SystemStreamPartition(SYSTEM, ""stream1"", new Partition(1)), ""u3"")
        .put(new SystemStreamPartition(SYSTEM, ""stream2"", new Partition(1)), ""u4"")
        .build();

    Map<String, SystemStreamMetadata> metadata = assembleMetadata(oldestOffsets, newestOffsets, upcomingOffsets);
    assertNotNull(metadata);
    assertEquals(2, metadata.size());
    assertTrue(metadata.containsKey(""stream1""));
    assertTrue(metadata.containsKey(""stream2""));
    SystemStreamMetadata stream1Metadata = metadata.get(""stream1"");
    SystemStreamMetadata stream2Metadata = metadata.get(""stream2"");
    assertNotNull(stream1Metadata);
    assertNotNull(stream2Metadata);
    assertEquals(""stream1"", stream1Metadata.getStreamName());
    assertEquals(""stream2"", stream2Metadata.getStreamName());
    SystemStreamMetadata.SystemStreamPartitionMetadata expectedSystemStream1Partition0Metadata =
        new SystemStreamMetadata.SystemStreamPartitionMetadata(""o1"", ""n1"", ""u1"");
    SystemStreamMetadata.SystemStreamPartitionMetadata expectedSystemStream1Partition1Metadata =
        new SystemStreamMetadata.SystemStreamPartitionMetadata(""o3"", ""n3"", ""u3"");
    SystemStreamMetadata.SystemStreamPartitionMetadata expectedSystemStream2Partition0Metadata =
        new SystemStreamMetadata.SystemStreamPartitionMetadata(""o2"", ""n2"", ""u2"");
    SystemStreamMetadata.SystemStreamPartitionMetadata expectedSystemStream2Partition1Metadata =
        new SystemStreamMetadata.SystemStreamPartitionMetadata(""o4"", ""n4"", ""u4"");
    Map<Partition, SystemStreamMetadata.SystemStreamPartitionMetadata> stream1PartitionMetadata =
        stream1Metadata.getSystemStreamPartitionMetadata();
    Map<Partition, SystemStreamMetadata.SystemStreamPartitionMetadata> stream2PartitionMetadata =
        stream2Metadata.getSystemStreamPartitionMetadata();
    assertEquals(expectedSystemStream1Partition0Metadata, stream1PartitionMetadata.get(new Partition(0)));
    assertEquals(expectedSystemStream1Partition1Metadata, stream1PartitionMetadata.get(new Partition(1)));
    assertEquals(expectedSystemStream2Partition0Metadata, stream2PartitionMetadata.get(new Partition(0)));
    assertEquals(expectedSystemStream2Partition1Metadata, stream2PartitionMetadata.get(new Partition(1)));
  }
",non-flaky,5
89339,apache_samza,TestKafkaSystemAdminJava.testStartpointSpecificOffsetVisitorShouldResolveToCorrectOffset,"  @Test
  public void testStartpointSpecificOffsetVisitorShouldResolveToCorrectOffset() {
    final KafkaConsumer consumer = Mockito.mock(KafkaConsumer.class);
    final KafkaStartpointToOffsetResolver kafkaStartpointToOffsetResolver = new KafkaStartpointToOffsetResolver(consumer);

    final StartpointSpecific testStartpointSpecific = new StartpointSpecific(TEST_OFFSET);

    // Invoke the consumer with startpoint.
    String resolvedOffset = kafkaStartpointToOffsetResolver.visit(TEST_SYSTEM_STREAM_PARTITION, testStartpointSpecific);
    Assert.assertEquals(TEST_OFFSET, resolvedOffset);
  }
",non-flaky,5
89340,apache_samza,TestKafkaSystemAdminJava.testStartpointTimestampVisitorShouldResolveToCorrectOffset,"  @Test
  public void testStartpointTimestampVisitorShouldResolveToCorrectOffset() {
    // Define dummy variables for testing.
    final Long testTimeStamp = 10L;

    final KafkaConsumer consumer = Mockito.mock(KafkaConsumer.class);

    final KafkaStartpointToOffsetResolver kafkaStartpointToOffsetResolver = new KafkaStartpointToOffsetResolver(consumer);

    final StartpointTimestamp startpointTimestamp = new StartpointTimestamp(testTimeStamp);
    final Map<TopicPartition, OffsetAndTimestamp> offsetForTimesResult = ImmutableMap.of(
        TEST_TOPIC_PARTITION, new OffsetAndTimestamp(Long.valueOf(TEST_OFFSET), testTimeStamp));

    // Mock the consumer interactions.
    Mockito.when(consumer.offsetsForTimes(ImmutableMap.of(TEST_TOPIC_PARTITION, testTimeStamp))).thenReturn(offsetForTimesResult);
    Mockito.when(consumer.position(TEST_TOPIC_PARTITION)).thenReturn(Long.valueOf(TEST_OFFSET));

    String resolvedOffset = kafkaStartpointToOffsetResolver.visit(TEST_SYSTEM_STREAM_PARTITION, startpointTimestamp);
    Assert.assertEquals(TEST_OFFSET, resolvedOffset);
  }
",non-flaky,5
89341,apache_samza,TestKafkaSystemAdminJava.testStartpointTimestampVisitorShouldResolveToCorrectOffsetWhenTimestampDoesNotExist,"  @Test
  public void testStartpointTimestampVisitorShouldResolveToCorrectOffsetWhenTimestampDoesNotExist() {
    final KafkaConsumer consumer = Mockito.mock(KafkaConsumer.class);
    final KafkaStartpointToOffsetResolver kafkaStartpointToOffsetResolver = new KafkaStartpointToOffsetResolver(consumer);

    final StartpointTimestamp startpointTimestamp = new StartpointTimestamp(0L);
    final Map<TopicPartition, OffsetAndTimestamp> offsetForTimesResult = new HashMap<>();
    offsetForTimesResult.put(TEST_TOPIC_PARTITION, null);

    // Mock the consumer interactions.
    Mockito.when(consumer.offsetsForTimes(ImmutableMap.of(TEST_TOPIC_PARTITION, 0L))).thenReturn(offsetForTimesResult);
    Mockito.when(consumer.endOffsets(ImmutableSet.of(TEST_TOPIC_PARTITION))).thenReturn(ImmutableMap.of(TEST_TOPIC_PARTITION, 10L));

    String resolvedOffset = kafkaStartpointToOffsetResolver.visit(TEST_SYSTEM_STREAM_PARTITION, startpointTimestamp);
    Assert.assertEquals(TEST_OFFSET, resolvedOffset);

    // Mock verifications.
    Mockito.verify(consumer).offsetsForTimes(ImmutableMap.of(TEST_TOPIC_PARTITION, 0L));
  }
",non-flaky,5
89342,apache_samza,TestKafkaSystemAdminJava.testStartpointOldestVisitorShouldResolveToCorrectOffset,"  @Test
  public void testStartpointOldestVisitorShouldResolveToCorrectOffset() {
    // Define dummy variables for testing.
    final KafkaConsumer consumer = Mockito.mock(KafkaConsumer.class);
    final KafkaStartpointToOffsetResolver kafkaStartpointToOffsetResolver = new KafkaStartpointToOffsetResolver(consumer);

    final StartpointOldest testStartpointSpecific = new StartpointOldest();

    // Mock the consumer interactions.
    Mockito.when(consumer.beginningOffsets(ImmutableSet.of(TEST_TOPIC_PARTITION))).thenReturn(ImmutableMap.of(TEST_TOPIC_PARTITION, 10L));

    // Invoke the consumer with startpoint.
    String resolvedOffset = kafkaStartpointToOffsetResolver.visit(TEST_SYSTEM_STREAM_PARTITION, testStartpointSpecific);
    Assert.assertEquals(TEST_OFFSET, resolvedOffset);
  }
",non-flaky,5
89343,apache_samza,TestKafkaSystemAdminJava.testStartpointUpcomingVisitorShouldResolveToCorrectOffset,"  @Test
  public void testStartpointUpcomingVisitorShouldResolveToCorrectOffset() {
    // Define dummy variables for testing.
    final KafkaConsumer consumer = Mockito.mock(KafkaConsumer.class);

    final KafkaStartpointToOffsetResolver kafkaStartpointToOffsetResolver = new KafkaStartpointToOffsetResolver(consumer);

    final StartpointUpcoming testStartpointSpecific = new StartpointUpcoming();

    // Mock the consumer interactions.
    Mockito.when(consumer.endOffsets(ImmutableSet.of(TEST_TOPIC_PARTITION))).thenReturn(ImmutableMap.of(TEST_TOPIC_PARTITION, 10L));

    // Invoke the consumer with startpoint.
    String resolvedOffset = kafkaStartpointToOffsetResolver.visit(TEST_SYSTEM_STREAM_PARTITION, testStartpointSpecific);
    Assert.assertEquals(TEST_OFFSET, resolvedOffset);
  }
",non-flaky,5
89344,apache_samza,TestKafkaStreamSpec.testUnsupportedConfigStrippedFromProperties,"  @Test
  public void testUnsupportedConfigStrippedFromProperties() {
    StreamSpec original = new StreamSpec(""dummyId"", ""dummyPhysicalName"", ""dummySystemName"",
        ImmutableMap.of(""segment.bytes"", ""4"", ""replication.factor"", ""7""));

    // First verify the original
    assertEquals(""7"", original.get(""replication.factor""));
    assertEquals(""4"", original.get(""segment.bytes""));

    Map<String, String> config = original.getConfig();
    assertEquals(""7"", config.get(""replication.factor""));
    assertEquals(""4"", config.get(""segment.bytes""));


    // Now verify the Kafka spec
    KafkaStreamSpec spec = KafkaStreamSpec.fromSpec(original);
    assertNull(spec.get(""replication.factor""));
    assertEquals(""4"", spec.get(""segment.bytes""));

    Properties kafkaProperties = spec.getProperties();
    Map<String, String> kafkaConfig = spec.getConfig();
    assertNull(kafkaProperties.get(""replication.factor""));
    assertEquals(""4"", kafkaProperties.get(""segment.bytes""));

    assertNull(kafkaConfig.get(""replication.factor""));
    assertEquals(""4"", kafkaConfig.get(""segment.bytes""));
  }
",non-flaky,5
89345,apache_samza,TestKafkaStreamSpec.testInvalidPartitionCount,"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidPartitionCount() {
    new KafkaStreamSpec(""dummyId"", ""dummyPhysicalName"", ""dummySystemName"", 0);
  }
",non-flaky,5
89346,apache_samza,TestKafkaSystemProducerJava.apply,"  @Test
  public void testInstantiateProducer() {
    KafkaSystemProducer ksp = new KafkaSystemProducer(""SysName"", new ExponentialSleepStrategy(2.0, 200, 10000),
      new AbstractFunction0<Producer<byte[], byte[]>>() {
        @Override
        public Producer<byte[], byte[]> apply() {
          return new KafkaProducer<>(new HashMap<String, Object>());
        }
      }, new KafkaSystemProducerMetrics(""SysName"", new MetricsRegistryMap()), new AbstractFunction0<Object>() {
        @Override
        public Object apply() {
          return System.currentTimeMillis();
        }
",non-flaky,5
89347,apache_samza,TestKafkaInputDescriptor.testISDConfigsWithOverrides,"  @Test
  public void testISDConfigsWithOverrides() {
    KafkaSystemDescriptor sd = new KafkaSystemDescriptor(""kafka"");

    KafkaInputDescriptor<KV<String, Integer>> isd =
        sd.getInputDescriptor(""input-stream"", KVSerde.of(new StringSerde(), new IntegerSerde()))
            .withConsumerAutoOffsetReset(""largest"")
            .withConsumerFetchMessageMaxBytes(1024 * 1024);

    Map<String, String> generatedConfigs = isd.toConfig();
    assertEquals(""kafka"", generatedConfigs.get(""streams.input-stream.samza.system""));
    assertEquals(""largest"", generatedConfigs.get(""systems.kafka.streams.input-stream.consumer.auto.offset.reset""));
    assertEquals(""1048576"", generatedConfigs.get(""systems.kafka.streams.input-stream.consumer.fetch.message.max.bytes""));
  }
",non-flaky,5
89348,apache_samza,TestKafkaInputDescriptor.testISDConfigsWithDefaults,"  @Test
  public void testISDConfigsWithDefaults() {
    KafkaSystemDescriptor sd = new KafkaSystemDescriptor(""kafka"")
        .withConsumerZkConnect(ImmutableList.of(""localhost:123""))
        .withProducerBootstrapServers(ImmutableList.of(""localhost:567"", ""localhost:890""));

    KafkaInputDescriptor<KV<String, Integer>> isd =
        sd.getInputDescriptor(""input-stream"", KVSerde.of(new StringSerde(), new IntegerSerde()));

    Map<String, String> generatedConfigs = isd.toConfig();
    assertEquals(""kafka"", generatedConfigs.get(""streams.input-stream.samza.system""));
    assertEquals(1, generatedConfigs.size()); // verify that there are no other configs
  }
",non-flaky,5
89349,apache_samza,TestKafkaSystemDescriptor.testSDConfigsWithOverrides,"  @Test
  public void testSDConfigsWithOverrides() {
    KafkaSystemDescriptor sd =
        new KafkaSystemDescriptor(""kafka"")
            .withConsumerZkConnect(ImmutableList.of(""localhost:1234""))
            .withProducerBootstrapServers(ImmutableList.of(""localhost:567"", ""localhost:890""))
            .withDefaultStreamOffsetDefault(SystemStreamMetadata.OffsetType.OLDEST)
            .withConsumerAutoOffsetReset(""smallest"")
            .withConsumerFetchMessageMaxBytes(1024 * 1024)
            .withSamzaFetchThreshold(10000)
            .withSamzaFetchThresholdBytes(1024 * 1024)
            .withConsumerConfigs(ImmutableMap.of(""custom-consumer-config-key"", ""custom-consumer-config-value""))
            .withProducerConfigs(ImmutableMap.of(""custom-producer-config-key"", ""custom-producer-config-value""))
            .withDefaultStreamConfigs(ImmutableMap.of(""custom-stream-config-key"", ""custom-stream-config-value""));

    Map<String, String> generatedConfigs = sd.toConfig();
    assertEquals(""org.apache.samza.system.kafka.KafkaSystemFactory"", generatedConfigs.get(""systems.kafka.samza.factory""));
    assertEquals(""localhost:1234"", generatedConfigs.get(""systems.kafka.consumer.zookeeper.connect""));
    assertEquals(""localhost:567,localhost:890"", generatedConfigs.get(""systems.kafka.producer.bootstrap.servers""));
    assertEquals(""smallest"", generatedConfigs.get(""systems.kafka.consumer.auto.offset.reset""));
    assertEquals(""1048576"", generatedConfigs.get(""systems.kafka.consumer.fetch.message.max.bytes""));
    assertEquals(""10000"", generatedConfigs.get(""systems.kafka.samza.fetch.threshold""));
    assertEquals(""1048576"", generatedConfigs.get(""systems.kafka.samza.fetch.threshold.bytes""));
    assertEquals(""custom-consumer-config-value"", generatedConfigs.get(""systems.kafka.consumer.custom-consumer-config-key""));
    assertEquals(""custom-producer-config-value"", generatedConfigs.get(""systems.kafka.producer.custom-producer-config-key""));
    assertEquals(""custom-stream-config-value"", generatedConfigs.get(""systems.kafka.default.stream.custom-stream-config-key""));
    assertEquals(""oldest"", generatedConfigs.get(""systems.kafka.default.stream.samza.offset.default""));
    assertEquals(11, generatedConfigs.size());
  }
",non-flaky,5
89350,apache_samza,TestKafkaSystemDescriptor.testSDConfigsWithoutOverrides,"  @Test
  public void testSDConfigsWithoutOverrides() {
    KafkaSystemDescriptor sd = new KafkaSystemDescriptor(""kafka"");

    Map<String, String> generatedConfigs = sd.toConfig();
    assertEquals(""org.apache.samza.system.kafka.KafkaSystemFactory"", generatedConfigs.get(""systems.kafka.samza.factory""));
    assertEquals(1, generatedConfigs.size()); // verify that there are no other configs
  }
",non-flaky,5
89351,apache_samza,TestKafkaSystemFactoryJava.testGetIntermediateStreamProperties,"  @Test
  public void testGetIntermediateStreamProperties() {
    Map<String, String> config = new HashMap<>();
    KafkaSystemFactory factory = new KafkaSystemFactory();
    Map<String, Properties> properties = JavaConversions.mapAsJavaMap(
        factory.getIntermediateStreamProperties(new MapConfig(config)));
    assertTrue(properties.isEmpty());

    // no properties for stream
    config.put(""streams.test.samza.intermediate"", ""true"");
    config.put(""streams.test.compression.type"", ""lz4""); //some random config
    properties = JavaConversions.mapAsJavaMap(
        factory.getIntermediateStreamProperties(new MapConfig(config)));
    assertTrue(properties.isEmpty());

    config.put(ApplicationConfig.APP_MODE, ApplicationConfig.ApplicationMode.BATCH.name());

    KafkaSystemAdmin admin = createSystemAdmin(SYSTEM(), config);
    StreamSpec spec = new StreamSpec(""test"", ""test"", SYSTEM(),
        Collections.singletonMap(""replication.factor"", ""1""));
    KafkaStreamSpec kspec = admin.toKafkaSpec(spec);

    Properties prop = kspec.getProperties();
    assertEquals(prop.getProperty(""retention.ms""), String.valueOf(KafkaConfig.DEFAULT_RETENTION_MS_FOR_BATCH()));
    assertEquals(prop.getProperty(""compression.type""), ""lz4"");

    // replication.factor should be removed from the properties and set on the spec directly
    assertEquals(kspec.getReplicationFactor(), 1);
    assertNull(prop.getProperty(""replication.factor""));
  }
",non-flaky,5
89352,apache_samza,TestKafkaCheckpointManagerFactory.testGetCheckpointTopicProperties,"  @Test
  public void testGetCheckpointTopicProperties() {
    Map<String, String> config = new HashMap<>();
    Properties properties = new KafkaConfig(new MapConfig(config)).getCheckpointTopicProperties();

    assertEquals(properties.getProperty(""cleanup.policy""), ""compact"");
    assertEquals(properties.getProperty(""segment.bytes""), String.valueOf(KafkaConfig.DEFAULT_CHECKPOINT_SEGMENT_BYTES()));

    config.put(ApplicationConfig.APP_MODE, ApplicationConfig.ApplicationMode.BATCH.name());
    properties = new KafkaConfig(new MapConfig(config)).getCheckpointTopicProperties();

    assertEquals(properties.getProperty(""cleanup.policy""), ""compact,delete"");
    assertEquals(properties.getProperty(""segment.bytes""), String.valueOf(KafkaConfig.DEFAULT_CHECKPOINT_SEGMENT_BYTES()));
    assertEquals(properties.getProperty(""retention.ms""), String.valueOf(KafkaConfig.DEFAULT_RETENTION_MS_FOR_BATCH()));
  }
",non-flaky,5
89353,apache_samza,TestKafkaCheckpointLogKeySerde.testBinaryCompatibility,"  @Test
  public void testBinaryCompatibility() {
    KafkaCheckpointLogKey logKey1 = new KafkaCheckpointLogKey(KafkaCheckpointLogKey.CHECKPOINT_V1_KEY_TYPE,
        new TaskName(""Partition 0""), GroupByPartitionFactory.class.getCanonicalName());
    KafkaCheckpointLogKeySerde checkpointSerde = new KafkaCheckpointLogKeySerde();

    byte[] bytes = (""{\""systemstreampartition-grouper-factory\"""" +
        "":\""org.apache.samza.container.grouper.stream.GroupByPartitionFactory\"",\""taskName\"":\""Partition 0\"","" +
        ""\""type\"":\""checkpoint\""}"").getBytes();

    // test that the checkpoints returned by the Serde are byte-wise identical to an actual checkpoint in Kafka
    Assert.assertEquals(true, Arrays.equals(bytes, checkpointSerde.toBytes(logKey1)));
  }
",non-flaky,5
89354,apache_samza,TestKafkaCheckpointLogKeySerde.testSerde,"  @Test
  public void testSerde() {
    KafkaCheckpointLogKey key = new KafkaCheckpointLogKey(KafkaCheckpointLogKey.CHECKPOINT_V1_KEY_TYPE,
        new TaskName(""Partition 0""), GroupByPartitionFactory.class.getCanonicalName());
    KafkaCheckpointLogKeySerde checkpointSerde = new KafkaCheckpointLogKeySerde();

    // test that deserialize(serialize(k)) == k
    Assert.assertEquals(key, checkpointSerde.fromBytes(checkpointSerde.toBytes(key)));
  }
",non-flaky,5
89355,apache_samza,TestKafkaCheckpointLogKeySerde.testCheckpointTypeV2,"  @Test
  public void testCheckpointTypeV2() {
    KafkaCheckpointLogKey keyV2 = new KafkaCheckpointLogKey(KafkaCheckpointLogKey.CHECKPOINT_V2_KEY_TYPE, new TaskName(""Partition 0""),
        GroupByPartitionFactory.class.getCanonicalName());
    KafkaCheckpointLogKeySerde checkpointKeySerde = new KafkaCheckpointLogKeySerde();

    // test that deserialize(serialize(k)) == k
    Assert.assertEquals(keyV2, checkpointKeySerde.fromBytes(checkpointKeySerde.toBytes(keyV2)));
  }
",non-flaky,5
89356,apache_samza,TestKafkaCheckpointLogKeySerde.testForwardsCompatibility,"  @Test
  public void testForwardsCompatibility() {
    // Set the key to another value, this is for the future if we want to support multiple checkpoint keys
    // we do not want to throw in the Serdes layer, but must be validated in the CheckpointManager
    KafkaCheckpointLogKey key = new KafkaCheckpointLogKey(""checkpoint-v2"",
        new TaskName(""Partition 0""), GroupByPartitionFactory.class.getCanonicalName());
    KafkaCheckpointLogKeySerde checkpointSerde = new KafkaCheckpointLogKeySerde();

    // test that deserialize(serialize(k)) == k
    Assert.assertEquals(key, checkpointSerde.fromBytes(checkpointSerde.toBytes(key)));
  }
",non-flaky,5
89357,apache_samza,TestKafkaCheckpointManager.testCreateResourcesTopicCreationError,"  @Test(expected = TopicAlreadyMarkedForDeletionException.class)
  public void testCreateResourcesTopicCreationError() {
    setupSystemFactory(config());
    // throw an exception during createStream
    doThrow(new TopicAlreadyMarkedForDeletionException(""invalid stream"")).when(this.createResourcesSystemAdmin)
        .createStream(CHECKPOINT_SPEC);
    KafkaCheckpointManager checkpointManager = buildKafkaCheckpointManager(true, config());
    // expect an exception during startup
    checkpointManager.createResources();
  }
",non-flaky,5
89358,apache_samza,TestKafkaCheckpointManager.testCreateResourcesTopicValidationError,"  @Test(expected = StreamValidationException.class)
  public void testCreateResourcesTopicValidationError() {
    setupSystemFactory(config());
    // throw an exception during validateStream
    doThrow(new StreamValidationException(""invalid stream"")).when(this.createResourcesSystemAdmin)
        .validateStream(CHECKPOINT_SPEC);
    KafkaCheckpointManager checkpointManager = buildKafkaCheckpointManager(true, config());
    // expect an exception during startup
    checkpointManager.createResources();
  }
",non-flaky,5
89359,apache_samza,TestKafkaCheckpointManager.testReadFailsOnSerdeExceptions,"  @Test(expected = SamzaException.class)
  public void testReadFailsOnSerdeExceptions() throws InterruptedException {
    setupSystemFactory(config());
    List<IncomingMessageEnvelope> checkpointEnvelopes =
        ImmutableList.of(newCheckpointV1Envelope(TASK0, buildCheckpointV1(INPUT_SSP0, ""0""), ""0""));
    setupConsumer(checkpointEnvelopes);
    // wire up an exception throwing serde with the checkpointManager
    CheckpointV1Serde checkpointV1Serde = mock(CheckpointV1Serde.class);
    doThrow(new RuntimeException(""serde failed"")).when(checkpointV1Serde).fromBytes(any());
    KafkaCheckpointManager checkpointManager =
        new KafkaCheckpointManager(CHECKPOINT_SPEC, this.systemFactory, true, config(), this.metricsRegistry,
            checkpointV1Serde, CHECKPOINT_V2_SERDE, KAFKA_CHECKPOINT_LOG_KEY_SERDE);
    checkpointManager.register(TASK0);

    // expect an exception
    checkpointManager.readLastCheckpoint(TASK0);
  }
",non-flaky,5
89360,apache_samza,TestKafkaCheckpointManager.testReadSucceedsOnKeySerdeExceptionsWhenValidationIsDisabled,"  @Test
  public void testReadSucceedsOnKeySerdeExceptionsWhenValidationIsDisabled() throws InterruptedException {
    setupSystemFactory(config());
    List<IncomingMessageEnvelope> checkpointEnvelopes =
        ImmutableList.of(newCheckpointV1Envelope(TASK0, buildCheckpointV1(INPUT_SSP0, ""0""), ""0""));
    setupConsumer(checkpointEnvelopes);
    // wire up an exception throwing serde with the checkpointManager
    CheckpointV1Serde checkpointV1Serde = mock(CheckpointV1Serde.class);
    doThrow(new RuntimeException(""serde failed"")).when(checkpointV1Serde).fromBytes(any());
    KafkaCheckpointManager checkpointManager =
        new KafkaCheckpointManager(CHECKPOINT_SPEC, this.systemFactory, false, config(), this.metricsRegistry,
            checkpointV1Serde, CHECKPOINT_V2_SERDE, KAFKA_CHECKPOINT_LOG_KEY_SERDE);
    checkpointManager.register(TASK0);

    // expect the read to succeed in spite of the exception from ExceptionThrowingSerde
    assertNull(checkpointManager.readLastCheckpoint(TASK0));
  }
",non-flaky,5
89361,apache_samza,TestKafkaCheckpointManager.testStart,"  @Test
  public void testStart() {
    setupSystemFactory(config());
    String oldestOffset = ""1"";
    String newestOffset = ""2"";
    SystemStreamMetadata checkpointTopicMetadata = new SystemStreamMetadata(CHECKPOINT_TOPIC,
        ImmutableMap.of(new Partition(0), new SystemStreamPartitionMetadata(oldestOffset, newestOffset,
            Integer.toString(Integer.parseInt(newestOffset) + 1))));
    when(this.systemAdmin.getSystemStreamMetadata(Collections.singleton(CHECKPOINT_TOPIC))).thenReturn(
        ImmutableMap.of(CHECKPOINT_TOPIC, checkpointTopicMetadata));

    KafkaCheckpointManager checkpointManager = buildKafkaCheckpointManager(true, config());

    checkpointManager.start();

    verify(this.systemProducer).start();
    verify(this.systemAdmin).start();
    verify(this.systemConsumer).register(CHECKPOINT_SSP, oldestOffset);
    verify(this.systemConsumer).start();
  }
",non-flaky,5
89362,apache_samza,TestKafkaCheckpointManager.testRegister,"  @Test
  public void testRegister() {
    setupSystemFactory(config());
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config());
    kafkaCheckpointManager.register(TASK0);
    verify(this.systemProducer).register(TASK0.getTaskName());
  }
",non-flaky,5
89363,apache_samza,TestKafkaCheckpointManager.testStop,"  @Test
  public void testStop() {
    setupSystemFactory(config());
    KafkaCheckpointManager checkpointManager = buildKafkaCheckpointManager(true, config());
    checkpointManager.stop();
    verify(this.systemProducer).stop();
    // default configuration for stopConsumerAfterFirstRead means that consumer is not stopped here
    verify(this.systemConsumer, never()).stop();
    verify(this.systemAdmin).stop();
  }
",non-flaky,5
89364,apache_samza,TestKafkaCheckpointManager.testWriteCheckpointShouldRecreateSystemProducerOnFailure,"  @Test
  public void testWriteCheckpointShouldRecreateSystemProducerOnFailure() {
    setupSystemFactory(config());
    SystemProducer secondKafkaProducer = mock(SystemProducer.class);
    // override default mock behavior to return a second producer on the second call to create a producer
    when(this.systemFactory.getProducer(CHECKPOINT_SYSTEM, config(), this.metricsRegistry,
        KafkaCheckpointManager.class.getSimpleName())).thenReturn(this.systemProducer, secondKafkaProducer);
    // first producer throws an exception on flush
    doThrow(new RuntimeException(""flush failed"")).when(this.systemProducer).flush(TASK0.getTaskName());
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config());
    kafkaCheckpointManager.register(TASK0);

    CheckpointV1 checkpointV1 = buildCheckpointV1(INPUT_SSP0, ""0"");
    kafkaCheckpointManager.writeCheckpoint(TASK0, checkpointV1);

    // first producer should be stopped
    verify(this.systemProducer).stop();
    // register and start the second producer
    verify(secondKafkaProducer).register(TASK0.getTaskName());
    verify(secondKafkaProducer).start();
    // check that the second producer was given the message to send out
    ArgumentCaptor<OutgoingMessageEnvelope> outgoingMessageEnvelopeArgumentCaptor =
        ArgumentCaptor.forClass(OutgoingMessageEnvelope.class);
    verify(secondKafkaProducer).send(eq(TASK0.getTaskName()), outgoingMessageEnvelopeArgumentCaptor.capture());
    assertEquals(CHECKPOINT_SSP, outgoingMessageEnvelopeArgumentCaptor.getValue().getSystemStream());
    assertEquals(new KafkaCheckpointLogKey(KafkaCheckpointLogKey.CHECKPOINT_V1_KEY_TYPE, TASK0, GROUPER_FACTORY_CLASS),
        KAFKA_CHECKPOINT_LOG_KEY_SERDE.fromBytes((byte[]) outgoingMessageEnvelopeArgumentCaptor.getValue().getKey()));
    assertEquals(checkpointV1,
        CHECKPOINT_V1_SERDE.fromBytes((byte[]) outgoingMessageEnvelopeArgumentCaptor.getValue().getMessage()));
    verify(secondKafkaProducer).flush(TASK0.getTaskName());
  }
",non-flaky,5
89365,apache_samza,TestKafkaCheckpointManager.testCreateResources,"  @Test
  public void testCreateResources() {
    setupSystemFactory(config());
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config());
    kafkaCheckpointManager.createResources();

    verify(this.createResourcesSystemAdmin).start();
    verify(this.createResourcesSystemAdmin).createStream(CHECKPOINT_SPEC);
    verify(this.createResourcesSystemAdmin).validateStream(CHECKPOINT_SPEC);
    verify(this.createResourcesSystemAdmin).stop();
  }
",non-flaky,5
89366,apache_samza,TestKafkaCheckpointManager.testCreateResourcesSkipValidation,"  @Test
  public void testCreateResourcesSkipValidation() {
    setupSystemFactory(config());
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(false, config());
    kafkaCheckpointManager.createResources();

    verify(this.createResourcesSystemAdmin).start();
    verify(this.createResourcesSystemAdmin).createStream(CHECKPOINT_SPEC);
    verify(this.createResourcesSystemAdmin, never()).validateStream(CHECKPOINT_SPEC);
    verify(this.createResourcesSystemAdmin).stop();
  }
",non-flaky,5
89367,apache_samza,TestKafkaCheckpointManager.testReadEmpty,"  @Test
  public void testReadEmpty() throws InterruptedException {
    setupSystemFactory(config());
    setupConsumer(ImmutableList.of());
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config());
    kafkaCheckpointManager.register(TASK0);
    assertNull(kafkaCheckpointManager.readLastCheckpoint(TASK0));
  }
",non-flaky,5
89368,apache_samza,TestKafkaCheckpointManager.testReadCheckpointV1,"  @Test
  public void testReadCheckpointV1() throws InterruptedException {
    setupSystemFactory(config());
    CheckpointV1 checkpointV1 = buildCheckpointV1(INPUT_SSP0, ""0"");
    List<IncomingMessageEnvelope> checkpointEnvelopes =
        ImmutableList.of(newCheckpointV1Envelope(TASK0, checkpointV1, ""0""));
    setupConsumer(checkpointEnvelopes);
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config());
    kafkaCheckpointManager.register(TASK0);
    Checkpoint actualCheckpoint = kafkaCheckpointManager.readLastCheckpoint(TASK0);
    assertEquals(checkpointV1, actualCheckpoint);
  }
",non-flaky,5
89369,apache_samza,TestKafkaCheckpointManager.testReadIgnoreCheckpointV2WhenV1Enabled,"  @Test
  public void testReadIgnoreCheckpointV2WhenV1Enabled() throws InterruptedException {
    setupSystemFactory(config());
    CheckpointV1 checkpointV1 = buildCheckpointV1(INPUT_SSP0, ""0"");
    List<IncomingMessageEnvelope> checkpointEnvelopes =
        ImmutableList.of(newCheckpointV1Envelope(TASK0, checkpointV1, ""0""),
            newCheckpointV2Envelope(TASK0, buildCheckpointV2(INPUT_SSP0, ""1""), ""1""));
    setupConsumer(checkpointEnvelopes);
    // default is to only read CheckpointV1
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config());
    kafkaCheckpointManager.register(TASK0);
    Checkpoint actualCheckpoint = kafkaCheckpointManager.readLastCheckpoint(TASK0);
    assertEquals(checkpointV1, actualCheckpoint);
  }
",non-flaky,5
89370,apache_samza,TestKafkaCheckpointManager.testReadCheckpointV2,"  @Test
  public void testReadCheckpointV2() throws InterruptedException {
    Config config = config(ImmutableMap.of(TaskConfig.CHECKPOINT_READ_VERSIONS, ""1,2""));
    setupSystemFactory(config);
    CheckpointV2 checkpointV2 = buildCheckpointV2(INPUT_SSP0, ""0"");
    List<IncomingMessageEnvelope> checkpointEnvelopes =
        ImmutableList.of(newCheckpointV2Envelope(TASK0, checkpointV2, ""0""));
    setupConsumer(checkpointEnvelopes);
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config);
    kafkaCheckpointManager.register(TASK0);
    Checkpoint actualCheckpoint = kafkaCheckpointManager.readLastCheckpoint(TASK0);
    assertEquals(checkpointV2, actualCheckpoint);
  }
",non-flaky,5
89371,apache_samza,TestKafkaCheckpointManager.testReadCheckpointPriority,"  @Test
  public void testReadCheckpointPriority() throws InterruptedException {
    Config config = config(ImmutableMap.of(TaskConfig.CHECKPOINT_READ_VERSIONS, ""2,1""));
    setupSystemFactory(config);
    CheckpointV2 checkpointV2 = buildCheckpointV2(INPUT_SSP0, ""1"");
    List<IncomingMessageEnvelope> checkpointEnvelopes =
        ImmutableList.of(newCheckpointV1Envelope(TASK0, buildCheckpointV1(INPUT_SSP0, ""0""), ""0""),
            newCheckpointV2Envelope(TASK0, checkpointV2, ""1""));
    setupConsumer(checkpointEnvelopes);
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config);
    kafkaCheckpointManager.register(TASK0);
    Checkpoint actualCheckpoint = kafkaCheckpointManager.readLastCheckpoint(TASK0);
    assertEquals(checkpointV2, actualCheckpoint);
  }
",non-flaky,5
89372,apache_samza,TestKafkaCheckpointManager.testReadMultipleCheckpointsMultipleSSP,"  @Test
  public void testReadMultipleCheckpointsMultipleSSP() throws InterruptedException {
    setupSystemFactory(config());
    KafkaCheckpointManager checkpointManager = buildKafkaCheckpointManager(true, config());
    checkpointManager.register(TASK0);
    checkpointManager.register(TASK1);

    // mock out a consumer that returns 5 checkpoint IMEs for each SSP
    int newestOffset = 5;
    int checkpointOffsetCounter = 0;
    List<List<IncomingMessageEnvelope>> pollOutputs = new ArrayList<>();
    for (int offset = 1; offset <= newestOffset; offset++) {
      pollOutputs.add(ImmutableList.of(
          // use regular offset value for INPUT_SSP0
          newCheckpointV1Envelope(TASK0, buildCheckpointV1(INPUT_SSP0, Integer.toString(offset)),
              Integer.toString(checkpointOffsetCounter++)),
          // use (offset * 2) value for INPUT_SSP1 so offsets are different from INPUT_SSP0
          newCheckpointV1Envelope(TASK1, buildCheckpointV1(INPUT_SSP1, Integer.toString(offset * 2)),
              Integer.toString(checkpointOffsetCounter++))));
    }
    setupConsumerMultiplePoll(pollOutputs);

    assertEquals(buildCheckpointV1(INPUT_SSP0, Integer.toString(newestOffset)),
        checkpointManager.readLastCheckpoint(TASK0));
    assertEquals(buildCheckpointV1(INPUT_SSP1, Integer.toString(newestOffset * 2)),
        checkpointManager.readLastCheckpoint(TASK1));
    // check expected number of polls (+1 is for the final empty poll), and the checkpoint is the newest message
    verify(this.systemConsumer, times(newestOffset + 1)).poll(ImmutableSet.of(CHECKPOINT_SSP),
        SystemConsumer.BLOCK_ON_OUTSTANDING_MESSAGES);
  }
",non-flaky,5
89373,apache_samza,TestKafkaCheckpointManager.testReadMultipleCheckpointsUpgradeCheckpointVersion,"  @Test
  public void testReadMultipleCheckpointsUpgradeCheckpointVersion() throws InterruptedException {
    Config config = config(ImmutableMap.of(TaskConfig.CHECKPOINT_READ_VERSIONS, ""2,1""));
    setupSystemFactory(config);
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config);
    kafkaCheckpointManager.register(TASK0);
    kafkaCheckpointManager.register(TASK1);

    List<IncomingMessageEnvelope> checkpointEnvelopesV1 =
        ImmutableList.of(newCheckpointV1Envelope(TASK0, buildCheckpointV1(INPUT_SSP0, ""0""), ""0""),
            newCheckpointV1Envelope(TASK1, buildCheckpointV1(INPUT_SSP1, ""0""), ""1""));
    CheckpointV2 ssp0CheckpointV2 = buildCheckpointV2(INPUT_SSP0, ""10"");
    CheckpointV2 ssp1CheckpointV2 = buildCheckpointV2(INPUT_SSP1, ""11"");
    List<IncomingMessageEnvelope> checkpointEnvelopesV2 =
        ImmutableList.of(newCheckpointV2Envelope(TASK0, ssp0CheckpointV2, ""2""),
            newCheckpointV2Envelope(TASK1, ssp1CheckpointV2, ""3""));
    setupConsumerMultiplePoll(ImmutableList.of(checkpointEnvelopesV1, checkpointEnvelopesV2));
    assertEquals(ssp0CheckpointV2, kafkaCheckpointManager.readLastCheckpoint(TASK0));
    assertEquals(ssp1CheckpointV2, kafkaCheckpointManager.readLastCheckpoint(TASK1));
    // 2 polls for actual checkpoints, 1 final empty poll
    verify(this.systemConsumer, times(3)).poll(ImmutableSet.of(CHECKPOINT_SSP),
        SystemConsumer.BLOCK_ON_OUTSTANDING_MESSAGES);
  }
",non-flaky,5
192,aws_aws-sdk-java-v2,S3TransferManagerListenerTest.upload_success_shouldInvokeListener,"@Test
public void upload_success_shouldInvokeListener() throws Exception {
    TransferListener listener = mock(TransferListener.class);
    Path path = newTempFile();
    Files.write(path, randomBytes(contentLength));
    UploadRequest uploadRequest = UploadRequest.builder().putObjectRequest(( r) -> r.bucket(""bucket"").key(""key"")).source(path).overrideConfiguration(( b) -> b.addListener(listener)).build();
    Upload upload = tm.upload(uploadRequest);
    upload.completionFuture().join();
    ArgumentCaptor<TransferListener.Context.TransferInitiated> captor1 = ArgumentCaptor.forClass(TransferInitiated.class);
    verify(listener, times(1)).transferInitiated(captor1.capture());
    TransferListener.Context.TransferInitiated ctx1 = captor1.getValue();
    assertThat(ctx1.request()).isSameAs(uploadRequest);
    assertThat(ctx1.progressSnapshot().transferSizeInBytes()).hasValue(contentLength);
    assertThat(ctx1.progressSnapshot().bytesTransferred()).isZero();
    ArgumentCaptor<TransferListener.Context.BytesTransferred> captor2 = ArgumentCaptor.forClass(BytesTransferred.class);
    verify(listener, times(1)).bytesTransferred(captor2.capture());
    TransferListener.Context.BytesTransferred ctx2 = captor2.getValue();
    assertThat(ctx2.request()).isSameAs(uploadRequest);
    assertThat(ctx2.progressSnapshot().transferSizeInBytes()).hasValue(contentLength);
    assertThat(ctx2.progressSnapshot().bytesTransferred()).isPositive();
    ArgumentCaptor<TransferListener.Context.TransferComplete> captor3 = ArgumentCaptor.forClass(TransferComplete.class);
    verify(listener, times(1)).transferComplete(captor3.capture());
    TransferListener.Context.TransferComplete ctx3 = captor3.getValue();
    assertThat(ctx3.request()).isSameAs(uploadRequest);
    assertThat(ctx3.progressSnapshot().transferSizeInBytes()).hasValue(contentLength);
    assertThat(ctx3.progressSnapshot().bytesTransferred()).isEqualTo(contentLength);
    assertThat(ctx3.completedTransfer()).isSameAs(upload.completionFuture().get());
    verifyNoMoreInteractions(listener);
}",async wait,0
114034,aws_aws-sdk-java-v2,__handlerClassName__Test.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        ${handlerClassName} function = new ${handlerClassName}();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
114035,aws_aws-sdk-java-v2,MyDynamoDbStreamsFunctionTest.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        MyDynamoDbStreamsFunction function = new MyDynamoDbStreamsFunction();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
114036,aws_aws-sdk-java-v2,AppTest.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        App function = new App();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
114037,aws_aws-sdk-java-v2,MyNettyFunctionTest.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        MyNettyFunction function = new MyNettyFunction();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
114038,aws_aws-sdk-java-v2,MyWafRegionalFunctionTest.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        MyWafRegionalFunction function = new MyWafRegionalFunction();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
114039,aws_aws-sdk-java-v2,MyApacheFunctionTest.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        MyApacheFunction function = new MyApacheFunction();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
114040,aws_aws-sdk-java-v2,UpdateItemWithResponseIntegrationTest.updateItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull,"    @Test
    public void updateItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull() {
        Record record = new Record().setId(1).setId2(10);
        UpdateItemEnhancedRequest<Record> request = UpdateItemEnhancedRequest.builder(Record.class)
                                                                          .item(record)
                                                                          .build();

        UpdateItemEnhancedResponse<Record> response = mappedTable.updateItemWithResponse(request);

        assertThat(response.itemCollectionMetrics()).isNull();
    }
",non-flaky,5
114041,aws_aws-sdk-java-v2,UpdateItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Record record = new Record().setId(1).setId2(10);
        UpdateItemEnhancedRequest<Record> request = UpdateItemEnhancedRequest.builder(Record.class)
                                                                             .item(record)
                                                                             .returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE)
                                                                             .build();

        UpdateItemEnhancedResponse<Record> response = mappedTable.updateItemWithResponse(request);

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
114042,aws_aws-sdk-java-v2,PutItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull() {
        Record record = new Record().setId(1).setId2(10);
        PutItemEnhancedRequest<Record> request = PutItemEnhancedRequest.builder(Record.class)
                                                                       .item(record)
                                                                       .build();

        PutItemEnhancedResponse<Record> response = mappedTable.putItemWithResponse(request);

        assertThat(response.itemCollectionMetrics()).isNull();
    }
",non-flaky,5
114043,aws_aws-sdk-java-v2,PutItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Record record = new Record().setId(1).setId2(10);
        PutItemEnhancedRequest<Record> request = PutItemEnhancedRequest.builder(Record.class)
                                                                       .item(record)
                                                                       .returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE)
                                                                       .build();

        PutItemEnhancedResponse<Record> response = mappedTable.putItemWithResponse(request);

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
114044,aws_aws-sdk-java-v2,AsyncUpdateItemWithResponseIntegrationTest.updateItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull,"    @Test
    public void updateItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull() {
        Record record = new Record().setId(1).setId2(10);
        UpdateItemEnhancedRequest<Record> request = UpdateItemEnhancedRequest.builder(Record.class)
                                                                          .item(record)
                                                                          .build();

        UpdateItemEnhancedResponse<Record> response = mappedTable.updateItemWithResponse(request).join();

        assertThat(response.itemCollectionMetrics()).isNull();
    }
",non-flaky,5
114045,aws_aws-sdk-java-v2,AsyncUpdateItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Record record = new Record().setId(1).setId2(10);
        UpdateItemEnhancedRequest<Record> request = UpdateItemEnhancedRequest.builder(Record.class)
                                                                             .item(record)
                                                                             .returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE)
                                                                             .build();

        UpdateItemEnhancedResponse<Record> response = mappedTable.updateItemWithResponse(request).join();

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
114046,aws_aws-sdk-java-v2,DeleteItemWithResponseIntegrationTest.deleteItem_returnConsumedCapacity_unset_consumedCapacityNull,"    @Test
    public void deleteItem_returnConsumedCapacity_unset_consumedCapacityNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response = mappedTable.deleteItemWithResponse(r -> r.key(key));

        assertThat(response.consumedCapacity()).isNull();
    }
",non-flaky,5
114047,aws_aws-sdk-java-v2,DeleteItemWithResponseIntegrationTest.deleteItem_returnConsumedCapacity_set_consumedCapacityNotNull,"    @Test
    public void deleteItem_returnConsumedCapacity_set_consumedCapacityNotNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response =
            mappedTable.deleteItemWithResponse(r -> r.key(key).returnConsumedCapacity(ReturnConsumedCapacity.TOTAL));

        assertThat(response.consumedCapacity()).isNotNull();
    }
",non-flaky,5
114048,aws_aws-sdk-java-v2,DeleteItemWithResponseIntegrationTest.delete_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void delete_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response =
            mappedTable.deleteItemWithResponse(r -> r.key(key).returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE));

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
114049,aws_aws-sdk-java-v2,AsyncDeleteItemWithResponseIntegrationTest.deleteItem_returnConsumedCapacity_unset_consumedCapacityNull,"    @Test
    public void deleteItem_returnConsumedCapacity_unset_consumedCapacityNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response = mappedTable.deleteItemWithResponse(r -> r.key(key)).join();

        assertThat(response.consumedCapacity()).isNull();
    }
",non-flaky,5
114050,aws_aws-sdk-java-v2,AsyncDeleteItemWithResponseIntegrationTest.deleteItem_returnConsumedCapacity_set_consumedCapacityNotNull,"    @Test
    public void deleteItem_returnConsumedCapacity_set_consumedCapacityNotNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response =
            mappedTable.deleteItemWithResponse(r -> r.key(key).returnConsumedCapacity(ReturnConsumedCapacity.TOTAL)).join();

        assertThat(response.consumedCapacity()).isNotNull();
    }
",non-flaky,5
114051,aws_aws-sdk-java-v2,AsyncDeleteItemWithResponseIntegrationTest.delete_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void delete_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response =
            mappedTable.deleteItemWithResponse(r -> r.key(key).returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE))
                       .join();

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
114052,aws_aws-sdk-java-v2,AsyncPutItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull() {
        Record record = new Record().setId(1).setId2(10);
        PutItemEnhancedRequest<Record> request = PutItemEnhancedRequest.builder(Record.class)
                                                                       .item(record)
                                                                       .build();

        PutItemEnhancedResponse<Record> response = mappedTable.putItemWithResponse(request).join();

        assertThat(response.itemCollectionMetrics()).isNull();
    }
",non-flaky,5
114053,aws_aws-sdk-java-v2,AsyncPutItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Record record = new Record().setId(1).setId2(10);
        PutItemEnhancedRequest<Record> request = PutItemEnhancedRequest.builder(Record.class)
                                                                       .item(record)
                                                                       .returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE)
                                                                       .build();

        PutItemEnhancedResponse<Record> response = mappedTable.putItemWithResponse(request).join();

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
114054,aws_aws-sdk-java-v2,EnhancedTypeTest.anonymousCreationCapturesComplexTypeArguments,"    @Test
    public void anonymousCreationCapturesComplexTypeArguments() {
        EnhancedType<Map<String, List<List<String>>>> enhancedType = new EnhancedType<Map<String, List<List<String>>>>(){};
        assertThat(enhancedType.rawClass()).isEqualTo(Map.class);
        assertThat(enhancedType.rawClassParameters().get(0).rawClass()).isEqualTo(String.class);
        assertThat(enhancedType.rawClassParameters().get(1).rawClass()).isEqualTo(List.class);
        assertThat(enhancedType.rawClassParameters().get(1).rawClassParameters().get(0).rawClass()).isEqualTo(List.class);
        assertThat(enhancedType.rawClassParameters().get(1).rawClassParameters().get(0).rawClassParameters().get(0).rawClass())
            .isEqualTo(String.class);
    }
",non-flaky,5
114055,aws_aws-sdk-java-v2,EnhancedTypeTest.customTypesWork,"    @Test
    public void customTypesWork() {
        EnhancedType<EnhancedTypeTest> enhancedType = new EnhancedType<EnhancedTypeTest>(){};
        assertThat(enhancedType.rawClass()).isEqualTo(EnhancedTypeTest.class);
    }
",non-flaky,5
114056,aws_aws-sdk-java-v2,EnhancedTypeTest.nonStaticInnerTypesWork,"    @Test
    public void nonStaticInnerTypesWork() {
        EnhancedType<InnerType> enhancedType = new EnhancedType<InnerType>(){};
        assertThat(enhancedType.rawClass()).isEqualTo(InnerType.class);
    }
",non-flaky,5
114057,aws_aws-sdk-java-v2,EnhancedTypeTest.staticInnerTypesWork,"    @Test
    public void staticInnerTypesWork() {
        EnhancedType<InnerStaticType> enhancedType = new EnhancedType<InnerStaticType>(){};
        assertThat(enhancedType.rawClass()).isEqualTo(InnerStaticType.class);
    }
",non-flaky,5
114058,aws_aws-sdk-java-v2,EnhancedTypeTest.helperCreationMethodsWork,"    @Test
    public void helperCreationMethodsWork() {
        assertThat(EnhancedType.of(String.class).rawClass()).isEqualTo(String.class);

        assertThat(EnhancedType.listOf(String.class)).satisfies(v -> {
            assertThat(v.rawClass()).isEqualTo(List.class);
            assertThat(v.rawClassParameters()).hasSize(1);
            assertThat(v.rawClassParameters().get(0).rawClass()).isEqualTo(String.class);
        });

        assertThat(EnhancedType.mapOf(String.class, Integer.class)).satisfies(v -> {
            assertThat(v.rawClass()).isEqualTo(Map.class);
            assertThat(v.rawClassParameters()).hasSize(2);
            assertThat(v.rawClassParameters().get(0).rawClass()).isEqualTo(String.class);
            assertThat(v.rawClassParameters().get(1).rawClass()).isEqualTo(Integer.class);
        });
    }
",non-flaky,5
114059,aws_aws-sdk-java-v2,EnhancedTypeTest.equalityIsBasedOnInnerEquality,"    @Test
    public void equalityIsBasedOnInnerEquality() {
        verifyEquals(EnhancedType.of(String.class), EnhancedType.of(String.class));
        verifyNotEquals(EnhancedType.of(String.class), EnhancedType.of(Integer.class));

        verifyEquals(new EnhancedType<Map<String, List<String>>>(){}, new EnhancedType<Map<String, List<String>>>(){});
        verifyNotEquals(new EnhancedType<Map<String, List<String>>>(){}, new EnhancedType<Map<String,
            List<Integer>>>(){});

        TableSchema<String> tableSchema = StaticTableSchema.builder(String.class).build();

        verifyNotEquals(EnhancedType.documentOf(String.class,
                                             tableSchema,
                                             b -> b.ignoreNulls(false)), EnhancedType.documentOf(String.class,
                                                                                                 tableSchema,
                                                                                                 b -> b.ignoreNulls(true)));
        verifyEquals(EnhancedType.documentOf(String.class,
                                                tableSchema,
                                                b -> b.ignoreNulls(false).preserveEmptyObject(true)),
                        EnhancedType.documentOf(String.class,
                                                tableSchema,
                                                b -> b.ignoreNulls(false).preserveEmptyObject(true)));
    }
",non-flaky,5
114060,aws_aws-sdk-java-v2,EnhancedTypeTest.dequeOf_ReturnsRawClassOfDeque_WhenSpecifyingClass,"    @Test
    public void dequeOf_ReturnsRawClassOfDeque_WhenSpecifyingClass() {
        EnhancedType<Deque<String>> type = EnhancedType.dequeOf(String.class);

        assertThat(type.rawClass()).isEqualTo(Deque.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114061,aws_aws-sdk-java-v2,EnhancedTypeTest.dequeOf_ReturnsRawClassOfDeque_WhenSpecifyingEnhancedType,"    @Test
    public void dequeOf_ReturnsRawClassOfDeque_WhenSpecifyingEnhancedType() {
        EnhancedType<Deque<String>> type = EnhancedType.dequeOf(EnhancedType.of(String.class));

        assertThat(type.rawClass()).isEqualTo(Deque.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114062,aws_aws-sdk-java-v2,EnhancedTypeTest.sortedSetOf_ReturnsRawClassOfDeque_WhenSpecifyingClass,"    @Test
    public void sortedSetOf_ReturnsRawClassOfDeque_WhenSpecifyingClass() {
        EnhancedType<SortedSet<String>> type = EnhancedType.sortedSetOf(String.class);

        assertThat(type.rawClass()).isEqualTo(SortedSet.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114063,aws_aws-sdk-java-v2,EnhancedTypeTest.sortedSetOf_ReturnsRawClassOfDeque_WhenSpecifyingEnhancedType,"    @Test
    public void sortedSetOf_ReturnsRawClassOfDeque_WhenSpecifyingEnhancedType() {
        EnhancedType<SortedSet<String>> type = EnhancedType.sortedSetOf(EnhancedType.of(String.class));

        assertThat(type.rawClass()).isEqualTo(SortedSet.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114064,aws_aws-sdk-java-v2,EnhancedTypeTest.navigableSetOf_ReturnsRawClassOfNavigableSet_WhenSpecifyingClass,"    @Test
    public void navigableSetOf_ReturnsRawClassOfNavigableSet_WhenSpecifyingClass() {
        EnhancedType<NavigableSet<String>> type = EnhancedType.navigableSetOf(String.class);

        assertThat(type.rawClass()).isEqualTo(NavigableSet.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114065,aws_aws-sdk-java-v2,EnhancedTypeTest.navigableSetOf_ReturnsRawClassOfNavigableSet_WhenSpecifyingEnhancedType,"    @Test
    public void navigableSetOf_ReturnsRawClassOfNavigableSet_WhenSpecifyingEnhancedType() {
        EnhancedType<NavigableSet<String>> type = EnhancedType.navigableSetOf(EnhancedType.of(String.class));

        assertThat(type.rawClass()).isEqualTo(NavigableSet.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114066,aws_aws-sdk-java-v2,EnhancedTypeTest.collectionOf_ReturnsRawClassOfCollection_WhenSpecifyingClass,"    @Test
    public void collectionOf_ReturnsRawClassOfCollection_WhenSpecifyingClass() {
        EnhancedType<Collection<String>> type = EnhancedType.collectionOf(String.class);

        assertThat(type.rawClass()).isEqualTo(Collection.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114067,aws_aws-sdk-java-v2,EnhancedTypeTest.collectionOf_ReturnsRawClassOfCollection_WhenSpecifyingEnhancedType,"    @Test
    public void collectionOf_ReturnsRawClassOfCollection_WhenSpecifyingEnhancedType() {
        EnhancedType<Collection<String>> type = EnhancedType.collectionOf(EnhancedType.of(String.class));

        assertThat(type.rawClass()).isEqualTo(Collection.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114068,aws_aws-sdk-java-v2,EnhancedTypeTest.sortedMapOf_ReturnsRawClassOfSortedMap_WhenSpecifyingClass,"    @Test
    public void sortedMapOf_ReturnsRawClassOfSortedMap_WhenSpecifyingClass() {
        EnhancedType<SortedMap<String, Integer>> type = EnhancedType.sortedMapOf(String.class, Integer.class);

        assertThat(type.rawClass()).isEqualTo(SortedMap.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class), EnhancedType.of(Integer.class));
    }
",non-flaky,5
114069,aws_aws-sdk-java-v2,EnhancedTypeTest.sortedMapOf_ReturnsRawClassOfSortedMap_WhenSpecifyingEnhancedType,"    @Test
    public void sortedMapOf_ReturnsRawClassOfSortedMap_WhenSpecifyingEnhancedType() {
        EnhancedType<SortedMap<String, Integer>> type =
            EnhancedType.sortedMapOf(EnhancedType.of(String.class), EnhancedType.of(Integer.class));

        assertThat(type.rawClass()).isEqualTo(SortedMap.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class), EnhancedType.of(Integer.class));
    }
",non-flaky,5
114070,aws_aws-sdk-java-v2,EnhancedTypeTest.concurrentMapOf_ReturnsRawClassOfConcurrentMap_WhenSpecifyingClass,"    @Test
    public void concurrentMapOf_ReturnsRawClassOfConcurrentMap_WhenSpecifyingClass() {
        EnhancedType<ConcurrentMap<String, Integer>> type = EnhancedType.concurrentMapOf(String.class, Integer.class);

        assertThat(type.rawClass()).isEqualTo(ConcurrentMap.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class), EnhancedType.of(Integer.class));
    }
",non-flaky,5
114071,aws_aws-sdk-java-v2,EnhancedTypeTest.concurrentMapOf_ReturnsRawClassOfConcurrentMap_WhenSpecifyingEnhancedType,"    @Test
    public void concurrentMapOf_ReturnsRawClassOfConcurrentMap_WhenSpecifyingEnhancedType() {
        EnhancedType<ConcurrentMap<String, Integer>> type =
            EnhancedType.concurrentMapOf(EnhancedType.of(String.class), EnhancedType.of(Integer.class));

        assertThat(type.rawClass()).isEqualTo(ConcurrentMap.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class), EnhancedType.of(Integer.class));
    }
",non-flaky,5
114072,aws_aws-sdk-java-v2,EnhancedTypeTest.navigableMapOf_ReturnsRawClassOfNavigableMap_WhenSpecifyingClass,"    @Test
    public void navigableMapOf_ReturnsRawClassOfNavigableMap_WhenSpecifyingClass() {
        EnhancedType<NavigableMap<String, Integer>> type = EnhancedType.navigableMapOf(String.class, Integer.class);

        assertThat(type.rawClass()).isEqualTo(NavigableMap.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class), EnhancedType.of(Integer.class));
    }
",non-flaky,5
114073,aws_aws-sdk-java-v2,EnhancedTypeTest.navigableMapOf_ReturnsRawClassOfNavigableMap_WhenSpecifyingEnhancedType,"    @Test
    public void navigableMapOf_ReturnsRawClassOfNavigableMap_WhenSpecifyingEnhancedType() {
        EnhancedType<NavigableMap<String, Integer>> type =
            EnhancedType.navigableMapOf(EnhancedType.of(String.class), EnhancedType.of(Integer.class));

        assertThat(type.rawClass()).isEqualTo(NavigableMap.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class), EnhancedType.of(Integer.class));
    }
",non-flaky,5
114074,aws_aws-sdk-java-v2,EnhancedTypeTest.documentOf_toString_doesNotRaiseNPE,"    @Test
    public void documentOf_toString_doesNotRaiseNPE() {
        TableSchema<String> tableSchema = StaticTableSchema.builder(String.class).build();
        EnhancedType<String> type = EnhancedType.documentOf(String.class, tableSchema);
        assertThatCode(() -> type.toString()).doesNotThrowAnyException();
    }
",non-flaky,5
114075,aws_aws-sdk-java-v2,EnhancedTypeTest.documentOf_withEnhancedTypeConfiguration,"    @Test
    public void documentOf_withEnhancedTypeConfiguration() {
        TableSchema<String> tableSchema = StaticTableSchema.builder(String.class).build();
        EnhancedType<String> type = EnhancedType.documentOf(String.class, tableSchema, b -> b.preserveEmptyObject(true));
        assertThat(type.documentConfiguration()).isPresent();
        assertThat(type.documentConfiguration().get().preserveEmptyObject()).isTrue();
    }
",non-flaky,5
114076,aws_aws-sdk-java-v2,ExpressionTest.join_correctlyWrapsExpressions,"    @Test
    public void join_correctlyWrapsExpressions() {
        Expression expression1 = Expression.builder().expression(""one"").build();
        Expression expression2 = Expression.builder().expression(""two"").build();
        Expression expression3 = Expression.builder().expression(""three"").build();

        Expression coalescedExpression = Expression.join(Expression.join(expression1, expression2, "" AND ""),
                                                         expression3, "" AND "");

        String expectedExpression = ""((one) AND (two)) AND (three)"";
        assertThat(coalescedExpression.expression(), is(expectedExpression));
    }
",non-flaky,5
114077,aws_aws-sdk-java-v2,ExpressionTest.joinExpressions_correctlyJoins,"    @Test
    public void joinExpressions_correctlyJoins() {
        String result = Expression.joinExpressions(""one"", ""two"", "" AND "");
        assertThat(result, is(""(one) AND (two)""));
    }
",non-flaky,5
114078,aws_aws-sdk-java-v2,ExpressionTest.joinNames_correctlyJoins,"    @Test
    public void joinNames_correctlyJoins() {
        Map<String, String> names1 = new HashMap<>();
        names1.put(""one"", ""1"");
        names1.put(""two"", ""2"");
        Map<String, String> names2 = new HashMap<>();
        names2.put(""three"", ""3"");
        names2.put(""four"", ""4"");

        Map<String, String> result = Expression.joinNames(names1, names2);

        assertThat(result.size(), is(4));
        assertThat(result, hasEntry(""one"", ""1""));
        assertThat(result, hasEntry(""two"", ""2""));
        assertThat(result, hasEntry(""three"", ""3""));
        assertThat(result, hasEntry(""four"", ""4""));
    }
",non-flaky,5
114079,aws_aws-sdk-java-v2,ExpressionTest.joinNames_correctlyJoinsEmpty,"    @Test
    public void joinNames_correctlyJoinsEmpty() {
        Map<String, String> names1 = new HashMap<>();
        names1.put(""one"", ""1"");
        names1.put(""two"", ""2"");
        Map<String, String> names2 = new HashMap<>();
        names2.put(""three"", ""3"");
        names2.put(""four"", ""4"");

        Map<String, String> result = Expression.joinNames(names1, null);
        assertThat(result.size(), is(2));
        assertThat(result, hasEntry(""one"", ""1""));
        assertThat(result, hasEntry(""two"", ""2""));

        result = Expression.joinNames(null, names2);
        assertThat(result.size(), is(2));
        assertThat(result, hasEntry(""three"", ""3""));
        assertThat(result, hasEntry(""four"", ""4""));

        result = Expression.joinNames(names1, Collections.emptyMap());
        assertThat(result.size(), is(2));
        assertThat(result, hasEntry(""one"", ""1""));
        assertThat(result, hasEntry(""two"", ""2""));

        result = Expression.joinNames(Collections.emptyMap(), names2);
        assertThat(result.size(), is(2));
        assertThat(result, hasEntry(""three"", ""3""));
        assertThat(result, hasEntry(""four"", ""4""));
    }
",non-flaky,5
114080,aws_aws-sdk-java-v2,ExpressionTest.joinNames_conflictingKey,"    @Test
    public void joinNames_conflictingKey() {
        Map<String, String> names1 = new HashMap<>();
        names1.put(""one"", ""1"");
        names1.put(""two"", ""2"");
        Map<String, String> names2 = new HashMap<>();
        names2.put(""three"", ""3"");
        names2.put(""two"", ""4"");

        exception.expect(IllegalArgumentException.class);
        exception.expectMessage(""two"");
        Expression.joinNames(names1, names2);
    }
",non-flaky,5
114081,aws_aws-sdk-java-v2,ExpressionTest.joinValues_correctlyJoins,"    @Test
    public void joinValues_correctlyJoins() {
        Map<String, AttributeValue> values1 = new HashMap<>();
        values1.put(""one"", EnhancedAttributeValue.fromString(""1"").toAttributeValue());
        values1.put(""two"", EnhancedAttributeValue.fromString(""2"").toAttributeValue());
        Map<String, AttributeValue> values2 = new HashMap<>();
        values2.put(""three"", EnhancedAttributeValue.fromString(""3"").toAttributeValue());
        values2.put(""four"", EnhancedAttributeValue.fromString(""4"").toAttributeValue());

        Map<String, AttributeValue> result = Expression.joinValues(values1, values2);

        assertThat(result.size(), is(4));
        assertThat(result, hasEntry(""one"", EnhancedAttributeValue.fromString(""1"").toAttributeValue()));
        assertThat(result, hasEntry(""two"", EnhancedAttributeValue.fromString(""2"").toAttributeValue()));
        assertThat(result, hasEntry(""three"", EnhancedAttributeValue.fromString(""3"").toAttributeValue()));
        assertThat(result, hasEntry(""four"", EnhancedAttributeValue.fromString(""4"").toAttributeValue()));
    }
",non-flaky,5
114082,aws_aws-sdk-java-v2,ExpressionTest.joinValues_conflictingKey,"    @Test
    public void joinValues_conflictingKey() {
        Map<String, AttributeValue> values1 = new HashMap<>();
        values1.put(""one"", EnhancedAttributeValue.fromString(""1"").toAttributeValue());
        values1.put(""two"", EnhancedAttributeValue.fromString(""2"").toAttributeValue());
        Map<String, AttributeValue> values2 = new HashMap<>();
        values2.put(""three"", EnhancedAttributeValue.fromString(""3"").toAttributeValue());
        values2.put(""two"", EnhancedAttributeValue.fromString(""4"").toAttributeValue());

        exception.expect(IllegalArgumentException.class);
        exception.expectMessage(""two"");
        Expression.joinValues(values1, values2);
    }
",non-flaky,5
114083,aws_aws-sdk-java-v2,KeyTest.getKeyMap,"    @Test
    public void getKeyMap() {
        Map<String, AttributeValue> expectedResult = new HashMap<>();
        expectedResult.put(""gsi_id"", AttributeValue.builder().s(""id123"").build());
        expectedResult.put(""gsi_sort"", AttributeValue.builder().s(""id456"").build());
        assertThat(key.keyMap(FakeItemWithIndices.getTableSchema(), ""gsi_1""), is(expectedResult));
    }
",non-flaky,5
114084,aws_aws-sdk-java-v2,KeyTest.getPrimaryKeyMap,"    @Test
    public void getPrimaryKeyMap() {
        Map<String, AttributeValue> expectedResult = new HashMap<>();
        expectedResult.put(""id"", AttributeValue.builder().s(""id123"").build());
        expectedResult.put(""sort"", AttributeValue.builder().s(""id456"").build());
        assertThat(key.primaryKeyMap(FakeItemWithIndices.getTableSchema()), is(expectedResult));
    }
",non-flaky,5
114085,aws_aws-sdk-java-v2,KeyTest.getPartitionKeyValue,"    @Test
    public void getPartitionKeyValue() {
        assertThat(key.partitionKeyValue(),
                   is(AttributeValue.builder().s(""id123"").build()));
    }
",non-flaky,5
114086,aws_aws-sdk-java-v2,KeyTest.getSortKeyValue,"    @Test
    public void getSortKeyValue() {
        assertThat(key.sortKeyValue(), is(Optional.of(AttributeValue.builder().s(""id456"").build())));
    }
",non-flaky,5
114087,aws_aws-sdk-java-v2,KeyTest.getKeyMap_partitionOnly,"    @Test
    public void getKeyMap_partitionOnly() {
        Map<String, AttributeValue> expectedResult = new HashMap<>();
        expectedResult.put(""gsi_id"", AttributeValue.builder().s(""id123"").build());
        assertThat(partitionOnlyKey.keyMap(FakeItemWithIndices.getTableSchema(), ""gsi_1""), is(expectedResult));
    }
",non-flaky,5
114088,aws_aws-sdk-java-v2,KeyTest.getPrimaryKeyMap_partitionOnly,"    @Test
    public void getPrimaryKeyMap_partitionOnly() {
        Map<String, AttributeValue> expectedResult = new HashMap<>();
        expectedResult.put(""id"", AttributeValue.builder().s(""id123"").build());
        assertThat(partitionOnlyKey.primaryKeyMap(FakeItemWithIndices.getTableSchema()), is(expectedResult));
    }
",non-flaky,5
114089,aws_aws-sdk-java-v2,KeyTest.getPartitionKeyValue_partitionOnly,"    @Test
    public void getPartitionKeyValue_partitionOnly() {
        assertThat(partitionOnlyKey.partitionKeyValue(),
                   is(AttributeValue.builder().s(""id123"").build()));
    }
",non-flaky,5
114090,aws_aws-sdk-java-v2,KeyTest.getSortKeyValue_partitionOnly,"    @Test
    public void getSortKeyValue_partitionOnly() {
        assertThat(partitionOnlyKey.sortKeyValue(), is(Optional.empty()));
    }
",non-flaky,5
114091,aws_aws-sdk-java-v2,KeyTest.numericKeys_convertsToCorrectAttributeValue,"    @Test
    public void numericKeys_convertsToCorrectAttributeValue() {
        Key key = Key.builder().partitionValue(123).sortValue(45.6).build();

        assertThat(key.partitionKeyValue(), is(AttributeValue.builder().n(""123"").build()));
        assertThat(key.sortKeyValue(), is(Optional.of(AttributeValue.builder().n(""45.6"").build())));
    }
",non-flaky,5
114092,aws_aws-sdk-java-v2,KeyTest.stringKeys_convertsToCorrectAttributeValue,"    @Test
    public void stringKeys_convertsToCorrectAttributeValue() {
        Key key = Key.builder().partitionValue(""one"").sortValue(""two"").build();

        assertThat(key.partitionKeyValue(), is(AttributeValue.builder().s(""one"").build()));
        assertThat(key.sortKeyValue(), is(Optional.of(AttributeValue.builder().s(""two"").build())));
    }
",non-flaky,5
114093,aws_aws-sdk-java-v2,KeyTest.binaryKeys_convertsToCorrectAttributeValue,"    @Test
    public void binaryKeys_convertsToCorrectAttributeValue() {
        SdkBytes partition = SdkBytes.fromString(""one"", StandardCharsets.UTF_8);
        SdkBytes sort = SdkBytes.fromString(""two"", StandardCharsets.UTF_8);

        Key key = Key.builder().partitionValue(partition).sortValue(sort).build();

        assertThat(key.partitionKeyValue(), is(AttributeValue.builder().b(partition).build()));
        assertThat(key.sortKeyValue(), is(Optional.of(AttributeValue.builder().b(sort).build())));
    }
",non-flaky,5
114094,aws_aws-sdk-java-v2,KeyTest.toBuilder,"    @Test
    public void toBuilder() {
        Key keyClone = key.toBuilder().build();

        assertThat(key, is(equalTo(keyClone)));
    }
",non-flaky,5
114095,aws_aws-sdk-java-v2,KeyTest.nullPartitionKey_shouldThrowException,"    @Test
    public void nullPartitionKey_shouldThrowException() {
        AttributeValue attributeValue = null;
        assertThatThrownBy(() ->  Key.builder().partitionValue(attributeValue).build())
         .isInstanceOf(IllegalArgumentException.class).hasMessageContaining(""partitionValue should not be null"");

        assertThatThrownBy(() ->  Key.builder().partitionValue(AttributeValue.builder().nul(true).build()).build())
            .isInstanceOf(IllegalArgumentException.class).hasMessageContaining(""partitionValue should not be null"");
    }
",non-flaky,5
114096,aws_aws-sdk-java-v2,TableSchemaTest.builder_constructsStaticTableSchemaBuilder,"    @Test
    public void builder_constructsStaticTableSchemaBuilder() {
        StaticTableSchema.Builder<FakeItem> builder = TableSchema.builder(FakeItem.class);
        assertThat(builder).isNotNull();
    }
",non-flaky,5
114097,aws_aws-sdk-java-v2,TableSchemaTest.fromBean_constructsBeanTableSchema,"    @Test
    public void fromBean_constructsBeanTableSchema() {
        BeanTableSchema<SimpleBean> beanBeanTableSchema = TableSchema.fromBean(SimpleBean.class);
        assertThat(beanBeanTableSchema).isNotNull();
    }
",non-flaky,5
114098,aws_aws-sdk-java-v2,TableSchemaTest.fromImmutable_constructsImmutableTableSchema,"    @Test
    public void fromImmutable_constructsImmutableTableSchema() {
        ImmutableTableSchema<SimpleImmutable> immutableTableSchema =
            TableSchema.fromImmutableClass(SimpleImmutable.class);

        assertThat(immutableTableSchema).isNotNull();
    }
",non-flaky,5
114099,aws_aws-sdk-java-v2,TableSchemaTest.fromClass_constructsBeanTableSchema,"    @Test
    public void fromClass_constructsBeanTableSchema() {
        TableSchema<SimpleBean> tableSchema = TableSchema.fromClass(SimpleBean.class);
        assertThat(tableSchema).isInstanceOf(BeanTableSchema.class);
    }
",non-flaky,5
114100,aws_aws-sdk-java-v2,TableSchemaTest.fromClass_constructsImmutableTableSchema,"    @Test
    public void fromClass_constructsImmutableTableSchema() {
        TableSchema<SimpleImmutable> tableSchema = TableSchema.fromClass(SimpleImmutable.class);
        assertThat(tableSchema).isInstanceOf(ImmutableTableSchema.class);
    }
",non-flaky,5
114101,aws_aws-sdk-java-v2,TableSchemaTest.fromClass_invalidClassThrowsException,"    @Test
    public void fromClass_invalidClassThrowsException() {
        exception.expect(IllegalArgumentException.class);
        exception.expectMessage(""InvalidBean"");
        TableSchema.fromClass(InvalidBean.class);
    }
",non-flaky,5
114102,aws_aws-sdk-java-v2,EnhancedTypeDocumentationConfigurationTest.defaultBuilder_defaultToFalse,"    @Test
    public void defaultBuilder_defaultToFalse() {
        EnhancedTypeDocumentConfiguration configuration =
            EnhancedTypeDocumentConfiguration.builder().build();
        assertThat(configuration.ignoreNulls()).isFalse();
        assertThat(configuration.preserveEmptyObject()).isFalse();
    }
",non-flaky,5
114103,aws_aws-sdk-java-v2,EnhancedTypeDocumentationConfigurationTest.equalsHashCode,"    @Test
    public void equalsHashCode() {
        EnhancedTypeDocumentConfiguration configuration =
            EnhancedTypeDocumentConfiguration.builder()
                                             .preserveEmptyObject(true)
                                             .ignoreNulls(false)
                                             .build();

        EnhancedTypeDocumentConfiguration another =
            EnhancedTypeDocumentConfiguration.builder()
                                             .preserveEmptyObject(true)
                                             .ignoreNulls(false)
                                             .build();

        EnhancedTypeDocumentConfiguration different =
            EnhancedTypeDocumentConfiguration.builder()
                                             .preserveEmptyObject(false)
                                             .ignoreNulls(true)
                                             .build();

        assertThat(configuration).isEqualTo(another);
        assertThat(configuration.hashCode()).isEqualTo(another.hashCode());
        assertThat(configuration).isNotEqualTo(different);
        assertThat(configuration.hashCode()).isNotEqualTo(different.hashCode());
    }
",non-flaky,5
114104,aws_aws-sdk-java-v2,TypeConvertingVisitorTest.defaultConvertersThrowExceptions,"    @Test
    public void defaultConvertersThrowExceptions() {
        assertThat(DefaultVisitor.INSTANCE.convert(EnhancedAttributeValue.nullValue())).isEqualTo(null);

        assertDefaultConversionFails(EnhancedAttributeValue.fromString(""foo""));
        assertDefaultConversionFails(EnhancedAttributeValue.fromNumber(""1""));
        assertDefaultConversionFails(EnhancedAttributeValue.fromBoolean(true));
        assertDefaultConversionFails(EnhancedAttributeValue.fromBytes(SdkBytes.fromUtf8String("""")));
        assertDefaultConversionFails(EnhancedAttributeValue.fromSetOfStrings(Collections.emptyList()));
        assertDefaultConversionFails(EnhancedAttributeValue.fromSetOfNumbers(Collections.emptyList()));
        assertDefaultConversionFails(EnhancedAttributeValue.fromSetOfBytes(Collections.emptyList()));
        assertDefaultConversionFails(EnhancedAttributeValue.fromListOfAttributeValues(Collections.emptyList()));
        assertDefaultConversionFails(EnhancedAttributeValue.fromMap(Collections.emptyMap()));
    }
",non-flaky,5
114105,aws_aws-sdk-java-v2,OptionalAttributeConvertersTest.optionalDoubleConverterWorksCorrectly,"    @Test
    public void optionalDoubleConverterWorksCorrectly() {
        OptionalDoubleAttributeConverter converter = OptionalDoubleAttributeConverter.create();

        assertThat(transformFrom(converter, OptionalDouble.empty())).isEqualTo(nullValue().toAttributeValue());
        assertThat(transformFrom(converter, OptionalDouble.of(-Double.MAX_VALUE))).isEqualTo(fromNumber(""-1.7976931348623157E308"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalDouble.of(-Double.MIN_VALUE))).isEqualTo(fromNumber(""-4.9E-324"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalDouble.of(0.0))).isEqualTo(fromNumber(""0.0"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalDouble.of(Double.MIN_VALUE))).isEqualTo(fromNumber(""4.9E-324"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalDouble.of(Double.MAX_VALUE))).isEqualTo(fromNumber(""1.7976931348623157E308"").toAttributeValue());

        assertThat(transformTo(converter, nullValue().toAttributeValue())).isEmpty();
        assertThat(transformTo(converter, fromNumber(""-1.7976931348623157E308""))).hasValue(-Double.MAX_VALUE);
        assertThat(transformTo(converter, fromNumber(""-4.9E-324""))).hasValue(-Double.MIN_VALUE);
        assertThat(transformTo(converter, fromNumber(""0.0""))).hasValue(0.0);
        assertThat(transformTo(converter, fromNumber(""4.9E-324""))).hasValue(Double.MIN_VALUE);
        assertThat(transformTo(converter, fromNumber(""1.7976931348623157E308""))).hasValue(Double.MAX_VALUE);
    }
",non-flaky,5
114106,aws_aws-sdk-java-v2,OptionalAttributeConvertersTest.optionalIntConverterWorksCorrectly,"    @Test
    public void optionalIntConverterWorksCorrectly() {
        OptionalIntAttributeConverter converter = OptionalIntAttributeConverter.create();

        assertThat(transformFrom(converter, OptionalInt.empty())).isEqualTo(nullValue().toAttributeValue());
        assertThat(transformFrom(converter, OptionalInt.of(Integer.MIN_VALUE))).isEqualTo(fromNumber(""-2147483648"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalInt.of(0))).isEqualTo(fromNumber(""0"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalInt.of(Integer.MAX_VALUE))).isEqualTo(fromNumber(""2147483647"").toAttributeValue());

        assertThat(transformTo(converter, nullValue().toAttributeValue())).isEmpty();
        assertThat(transformTo(converter, fromNumber(""-2147483648""))).hasValue(Integer.MIN_VALUE);
        assertThat(transformTo(converter, fromNumber(""0""))).hasValue(0);
        assertThat(transformTo(converter, fromNumber(""2147483647""))).hasValue(Integer.MAX_VALUE);
    }
",non-flaky,5
114107,aws_aws-sdk-java-v2,OptionalAttributeConvertersTest.optionalLongConverterWorksCorrectly,"    @Test
    public void optionalLongConverterWorksCorrectly() {
        OptionalLongAttributeConverter converter = OptionalLongAttributeConverter.create();

        assertThat(transformFrom(converter, OptionalLong.empty())).isEqualTo(nullValue().toAttributeValue());
        assertThat(transformFrom(converter, OptionalLong.of(Long.MIN_VALUE))).isEqualTo(fromNumber(""-9223372036854775808"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalLong.of(0))).isEqualTo(fromNumber(""0"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalLong.of(Long.MAX_VALUE))).isEqualTo(fromNumber(""9223372036854775807"").toAttributeValue());

        assertThat(transformTo(converter, nullValue().toAttributeValue())).isEmpty();
        assertThat(transformTo(converter, fromNumber(""-9223372036854775808""))).hasValue(Long.MIN_VALUE);
        assertThat(transformTo(converter, fromNumber(""0""))).hasValue(0);
        assertThat(transformTo(converter, fromNumber(""9223372036854775807""))).hasValue(Long.MAX_VALUE);
    }
",non-flaky,5
114108,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterMinTest,"    @Test
    public void InstantAsStringAttributeConverterMinTest() {
        verifyTransform(Instant.MIN, ""-1000000000-01-01T00:00:00Z"");
    }
",non-flaky,5
114109,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterEpochMinusOneMilliTest,"    @Test
    public void InstantAsStringAttributeConverterEpochMinusOneMilliTest() {
        verifyTransform(Instant.EPOCH.minusMillis(1), ""1969-12-31T23:59:59.999Z"");
    }
",non-flaky,5
114110,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterEpochTest,"    @Test
    public void InstantAsStringAttributeConverterEpochTest() {
        verifyTransform(Instant.EPOCH, ""1970-01-01T00:00:00Z"");
    }
",non-flaky,5
114111,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterEpochPlusOneMilliTest,"    @Test
    public void InstantAsStringAttributeConverterEpochPlusOneMilliTest() {
        verifyTransform(Instant.EPOCH.plusMillis(1), ""1970-01-01T00:00:00.001Z"");
    }
",non-flaky,5
114112,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterMaxTest,"    @Test
    public void InstantAsStringAttributeConverterMaxTest() {
        verifyTransform(Instant.MAX, ""+1000000000-12-31T23:59:59.999999999Z"");
    }
",non-flaky,5
114113,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterExceedLowerBoundTest,"    @Test
    public void InstantAsStringAttributeConverterExceedLowerBoundTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""-1000000001-12-31T23:59:59.999999999Z"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114114,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterInvalidFormatTest,"    @Test
    public void InstantAsStringAttributeConverterInvalidFormatTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""X"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114115,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterExceedHigherBoundTest,"    @Test
    public void InstantAsStringAttributeConverterExceedHigherBoundTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""+1000000001-01-01T00:00:00Z"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114116,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterNotAcceptLocalDateTimeTest,"    @Test
    public void InstantAsStringAttributeConverterNotAcceptLocalDateTimeTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""1988-05-21T00:12:00.000000001"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114117,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterNotAcceptOffsetTimeTest,"    @Test
    public void InstantAsStringAttributeConverterNotAcceptOffsetTimeTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""1988-05-21T00:12:00+01:00"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114118,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterNotAcceptZonedTimeTest,"    @Test
    public void InstantAsStringAttributeConverterNotAcceptZonedTimeTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""1988-05-21T00:12:00+01:00[Europe/Paris]"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114119,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterNotAcceptLocalDateTest,"    @Test
    public void InstantAsStringAttributeConverterNotAcceptLocalDateTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""1988-05-21"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114120,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterNotAcceptLocalTimeTest,"    @Test
    public void InstantAsStringAttributeConverterNotAcceptLocalTimeTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""00:12:00.000000001"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114121,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterNotAcceptMonthDayTest,"    @Test
    public void InstantAsStringAttributeConverterNotAcceptMonthDayTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""05-21"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114122,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterMinTest,"    @Test
    public void localDateTimeAttributeConverterMinTest() {
        verifyTransform(LocalDateTime.MIN, ""-999999999-01-01T00:00"");
    }
",non-flaky,5
114123,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterNormalTest,"    @Test
    public void localDateTimeAttributeConverterNormalTest() {
        verifyTransform(LocalDateTime.of(0, 1, 1, 0, 0, 0, 0), ""0000-01-01T00:00"");
    }
",non-flaky,5
114124,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterMaxTest,"    @Test
    public void localDateTimeAttributeConverterMaxTest() {
        verifyTransform(LocalDateTime.MAX, ""+999999999-12-31T23:59:59.999999999"");
    }
",non-flaky,5
114125,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterLowerBoundTest,"    @Test
    public void localDateTimeAttributeConverterLowerBoundTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""-9999999999-01-01T00:00"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114126,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterHigherBoundTest,"    @Test
    public void localDateTimeAttributeConverterHigherBoundTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""9999999999-12-31T00:00:00"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114127,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterExceedHigherBoundTest,"    @Test
    public void localDateTimeAttributeConverterExceedHigherBoundTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""9999999999-12-32T00:00:00"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114128,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterInvalidNanoSecondsTest,"    @Test
    public void localDateTimeAttributeConverterInvalidNanoSecondsTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""0-01-01T00:00:00.9999999999"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114129,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterNotAcceptInstantTest,"    @Test
    public void localDateTimeAttributeConverterNotAcceptInstantTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""1988-05-21T00:12:00.000000001Z"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114130,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterNotAcceptOffsetTimeTest,"    @Test
    public void localDateTimeAttributeConverterNotAcceptOffsetTimeTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""1988-05-21T00:12:00+01:00"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114131,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterNotAcceptZonedTimeTest,"    @Test
    public void localDateTimeAttributeConverterNotAcceptZonedTimeTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""1988-05-21T00:12:00+01:00[Europe/Paris]"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114132,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterNotAcceptLocalTimeTest,"    @Test
    public void localDateTimeAttributeConverterNotAcceptLocalTimeTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""00:12:00.000000001"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114133,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterNotAcceptMonthDayTest,"    @Test
    public void localDateTimeAttributeConverterNotAcceptMonthDayTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""05-21"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
259,microsoft_botbuilder-java,AdditionalPropertiesSerializerTests.canSerializeAdditionalProperties,"@Test
public void canSerializeAdditionalProperties() throws Exception {
    Foo foo = new Foo();
    foo.bar = ""hello.world"";
    foo.baz = new ArrayList<>();
    foo.baz.add(""hello"");
    foo.baz.add(""hello.world"");
    foo.qux = new HashMap<>();
    foo.qux.put(""hello"", ""world"");
    foo.qux.put(""a.b"", ""c.d"");
    foo.qux.put(""bar.a"", ""ttyy"");
    foo.qux.put(""bar.b"", ""uuzz"");
    foo.additionalProperties = new HashMap<>();
    foo.additionalProperties.put(""bar"", ""baz"");
    foo.additionalProperties.put(""a.b"", ""c.d"");
    foo.additionalProperties.put(""properties.bar"", ""barbar"");
    String serialized = new JacksonAdapter().serialize(foo);
    Assert.assertEquals(""{\""$type\"":\""foo\"",\""properties\"":{\""bar\"":\""hello.world\"",\""props\"":{\""baz\"":[\""hello\"",\""hello.world\""],\""q\"":{\""qux\"":{\""hello\"":\""world\"",\""a.b\"":\""c.d\"",\""bar.b\"":\""uuzz\"",\""bar.a\"":\""ttyy\""}}}},\""bar\"":\""baz\"",\""a.b\"":\""c.d\"",\""properties.bar\"":\""barbar\""}"", serialized);
}",unordered collections,3
148803,microsoft_botbuilder-java,HeroCardTest.testToAttachment,"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.hero"", attachment.getContentType());
    }
",non-flaky,5
148804,microsoft_botbuilder-java,AudioCardTest.testToAttachment,"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.audio"", attachment.getContentType());
    }
",non-flaky,5
148805,microsoft_botbuilder-java,ActivityTest.GetConversationReference,"    @Test
    public void GetConversationReference() {
        Activity activity = createActivity();
        ConversationReference conversationReference = activity.getConversationReference();

        Assert.assertEquals(activity.getId(), conversationReference.getActivityId());
        Assert.assertEquals(activity.getFrom().getId(), conversationReference.getUser().getId());
        Assert.assertEquals(activity.getRecipient().getId(), conversationReference.getBot().getId());
        Assert.assertEquals(activity.getConversation().getId(), conversationReference.getConversation().getId());
        Assert.assertEquals(activity.getLocale(), conversationReference.getLocale());
        Assert.assertEquals(activity.getChannelId(), conversationReference.getChannelId());
        Assert.assertEquals(activity.getServiceUrl(), conversationReference.getServiceUrl());

        activity.setType(ActivityTypes.CONVERSATION_UPDATE);
        conversationReference = activity.getConversationReference();
        Assert.assertNull(conversationReference.getActivityId());

    }
",non-flaky,5
148806,microsoft_botbuilder-java,ActivityTest.GetReplyConversationReference,"    @Test
    public void GetReplyConversationReference() {
        Activity activity = createActivity();

        ResourceResponse reply = new ResourceResponse();
        reply.setId(""1234"");

        ConversationReference conversationReference = activity.getReplyConversationReference(reply);

        Assert.assertEquals(reply.getId(), conversationReference.getActivityId());
        Assert.assertEquals(activity.getFrom().getId(), conversationReference.getUser().getId());
        Assert.assertEquals(activity.getRecipient().getId(), conversationReference.getBot().getId());
        Assert.assertEquals(activity.getConversation().getId(), conversationReference.getConversation().getId());
        Assert.assertEquals(activity.getLocale(), conversationReference.getLocale());
        Assert.assertEquals(activity.getChannelId(), conversationReference.getChannelId());
        Assert.assertEquals(activity.getServiceUrl(), conversationReference.getServiceUrl());
    }
",non-flaky,5
148807,microsoft_botbuilder-java,ActivityTest.ApplyConversationReference_isIncoming,"    @Test
    public void ApplyConversationReference_isIncoming() {
        Activity activity = createActivity();

        ConversationReference conversationReference = new ConversationReference();
        conversationReference.setChannelId(""cr_123"");
        conversationReference.setServiceUrl(""cr_serviceUrl"");
        ConversationAccount conversation = new ConversationAccount();
        conversation.setId(""cr_456"");
        conversationReference.setConversation(conversation);
        ChannelAccount userAccount = new ChannelAccount();
        userAccount.setId(""cr_abc"");
        conversationReference.setUser(userAccount);
        ChannelAccount botAccount = new ChannelAccount();
        botAccount.setId(""cr_def"");
        conversationReference.setBot(botAccount);
        conversationReference.setActivityId(""cr_12345"");
        // Intentionally oddly-cased to check that it isn't defaulted somewhere, but
        // tests stay in English
        conversationReference.setLocale(""en-uS"");

        activity.applyConversationReference(conversationReference, true);

        Assert.assertEquals(conversationReference.getChannelId(), activity.getChannelId());
        Assert.assertEquals(conversationReference.getLocale(), activity.getLocale());
        Assert.assertEquals(conversationReference.getServiceUrl(), activity.getServiceUrl());
        Assert.assertEquals(conversationReference.getConversation().getId(), activity.getConversation().getId());

        Assert.assertEquals(conversationReference.getUser().getId(), activity.getFrom().getId());
        Assert.assertEquals(conversationReference.getBot().getId(), activity.getRecipient().getId());
        Assert.assertEquals(conversationReference.getActivityId(), activity.getId());
    }
",non-flaky,5
148808,microsoft_botbuilder-java,ActivityTest.ApplyConversationReference,"    @Test
    public void ApplyConversationReference() {
        Activity activity = createActivity();

        ConversationReference conversationReference = new ConversationReference();
        conversationReference.setChannelId(""123"");
        conversationReference.setServiceUrl(""serviceUrl"");
        ConversationAccount conversation = new ConversationAccount();
        conversation.setId(""456"");
        conversationReference.setConversation(conversation);
        ChannelAccount userAccount = new ChannelAccount();
        userAccount.setId(""abc"");
        conversationReference.setUser(userAccount);
        ChannelAccount botAccount = new ChannelAccount();
        botAccount.setId(""def"");
        conversationReference.setBot(botAccount);
        conversationReference.setActivityId(""12345"");
        // Intentionally oddly-cased to check that it isn't defaulted somewhere, but
        // tests stay in English
        conversationReference.setLocale(""en-uS"");

        activity.applyConversationReference(conversationReference, false);

        Assert.assertEquals(conversationReference.getChannelId(), activity.getChannelId());
        Assert.assertEquals(conversationReference.getLocale(), activity.getLocale());
        Assert.assertEquals(conversationReference.getServiceUrl(), activity.getServiceUrl());
        Assert.assertEquals(conversationReference.getConversation().getId(), activity.getConversation().getId());

        Assert.assertEquals(conversationReference.getBot().getId(), activity.getFrom().getId());
        Assert.assertEquals(conversationReference.getUser().getId(), activity.getRecipient().getId());
        Assert.assertEquals(conversationReference.getActivityId(), activity.getReplyToId());
    }
",non-flaky,5
148809,microsoft_botbuilder-java,ActivityTest.ApplyConversationReferenceOverload,"    @Test
    public void ApplyConversationReferenceOverload() {
        Activity activity = createActivity();

        ConversationReference conversationReference = new ConversationReference();
        conversationReference.setChannelId(""123"");
        conversationReference.setServiceUrl(""serviceUrl"");
        ConversationAccount conversation = new ConversationAccount();
        conversation.setId(""456"");
        conversationReference.setConversation(conversation);
        ChannelAccount userAccount = new ChannelAccount();
        userAccount.setId(""abc"");
        conversationReference.setUser(userAccount);
        ChannelAccount botAccount = new ChannelAccount();
        botAccount.setId(""def"");
        conversationReference.setBot(botAccount);
        conversationReference.setActivityId(""12345"");
        // Intentionally oddly-cased to check that it isn't defaulted somewhere, but
        // tests stay in English
        conversationReference.setLocale(""en-uS"");

        activity.applyConversationReference(conversationReference);

        Assert.assertEquals(conversationReference.getChannelId(), activity.getChannelId());
        Assert.assertEquals(conversationReference.getLocale(), activity.getLocale());
        Assert.assertEquals(conversationReference.getServiceUrl(), activity.getServiceUrl());
        Assert.assertEquals(conversationReference.getConversation().getId(), activity.getConversation().getId());

        Assert.assertEquals(conversationReference.getBot().getId(), activity.getFrom().getId());
        Assert.assertEquals(conversationReference.getUser().getId(), activity.getRecipient().getId());
        Assert.assertEquals(conversationReference.getActivityId(), activity.getReplyToId());
    }
",non-flaky,5
148810,microsoft_botbuilder-java,ActivityTest.ApplyConversationReferenceOverloadAlternatePaths,"    @Test
    public void ApplyConversationReferenceOverloadAlternatePaths() {
        Activity activity = createActivity();

        ConversationReference conversationReference = new ConversationReference();
        conversationReference.setChannelId(""123"");
        conversationReference.setServiceUrl(""serviceUrl"");
        ConversationAccount conversation = new ConversationAccount();
        conversation.setId(""456"");
        conversationReference.setConversation(conversation);
        ChannelAccount userAccount = new ChannelAccount();
        userAccount.setId(""abc"");
        conversationReference.setUser(userAccount);
        ChannelAccount botAccount = new ChannelAccount();
        botAccount.setId(""def"");
        conversationReference.setBot(botAccount);
        conversationReference.setActivityId(null);
        conversationReference.setLocale(null);

        activity.applyConversationReference(conversationReference, false);

        Assert.assertEquals(conversationReference.getChannelId(), activity.getChannelId());
        Assert.assertEquals(""en-uS"", activity.getLocale());
        Assert.assertEquals(conversationReference.getServiceUrl(), activity.getServiceUrl());
        Assert.assertEquals(conversationReference.getConversation().getId(), activity.getConversation().getId());

        Assert.assertEquals(conversationReference.getBot().getId(), activity.getFrom().getId());
        Assert.assertEquals(conversationReference.getUser().getId(), activity.getRecipient().getId());
        Assert.assertEquals(conversationReference.getActivityId(), activity.getReplyToId());

        activity.applyConversationReference(conversationReference, true);

        Assert.assertEquals(conversationReference.getChannelId(), activity.getChannelId());
        Assert.assertEquals(""en-uS"", activity.getLocale());
        Assert.assertEquals(conversationReference.getServiceUrl(), activity.getServiceUrl());
        Assert.assertEquals(conversationReference.getConversation().getId(), activity.getConversation().getId());

        Assert.assertEquals(conversationReference.getUser().getId(), activity.getFrom().getId());
        Assert.assertEquals(conversationReference.getBot().getId(), activity.getRecipient().getId());
        Assert.assertEquals(conversationReference.getActivityId(), activity.getReplyToId());
    }
",non-flaky,5
148811,microsoft_botbuilder-java,ActivityTest.CreateTraceAllowsNullRecipient,"    @Test
    public void CreateTraceAllowsNullRecipient() {
        Activity activity = createActivity();
        activity.setRecipient(null);
        Activity trace = activity.createTrace(""test"");

        Assert.assertNull(trace.getFrom().getId());
    }
",non-flaky,5
148812,microsoft_botbuilder-java,ActivityTest.DeserializeActivity,"    @Test
    public void DeserializeActivity() throws IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();
        Activity activity = objectMapper.readValue(this.serializedActivity, Activity.class);

        Assert.assertNotNull(activity.getTimestamp());
        Assert.assertEquals(""b18a1c99-7a29-4801-ac0c-579f2c36d52c"", activity.getConversation().getId());
        Assert.assertNotNull(activity.getValue());
    }
",non-flaky,5
148813,microsoft_botbuilder-java,ActivityTest.DeserializeActivityWithDifferentTimeZone,"    @Test
    public void DeserializeActivityWithDifferentTimeZone() throws IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();
        Activity activity = objectMapper.readValue(this.serializedActivityWithDifferentTimeZone, Activity.class);

        Assert.assertNotNull(activity.getTimestamp());
        Assert.assertEquals(""b18a1c99-7a29-4801-ac0c-579f2c36d52c"", activity.getConversation().getId());
        Assert.assertNotNull(activity.getValue());
    }
",non-flaky,5
148814,microsoft_botbuilder-java,ActivityTest.GetInformationForMicrosoftTeams,"    @Test
    public void GetInformationForMicrosoftTeams() throws JsonProcessingException, IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();
        Activity activity = objectMapper.readValue(ActivityTest.serializedActivityFromTeams, Activity.class);
        Assert.assertEquals(""19:123cb42aa5a0a7e56f83@thread.skype"", activity.teamsGetChannelId());
        Assert.assertEquals(""19:104f2cb42aa5a0a7e56f83@thread.skype"", activity.teamsGetTeamId());
        Assert.assertEquals(true, activity.isTeamsActivity());

        activity = objectMapper.readValue(ActivityTest.serializedActivityFromTeamsWithoutTeamsChannelIdorTeamId,
                Activity.class);

        Assert.assertEquals(""channel_id"", activity.teamsGetChannelId());
        Assert.assertEquals(""team_id"", activity.teamsGetTeamId());

        TeamsChannelData teamsChannelData = activity.getChannelData(TeamsChannelData.class);
        Assert.assertEquals(""channel_id"", teamsChannelData.getChannel().getId());
        Assert.assertEquals(""channel_name"", teamsChannelData.getChannel().getName());
        Assert.assertEquals(""team_id"", teamsChannelData.getTeam().getId());
        Assert.assertEquals(""team_name"", teamsChannelData.getTeam().getName());
        Assert.assertEquals(""aad_groupid"", teamsChannelData.getTeam().getAadGroupId());
        Assert.assertEquals(true, teamsChannelData.getNotification().getAlert());
        Assert.assertEquals(""teamMemberAdded"", teamsChannelData.getEventType());
        Assert.assertEquals(""tenant_id"", teamsChannelData.getTenant().getId());
    }
",non-flaky,5
148815,microsoft_botbuilder-java,ActivityTest.GetTeamsChannelIdBadChannelData,"    @Test
    public void GetTeamsChannelIdBadChannelData() {
        Activity activity = new Activity();
        activity.setChannelData(""badChannelData"");
        String channelId = activity.teamsGetChannelId();
        Assert.assertNull(channelId);
    }
",non-flaky,5
148816,microsoft_botbuilder-java,ActivityTest.GetTeamsTeamIdBadChannelData,"    @Test
    public void GetTeamsTeamIdBadChannelData() {
        Activity activity = new Activity();
        activity.setChannelData(""badChannelData"");
        String channelId = activity.teamsGetTeamId();
        Assert.assertNull(channelId);
    }
",non-flaky,5
148817,microsoft_botbuilder-java,ActivityTest.GetTeamsTeamIdNullChannelData,"    @Test
    public void GetTeamsTeamIdNullChannelData() {
        Activity activity = new Activity();
        String channelId = activity.teamsGetTeamId();
        Assert.assertNull(channelId);
    }
",non-flaky,5
148818,microsoft_botbuilder-java,ActivityTest.GetTeamsGetInfo,"    @Test
    public void GetTeamsGetInfo() throws JsonProcessingException, IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();

        Activity activity = objectMapper.readValue(
            ActivityTest.serializedActivityFromTeamsWithoutTeamsChannelIdorTeamId, Activity.class);

        TeamInfo teamsInfo = activity.teamsGetTeamInfo();
        Assert.assertNotNull(teamsInfo);
    }
",non-flaky,5
148819,microsoft_botbuilder-java,ActivityTest.GetTeamsGetInfoBadChannelData,"    @Test
    public void GetTeamsGetInfoBadChannelData() {
        Activity activity = new Activity();
        activity.setChannelData(""badChannelData"");
        TeamInfo teamInfo = activity.teamsGetTeamInfo();
        Assert.assertNull(teamInfo);
    }
",non-flaky,5
148820,microsoft_botbuilder-java,ActivityTest.TeamsNotifyUser,"    @Test
    public void TeamsNotifyUser() throws JsonProcessingException, IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();
        Activity activity = objectMapper.readValue(
            ActivityTest.serializedActivityFromTeamsWithoutNotificationTeamsChannelIdOrTeamId, Activity.class);

        TeamsChannelData channelData = activity.teamsGetChannelData();
        Assert.assertNull(channelData.getNotification());
        activity.teamsNotifyUser();
        Assert.assertNotNull(activity.teamsGetChannelData().getNotification());
    }
",non-flaky,5
148821,microsoft_botbuilder-java,ActivityTest.TeamsNotifyUserBadChannelData,"    @Test
    public void TeamsNotifyUserBadChannelData() throws JsonProcessingException, IOException {
        Activity activity = new Activity();
        activity.setChannelData(""badChannelData"");

        TeamsChannelData channelData = activity.teamsGetChannelData();
        Assert.assertNull(channelData);
        activity.teamsNotifyUser();
        Assert.assertNotNull(activity.teamsGetChannelData().getNotification());
    }
",non-flaky,5
148822,microsoft_botbuilder-java,ActivityTest.TeamsNotifyUserAlertInMeeting,"    @Test
    public void TeamsNotifyUserAlertInMeeting() throws JsonProcessingException, IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();
        Activity activity = objectMapper.readValue(
            ActivityTest.serializedActivityFromTeamsWithoutNotificationTeamsChannelIdOrTeamId, Activity.class);

        TeamsChannelData channelData = activity.teamsGetChannelData();
        Assert.assertNull(channelData.getNotification());
        activity.teamsNotifyUser(true, ""externalresourceURL"");
        Assert.assertNotNull(activity.teamsGetChannelData().getNotification());
        Assert.assertEquals(activity.teamsGetChannelData().getNotification().getExternalResourceUrl(),
                            ""externalresourceURL"");
        Assert.assertTrue(activity.teamsGetChannelData().getNotification().getAlertInMeeting());
    }
",non-flaky,5
148823,microsoft_botbuilder-java,ActivityTest.TeamsNotifyUserAlertInMeetingBadChannelData,"    @Test
    public void TeamsNotifyUserAlertInMeetingBadChannelData() throws JsonProcessingException, IOException {
        Activity activity = new Activity();
        activity.setChannelData(""badChannelData"");

        Assert.assertNull(activity.teamsGetChannelData());
        activity.teamsNotifyUser(true, ""externalresourceURL"");
        Assert.assertNotNull(activity.teamsGetChannelData().getNotification());
        Assert.assertEquals(activity.teamsGetChannelData().getNotification().getExternalResourceUrl(),
                            ""externalresourceURL"");
        Assert.assertTrue(activity.teamsGetChannelData().getNotification().getAlertInMeeting());
    }
",non-flaky,5
148824,microsoft_botbuilder-java,ActivityTest.TeamsGetMeetingInfoNull,"    @Test
    public void TeamsGetMeetingInfoNull() throws JsonProcessingException, IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();
        Activity activity = objectMapper.readValue(
            ActivityTest.serializedActivityFromTeamsWithoutNotificationTeamsChannelIdOrTeamId, Activity.class);

        TeamsMeetingInfo meetingInfo = activity.teamsGetMeetingInfo();
        Assert.assertNull(meetingInfo);
    }
",non-flaky,5
148825,microsoft_botbuilder-java,ActivityTest.TeamsGetMeetingInfo,"    @Test
    public void TeamsGetMeetingInfo() throws JsonProcessingException, IOException {
        Activity activity = new Activity();
        TeamsChannelData channelData = new TeamsChannelData();
        TeamsMeetingInfo meeting = new TeamsMeetingInfo();
        meeting.setId(""meetingId"");
        channelData.setMeeting(meeting);
        activity.setChannelData(channelData);

        TeamsMeetingInfo meetingInfo = activity.teamsGetMeetingInfo();
        Assert.assertNotNull(meetingInfo);
        Assert.assertEquals(meetingInfo.getId(), ""meetingId"");
    }
",non-flaky,5
148826,microsoft_botbuilder-java,ActivityTest.TeamsGetMeetingInfoBadChannelData,"    @Test
    public void TeamsGetMeetingInfoBadChannelData() throws JsonProcessingException, IOException {
        Activity activity = new Activity();
        activity.setChannelData(""badChannelData"");

        TeamsMeetingInfo meetingInfo = activity.teamsGetMeetingInfo();
        Assert.assertNull(meetingInfo);
    }
",non-flaky,5
148827,microsoft_botbuilder-java,ActivityTest.CreateMessageActivity,"    @Test
    public void CreateMessageActivity() {
        Activity activity = Activity.createMessageActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.MESSAGE);
    }
",non-flaky,5
148828,microsoft_botbuilder-java,ActivityTest.CreateContactRelationUpdateActivity,"    @Test
    public void CreateContactRelationUpdateActivity() {
        Activity activity = Activity.createContactRelationUpdateActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.CONTACT_RELATION_UPDATE);
    }
",non-flaky,5
148829,microsoft_botbuilder-java,ActivityTest.CreateConversationUpdateActivity,"    @Test
    public void CreateConversationUpdateActivity() {
        Activity activity = Activity.createConversationUpdateActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.CONVERSATION_UPDATE);
    }
",non-flaky,5
148830,microsoft_botbuilder-java,ActivityTest.CreateTypingActivity,"    @Test
    public void CreateTypingActivity() {
        Activity activity = Activity.createTypingActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.TYPING);
    }
",non-flaky,5
148831,microsoft_botbuilder-java,ActivityTest.CreateHandoffActivity,"    @Test
    public void CreateHandoffActivity() {
        Activity activity = Activity.createHandoffActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.HANDOFF);
    }
",non-flaky,5
148832,microsoft_botbuilder-java,ActivityTest.CreateEndOfConversationActivity,"    @Test
    public void CreateEndOfConversationActivity() {
        Activity activity = Activity.createEndOfConversationActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.END_OF_CONVERSATION);
    }
",non-flaky,5
148833,microsoft_botbuilder-java,ActivityTest.CreateEventActivity,"    @Test
    public void CreateEventActivity() {
        Activity activity = Activity.createEventActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.EVENT);
    }
",non-flaky,5
148834,microsoft_botbuilder-java,ActivityTest.CreateInvokeActivity,"    @Test
    public void CreateInvokeActivity() {
        Activity activity = Activity.createInvokeActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.INVOKE);
    }
",non-flaky,5
148835,microsoft_botbuilder-java,ActivityTest.CreateTraceActivity,"    @Test
    public void CreateTraceActivity() {
        String name = ""test-activity"";
        String valueType = ""string"";
        String value = ""test-value"";
        String label = ""test-label"";

        Activity activity = Activity.createTraceActivity(name, valueType, value, label);

        Assert.assertEquals(activity.getType(), ActivityTypes.TRACE);
        Assert.assertEquals(activity.getName(), name);
        Assert.assertEquals(activity.getValueType(), valueType);
        Assert.assertEquals(activity.getValue(), value);
        Assert.assertEquals(activity.getLabel(), label);

        Activity secondActivity = Activity.createTraceActivity(name);
        Assert.assertEquals(secondActivity.getType(), ActivityTypes.TRACE);
        Assert.assertEquals(secondActivity.getName(), name);

        Activity thirdActivity = Activity.createTraceActivity(name, null, value, label);
        Assert.assertEquals(thirdActivity.getType(), ActivityTypes.TRACE);
        Assert.assertEquals(thirdActivity.getName(), name);

        Assert.assertTrue(thirdActivity.isType(ActivityTypes.TRACE));
    }
",non-flaky,5
148836,microsoft_botbuilder-java,ActivityTest.CreateTraceActivityWithoutValueType,"    @Test
    public void CreateTraceActivityWithoutValueType() {
        String name = ""test-activity"";
        String value = ""test-value"";
        String label = ""test-label"";

        Activity activity = Activity.createTraceActivity(name, null, value, label);

        Assert.assertEquals(activity.getType(), ActivityTypes.TRACE);
        Assert.assertEquals(activity.getValueType(), value.getClass().getTypeName());
        Assert.assertEquals(activity.getLabel(), label);
    }
",non-flaky,5
148837,microsoft_botbuilder-java,ActivityTest.CreateReply,"    @Test
    public void CreateReply() {
        Activity activity = createActivity();

        String text = ""test-reply"";
        String locale = ""en-us"";

        Activity reply = activity.createReply(text, locale);

        Assert.assertEquals(reply.getType(), ActivityTypes.MESSAGE);
        Assert.assertEquals(reply.getText(), text);
        Assert.assertEquals(reply.getLocale(), locale);

        activity.setFrom(null);
        activity.setRecipient(null);
        activity.setConversation(null);
        Activity reply2 = activity.createReply(text);
        Assert.assertEquals(reply2.getType(), ActivityTypes.MESSAGE);
        Assert.assertEquals(reply2.getText(), text);
        Assert.assertEquals(reply2.getLocale(), ""en-uS"");
        Assert.assertTrue(reply2.getFrom() != null);
        Assert.assertTrue(reply2.getRecipient() != null);
        Assert.assertTrue(reply2.getConversation() != null);
    }
",non-flaky,5
148838,microsoft_botbuilder-java,ActivityTest.CreateReplyWithoutArguments,"    @Test
    public void CreateReplyWithoutArguments() {
        Activity activity = createActivity();

        Activity reply = activity.createReply();

        Assert.assertEquals(reply.getType(), ActivityTypes.MESSAGE);
        Assert.assertEquals(reply.getText(), """");
        Assert.assertEquals(reply.getLocale(), activity.getLocale());
    }
",non-flaky,5
148839,microsoft_botbuilder-java,ActivityTest.HasContentIsFalseWhenActivityTextHasNoContent,"    @Test
    public void HasContentIsFalseWhenActivityTextHasNoContent() {
        Activity activity = createActivity();

        boolean result = activity.hasContent();

        Assert.assertEquals(result, false);
    }
",non-flaky,5
148840,microsoft_botbuilder-java,ActivityTest.HasContentIsTrueWhenActivityTextHasContent,"    @Test
    public void HasContentIsTrueWhenActivityTextHasContent() {
        Activity activity = createActivity();

        activity.setText(""test-text"");

        boolean result = activity.hasContent();

        Assert.assertEquals(result, true);
    }
",non-flaky,5
148841,microsoft_botbuilder-java,ActivityTest.HasContentIsTrueWhenActivitySummaryContent,"    @Test
    public void HasContentIsTrueWhenActivitySummaryContent() {
        Activity activity = createActivity();

        activity.setText(null);
        activity.setSummary(""test-summary"");

        boolean result = activity.hasContent();

        Assert.assertEquals(result, true);
    }
",non-flaky,5
148842,microsoft_botbuilder-java,ActivityTest.HasContentIsTrueWhenActivityAttachmentsHaveContent,"    @Test
    public void HasContentIsTrueWhenActivityAttachmentsHaveContent() {
        Activity activity = createActivity();
        ArrayList<Attachment> attachments = new ArrayList<>();
        attachments.add(CreateAttachment());

        activity.setText(null);
        activity.setSummary(null);
        activity.setAttachments(attachments);

        boolean result = activity.hasContent();

        Assert.assertEquals(result, true);
    }
",non-flaky,5
148843,microsoft_botbuilder-java,ActivityTest.HasContentIsTrueWhenActivityChannelDataHasContent,"    @Test
    public void HasContentIsTrueWhenActivityChannelDataHasContent() {
        Activity activity = createActivity();

        activity.setText(null);
        activity.setSummary(null);
        activity.setChannelData(""test-channelData"");

        boolean result = activity.hasContent();

        Assert.assertEquals(result, true);
    }
",non-flaky,5
148844,microsoft_botbuilder-java,ActivityTest.GetMentions,"    @Test
    public void GetMentions() {
        ArrayList<Entity> mentions = new ArrayList<Entity>();

        Entity mentionEntity = new Entity();
        mentionEntity.setType(""mention"");
        mentions.add(mentionEntity);
        Entity reactionEntity = new Entity();
        reactionEntity.setType(""reaction"");
        mentions.add(reactionEntity);

        Activity activity = createActivity();

        activity.setEntities(mentions);

        List<Mention> mentionsResult = activity.getMentions();

        Assert.assertEquals(mentionsResult.size(), 1);
        Assert.assertEquals(mentionsResult.get(0).getType(), ""mention"");
    }
",non-flaky,5
148845,microsoft_botbuilder-java,ActivityTest.GetMentionsNull,"    @Test
    public void GetMentionsNull() {
        Activity activity = createActivity();
        activity.setEntities(null);
        Assert.assertTrue(activity.getMentions() != null);
    }
",non-flaky,5
148846,microsoft_botbuilder-java,ActivityTest.CreateTraceForConversationUpdateActivity,"    @Test
    public void CreateTraceForConversationUpdateActivity() {
        Activity activity = createActivity();
        activity.setType(ActivityTypes.CONVERSATION_UPDATE);
        Activity trace = activity.createTrace(""test"");
        Assert.assertNull(trace.getReplyToId());
    }
",non-flaky,5
148847,microsoft_botbuilder-java,ActivityTest.CreateReplyForConversationUpdateActivity,"    @Test
    public void CreateReplyForConversationUpdateActivity() {
        Activity activity = createActivity();
        activity.setType(ActivityTypes.CONVERSATION_UPDATE);
        Activity reply = activity.createReply(""test"");
        Assert.assertNull(reply.getReplyToId());
    }
",non-flaky,5
148848,microsoft_botbuilder-java,ActivityTest.CreateTrace,"    @Test
    public void CreateTrace() {
        Activity activity = createActivity();

        String name = ""test-activity"";
        String value = ""test-value"";
        String valueType = ""string"";
        String label = ""test-label"";

        Activity trace = activity.createTrace(name, value, valueType, label);

        Assert.assertEquals(trace.getType(), ActivityTypes.TRACE);
        Assert.assertEquals(trace.getName(), name);
        Assert.assertEquals(trace.getValue(), value);
        Assert.assertEquals(trace.getValueType(), valueType);
        Assert.assertEquals(trace.getLabel(), label);

        Activity secondActivity = createActivity();
        secondActivity.setRecipient(null);
        secondActivity.setFrom(null);
        Activity secondTrace = secondActivity.createTrace(name, value, null, label);
        Assert.assertEquals(secondTrace.getType(), ActivityTypes.TRACE);
        Assert.assertEquals(secondTrace.getName(), name);
        Assert.assertEquals(secondTrace.getValue(), value);
        Assert.assertEquals(secondTrace.getValueType(), value.getClass().getTypeName());
        Assert.assertEquals(secondTrace.getLabel(), label);
        Assert.assertTrue(secondTrace.getRecipient() != null);
        Assert.assertTrue(secondTrace.getFrom() != null);
    }
",non-flaky,5
148849,microsoft_botbuilder-java,ActivityTest.IsFromStreamingConnection,"    @Test
    public void IsFromStreamingConnection() {
        ArrayList<String> nonStreaming = new ArrayList<>();
        nonStreaming.add(""http://yayay.com"");
        nonStreaming.add(""https://yayay.com"");
        nonStreaming.add(""HTTP://yayay.com"");
        nonStreaming.add(""HTTPS://yayay.com"");

        ArrayList<String> streaming = new ArrayList<>();
        streaming.add(""urn:botframework:WebSocket:wss://beep.com"");
        streaming.add(""urn:botframework:WebSocket:http://beep.com"");
        streaming.add(""URN:botframework:WebSocket:wss://beep.com"");
        streaming.add(""URN:botframework:WebSocket:http://beep.com"");

        Activity activity = createActivity();
        activity.setServiceUrl(null);

        Assert.assertFalse(activity.isFromStreamingConnection());

        nonStreaming.forEach(s ->
        {
            activity.setServiceUrl(s);
            Assert.assertFalse(activity.isFromStreamingConnection());
        });

        streaming.forEach(s ->
        {
            activity.setServiceUrl(s);
            Assert.assertTrue(activity.isFromStreamingConnection());
        });
    }
",non-flaky,5
148850,microsoft_botbuilder-java,ActivityTest.ActivityCloneTest,"    @Test
    public void ActivityCloneTest() throws JsonProcessingException {
        Activity activity = new Activity(ActivityTypes.MESSAGE);
        activity.setAction(""TestAction"");

        Attachment attachment = new Attachment();
        attachment.setContentType(""testContentType"");
        attachment.setContentUrl(""testContentUrl"");
        attachment.setContent(""testContent"");
        attachment.setName(""testName"");
        attachment.setThumbnailUrl(""testThumbnailUrl"");
        attachment.setProperties(""testProperty"", getTestNode());
        activity.setAttachment(attachment);

        activity.setCallerId(""testCallerId"");
        activity.setChannelData(""testChannelData"");
        activity.setCode(EndOfConversationCodes.BOT_TIMED_OUT);

        ConversationAccount conversation = new ConversationAccount(""testConversation"");
        activity.setConversation(conversation);

        activity.setDeliveryMode(""testDeliveryMode"");

        List<Entity> entityList = new ArrayList<Entity>();
        Entity entity1 = new Entity();
        entity1.setType(""testEntity"");
        entityList.add(entity1);
        activity.setEntities(entityList);

        LocalDateTime expiration = LocalDateTime.now();
        activity.setExpiration(expiration);

        ChannelAccount fromChannel = new ChannelAccount(""fromChannel"");
        activity.setFrom(fromChannel);

        activity.setHistoryDisclosed(true);
        activity.setId(""testId"");
        activity.setImportance(""testImportance"");
        activity.setInputHint(InputHints.ACCEPTING_INPUT);
        activity.setLabel(""testLabel"");

        List<String> listen = new ArrayList<String>();
        listen.add(""listen1"");
        listen.add(""listen2"");
        activity.setListenFor(listen);

        activity.setLocalTimeZone(""testLocalTimeZone"");
        OffsetDateTime offsetDateTime = OffsetDateTime.now();
        activity.setLocalTimestamp(offsetDateTime);
        activity.setLocale(""testLocale"");

        List<ChannelAccount> membersAdded = new ArrayList<ChannelAccount>();
        ChannelAccount firstMember = new ChannelAccount(""firstMember"");
        ChannelAccount secondMember = new ChannelAccount(""secondMember"");
        membersAdded.add(firstMember);
        membersAdded.add(secondMember);
        activity.setMembersAdded(membersAdded);

        List<ChannelAccount> membersRemoved = new ArrayList<ChannelAccount>();
        ChannelAccount firstMemberRemoved = new ChannelAccount(""firstMember"");
        ChannelAccount secondMemberRemoved = new ChannelAccount(""secondMember"");
        membersRemoved.add(firstMemberRemoved);
        membersRemoved.add(secondMemberRemoved);
        activity.setMembersRemoved(membersRemoved);

        List<Mention> mentions = new ArrayList<Mention>();
        Mention firstMention = new Mention();
        firstMention.setText(""testTest"");
        firstMention.setMentioned(firstMember);
        Mention secondMention = new Mention();
        secondMention.setText(""testTest"");
        secondMention.setMentioned(firstMember);
        mentions.add(secondMention);
        activity.setMentions(mentions);

        activity.setName(""testName"");
        activity.setProperties(""testProperty"", getTestNode());

        List<MessageReaction> reactionsAdded = new ArrayList<MessageReaction>();
        MessageReaction firstReaction = new MessageReaction();
        firstReaction.setType(""testType"");
        reactionsAdded.add(firstReaction);
        MessageReaction secondReaction = new MessageReaction();
        secondReaction.setType(""testType"");
        reactionsAdded.add(secondReaction);
        activity.setReactionsAdded(reactionsAdded);

        List<MessageReaction> reactionsRemoved = new ArrayList<MessageReaction>();
        MessageReaction firstReactionRemoved = new MessageReaction();
        firstReactionRemoved.setType(""testType"");
        reactionsRemoved.add(firstReactionRemoved);
        MessageReaction secondReactionRemoved = new MessageReaction();
        secondReactionRemoved.setType(""testType"");
        reactionsRemoved.add(secondReactionRemoved);
        activity.setReactionsRemoved(reactionsRemoved);

        ChannelAccount recipientRemoved = new ChannelAccount();
        recipientRemoved.setId(""testRecipient"");
        activity.setRecipient(recipientRemoved);

        ConversationReference relatesToReference = new ConversationReference();
        relatesToReference.setActivityId(""testActivityId"");
        activity.setRelatesTo(relatesToReference);

        activity.setReplyToId(""testReplyToId"");
        activity.setServiceUrl(""testServiceUrl"");
        activity.setText(""testText"");
        activity.setTextFormat(TextFormatTypes.MARKDOWN);

        List<TextHighlight> textHighlights = new ArrayList<TextHighlight>();
        TextHighlight firstTextHighlight = new TextHighlight();
        firstTextHighlight.setText(""testText"");
        textHighlights.add(firstTextHighlight);
        TextHighlight secondTextHighlight = new TextHighlight();
        secondTextHighlight.setText(""testText"");
        textHighlights.add(secondTextHighlight);
        activity.setTextHighlights(textHighlights);

        OffsetDateTime timestamp = OffsetDateTime.now();
        activity.setTimestamp(timestamp);

        activity.setTopicName(""testTopicName"");
        activity.setType(""testType"");
        activity.setValue(""testValue"");
        activity.setValueType(""testValueType"");

        Activity clonedActivity = Activity.clone(activity);

        Assert.assertEquals(activity.getAction(), clonedActivity.getAction());
        Assert.assertEquals(activity.getCallerId(), clonedActivity.getCallerId());
        Assert.assertEquals(activity.getChannelData(), clonedActivity.getChannelData());
        Assert.assertEquals(activity.getDeliveryMode(), clonedActivity.getDeliveryMode());
        Assert.assertEquals(activity.getId(), clonedActivity.getId());
        Assert.assertEquals(activity.getImportance(), clonedActivity.getImportance());
        Assert.assertEquals(activity.getLabel(), clonedActivity.getLabel());
        Assert.assertEquals(activity.getLocalTimezone(), clonedActivity.getLocalTimezone());
        Assert.assertEquals(activity.getLocale(), clonedActivity.getLocale());
        Assert.assertEquals(activity.getName(), clonedActivity.getName());
        Assert.assertEquals(activity.getReplyToId(), clonedActivity.getReplyToId());
        Assert.assertEquals(activity.getServiceUrl(), clonedActivity.getServiceUrl());
        Assert.assertEquals(activity.getSpeak(), clonedActivity.getSpeak());
        Assert.assertEquals(activity.getSummary(), clonedActivity.getSummary());
        Assert.assertEquals(activity.getText(), clonedActivity.getText());
        Assert.assertEquals(activity.getTopicName(), clonedActivity.getTopicName());
        Assert.assertEquals(activity.getType(), clonedActivity.getType());
        Assert.assertEquals(activity.getValue(), clonedActivity.getValue());
        Assert.assertEquals(activity.getValueType(), clonedActivity.getValueType());
        Assert.assertEquals(activity.getAttachmentLayout(), clonedActivity.getAttachmentLayout());
        Assert.assertEquals(activity.getAttachments().get(0).getName(),
                            clonedActivity.getAttachments().get(0).getName());
        Assert.assertEquals(activity.getChannelData(ChannelAccount.class).getId(),
                            clonedActivity.getChannelData(ChannelAccount.class).getId());
        Assert.assertEquals(activity.getCode(), clonedActivity.getCode());
        Assert.assertEquals(activity.getConversation().getName(), clonedActivity.getConversation().getName());
        Assert.assertEquals(activity.getConversationReference().getChannelId(),
                            clonedActivity.getConversationReference().getChannelId());
        Assert.assertEquals(activity.getEntities().get(0).getType(), clonedActivity.getEntities().get(0).getType());
        Assert.assertEquals(activity.getExpiration(), clonedActivity.getExpiration());
        Assert.assertEquals(activity.getFrom().getId(), clonedActivity.getFrom().getId());
        Assert.assertEquals(activity.getInputHint(), clonedActivity.getInputHint());
        Assert.assertEquals(activity.getListenFor(), clonedActivity.getListenFor());
        Assert.assertEquals(activity.getLocalTimestamp(), clonedActivity.getLocalTimestamp());
        Assert.assertEquals(activity.getMembersAdded().get(0).getId(), clonedActivity.getMembersAdded().get(0).getId());
        Assert.assertEquals(activity.getMembersRemoved().get(0).getId(),
                            clonedActivity.getMembersRemoved().get(0).getId());
        Assert.assertEquals(activity.getMentions().get(0).getText(), clonedActivity.getMentions().get(0).getText());
        Assert.assertEquals(activity.getProperties(), clonedActivity.getProperties());
        Assert.assertEquals(activity.getReactionsAdded().get(0).getType(),
                            clonedActivity.getReactionsAdded().get(0).getType());
        Assert.assertEquals(activity.getReactionsRemoved().get(0).getType(),
                            clonedActivity.getReactionsRemoved().get(0).getType());
        Assert.assertEquals(activity.getRecipient().getId(), clonedActivity.getRecipient().getId());
        Assert.assertEquals(activity.getRelatesTo().getActivityId(), clonedActivity.getRelatesTo().getActivityId());
        // add activity.getReplyConversationReference(reply)
        Assert.assertEquals(activity.getSuggestedActions(), clonedActivity.getSuggestedActions());
        Assert.assertEquals(activity.getTextFormat(), clonedActivity.getTextFormat());
        Assert.assertEquals(activity.getTextHighlights(), clonedActivity.getTextHighlights());
        Assert.assertEquals(activity.getTimestamp(), clonedActivity.getTimestamp());
    }
",non-flaky,5
148851,microsoft_botbuilder-java,ActivityTest.EnsureCloneAddsIdIfMissing,"    @Test
    public void EnsureCloneAddsIdIfMissing() {
        Activity testActivity = new Activity(ActivityTypes.COMMAND);
        Assert.assertTrue(testActivity.getId() == null);
        Activity clonedActivity = Activity.clone(testActivity);
        Assert.assertTrue(clonedActivity.getId() != null);
    }
",non-flaky,5
148852,microsoft_botbuilder-java,ActivityTest.TryGetChannelData,"    @Test
    public void TryGetChannelData() {
        Activity activity = createActivity();
        ResultPair<TeamsChannelData> channelData = activity.tryGetChannelData(
            TeamsChannelData.class
        );

        activity.setChannelData(new TeamsChannelData());
        channelData = activity.tryGetChannelData(
            TeamsChannelData.class
        );
        Assert.assertTrue(channelData.getLeft());

        activity.setChannelData(null);
        Assert.assertNull(activity.teamsGetChannelData());
    }
",non-flaky,5
148853,microsoft_botbuilder-java,ActivityTest.TryGetChannelDataBadChannelData,"    @Test
    public void TryGetChannelDataBadChannelData() {
        Activity activity = createActivity();
        activity.setChannelData(""badChannelData"");
        ResultPair<TeamsChannelData> channelData = activity.tryGetChannelData(
            TeamsChannelData.class
        );
        Assert.assertFalse(channelData.getLeft());
        Assert.assertNull(channelData.getRight());
    }
",non-flaky,5
148854,microsoft_botbuilder-java,ActivityTest.RemoveRecipientMention,"    @Test
    public void RemoveRecipientMention() {
        Activity activity = createActivity();
        activity.setText(""<at>firstName</at> lastName\n"");
        String expectedStrippedName = ""lastName"";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);

        String strippedActivityText = activity.removeRecipientMention();
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
",non-flaky,5
148855,microsoft_botbuilder-java,ActivityTest.RemoveRecipientMentionImmutable,"    @Test
    public void RemoveRecipientMentionImmutable() {
        Activity activity = createActivity();
        activity.setText(""<at>firstName</at> lastName\n"");
        String expectedStrippedName = ""lastName"";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);

        String strippedActivityText = Activity.removeRecipientMentionImmutable(activity);
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
",non-flaky,5
148856,microsoft_botbuilder-java,ActivityTest.RemoveRecipientMentionNoRecipient,"    @Test
    public void RemoveRecipientMentionNoRecipient() {
        Activity activity = createActivity();
        activity.setText(""<at>firstName</at> lastName\n"");
        String expectedStrippedName = ""<at>firstName</at> lastName\n"";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);
        activity.setRecipient(null);

        String strippedActivityText = activity.removeRecipientMention();
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
",non-flaky,5
148857,microsoft_botbuilder-java,ActivityTest.RemoveRecipientMentionImmutableNoRecipient,"    @Test
    public void RemoveRecipientMentionImmutableNoRecipient() {
        Activity activity = createActivity();
        activity.setText(""<at>firstName</at> lastName\n"");
        String expectedStrippedName = ""<at>firstName</at> lastName\n"";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);
        activity.setRecipient(null);

        String strippedActivityText = Activity.removeRecipientMentionImmutable(activity);
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
",non-flaky,5
148858,microsoft_botbuilder-java,ActivityTest.RemoveRecipientMentionText,"    @Test
    public void RemoveRecipientMentionText() {
        Activity activity = createActivity();
        activity.setText(""<at>firstName</at> lastName\n"");
        String expectedStrippedName = ""<at>firstName</at>"";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        mention.setText(""lastName"");
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);

        String strippedActivityText = activity.removeRecipientMention();
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
",non-flaky,5
148859,microsoft_botbuilder-java,ActivityTest.RemoveRecipientMentionTextNoId,"    @Test
    public void RemoveRecipientMentionTextNoId() {
        Activity activity = createActivity();
        activity.setText(""<at>firstName</at> lastName\n"");
        String expectedStrippedName = ""<at>firstName</at> lastName\n"";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        mention.setText(""lastName"");
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);

        String strippedActivityText = Activity.removeMentionTextImmutable(activity, null);
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
",non-flaky,5
148860,microsoft_botbuilder-java,ActivityTest.RemoveRecipientMentionTextNoText,"    @Test
    public void RemoveRecipientMentionTextNoText() {
        Activity activity = createActivity();
        activity.setText("""");
        String expectedStrippedName = """";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        mention.setText(""lastName"");
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);

        String strippedActivityText = Activity.removeMentionTextImmutable(activity, ""lastName"");
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
",non-flaky,5
148861,microsoft_botbuilder-java,ActivityTest.isActivity,"    @Test
    public void IsActivity() {
        class MyActivity extends Activity {
            @Override
            public boolean isActivity(String activityType) {
                return super.isActivity(activityType);
            }
",non-flaky,5
148862,microsoft_botbuilder-java,ActivityTest.isActivity,"    @Test
    public void IsActivityNoType() {
        class MyActivity extends Activity {
            @Override
            public boolean isActivity(String activityType) {
                return super.isActivity(activityType);
            }
",non-flaky,5
148863,microsoft_botbuilder-java,ActivityTest.isActivity,"    @Test
    public void IsActivityExtendedType() {
        class MyActivity extends Activity {
            @Override
            public boolean isActivity(String activityType) {
                return super.isActivity(activityType);
            }
",non-flaky,5
148864,microsoft_botbuilder-java,ActivityTest.isActivity,"    @Test
    public void IsActivityExtendedTypeNoMatch() {
        class MyActivity extends Activity {
            @Override
            public boolean isActivity(String activityType) {
                return super.isActivity(activityType);
            }
",non-flaky,5
148865,microsoft_botbuilder-java,ActivityTest.isActivity,"    @Test
    public void IsActivityNoMatch() {
        class MyActivity extends Activity {
            @Override
            public boolean isActivity(String activityType) {
                return super.isActivity(activityType);
            }
",non-flaky,5
148866,microsoft_botbuilder-java,ActivityTest.isActivity,"    @Test
    public void IsActivityShorterTypeName() {
        class MyActivity extends Activity {
            @Override
            public boolean isActivity(String activityType) {
                return super.isActivity(activityType);
            }
",non-flaky,5
148867,microsoft_botbuilder-java,MediaCardTest.TestPropertySetterGetter,"    @Test
    public void TestPropertySetterGetter() {
        MediaCard mediaCard = new MediaCard();
        mediaCard.setAspect(""aspect"");
        mediaCard.setAutoloop(true);
        mediaCard.setAutostart(true);

        List<CardAction> buttons = new ArrayList<CardAction>();
        CardAction cardAction1 = new CardAction(ActionTypes.CALL, ""test1"");
        CardAction cardAction2 = new CardAction(ActionTypes.DOWNLOAD_FILE, ""test2"");
        buttons.add(cardAction1);
        buttons.add(cardAction2);
        mediaCard.setButtons(buttons);

        mediaCard.setDuration(""duration"");

        ThumbnailUrl thumbnailUrl = new ThumbnailUrl();
        thumbnailUrl.setAlt(""alt"");
        thumbnailUrl.setUrl(""testUrl"");
        mediaCard.setImage(thumbnailUrl);

        mediaCard.setShareable(true);
        mediaCard.setSubtitle(""subTitle"");
        mediaCard.setText(""text"");
        mediaCard.setTitle(""title"");
        mediaCard.setValue(""value"");

        Assert.assertEquals(mediaCard.getAspect(), ""aspect"");
        Assert.assertEquals(mediaCard.getAutoloop(), true);
        Assert.assertEquals(mediaCard.getAutostart(), true);
        Assert.assertEquals(mediaCard.getButtons().size(), 2);
        Assert.assertEquals(mediaCard.getButtons().get(0).getType(), ActionTypes.CALL);
        Assert.assertEquals(mediaCard.getButtons().get(0).getTitle(), ""test1"");
        Assert.assertEquals(mediaCard.getButtons().get(1).getType(), ActionTypes.DOWNLOAD_FILE);
        Assert.assertEquals(mediaCard.getButtons().get(1).getTitle(), ""test2"");
        Assert.assertEquals(mediaCard.getDuration(), ""duration"");
        Assert.assertEquals(mediaCard.getImage().getUrl(), ""testUrl"");
        Assert.assertEquals(mediaCard.getImage().getAlt(), ""alt"");
        Assert.assertEquals(mediaCard.getShareable(), true);
        Assert.assertEquals(mediaCard.getSubtitle(), ""subTitle"");
        Assert.assertEquals(mediaCard.getText(), ""text"");
        Assert.assertEquals(mediaCard.getTitle(), ""title"");
        Assert.assertEquals(mediaCard.getValue(), ""value"");
    }
",non-flaky,5
148868,microsoft_botbuilder-java,ReceiptCardTest.testToAttachment,"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.receipt"", attachment.getContentType());
    }
",non-flaky,5
148869,microsoft_botbuilder-java,SigninCardTest.testToAttachment,"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.signin"", attachment.getContentType());
    }
",non-flaky,5
148870,microsoft_botbuilder-java,MessageActionsPayloadTest.TestMessageActionPayloadConstructor,"    @Test
    public void TestMessageActionPayloadConstructor(){
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        Assert.assertNotNull(messageActionsPayload);
    }
",non-flaky,5
148871,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetId,"    @Test
    public void TestGetId(){
        String id = ""testId"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setId(id);
        String result = messageActionsPayload.getId();

        Assert.assertEquals(result, id);
    }
",non-flaky,5
148872,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetReplyToId,"    @Test
    public void TestGetReplyToId(){
        String replyToId = ""testReplyToId"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setReplyToId(replyToId);
        String result = messageActionsPayload.getReplyToId();

        Assert.assertEquals(result, replyToId);
    }
",non-flaky,5
148873,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetMessageType,"    @Test
    public void TestGetMessageType(){
        String messageType = ""testMessageType"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setMessageType(messageType);
        String result = messageActionsPayload.getMessageType();

        Assert.assertEquals(result, messageType);
    }
",non-flaky,5
148874,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetCreatedDateTime,"    @Test
    public void TestGetCreatedDateTime(){
        String createdDateTime = ""2000-01-01"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setCreatedDateTime(createdDateTime);
        String result = messageActionsPayload.getCreatedDateTime();

        Assert.assertEquals(result, createdDateTime);
    }
",non-flaky,5
148875,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetLastModifiedDateTime,"    @Test
    public void TestGetLastModifiedDateTime(){
        String lastModifiedDateTime = ""2000-01-01"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setLastModifiedDateTime(lastModifiedDateTime);
        String result = messageActionsPayload.getLastModifiedDateTime();

        Assert.assertEquals(result, lastModifiedDateTime);
    }
",non-flaky,5
148876,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetDeleted,"    @Test
    public void TestGetDeleted(){
        Boolean deleted = false;
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setDeleted(deleted);
        Boolean result = messageActionsPayload.getDeleted();

        Assert.assertEquals(result, deleted);
    }
",non-flaky,5
148877,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetSubject,"    @Test
    public void TestGetSubject(){
        String subject = ""testSubject"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setSubject(subject);
        String result = messageActionsPayload.getSubject();

        Assert.assertEquals(result, subject);
    }
",non-flaky,5
148878,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetSummary,"    @Test
    public void TestGetSummary(){
        String summary = ""testSummary"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setSummary(summary);
        String result = messageActionsPayload.getSummary();

        Assert.assertEquals(result, summary);
    }
",non-flaky,5
148879,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetImportance,"    @Test
    public void TestGetImportance(){
        String importance = ""normal"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setImportance(importance);
        String result = messageActionsPayload.getImportance();

        Assert.assertEquals(result, importance);
    }
",non-flaky,5
148880,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetLinkToMessage,"    @Test
    public void TestGetLinkToMessage(){
        String linkToMessage = ""https://teams.microsoft.com/l/message/testing-id"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setLinkToMessage(linkToMessage);
        String result = messageActionsPayload.getLinkToMessage();

        Assert.assertEquals(result, linkToMessage);
    }
",non-flaky,5
148881,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetLocale,"    @Test
    public void TestGetLocale(){
        String locale = ""US"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setLocale(locale);
        String result = messageActionsPayload.getLocale();

        Assert.assertEquals(result, locale);
    }
",non-flaky,5
148882,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetFrom,"    @Test
    public void TestGetFrom(){
        MessageActionsPayloadFrom from = new MessageActionsPayloadFrom();
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setFrom(from);
        MessageActionsPayloadFrom result = messageActionsPayload.getFrom();

        Assert.assertEquals(result, from);
    }
",non-flaky,5
148883,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetBody,"    @Test
    public void TestGetBody(){
        MessageActionsPayloadBody body = new MessageActionsPayloadBody();
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setBody(body);
        MessageActionsPayloadBody result = messageActionsPayload.getBody();

        Assert.assertEquals(result, body);
    }
",non-flaky,5
148884,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetAttachmentLayout,"    @Test
    public void TestGetAttachmentLayout(){
        String attachmentLayout = ""testAttachmentLayout"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setAttachmentLayout(attachmentLayout);
        String result = messageActionsPayload.getAttachmentLayout();

        Assert.assertEquals(result, attachmentLayout);
    }
",non-flaky,5
148885,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetAttachments,"    @Test
    public void TestGetAttachments(){
        List<MessageActionsPayloadAttachment> attachments = new ArrayList<MessageActionsPayloadAttachment>();
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setAttachments(attachments);
        List<MessageActionsPayloadAttachment> result = messageActionsPayload.getAttachments();

        Assert.assertEquals(result, attachments);
    }
",non-flaky,5
148886,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetMentions,"    @Test
    public void TestGetMentions(){
        List<MessageActionsPayloadMention> mentions = new ArrayList<MessageActionsPayloadMention>();
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setMentions(mentions);
        List<MessageActionsPayloadMention> result = messageActionsPayload.getMentions();

        Assert.assertEquals(result, mentions);
    }
",non-flaky,5
148887,microsoft_botbuilder-java,MessageActionsPayloadTest.TestGetReactions,"    @Test
    public void TestGetReactions(){
        List<MessageActionsPayloadReaction> reactions = new ArrayList<MessageActionsPayloadReaction>();
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setReactions(reactions);
        List<MessageActionsPayloadReaction> result = messageActionsPayload.getReactions();

        Assert.assertEquals(result, reactions);
    }
",non-flaky,5
148888,microsoft_botbuilder-java,OAuthCardTest.testToAttachment,"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.oauth"", attachment.getContentType());
    }
",non-flaky,5
148889,microsoft_botbuilder-java,EntitySchemaValidationTest.EntityTests_GeoCoordinatesSerializationDeserializationTest,"    @Test
    public void EntityTests_GeoCoordinatesSerializationDeserializationTest() {
        GeoCoordinates geoCoordinates = new GeoCoordinates();
        geoCoordinates.setLatitude(22.00);
        geoCoordinates.setLongitude(23.00);

        Assert.assertEquals(""GeoCoordinates"", geoCoordinates.getType());

        Entity deserializedEntity = new Entity().setAs(geoCoordinates);
        Assert.assertEquals(deserializedEntity.getType(), geoCoordinates.getType());

        GeoCoordinates geoDeserialized = deserializedEntity.getAs(GeoCoordinates.class);
        Assert.assertEquals(geoCoordinates.getType(), geoDeserialized.getType());
        Assert.assertEquals(
            geoCoordinates.getLatitude(), geoDeserialized.getLatitude(), Double.MAX_VALUE
        );
        Assert.assertEquals(
            geoCoordinates.getLongitude(), geoDeserialized.getLongitude(), Double.MAX_VALUE
        );
    }
",non-flaky,5
148890,microsoft_botbuilder-java,EntitySchemaValidationTest.EntityTests_MentionSerializationDeserializationTest,"    @Test
    public void EntityTests_MentionSerializationDeserializationTest() {
        Mention mentionEntity = new Mention();
        mentionEntity.setText(""TESTTEST"");

        Assert.assertEquals(""mention"", mentionEntity.getType());

        Entity deserializedEntity = new Entity().setAs(mentionEntity);
        Assert.assertEquals(deserializedEntity.getType(), mentionEntity.getType());
        Assert.assertEquals(
            deserializedEntity.getProperties().get(""text"").textValue(), mentionEntity.getText()
        );

        Mention mentionDeserialized = deserializedEntity.getAs(Mention.class);
        Assert.assertEquals(mentionEntity.getType(), mentionDeserialized.getType());
        Assert.assertEquals(
            deserializedEntity.getProperties().get(""text"").textValue(), mentionEntity.getText()
        );
    }
",non-flaky,5
148891,microsoft_botbuilder-java,EntitySchemaValidationTest.EntityTests_PlaceSerializationDeserializationTest,"    @Test
    public void EntityTests_PlaceSerializationDeserializationTest() {
        Place placeEntity = new Place();
        placeEntity.setName(""TESTTEST"");

        Assert.assertEquals(""Place"", placeEntity.getType());

        Entity deserializedEntity = new Entity().setAs(placeEntity);
        Assert.assertEquals(deserializedEntity.getType(), placeEntity.getType());

        Place placeDeserialized = deserializedEntity.getAs(Place.class);
        Assert.assertEquals(placeEntity.getType(), placeDeserialized.getType());
    }
",non-flaky,5
148892,microsoft_botbuilder-java,ThumbnailCardTest.testToAttachment,"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.thumbnail"", attachment.getContentType());
    }
",non-flaky,5
148893,microsoft_botbuilder-java,AnimationCardTest.testToAttachment,"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.animation"", attachment.getContentType());
    }
",non-flaky,5
148894,microsoft_botbuilder-java,CardActionTest.TestImplicitConversation,"    @Test
    public void TestImplicitConversation() {
        SuggestedActions actions = new SuggestedActions(
            new CardAction[] { new CardAction(""x""), new CardAction(""y""), new CardAction(""z"") }
        );

        Assert.assertEquals(""x"", actions.getActions().get(0).getTitle());
        Assert.assertEquals(""x"", actions.getActions().get(0).getValue());
        Assert.assertEquals(""y"", actions.getActions().get(1).getTitle());
        Assert.assertEquals(""y"", actions.getActions().get(1).getValue());
        Assert.assertEquals(""z"", actions.getActions().get(2).getTitle());
        Assert.assertEquals(""z"", actions.getActions().get(2).getValue());
    }
",non-flaky,5
148895,microsoft_botbuilder-java,CardActionTest.TestClone,"    @Test
    public void TestClone() {

        CardAction cardAction =  new CardAction();
        cardAction.setChannelData(""channelData"");
        cardAction.setDisplayText(""displayTest"");
        cardAction.setImage(""image"");
        cardAction.setImageAltText(""imageAltText"");
        cardAction.setText(""text"");
        cardAction.setTitle(""title"");
        cardAction.setType(ActionTypes.CALL);
        cardAction.setValue(""value"");

        CardAction newCardAction = CardAction.clone(cardAction);

        Assert.assertEquals(cardAction.getChannelData(), newCardAction.getChannelData());
        Assert.assertEquals(cardAction.getDisplayText(), newCardAction.getDisplayText());
        Assert.assertEquals(cardAction.getImage(), newCardAction.getImage());
        Assert.assertEquals(cardAction.getImageAltText(), newCardAction.getImageAltText());
        Assert.assertEquals(cardAction.getText(), newCardAction.getText());
        Assert.assertEquals(cardAction.getTitle(), newCardAction.getTitle());
        Assert.assertEquals(cardAction.getType(), newCardAction.getType());
        Assert.assertEquals(cardAction.getValue(), newCardAction.getValue());
    }
",non-flaky,5
148896,microsoft_botbuilder-java,CardActionTest.TestCloneNull,"    @Test
    public void TestCloneNull() {
        CardAction newCardAction = CardAction.clone(null);
        Assert.assertNull(newCardAction);
    }
",non-flaky,5
148897,microsoft_botbuilder-java,CardActionTest.TestConstructorTwoParams,"    @Test
    public void TestConstructorTwoParams() {
        CardAction cardAction =  new CardAction(ActionTypes.CALL, ""title"");
        Assert.assertEquals(cardAction.getType(), ActionTypes.CALL);
        Assert.assertEquals(cardAction.getTitle(), ""title"");
    }
",non-flaky,5
148898,microsoft_botbuilder-java,CardActionTest.TestConstructorThreeParams,"    @Test
    public void TestConstructorThreeParams() {
        CardAction cardAction =  new CardAction(ActionTypes.CALL, ""title"", ""value"");
        Assert.assertEquals(cardAction.getType(), ActionTypes.CALL);
        Assert.assertEquals(cardAction.getTitle(), ""title"");
        Assert.assertEquals(cardAction.getValue(), ""value"");
    }
",non-flaky,5
148899,microsoft_botbuilder-java,SerializationTest.testGetAs,"    @Test
    public void testGetAs() {
        Activity activity = createActivity();
        JsonNode activityNode = Serialization.objectToTree(activity);
        Activity resultActivity = Serialization.getAs(activityNode, Activity.class);
        Assert.assertEquals(activity.getId(), resultActivity.getId());
        Assert.assertEquals(activity.getFrom().getId(), resultActivity.getFrom().getId());
        Assert.assertEquals(activity.getConversation().getId(), resultActivity.getConversation().getId());
    }
",non-flaky,5
148900,microsoft_botbuilder-java,SerializationTest.testGetAsNull,"    @Test
    public void testGetAsNull() {
        Activity resultActivity = Serialization.getAs(null, Activity.class);
        Assert.assertNull(resultActivity);
    }
",non-flaky,5
148901,microsoft_botbuilder-java,SerializationTest.testClone,"    @Test
    public void testClone() {
        Activity activity = createActivity();
        Activity resultActivity = (Activity) Serialization.clone((Object) activity);
        Assert.assertEquals(activity.getId(), resultActivity.getId());
        Assert.assertEquals(activity.getFrom().getId(), resultActivity.getFrom().getId());
        Assert.assertEquals(activity.getConversation().getId(), resultActivity.getConversation().getId());
    }
",non-flaky,5
148902,microsoft_botbuilder-java,SerializationTest.testCloneNull,"    @Test
    public void testCloneNull() {
        Activity resultActivity = (Activity) Serialization.clone((Object) null);
        Assert.assertNull(resultActivity);
    }
",non-flaky,5
46,networknt_json-schema-validator,CollectorContextTest.testCollectorContextWithKeyword,"@Test
public void testCollectorContextWithKeyword() throws Exception {
    ValidationResult validationResult = validate(""{\""test-property1\"":\""sample1\"",\""test-property2\"":\""sample2\""}"");
    Assertions.assertEquals(0, validationResult.getValidationMessages().size());
    List<String> contextValues = ((List<String>) (validationResult.getCollectorContext().get(SAMPLE_COLLECTOR)));
    Assertions.assertEquals(0, validationResult.getValidationMessages().size());
    Assertions.assertEquals(2, contextValues.size());
    Assertions.assertEquals(contextValues.get(0), ""actual_value_added_to_context1"");
    Assertions.assertEquals(contextValues.get(1), ""actual_value_added_to_context2"");
}",unordered collections,3
77106,networknt_json-schema-validator,Issue406Test.testPreloadingNotHappening,"    @Test
    public void testPreloadingNotHappening() {
        final JsonSchemaFactory factory = JsonSchemaFactory.getInstance(SpecVersion.VersionFlag.V7);
        final JsonSchema schema = factory.getSchema(INVALID_$REF_SCHEMA);
        // not breaking - pass
        Assertions.assertNotNull(schema);
    }
",non-flaky,5
77107,networknt_json-schema-validator,Issue406Test.execute,"    @Test
    public void testPreloadingHappening() {
        final JsonSchemaFactory factory = JsonSchemaFactory.getInstance(SpecVersion.VersionFlag.V7);
        final JsonSchema schema = factory.getSchema(INVALID_$REF_SCHEMA);
        Assertions.assertThrows(JsonSchemaException.class,
                            new Executable() {
                                @Override
                                public void execute() {
                                    schema.initializeValidators();
                                }
",non-flaky,5
77108,networknt_json-schema-validator,Issue406Test.testPreloadingHappeningForCircularDependency,"    @Test
    public void testPreloadingHappeningForCircularDependency() {
        final JsonSchemaFactory factory = JsonSchemaFactory.getInstance(SpecVersion.VersionFlag.V7);
        final JsonSchema schema = factory.getSchema(CIRCULAR_$REF_SCHEMA);
        schema.initializeValidators();
    }
",non-flaky,5
77109,networknt_json-schema-validator,Issue386Test.dataIsValid,"    @ParameterizedTest
    public void dataIsValid(boolean failFast) throws Exception {
        String schemaPath = ""/schema/issue386-v7.json"";
        String dataPath = ""/data/issue386.json"";
        JsonSchema schema = getJsonSchemaFromPathV7(schemaPath, failFast);
        JsonNode node = getJsonNodeFromPath(dataPath).get(""valid"");
        node.forEach(testNode -> {
            Set<ValidationMessage> errors = schema.validate(testNode.get(""data""));
            Assertions.assertEquals(0, errors.size(), ""Expected no errors for "" + testNode.get(""data""));
        });
    }
",non-flaky,5
77110,networknt_json-schema-validator,Issue386Test.dataIsInvalidFailFast,"    @Test
    public void dataIsInvalidFailFast() throws Exception {
        String schemaPath = ""/schema/issue386-v7.json"";
        String dataPath = ""/data/issue386.json"";
        JsonSchema schema = getJsonSchemaFromPathV7(schemaPath, true);
        JsonNode node = getJsonNodeFromPath(dataPath).get(""invalid"");
        node.forEach(testNode -> {
            try {
                schema.validate(testNode.get(""data""));
                Assertions.fail();
            } catch (JsonSchemaException e) {
                Assertions.assertEquals(testNode.get(""expectedErrors"").get(0).asText(), e.getMessage());
            }
        });
    }
",non-flaky,5
77111,networknt_json-schema-validator,Issue386Test.dataIsInvalidFailSlow,"    @Test
    public void dataIsInvalidFailSlow() throws Exception {
        String schemaPath = ""/schema/issue386-v7.json"";
        String dataPath = ""/data/issue386.json"";
        JsonSchema schema = getJsonSchemaFromPathV7(schemaPath, false);
        JsonNode node = getJsonNodeFromPath(dataPath).get(""invalid"");
        node.forEach(testNode -> {
            Set<ValidationMessage> errors = schema.validate(testNode.get(""data""));
            List<String> errorMessages = errors.stream().map(x -> x.getMessage()).collect(Collectors.toList());
            testNode.get(""expectedErrors"").forEach(expectedError -> {
                Assertions.assertTrue(errorMessages.contains(expectedError.asText()));
            });
        });
    }
",non-flaky,5
77112,networknt_json-schema-validator,Issue425Test.testNullableOneOf,"    @Test
    public void testNullableOneOf() throws Exception {
        runTestFile(""data/issue425.json"");
    }
",non-flaky,5
77113,networknt_json-schema-validator,Issue366FailFastTest.setup,"  @BeforeEach
  public void setup() throws IOException {
    setupSchema();
  }
",non-flaky,5
77114,networknt_json-schema-validator,Issue366FailFastTest.firstOneValid,"  @Test
  public void firstOneValid() throws Exception {
    String dataPath = ""/data/issue366.json"";

    InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
    JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
    List<JsonNode> testNodes = node.findValues(""tests"");
    JsonNode testNode = testNodes.get(0).get(0);
    JsonNode dataNode = testNode.get(""data"");
    Set<ValidationMessage> errors = jsonSchema.validate(dataNode);
    assertTrue(errors.isEmpty());
  }
",non-flaky,5
77115,networknt_json-schema-validator,Issue366FailFastTest.secondOneValid,"  @Test
  public void secondOneValid() throws Exception {
    String dataPath = ""/data/issue366.json"";

    InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
    JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
    List<JsonNode> testNodes = node.findValues(""tests"");
    JsonNode testNode = testNodes.get(0).get(1);
    JsonNode dataNode = testNode.get(""data"");
    Set<ValidationMessage> errors = jsonSchema.validate(dataNode);
    assertTrue(errors.isEmpty());
  }
",non-flaky,5
77116,networknt_json-schema-validator,Issue366FailFastTest.bothValid,"  @Test
  public void bothValid() throws Exception {
    String dataPath = ""/data/issue366.json"";

    assertThrows(JsonSchemaException.class, () -> {
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
        List<JsonNode> testNodes = node.findValues(""tests"");
        JsonNode testNode = testNodes.get(0).get(2);
        JsonNode dataNode = testNode.get(""data"");
        jsonSchema.validate(dataNode);
    });
  }
",non-flaky,5
77117,networknt_json-schema-validator,Issue366FailFastTest.neitherValid,"  @Test
  public void neitherValid() throws Exception {
    String dataPath = ""/data/issue366.json"";

    assertThrows(JsonSchemaException.class, () -> {
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
        List<JsonNode> testNodes = node.findValues(""tests"");
        JsonNode testNode = testNodes.get(0).get(3);
        JsonNode dataNode = testNode.get(""data"");
        jsonSchema.validate(dataNode);
    });
  }
",non-flaky,5
77118,networknt_json-schema-validator,TypeFactoryTest.testValidIntegralValuesWithJavaSemantics,"    @Test
    public void testValidIntegralValuesWithJavaSemantics() {
        schemaValidatorsConfig.setJavaSemantics(true);
        for (String validValue : validIntegralValues) {
            assertSame(JsonType.INTEGER,
                    getValueNodeType(DecimalNode.valueOf(new BigDecimal(validValue)), schemaValidatorsConfig),
                    validValue);
        }
    }
",non-flaky,5
77119,networknt_json-schema-validator,TypeFactoryTest.testValidIntegralValuesWithoutJavaSemantics,"    @Test
    public void testValidIntegralValuesWithoutJavaSemantics() {
        schemaValidatorsConfig.setJavaSemantics(false);
        for (String validValue : validIntegralValues) {
            assertSame(JsonType.NUMBER,
                    getValueNodeType(DecimalNode.valueOf(new BigDecimal(validValue)), schemaValidatorsConfig),
                    validValue);
        }
    }
",non-flaky,5
77120,networknt_json-schema-validator,TypeFactoryTest.testWithLosslessNarrowing,"    @Test
    public void testWithLosslessNarrowing() {
        schemaValidatorsConfig.setLosslessNarrowing(true);
        for (String validValue : validIntegralValues) {
            assertSame(JsonType.INTEGER,
                    getValueNodeType(DecimalNode.valueOf(new BigDecimal(""1.0"")), schemaValidatorsConfig),
                    validValue);

            assertSame(JsonType.NUMBER,
                    getValueNodeType(DecimalNode.valueOf(new BigDecimal(""1.5"")), schemaValidatorsConfig),
                    validValue);
        }
    }
",non-flaky,5
77121,networknt_json-schema-validator,TypeFactoryTest.testWithoutLosslessNarrowing,"    @Test
    public void testWithoutLosslessNarrowing() {
        schemaValidatorsConfig.setLosslessNarrowing(false);
        for (String validValue : validIntegralValues) {
            assertSame(JsonType.NUMBER,
                    getValueNodeType(DecimalNode.valueOf(new BigDecimal(""1.0"")), schemaValidatorsConfig),
                    validValue);

            assertSame(JsonType.NUMBER,
                    getValueNodeType(DecimalNode.valueOf(new BigDecimal(""1.5"")), schemaValidatorsConfig),
                    validValue);
        }

    }
",non-flaky,5
77122,networknt_json-schema-validator,Issue461Test.shouldWalkWithValidation,"    @Test
    public void shouldWalkWithValidation() throws URISyntaxException, IOException {
        JsonSchema schema = getJsonSchemaFromStreamContentV7(new URI(""http://json-schema"" +
                "".org/draft-07/schema#""));
        JsonNode data = mapper.readTree(Issue461Test.class.getResource(""/data/issue461-v7.json""));
        ValidationResult result = schema.walk(data, true);
        Assertions.assertTrue(result.getValidationMessages().isEmpty());
    }
",non-flaky,5
77123,networknt_json-schema-validator,TypeValidatorTest.testNumeicValues,"    @Test
    public void testNumeicValues() {
        for (String validValue : validNumericValues) {
            assertTrue(isNumeric(validValue), validValue);
        }
    }
",non-flaky,5
77124,networknt_json-schema-validator,TypeValidatorTest.testNonNumeicValues,"    @Test
    public void testNonNumeicValues() {
        for (String invalidValue : invalidNumericValues) {
            assertFalse(isNumeric(invalidValue), invalidValue);
        }
    }
",non-flaky,5
77125,networknt_json-schema-validator,SpecVersionTest.testGetVersionValue,"    @Test
    public void testGetVersionValue() {
        SpecVersion ds = new SpecVersion();
        Set versionFlags = EnumSet.of(
                SpecVersion.VersionFlag.V4,
                SpecVersion.VersionFlag.V201909);
        Assertions.assertEquals(ds.getVersionValue(versionFlags), 9); // 0001|1000
    }
",non-flaky,5
77126,networknt_json-schema-validator,SpecVersionTest.testGetVersionFlags,"    @Test
    public void testGetVersionFlags() {
        SpecVersion ds = new SpecVersion();

        long numericVersionCode = SpecVersion.VersionFlag.V201909.getVersionFlagValue()
                | SpecVersion.VersionFlag.V6.getVersionFlagValue()
                | SpecVersion.VersionFlag.V7.getVersionFlagValue();  // 14

        Set versionFlags = ds.getVersionFlags(numericVersionCode);

        assert !versionFlags.contains(SpecVersion.VersionFlag.V4);
        assert versionFlags.contains(SpecVersion.VersionFlag.V6);
        assert versionFlags.contains(SpecVersion.VersionFlag.V7);
        assert versionFlags.contains(SpecVersion.VersionFlag.V201909);

    }
",non-flaky,5
77127,networknt_json-schema-validator,SpecVersionTest.testAllVersionValue,"    @Test
    public void testAllVersionValue() {
        long numericVersionCode =
                SpecVersion.VersionFlag.V201909.getVersionFlagValue()
                        | SpecVersion.VersionFlag.V4.getVersionFlagValue()
                        | SpecVersion.VersionFlag.V6.getVersionFlagValue()
                        | SpecVersion.VersionFlag.V7.getVersionFlagValue();  // 15
        Assertions.assertEquals(numericVersionCode, 15);

    }
",non-flaky,5
77128,networknt_json-schema-validator,Issue383Test.nestedOneOfsShouldStillMatchV7,"    @Test
    public void nestedOneOfsShouldStillMatchV7() throws Exception {
        String schemaPath = ""/schema/issue383-v7.json"";
        String dataPath = ""/data/issue383.json"";
        InputStream schemaInputStream = getClass().getResourceAsStream(schemaPath);
        JsonSchema schema = getJsonSchemaFromStreamContentV7(schemaInputStream);
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
        Set<ValidationMessage> errors = schema.validate(node);
        Assertions.assertEquals(0, errors.size());
    }
",non-flaky,5
77129,networknt_json-schema-validator,Issue396Test.testComplexPropertyNamesV7,"    @Test
    public void testComplexPropertyNamesV7() throws Exception {
        String schemaPath = ""/schema/issue396-v7.json"";
        String dataPath = ""/data/issue396.json"";
        InputStream schemaInputStream = getClass().getResourceAsStream(schemaPath);
        JsonSchema schema = getJsonSchemaFromStreamContentV7(schemaInputStream);
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);

        final Set<String> invalidPaths = new HashSet<>();
        node.fields().forEachRemaining(entry -> {
            if (!entry.getValue().asBoolean())
                invalidPaths.add(""$."" + entry.getKey());
        });

        Set<ValidationMessage> errors = schema.validate(node);
        final Set<String> failedPaths = errors.stream().map(ValidationMessage::getPath).collect(Collectors.toSet());
        Assertions.assertEquals(failedPaths, invalidPaths);
    }
",non-flaky,5
77130,networknt_json-schema-validator,Issue255Test.shouldFailWhenRequiredPropertiesDoNotExistInReferencedSubSchema,"    @Test
    public void shouldFailWhenRequiredPropertiesDoNotExistInReferencedSubSchema() throws Exception {
        String schemaPath = ""/draft2019-09/issue255.json"";
        String dataPath = ""/data/issue255.json"";
        InputStream schemaInputStream = getClass().getResourceAsStream(schemaPath);
        JsonSchema schema = getJsonSchemaFromStreamContent(schemaInputStream);
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
        Set<ValidationMessage> errors = schema.validate(node);
        Assertions.assertEquals(2, errors.size());
    }
",non-flaky,5
77131,networknt_json-schema-validator,Issue342Test.propertyNameEnumShouldFailV7,"    @Test
    public void propertyNameEnumShouldFailV7() throws Exception {
        String schemaPath = ""/schema/issue342-v7.json"";
        String dataPath = ""/data/issue342.json"";
        InputStream schemaInputStream = getClass().getResourceAsStream(schemaPath);
        JsonSchema schema = getJsonSchemaFromStreamContentV7(schemaInputStream);
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
        Set<ValidationMessage> errors = schema.validate(node);
        Assertions.assertEquals(1, errors.size());
        final ValidationMessage error = errors.iterator().next();
        Assertions.assertEquals(""$.z"", error.getPath());
        Assertions.assertEquals(""Property name $.z is not valid for validation: does not have a value in the enumeration [a, b, c]"", error.getMessage());
    }
",non-flaky,5
77132,networknt_json-schema-validator,Issue285Test.nestedValidation,"    @Test
    public void nestedValidation() throws IOException {
        JsonSchema jsonSchema = schemaFactory.getSchema(schemaStr);
        Set<ValidationMessage> validationMessages = jsonSchema.validate(mapper.readTree(person));

        System.err.println(""\n"" + Arrays.toString(validationMessages.toArray()));

        assertFalse(validationMessages.isEmpty());


    }
",non-flaky,5
77133,networknt_json-schema-validator,Issue285Test.nestedTypeValidation,"    @Test
    public void nestedTypeValidation() throws IOException, URISyntaxException {
        URI uri = new URI(""https://json-schema.org/draft/2019-09/schema"");
        JsonSchema jsonSchema = schemaFactory.getSchema(uri);
        Set<ValidationMessage> validationMessages = jsonSchema.validate(mapper.readTree(invalidNestedSchema));

        System.err.println(""\n"" + Arrays.toString(validationMessages.toArray()));

        assertFalse(validationMessages.isEmpty());
    }
",non-flaky,5
77134,networknt_json-schema-validator,Issue285Test.typeValidation,"    @Test
    public void typeValidation() throws IOException, URISyntaxException {
        URI uri = new URI(""https://json-schema.org/draft/2019-09/schema"");
        JsonSchema jsonSchema = schemaFactory.getSchema(uri);
        Set<ValidationMessage> validationMessages = jsonSchema.validate(mapper.readTree(invalidSchema));

        System.err.println(""\n"" + Arrays.toString(validationMessages.toArray()));

        assertFalse(validationMessages.isEmpty());
    }
",non-flaky,5
77135,networknt_json-schema-validator,Issue426Test.shouldWorkV7,"    @Test
    public void shouldWorkV7() throws Exception {
        String schemaPath = ""/schema/issue426-v7.json"";
        String dataPath = ""/data/issue426.json"";
        InputStream schemaInputStream = getClass().getResourceAsStream(schemaPath);
        JsonSchema schema = getJsonSchemaFromStreamContentV7(schemaInputStream);
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
        Set<ValidationMessage> errors = schema.validate(node);
        Assertions.assertEquals(2, errors.size());
        final JsonNode message = schema.schemaNode.get(""message"");
        for(ValidationMessage error : errors) {
            //validating custom message
            Assertions.assertEquals(message.get(error.getType()).asText(),  error.getMessage());
        }
    }
",non-flaky,5
77136,networknt_json-schema-validator,Issue404Test.expectObjectNotIntegerV7,"    @Test
    public void expectObjectNotIntegerV7() throws Exception {
        String schemaPath = ""/schema/issue404-v7.json"";
        String dataPath = ""/data/issue404.json"";
        InputStream schemaInputStream = getClass().getResourceAsStream(schemaPath);
        JsonSchema schema = getJsonSchemaFromStreamContentV7(schemaInputStream);
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
        Set<ValidationMessage> errors = schema.validate(node);
        Assertions.assertEquals(0, errors.size());
    }
",non-flaky,5
77137,networknt_json-schema-validator,V4JsonSchemaTest.testLoadingWithId,"    @Test(/*expected = java.lang.StackOverflowError.class*/)
    public void testLoadingWithId() throws Exception {
        URL url = new URL(""http://localhost:1234/self_ref/selfRef.json"");
        JsonNode schemaJson = mapper.readTree(url);
        JsonSchemaFactory factory = JsonSchemaFactory.getInstance(SpecVersion.VersionFlag.V4);
        @SuppressWarnings(""unused"")
        JsonSchema schema = factory.getSchema(schemaJson);
    }
",non-flaky,5
77138,networknt_json-schema-validator,V4JsonSchemaTest.testBignumValidator,"    @Test
    public void testBignumValidator() throws Exception {
        runTestFile(""draft4/optional/bignum.json"");
    }
",non-flaky,5
77139,networknt_json-schema-validator,V4JsonSchemaTest.testFormatValidator,"    @Test
    public void testFormatValidator() throws Exception {
        runTestFile(""draft4/optional/format.json"");
    }
",non-flaky,5
77140,networknt_json-schema-validator,V4JsonSchemaTest.testComplexSchema,"    @Test
    public void testComplexSchema() throws Exception {
        runTestFile(""draft4/optional/complex.json"");
    }
",non-flaky,5
77141,networknt_json-schema-validator,V4JsonSchemaTest.testZeroTerminatedFloatsValidator,"    @Test
    public void testZeroTerminatedFloatsValidator() throws Exception {
        runTestFile(""draft4/optional/zeroTerminatedFloats.json"");
    }
",non-flaky,5
77142,networknt_json-schema-validator,V4JsonSchemaTest.testAdditionalItemsValidator,"    @Test
    public void testAdditionalItemsValidator() throws Exception {
        runTestFile(""draft4/additionalItems.json"");
    }
",non-flaky,5
77143,networknt_json-schema-validator,V4JsonSchemaTest.testAdditionalPropertiesValidator,"    @Test
    public void testAdditionalPropertiesValidator() throws Exception {
        runTestFile(""draft4/additionalProperties.json"");
    }
",non-flaky,5
77144,networknt_json-schema-validator,V4JsonSchemaTest.testAllOfValidator,"    @Test
    public void testAllOfValidator() throws Exception {
        runTestFile(""draft4/allOf.json"");
    }
",non-flaky,5
77145,networknt_json-schema-validator,V4JsonSchemaTest.testAnyOFValidator,"    @Test
    public void testAnyOFValidator() throws Exception {
        runTestFile(""draft4/anyOf.json"");
    }
",non-flaky,5
77146,networknt_json-schema-validator,V4JsonSchemaTest.testDefaultValidator,"    @Test
    public void testDefaultValidator() throws Exception {
        runTestFile(""draft4/default.json"");
    }
",non-flaky,5
77147,networknt_json-schema-validator,V4JsonSchemaTest.testDefinitionsValidator,"    @Test
    public void testDefinitionsValidator() throws Exception {
        runTestFile(""draft4/definitions.json"");
    }
",non-flaky,5
77148,networknt_json-schema-validator,V4JsonSchemaTest.testDependenciesValidator,"    @Test
    public void testDependenciesValidator() throws Exception {
        runTestFile(""draft4/dependencies.json"");
    }
",non-flaky,5
77149,networknt_json-schema-validator,V4JsonSchemaTest.testEnumValidator,"    @Test
    public void testEnumValidator() throws Exception {
        runTestFile(""draft4/enum.json"");
    }
",non-flaky,5
77150,networknt_json-schema-validator,V4JsonSchemaTest.testItemsValidator,"    @Test
    public void testItemsValidator() throws Exception {
        runTestFile(""draft4/items.json"");
    }
",non-flaky,5
77151,networknt_json-schema-validator,V4JsonSchemaTest.testMaximumValidator,"    @Test
    public void testMaximumValidator() throws Exception {
        runTestFile(""draft4/maximum.json"");
    }
",non-flaky,5
77152,networknt_json-schema-validator,V4JsonSchemaTest.testMaxItemsValidator,"    @Test
    public void testMaxItemsValidator() throws Exception {
        runTestFile(""draft4/maxItems.json"");
    }
",non-flaky,5
77153,networknt_json-schema-validator,V4JsonSchemaTest.testMaxLengthValidator,"    @Test
    public void testMaxLengthValidator() throws Exception {
        runTestFile(""draft4/maxLength.json"");
    }
",non-flaky,5
77154,networknt_json-schema-validator,V4JsonSchemaTest.testMaxPropertiesValidator,"    @Test
    public void testMaxPropertiesValidator() throws Exception {
        runTestFile(""draft4/maxProperties.json"");
    }
",non-flaky,5
77155,networknt_json-schema-validator,V4JsonSchemaTest.testMinimumValidator,"    @Test
    public void testMinimumValidator() throws Exception {
        runTestFile(""draft4/minimum.json"");
    }
",non-flaky,5
77156,networknt_json-schema-validator,V4JsonSchemaTest.testMinItemsValidator,"    @Test
    public void testMinItemsValidator() throws Exception {
        runTestFile(""draft4/minItems.json"");
    }
",non-flaky,5
77157,networknt_json-schema-validator,V4JsonSchemaTest.testMinLengthValidator,"    @Test
    public void testMinLengthValidator() throws Exception {
        runTestFile(""draft4/minLength.json"");
    }
",non-flaky,5
77158,networknt_json-schema-validator,V4JsonSchemaTest.testMinPropertiesValidator,"    @Test
    public void testMinPropertiesValidator() throws Exception {
        runTestFile(""draft4/minProperties.json"");
    }
",non-flaky,5
77159,networknt_json-schema-validator,V4JsonSchemaTest.testMultipleOfValidator,"    @Test
    public void testMultipleOfValidator() throws Exception {
        runTestFile(""draft4/multipleOf.json"");
    }
",non-flaky,5
77160,networknt_json-schema-validator,V4JsonSchemaTest.testNotValidator,"    @Test
    public void testNotValidator() throws Exception {
        runTestFile(""draft4/not.json"");
    }
",non-flaky,5
77161,networknt_json-schema-validator,V4JsonSchemaTest.testOneOfValidator,"    @Test
    public void testOneOfValidator() throws Exception {
        runTestFile(""draft4/oneOf.json"");
    }
",non-flaky,5
77162,networknt_json-schema-validator,V4JsonSchemaTest.testPatternValidator,"    @Test
    public void testPatternValidator() throws Exception {
        runTestFile(""draft4/pattern.json"");
    }
",non-flaky,5
77163,networknt_json-schema-validator,V4JsonSchemaTest.testPatternPropertiesValidator,"    @Test
    public void testPatternPropertiesValidator() throws Exception {
        runTestFile(""draft4/patternProperties.json"");
    }
",non-flaky,5
77164,networknt_json-schema-validator,V4JsonSchemaTest.testPropertiesValidator,"    @Test
    public void testPropertiesValidator() throws Exception {
        runTestFile(""draft4/properties.json"");
    }
",non-flaky,5
77165,networknt_json-schema-validator,V4JsonSchemaTest.testRefValidator,"    @Test
    public void testRefValidator() throws Exception {
        runTestFile(""draft4/ref.json"");
    }
",non-flaky,5
77166,networknt_json-schema-validator,V4JsonSchemaTest.testRefRemoteValidator,"    @Test
    public void testRefRemoteValidator() throws Exception {
        runTestFile(""draft4/refRemote.json"");
    }
",non-flaky,5
77167,networknt_json-schema-validator,V4JsonSchemaTest.testRefIdReference,"    @Test
    public void testRefIdReference() throws Exception {
        runTestFile(""draft4/idRef.json"");
    }
",non-flaky,5
77168,networknt_json-schema-validator,V4JsonSchemaTest.testRelativeRefRemoteValidator,"    @Test
    public void testRelativeRefRemoteValidator() throws Exception {
        runTestFile(""draft4/relativeRefRemote.json"");
    }
",non-flaky,5
77169,networknt_json-schema-validator,V4JsonSchemaTest.testRequiredValidator,"    @Test
    public void testRequiredValidator() throws Exception {
        runTestFile(""draft4/required.json"");
    }
",non-flaky,5
77170,networknt_json-schema-validator,V4JsonSchemaTest.testTypeValidator,"    @Test
    public void testTypeValidator() throws Exception {
        runTestFile(""draft4/type.json"");
    }
",non-flaky,5
77171,networknt_json-schema-validator,V4JsonSchemaTest.testUnionTypeValidator,"    @Test
    public void testUnionTypeValidator() throws Exception {
        runTestFile(""draft4/union_type.json"");
    }
",non-flaky,5
77172,networknt_json-schema-validator,V4JsonSchemaTest.testUniqueItemsValidator,"    @Test
    public void testUniqueItemsValidator() throws Exception {
        runTestFile(""draft4/uniqueItems.json"");
    }
",non-flaky,5
77173,networknt_json-schema-validator,V4JsonSchemaTest.testEnumObject,"    @Test
    public void testEnumObject() throws Exception {
        runTestFile(""draft4/enumObject.json"");
    }
",non-flaky,5
77174,networknt_json-schema-validator,V4JsonSchemaTest.testIdSchemaWithUrl,"    @Test
    public void testIdSchemaWithUrl() throws Exception {
        runTestFile(""draft4/property.json"");
    }
",non-flaky,5
77175,networknt_json-schema-validator,V4JsonSchemaTest.testSchemaFromClasspath,"    @Test
    public void testSchemaFromClasspath() throws Exception {
        runTestFile(""draft4/classpath/schema.json"");
    }
",non-flaky,5
77176,networknt_json-schema-validator,V4JsonSchemaTest.testUUIDValidator,"    @Test
    public void testUUIDValidator() throws Exception {
        runTestFile(""draft4/uuid.json"");
    }
",non-flaky,5
77177,networknt_json-schema-validator,V4JsonSchemaTest.testFailFast_AllErrors,"    @Test
    public void testFailFast_AllErrors() throws IOException {
        try {
            validateFailingFastSchemaFor(""product.schema.json"", ""product-all-errors-data.json"");
            fail(""Exception must be thrown"");
        } catch (JsonSchemaException e) {
            final Set<ValidationMessage> messages = e.getValidationMessages();
            assertEquals(1, messages.size());
        }
    }
",non-flaky,5
77178,networknt_json-schema-validator,V4JsonSchemaTest.testFailFast_OneErrors,"    @Test
    public void testFailFast_OneErrors() throws IOException {
        try {
            validateFailingFastSchemaFor(""product.schema.json"", ""product-one-error-data.json"");
            fail(""Exception must be thrown"");
        } catch (JsonSchemaException e) {
            final Set<ValidationMessage> messages = e.getValidationMessages();
            assertEquals(1, messages.size());
        }
    }
",non-flaky,5
77179,networknt_json-schema-validator,V4JsonSchemaTest.testFailFast_TwoErrors,"    @Test
    public void testFailFast_TwoErrors() throws IOException {
        try {
            validateFailingFastSchemaFor(""product.schema.json"", ""product-two-errors-data.json"");
            fail(""Exception must be thrown"");
        } catch (JsonSchemaException e) {
            final Set<ValidationMessage> messages = e.getValidationMessages();
            assertEquals(1, messages.size());
        }
    }
",non-flaky,5
77180,networknt_json-schema-validator,V4JsonSchemaTest.testFailFast_NoErrors,"    @Test
    public void testFailFast_NoErrors() throws IOException {
        try {
            final Set<ValidationMessage> messages = validateFailingFastSchemaFor(""product.schema.json"", ""product-no-errors-data.json"");
            assertTrue(messages.isEmpty());
        } catch (JsonSchemaException e) {
            fail(""Must not get an errors"");
        }
    }
",non-flaky,5
77181,networknt_json-schema-validator,Issue451Test.cleanup,"    @AfterEach
    public void cleanup() {
        reset();
    }
",non-flaky,5
77182,networknt_json-schema-validator,Issue451Test.shouldWalkAnyOfProperties,"    @Test
    public void shouldWalkAnyOfProperties() {
        walk(null, false);
    }
",non-flaky,5
77183,networknt_json-schema-validator,Issue451Test.shouldWalkAnyOfPropertiesWithWithPayloadAndValidation,"    @Test
    public void shouldWalkAnyOfPropertiesWithWithPayloadAndValidation() throws Exception {
        JsonNode data = getJsonNodeFromStreamContent(Issue451Test.class.getResourceAsStream(
                ""/data/issue451.json""));
        walk(data,true);
    }
",non-flaky,5
77184,networknt_json-schema-validator,Issue451Test.shouldWalkAnyOfPropertiesWithWithPayload,"    @Test
    public void shouldWalkAnyOfPropertiesWithWithPayload() throws Exception {
        JsonNode data = getJsonNodeFromStreamContent(Issue451Test.class.getResourceAsStream(
                ""/data/issue451.json""));
        walk(data, false);
    }
",non-flaky,5
77185,networknt_json-schema-validator,Issue456Test.shouldWorkT2,"    @Test
    public void shouldWorkT2() throws Exception {
        String schemaPath = ""/schema/issue456-v7.json"";
        String dataPath = ""/data/issue456-T2.json"";
        String dataT3Path = ""/data/issue456-T3.json"";
        InputStream schemaInputStream = getClass().getResourceAsStream(schemaPath);
        JsonSchema schema = getJsonSchemaFromStreamContentV7(schemaInputStream);
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
        Set<ValidationMessage> errors = schema.validate(node);
        Assertions.assertEquals(0, errors.size());
    }
",non-flaky,5
77186,networknt_json-schema-validator,Issue456Test.shouldWorkT3,"    @Test
    public void shouldWorkT3() throws Exception {
        String schemaPath = ""/schema/issue456-v7.json"";
        String dataPath = ""/data/issue456-T3.json"";
        InputStream schemaInputStream = getClass().getResourceAsStream(schemaPath);
        JsonSchema schema = getJsonSchemaFromStreamContentV7(schemaInputStream);
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
        Set<ValidationMessage> errors = schema.validate(node);
        Assertions.assertEquals(0, errors.size());
    }
",non-flaky,5
77187,networknt_json-schema-validator,JsonWalkTest.setup,"    @BeforeEach
    public void setup() {
        setupSchema();
    }
",non-flaky,5
77188,networknt_json-schema-validator,JsonWalkTest.cleanup,"    @AfterEach
    public void cleanup() {
       CollectorContext.getInstance().reset();
    }
",non-flaky,5
77189,networknt_json-schema-validator,JsonWalkTest.testWalk,"    @Test
    public void testWalk() throws IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        ValidationResult result = jsonSchema.walk(
                objectMapper.readTree(getClass().getClassLoader().getResourceAsStream(""data/walk-data.json"")), false);
        JsonNode collectedNode = (JsonNode) result.getCollectorContext().get(SAMPLE_WALK_COLLECTOR_TYPE);
        assertEquals(collectedNode, (objectMapper.readTree(""{"" +
                ""    \""PROPERTY1\"": \""sample1\"",""
                + ""    \""PROPERTY2\"": \""sample2\"",""
                + ""    \""property3\"": {""
                + ""        \""street_address\"":\""test-address\"",""
                + ""        \""phone_number\"": {""
                + ""            \""country-code\"": \""091\"",""
                + ""            \""number\"": \""123456789\""""
                + ""          }""
                + ""     }""
                + ""}"")));
    }
",non-flaky,5
77190,networknt_json-schema-validator,JsonWalkTest.testWalkWithDifferentListeners,"    @Test
    public void testWalkWithDifferentListeners() throws IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        // This instance of schema contains all listeners.
        ValidationResult result = jsonSchema.walk(
                objectMapper.readTree(getClass().getClassLoader().getResourceAsStream(""data/walk-data.json"")), false);
        JsonNode collectedNode = (JsonNode) result.getCollectorContext().get(SAMPLE_WALK_COLLECTOR_TYPE);
        assertEquals(collectedNode, (objectMapper.readTree(""{"" +
                ""    \""PROPERTY1\"": \""sample1\"",""
                + ""    \""PROPERTY2\"": \""sample2\"",""
                + ""    \""property3\"": {""
                + ""        \""street_address\"":\""test-address\"",""
                + ""        \""phone_number\"": {""
                + ""            \""country-code\"": \""091\"",""
                + ""            \""number\"": \""123456789\""""
                + ""          }""
                + ""     }""
                + ""}"")));
        // This instance of schema contains one listener removed.
        CollectorContext collectorContext = result.getCollectorContext();
        collectorContext.reset();
        result = jsonSchema1.walk(
                objectMapper.readTree(getClass().getClassLoader().getResourceAsStream(""data/walk-data.json"")), false);
        collectedNode = (JsonNode) result.getCollectorContext().get(SAMPLE_WALK_COLLECTOR_TYPE);
        assertEquals(collectedNode, (objectMapper.readTree(""{""
                + ""    \""property3\"": {""
                + ""        \""street_address\"":\""test-address\"",""
                + ""        \""phone_number\"": {""
                + ""            \""country-code\"": \""091\"",""
                + ""            \""number\"": \""123456789\""""
                + ""          }""
                + ""     }""
                + ""}"")));
    }
",non-flaky,5
77191,networknt_json-schema-validator,Issue313Test.shouldFailV201909,"    @Test
    public void shouldFailV201909() throws Exception {
        String schemaPath = ""/schema/issue313-2019-09.json"";
        String dataPath = ""/data/issue313.json"";
        InputStream schemaInputStream = getClass().getResourceAsStream(schemaPath);
        JsonSchema schema = getJsonSchemaFromStreamContentV201909(schemaInputStream);
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
        Set<ValidationMessage> errors = schema.validate(node);
        Assertions.assertEquals(2, errors.size());
    }
",non-flaky,5
77192,networknt_json-schema-validator,Issue313Test.shouldFailV7,"    @Test
    public void shouldFailV7() throws Exception {
        String schemaPath = ""/schema/issue313-v7.json"";
        String dataPath = ""/data/issue313.json"";
        InputStream schemaInputStream = getClass().getResourceAsStream(schemaPath);
        JsonSchema schema = getJsonSchemaFromStreamContentV7(schemaInputStream);
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
        Set<ValidationMessage> errors = schema.validate(node);
        Assertions.assertEquals(2, errors.size());
    }
",non-flaky,5
77193,networknt_json-schema-validator,Issue428Test.testNullableOneOf,"    @Test
    public void testNullableOneOf() throws Exception {
        runTestFile(""data/issue428.json"");
    }
",non-flaky,5
77194,networknt_json-schema-validator,MaximumValidatorTest.positiveNumber,"    @Test
    public void positiveNumber() throws IOException {
        String[][] values = augmentWithQuotes(new String[][]{
//            maximum,                       value
                {""1000.1"", ""1000""},
                {""1000"", ""1E3""},
        });

        expectNoMessages(values, NUMBER);

    }
",non-flaky,5
77195,networknt_json-schema-validator,MaximumValidatorTest.negativeNumber,"    @Test
    public void negativeNumber() throws IOException {
        String[][] values = augmentWithQuotes(new String[][]{
//            maximum,                           value
//            These values overflow 64bit IEEE 754
                {""1.7976931348623157e+308"", ""1.7976931348623159e+308""},
                {""1.7976931348623156e+308"", ""1.7976931348623157e+308""},

//            Here, threshold is parsed as integral number, yet payload is 'number'
                {""1000"", ""1000.1""},

//          See a {@link #doubleValueCoarsing() doubleValueCoarsing} test notes below
//            {""1.7976931348623157e+308"",         ""1.7976931348623158e+308""},
        });

        expectSomeMessages(values, NUMBER);

        expectSomeMessages(values, NUMBER, mapper, bigDecimalMapper);

        expectSomeMessages(values, NUMBER, bigDecimalMapper, bigDecimalMapper);
    }
",non-flaky,5
77196,networknt_json-schema-validator,MaximumValidatorTest.positiveInteger,"    @Test
    public void positiveInteger() throws IOException {
        String[][] values = augmentWithQuotes(new String[][]{
//            maximum,                       value
                {""9223372036854775807"", ""9223372036854775807""},
                {""9223372036854775808"", ""9223372036854775808""},

//                testIntegerTypeWithFloatMaxPositive
                {""37.7"", ""37""},

//                testMaximumDoubleValue
                {""1E39"", ""1000""},
        });

        expectNoMessages(values, INTEGER);

        expectNoMessages(values, INTEGER, bigIntegerMapper);
    }
",non-flaky,5
77197,networknt_json-schema-validator,MaximumValidatorTest.negativeInteger,"    @Test
    public void negativeInteger() throws IOException {
        String[][] values = augmentWithQuotes(new String[][]{
//            maximum,                value
                {""9223372036854775800"", ""9223372036854775855""},
                {""9223372036854775807"", ""9223372036854775808""},
                {""9223372036854775807"", new BigDecimal(String.valueOf(Double.MAX_VALUE)).add(BigDecimal.ONE).toString()},
                {""9223372036854775806"", new BigDecimal(String.valueOf(Double.MAX_VALUE)).add(BigDecimal.ONE).toString()},
                {""9223372036854776000"", ""9223372036854776001""},
                {""1000"", ""1E39""},
                {""37.7"", ""38""},
        });

        expectSomeMessages(values, INTEGER);

        expectSomeMessages(values, INTEGER, mapper, bigIntegerMapper);
    }
",non-flaky,5
77198,networknt_json-schema-validator,MaximumValidatorTest.positiveExclusiveInteger,"    @Test
    public void positiveExclusiveInteger() throws IOException {
        String[][] values = augmentWithQuotes(new String[][]{
//            maximum,                       value
                {""9223372036854775000"", ""9223372036854774988""},
                {""20"", ""10""},

//                threshold outside long range
                {""9223372036854775809"", ""9223372036854775806""},

//                both threshold and value are outside long range
                {""9223372036854775809"", ""9223372036854775808""},
        });

        expectNoMessages(values, EXCLUSIVE_INTEGER);

        expectNoMessages(values, EXCLUSIVE_INTEGER, bigIntegerMapper);
    }
",non-flaky,5
77199,networknt_json-schema-validator,MaximumValidatorTest.negativeExclusiveInteger,"    @Test
    public void negativeExclusiveInteger() throws IOException {
        String[][] values = augmentWithQuotes(new String[][]{
//            maximum,                       value
                {""10"", ""20""},

//                value outside long range
                {""9223372036854775806"", ""9223372036854775808""},

//                both threshold and value are outside long range
                {""9223372036854775808"", ""9223372036854775809""},
        });

        expectSomeMessages(values, EXCLUSIVE_INTEGER);

        expectSomeMessages(values, EXCLUSIVE_INTEGER, mapper, bigIntegerMapper);
    }
",non-flaky,5
77200,networknt_json-schema-validator,MaximumValidatorTest.negativeDoubleOverflowTest,"    @Test
    public void negativeDoubleOverflowTest() throws IOException {
        String[][] values = new String[][]{
//            maximum,                           value
//                both of these get parsed into double (with a precision loss) as  1.7976931348623157E+308
                {""1.79769313486231571E+308"", ""1.79769313486231572e+308""},
//                while underflow in not captures in previous case (unquoted number is parsed as double)
//                it is captured if value is passed as string, which is correctly parsed by BidDecimal
//                thus effective comparison is between
//                maximum 1.7976931348623157E+308  and
//                value   1.79769313486231572e+308
//                {""1.79769313486231571E+308"",        ""\""1.79769313486231572e+308\""""},
                {""1.7976931348623157E+309"", ""1.7976931348623157e+309""},
                {""1.7976931348623157E+309"", ""\""1.7976931348623157e+309\""""},
                {""1.000000000000000000000001E+400"", ""1.000000000000000000000001E+401""},
                {""1.000000000000000000000001E+400"", ""\""1.000000000000000000000001E+401\""""},
                {""1.000000000000000000000001E+400"", ""1.000000000000000000000002E+400""},
                {""1.000000000000000000000001E+400"", ""\""1.000000000000000000000002E+400\""""},
                {""1.000000000000000000000001E+400"", ""1.0000000000000000000000011E+400""},
                {""1.000000000000000000000001E+400"", ""\""1.0000000000000000000000011E+400\""""},
        };

        for (String[] aTestCycle : values) {
            String maximum = aTestCycle[0];
            String value = aTestCycle[1];
            String schema = format(NUMBER, maximum);
            SchemaValidatorsConfig config = new SchemaValidatorsConfig();
            config.setTypeLoose(true);
            // Schema and document parsed with just double
            JsonSchema v = factory.getSchema(mapper.readTree(schema), config);
            JsonNode doc = mapper.readTree(value);
            Set<ValidationMessage> messages = v.validate(doc);
            assertTrue(messages.isEmpty(), format(""Maximum %s and value %s are interpreted as Infinity, thus no schema violation should be reported"", maximum, value));

            // document parsed with BigDecimal

            doc = bigDecimalMapper.readTree(value);
            Set<ValidationMessage> messages2 = v.validate(doc);
            if (Double.valueOf(maximum).equals(Double.POSITIVE_INFINITY)) {
                assertTrue(messages2.isEmpty(), format(""Maximum %s and value %s are equal, thus no schema violation should be reported"", maximum, value));
            } else {
                assertFalse(messages2.isEmpty(), format(""Maximum %s is smaller than value %s ,  should be validation error reported"", maximum, value));
            }


            // schema and document parsed with BigDecimal
            v = factory.getSchema(bigDecimalMapper.readTree(schema), config);
            Set<ValidationMessage> messages3 = v.validate(doc);
            //when the schema and value are both using BigDecimal, the value should be parsed in same mechanism.
            if (maximum.toLowerCase().equals(value.toLowerCase()) || Double.valueOf(maximum).equals(Double.POSITIVE_INFINITY)) {
                assertTrue(messages3.isEmpty(), format(""Maximum %s and value %s are equal, thus no schema violation should be reported"", maximum, value));
            } else {
                assertFalse(messages3.isEmpty(), format(""Maximum %s is smaller than value %s ,  should be validation error reported"", maximum, value));
            }
        }
    }
",non-flaky,5
77201,networknt_json-schema-validator,MaximumValidatorTest.doubleValueCoarsing,"    @Test
    public void doubleValueCoarsing() throws IOException {
        String schema = ""{ \""$schema\"":\""http://json-schema.org/draft-04/schema#\"", \""type\"": \""number\"", \""maximum\"": 1.7976931348623157e+308 }"";
        String content = ""1.7976931348623158e+308"";

        JsonNode doc = mapper.readTree(content);
        JsonSchema v = factory.getSchema(mapper.readTree(schema));

        Set<ValidationMessage> messages = v.validate(doc);
        assertTrue(messages.isEmpty(), ""Validation should succeed as by default double values are used by mapper"");

        doc = bigDecimalMapper.readTree(content);
        messages = v.validate(doc);
        // ""1.7976931348623158e+308"" == ""1.7976931348623157e+308"" == Double.MAX_VALUE
        // new BigDecimal(""1.7976931348623158e+308"").compareTo(new BigDecimal(""1.7976931348623157e+308"")) > 0
        assertFalse(messages.isEmpty(), ""Validation should not succeed because content is using bigDecimalMapper, and bigger than the maximum"");

        /*
         * Note: technically this is where 1.7976931348623158e+308 rounding to 1.7976931348623157e+308 could be spotted,
         *       yet it requires a dedicated case of comparison BigDecimal to BigDecimal. Since values above
         *       1.7976931348623158e+308 are parsed as Infinity anyways (jackson uses double as primary type with later
         *       ""upcasting"" to BigDecimal, if property is set) adding a dedicated code block just for this one case
         *       seems infeasible.
         */
        v = factory.getSchema(bigDecimalMapper.readTree(schema));
        messages = v.validate(doc);
        assertFalse(messages.isEmpty(), ""Validation should succeed as by default double values are used by mapper"");
    }
",non-flaky,5
77202,networknt_json-schema-validator,MaximumValidatorTest.doubleValueCoarsingExceedRange,"    @Test
    public void doubleValueCoarsingExceedRange() throws IOException {
        String schema = ""{ \""$schema\"":\""http://json-schema.org/draft-04/schema#\"", \""type\"": \""number\"", \""maximum\"": 1.7976931348623159e+308 }"";
        String content = ""1.7976931348623160e+308"";

        JsonNode doc = mapper.readTree(content);
        JsonSchema v = factory.getSchema(mapper.readTree(schema));

        Set<ValidationMessage> messages = v.validate(doc);
        assertTrue(messages.isEmpty(), ""Validation should succeed as by default double values are used by mapper"");

        doc = bigDecimalMapper.readTree(content);
        messages = v.validate(doc);
        // ""1.7976931348623158e+308"" == ""1.7976931348623157e+308"" == Double.MAX_VALUE
        // new BigDecimal(""1.7976931348623158e+308"").compareTo(new BigDecimal(""1.7976931348623157e+308"")) > 0
        assertTrue(messages.isEmpty(), ""Validation should success because the bug of bigDecimalMapper, it will treat 1.7976931348623159e+308 as INFINITY"");

        /*
         * Note: technically this is where 1.7976931348623158e+308 rounding to 1.7976931348623157e+308 could be spotted,
         *       yet it requires a dedicated case of comparison BigDecimal to BigDecimal. Since values above
         *       1.7976931348623158e+308 are parsed as Infinity anyways (jackson uses double as primary type with later
         *       ""upcasting"" to BigDecimal, if property is set) adding a dedicated code block just for this one case
         *       seems infeasible.
         */
        v = factory.getSchema(bigDecimalMapper.readTree(schema));
        messages = v.validate(doc);
        assertTrue(messages.isEmpty(), ""Validation should success because the bug of bigDecimalMapper, it will treat 1.7976931348623159e+308 as INFINITY"");
    }
",non-flaky,5
77203,networknt_json-schema-validator,MinimumValidatorTest.setUp,"    @BeforeEach
    public void setUp() {
        mapper = new ObjectMapper();
        // due to a jackson bug, a float number which is larger than Double.POSITIVE_INFINITY cannot be convert to BigDecimal correctly
        // https://github.com/FasterXML/jackson-databind/issues/1770
        // https://github.com/FasterXML/jackson-databind/issues/2087
        bigDecimalMapper = new ObjectMapper().enable(DeserializationFeature.USE_BIG_DECIMAL_FOR_FLOATS);
        bigIntegerMapper = new ObjectMapper().enable(DeserializationFeature.USE_BIG_INTEGER_FOR_INTS);

    }
",non-flaky,5
77204,networknt_json-schema-validator,MinimumValidatorTest.positiveNumber,"    @Test
    public void positiveNumber() throws IOException {
        String[][] values = augmentWithQuotes(new String[][]{
//            minimum,                       value
                {""1000"", ""1000.1""},
        });

        expectNoMessages(values, NUMBER, mapper);
    }
",non-flaky,5
77205,networknt_json-schema-validator,MinimumValidatorTest.negativeNumber,"    @Test
    public void negativeNumber() throws IOException {
        String[][] values = augmentWithQuotes(new String[][]{
//            minimum,                           value
                {""-1.7976931348623157e+308"", ""-1.7976931348623159e+308""},
                {""-1.7976931348623156e+308"", ""-1.7976931348623157e+308""},
                {""-1000"", ""-1E309""},
                {""1000.1"", ""1000""},
//          See a {@link #doubleValueCoarsing() doubleValueCoarsing} test notes below
//            {""-1.7976931348623157e+308"",         ""-1.7976931348623158e+308""},
        });

        expectSomeMessages(values, NUMBER, mapper, mapper);

        expectSomeMessages(values, NUMBER, mapper, bigDecimalMapper);

        expectSomeMessages(values, NUMBER, bigDecimalMapper, bigDecimalMapper);
    }
",non-flaky,5
26,cloudfoundry_uaa,testMatchesSpeedTest,"@Test
public void testMatchesSpeedTest() throws Exception {
    int iterations = 15;
    String password = new RandomValueStringGenerator().generate();
    String encodedBcrypt = cachingPasswordEncoder.encode(password);
    long nanoStart = System.nanoTime();
    for (int i = 0; i < iterations; i++) {
        assertTrue(cachingPasswordEncoder.getPasswordEncoder().matches(password, encodedBcrypt));
        long nanoStop = System.nanoTime();
        long bcryptTime = nanoStop - nanoStart;
        nanoStart = System.nanoTime();
        for (int i = 0; i < iterations; i++) {
            nanoStop = System.nanoTime();
            long cacheTime = nanoStop - nanoStart;
            assertTrue(bcryptTime > (10 * cacheTime));
        }
    }
}",time,2
53127,cloudfoundry_uaa,UaaMetricsEmitterIT.assert_generic_metrics,"    @Test
    public void assert_generic_metrics() throws IOException {
        String data1 = firstBatch.get(statsDKey);
        String data2 = secondBatch.get(statsDKey);

        assertNotNull(""Expected to find message for:'"" + statsDKey + ""' in the first batch."", data1);
        long first = IntegrationTestUtils.getStatsDValueFromMessage(data1);
        assertThat(statsDKey + "" first value must have a positive value."", first, greaterThanOrEqualTo(0l));

        assertNotNull(""Expected to find message for:'""+statsDKey+""' in the second batch."", data2);
        long second = IntegrationTestUtils.getStatsDValueFromMessage(data2);
        assertThat(statsDKey + "" second value must have a positive value."", second, greaterThanOrEqualTo(0l));
    }
",non-flaky,5
53128,cloudfoundry_uaa,UaaMetricsScheduledTest.emittingMetrics_Is_Scheduled,"    @Test
    public void emittingMetrics_Is_Scheduled() throws Exception {
        Scheduled schedulerAnnotation = uaaMetricsEmitter.getClass().getMethod(""emitMetrics"").getAnnotation(Scheduled.class);
        Assert.assertEquals(5000, schedulerAnnotation.fixedRate());
    }
",non-flaky,5
53129,cloudfoundry_uaa,MBeanMapTests.testListDomain,"    @Test
    public void testListDomain() throws Exception {
        Set<ObjectName> names = server.queryNames(ObjectName.getInstance(""java.lang:type=Runtime,*""), null);
        System.err.println(names);
        assertTrue(names.size() == 1);
        MBeanMap result = new MBeanMap(server, names.iterator().next());
        @SuppressWarnings(""unchecked"")
        Map<String,String>  properties = (Map<String, String>) result.get(""system_properties"");
        assertTrue(properties.containsKey(""java.vm.version""));
    }
",non-flaky,5
53130,cloudfoundry_uaa,UaaMetricsEmitterTests.auditService_metrics_emitted,"    @Test
    public void auditService_metrics_emitted() throws Exception {
        Mockito.when(metricsUtils.pullUpMap(""cloudfoundry.identity"", ""*"", server)).thenReturn((Map)mBeanMap2);
        uaaMetricsEmitter.emitMetrics();
        Mockito.verify(statsDClient).gauge(""audit_service.user_authentication_count"", 3);
        Mockito.verify(statsDClient).gauge(""audit_service.user_not_found_count"", 1);
        Mockito.verify(statsDClient).gauge(""audit_service.principal_authentication_failure_count"", 4);
        Mockito.verify(statsDClient).gauge(""audit_service.principal_not_found_count"", 5);
        Mockito.verify(statsDClient).gauge(""audit_service.user_authentication_failure_count"", 6);
        Mockito.verify(statsDClient).gauge(""audit_service.client_authentication_count"", 7);
        Mockito.verify(statsDClient).gauge(""audit_service.client_authentication_failure_count"", 42);
    }
",non-flaky,5
53131,cloudfoundry_uaa,UaaMetricsEmitterTests.requestCount_metrics_emitted,"    @Test
    public void requestCount_metrics_emitted() throws Exception {
        Mockito.when(metricsUtils.getUaaMetrics(any())).thenReturn(uaaMetrics1, uaaMetrics2);
        uaaMetricsEmitter.emitGlobalRequestMetrics();
        Mockito.verify(statsDClient).count(""requests.global.completed.count"", 3087l);
        Mockito.verify(statsDClient).gauge(""requests.global.completed.time"", 29l);
        Mockito.verify(statsDClient).count(""requests.global.unhealthy.count"", 1l);
        Mockito.verify(statsDClient).gauge(""requests.global.unhealthy.time"", 4318l);
        Mockito.verify(statsDClient).count(""requests.global.status_1xx.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_2xx.count"", 2148l);
        Mockito.verify(statsDClient).count(""requests.global.status_3xx.count"", 763l);
        Mockito.verify(statsDClient).count(""requests.global.status_4xx.count"", 175l);
        Mockito.verify(statsDClient).count(""requests.global.status_5xx.count"", 1l);
        Mockito.verify(statsDClient).gauge(""server.inflight.count"", 3l);
        Mockito.verify(statsDClient).gauge(""server.up.time"", 12349843l);
        Mockito.verify(statsDClient).gauge(""server.idle.time"", 12349l);
        Mockito.verify(statsDClient).count(""database.global.completed.count"", 83797l);
        Mockito.verify(statsDClient).gauge(""database.global.completed.time"", 0l);
        Mockito.verify(statsDClient).count(""database.global.unhealthy.count"", 17549l);
        Mockito.verify(statsDClient).gauge(""database.global.unhealthy.time"", 0l);
        reset(statsDClient);
        uaaMetricsEmitter.emitGlobalRequestMetrics();
        Mockito.verify(statsDClient).count(""requests.global.completed.count"", 4l);
        Mockito.verify(statsDClient).count(""requests.global.unhealthy.count"", 1l);
        Mockito.verify(statsDClient).count(""requests.global.status_1xx.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_2xx.count"", 1l);
        Mockito.verify(statsDClient).count(""requests.global.status_3xx.count"", 1l);
        Mockito.verify(statsDClient).count(""requests.global.status_4xx.count"", 1l);
        Mockito.verify(statsDClient).count(""requests.global.status_5xx.count"", 1l);
        Mockito.verify(statsDClient).count(""database.global.completed.count"", 2l);
        Mockito.verify(statsDClient).count(""database.global.unhealthy.count"", 5l);
        reset(statsDClient);
        uaaMetricsEmitter.emitGlobalRequestMetrics();
        Mockito.verify(statsDClient).count(""requests.global.completed.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.unhealthy.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_1xx.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_2xx.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_3xx.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_4xx.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_5xx.count"", 0l);
        Mockito.verify(statsDClient).count(""database.global.completed.count"", 0l);
        Mockito.verify(statsDClient).count(""database.global.unhealthy.count"", 0l);
    }
",non-flaky,5
53132,cloudfoundry_uaa,UaaMetricsEmitterTests.test_delta_method,"    @Test
    public void test_delta_method() {
        String name = ""metric.name"";
        assertEquals(5l, uaaMetricsEmitter.getMetricDelta(name, 5l));
        assertEquals(0l, uaaMetricsEmitter.getMetricDelta(name, 5l));
        assertEquals(3l, uaaMetricsEmitter.getMetricDelta(name, 8l));
    }
",non-flaky,5
53133,cloudfoundry_uaa,UaaMetricsEmitterTests.vm_vitals,"    @Test
    public void vm_vitals() {
        uaaMetricsEmitter.emitVmVitals();
        Mockito.verify(statsDClient).gauge(eq(""vitals.vm.cpu.count""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.vm.cpu.load""), geq(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.vm.memory.total""), geq(134217728l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.vm.memory.committed""), geq(1l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.vm.memory.free""), geq(1l));
    }
",non-flaky,5
53134,cloudfoundry_uaa,UaaMetricsEmitterTests.perUrlGroup_request_metrics,"    @Test
    public void perUrlGroup_request_metrics() throws Exception {
        Mockito.when(metricsUtils.getUaaMetrics(any())).thenReturn(uaaMetrics1);
        uaaMetricsEmitter.emitUrlGroupRequestMetrics();
        Mockito.verify(statsDClient).gauge(eq(""requests.ui.completed.count""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""requests.ui.completed.time""), geq(300l));

        Mockito.verify(statsDClient).gauge(eq(""requests.static-content.completed.count""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""requests.static-content.completed.time""), geq(23l));
    }
",non-flaky,5
53135,cloudfoundry_uaa,UaaMetricsEmitterTests.testNotifications,"    @Test
    public void testNotifications() {
        uaaMetricsEmitter.enableNotification();
        emitter.sendNotification(new Notification(""/api"", 45L, 0));
        Mockito.verify(statsDClient).time(""requests.api.latency"", 45L);
    }
",non-flaky,5
53136,cloudfoundry_uaa,UaaMetricsEmitterTests.jvm_vitals,"    @Test
    public void jvm_vitals() {
        uaaMetricsEmitter.emitJvmVitals();
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.cpu.load""), and(geq(0l), leq(100l)));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.thread.count""), and(gt(1l), leq(1000l)));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.heap.init""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.heap.committed""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.heap.used""), gt(0l));
        //Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.heap.max""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.non-heap.init""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.non-heap.committed""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.non-heap.used""), gt(0l));
        //Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.non-heap.max""), gt(0l));
    }
",non-flaky,5
53137,cloudfoundry_uaa,UaaMetricsEmitterTests.auditService_metricValues_areNull,"    @Test
    public void auditService_metricValues_areNull() throws Exception {
        mBeanMap1.put(""user_authentication_count"", null);
        Mockito.when(metricsUtils.pullUpMap(""cloudfoundry.identity"", ""*"", server)).thenReturn((Map)mBeanMap2);
        uaaMetricsEmitter.emitMetrics();
        Mockito.verify(statsDClient).gauge(""audit_service.user_not_found_count"", 1);
        Mockito.verify(statsDClient, times(6)).gauge(anyString(), anyLong());
    }
",non-flaky,5
53138,cloudfoundry_uaa,UaaMetricsEmitterTests.auditService_Key_isNull,"    @Test
    public void auditService_Key_isNull () throws Exception {
        mBeanMap2.put(""UaaAudit"", null);
        Mockito.when(metricsUtils.pullUpMap(""cloudfoundry.identity"", ""*"", server)).thenReturn((Map)mBeanMap2);
        uaaMetricsEmitter.emitMetrics();
        Mockito.verify(statsDClient, times(0)).gauge(anyString(), anyLong());
    }
",non-flaky,5
53139,cloudfoundry_uaa,ApiControllerTests.testNoUser,"    @Test
    public void testNoUser() throws Exception {
        controller.setInfo(new ClassPathResource(""info.tmpl""));
        HashMap<String, Object> model = new HashMap<String, Object>();
        View view = controller.info(model, null);
        MockHttpServletResponse response = new MockHttpServletResponse();
        view.render(model, new MockHttpServletRequest(), response);
        String content = response.getContentAsString();
        assertFalse(""Wrong content: "" + content, content.contains(""\""user\""""));
    }
",non-flaky,5
53140,cloudfoundry_uaa,ApiControllerTests.testWithUser,"    @Test
    public void testWithUser() throws Exception {
        controller.setInfo(new ClassPathResource(""info.tmpl""));
        HashMap<String, Object> model = new HashMap<String, Object>();
        View view = controller.info(model, new UsernamePasswordAuthenticationToken(testAccounts.getUserName(), ""<NONE>""));
        MockHttpServletResponse response = new MockHttpServletResponse();
        view.render(model, new MockHttpServletRequest(), response);
        String content = response.getContentAsString();
        assertTrue(""Wrong content: "" + content, content.contains(""\n  \""user\"": \""""+testAccounts.getUserName()+""\""""));
    }
",non-flaky,5
53141,cloudfoundry_uaa,AppsIntegrationTests.testHappyDay,"    @Test
    public void testHappyDay() throws Exception {

        RestOperations restTemplate = serverRunning.createRestTemplate();
        ResponseEntity<String> response = restTemplate.getForEntity(serverRunning.getUrl(""/api/apps""), String.class);
        // first make sure the resource is actually protected.
        assertNotSame(HttpStatus.OK, response.getStatusCode());
        HttpHeaders approvalHeaders = new HttpHeaders();
        OAuth2AccessToken accessToken = context.getAccessToken();
        approvalHeaders.set(""Authorization"", ""bearer "" + accessToken.getValue());

        ResponseEntity<String> result = serverRunning.getForString(""/api/apps"");
        assertEquals(HttpStatus.OK, result.getStatusCode());
        String body = result.getBody();
        assertTrue(""Wrong response: "" + body, body.contains(""dsyerapi.cloudfoundry.com""));

    }
",non-flaky,5
53142,cloudfoundry_uaa,SamlConfigTest.testIsRequestSigned,"    @Test
    public void testIsRequestSigned() throws Exception {
        assertTrue(config.isRequestSigned());
    }
",non-flaky,5
53143,cloudfoundry_uaa,SamlConfigTest.legacy_key_is_part_of_map,"    @Test
    public void legacy_key_is_part_of_map() {
        config.setPrivateKey(privateKey);
        config.setPrivateKeyPassword(passphrase);
        config.setCertificate(certificate);
        Map<String, SamlKey> keys = config.getKeys();
        assertEquals(1, keys.size());
        assertNotNull(keys.get(LEGACY_KEY_ID));
        assertEquals(privateKey, keys.get(LEGACY_KEY_ID).getKey());
        assertEquals(passphrase, keys.get(LEGACY_KEY_ID).getPassphrase());
        assertEquals(certificate, keys.get(LEGACY_KEY_ID).getCertificate());
    }
",non-flaky,5
53144,cloudfoundry_uaa,SamlConfigTest.addActiveKey,"    @Test
    public void addActiveKey() {
        SamlKey key = new SamlKey(privateKey, passphrase, certificate);
        String keyId = ""testKeyId"";
        config.addAndActivateKey(keyId, key);
        Map<String, SamlKey> keys = config.getKeys();
        assertNotNull(keys);
        assertEquals(1, keys.size());
        assertEquals(keyId, config.getActiveKeyId());
        assertNotNull(keys.get(keyId));
        assertEquals(privateKey, keys.get(keyId).getKey());
        assertEquals(passphrase, keys.get(keyId).getPassphrase());
        assertEquals(certificate, keys.get(keyId).getCertificate());
    }
",non-flaky,5
53145,cloudfoundry_uaa,SamlConfigTest.addNonActive,"    @Test
    public void addNonActive() {
        addActiveKey();
        SamlKey key = new SamlKey(privateKey, passphrase, certificate);
        String keyId = ""nonActiveKeyId"";
        config.addKey(keyId, key);
        Map<String, SamlKey> keys = config.getKeys();
        assertNotNull(keys);
        assertEquals(2, keys.size());
        assertNotEquals(keyId, config.getActiveKeyId());
        assertNotNull(keys.get(keyId));
        assertEquals(privateKey, keys.get(keyId).getKey());
        assertEquals(passphrase, keys.get(keyId).getPassphrase());
        assertEquals(certificate, keys.get(keyId).getCertificate());
    }
",non-flaky,5
53146,cloudfoundry_uaa,SamlConfigTest.map_is_not_null_by_default,"    @Test
    public void map_is_not_null_by_default() {
        Map<String, SamlKey> keys = config.getKeys();
        assertNotNull(keys);
        assertEquals(0, keys.size());
        assertNull(config.getActiveKeyId());
    }
",non-flaky,5
53147,cloudfoundry_uaa,SamlConfigTest.testIsWantAssertionSigned,"    @Test
    public void testIsWantAssertionSigned() throws Exception {
        assertTrue(config.isWantAssertionSigned());
    }
",non-flaky,5
53148,cloudfoundry_uaa,SamlConfigTest.testSetKeyAndCert,"    @Test
    public void testSetKeyAndCert() throws CertificateException {
        config.setPrivateKey(privateKey);
        config.setPrivateKeyPassword(passphrase);
        config.setCertificate(certificate);
        assertEquals(privateKey, config.getPrivateKey());
        assertEquals(passphrase, config.getPrivateKeyPassword());
    }
",non-flaky,5
53149,cloudfoundry_uaa,SamlConfigTest.read_old_json_works,"    @Test
    public void read_old_json_works() throws Exception {
        read_json(oldJson);
        assertEquals(privateKey, config.getPrivateKey());
        assertEquals(passphrase, config.getPrivateKeyPassword());
        assertEquals(certificate, config.getCertificate());
    }
",non-flaky,5
53150,cloudfoundry_uaa,SamlConfigTest.to_json_ignores_legacy_values,"    @Test
    public void to_json_ignores_legacy_values() throws Exception {
        read_json(oldJson);
        String json = JsonUtils.writeValueAsString(config);
        read_json(json);
        assertEquals(privateKey, config.getPrivateKey());
        assertEquals(passphrase, config.getPrivateKeyPassword());
        assertEquals(certificate, config.getCertificate());
    }
",non-flaky,5
53151,cloudfoundry_uaa,SamlConfigTest.keys_are_not_modifiable,"    @Test
    public void keys_are_not_modifiable() {
        read_json(oldJson);
        exception.expect(UnsupportedOperationException.class);
        config.getKeys().clear();
    }
",non-flaky,5
53152,cloudfoundry_uaa,SamlConfigTest.can_clear_keys,"    @Test
    public void can_clear_keys() {
        read_json(oldJson);
        assertEquals(1, config.getKeys().size());
        assertNotNull(config.getActiveKeyId());
        config.setKeys(EMPTY_MAP);
        assertEquals(0, config.getKeys().size());
        assertNull(config.getActiveKeyId());
    }
",non-flaky,5
53153,cloudfoundry_uaa,TokenPolicyTest.json_has_expected_properties,"    @Test
    public void json_has_expected_properties() throws Exception {
        TokenPolicy tokenPolicy = new TokenPolicy();
        tokenPolicy.setAccessTokenValidity(1234);
        tokenPolicy.setRefreshTokenValidity(9876);
        tokenPolicy.setKeys(Collections.singletonMap(""aKeyId"", ""KeyKeyKey""));

        String json = JsonUtils.writeValueAsString(tokenPolicy);
        Map properties = JsonUtils.readValue(json, Map.class);

        assertNotNull(properties);
        assertEquals(1234, properties.get(""accessTokenValidity""));
        assertEquals(9876, properties.get(""refreshTokenValidity""));
        assertNotNull(properties.get(""keys""));
        Map keys = (Map) properties.get(""keys"");
        assertNotNull(keys);
        assertEquals(keys.size(), 1);
        assertEquals(""KeyKeyKey"", ((Map) keys.get(""aKeyId"")).get(""signingKey""));
    }
",non-flaky,5
53154,cloudfoundry_uaa,TokenPolicyTest.test_default_values,"    @Test
    public void test_default_values() throws Exception {
        TokenPolicy policy = new TokenPolicy();
        assertFalse(policy.isRefreshTokenUnique());
        assertFalse(policy.isJwtRevocable());
        assertEquals(TokenConstants.TokenFormat.JWT.getStringValue(), policy.getRefreshTokenFormat());
    }
",non-flaky,5
53155,cloudfoundry_uaa,TokenPolicyTest.nullSigningKey,"    @Test(expected = IllegalArgumentException.class)
    public void nullSigningKey() throws Exception {
        TokenPolicy tokenPolicy = new TokenPolicy();
        tokenPolicy.setKeys(Collections.singletonMap(""key-id"", null));
    }
",non-flaky,5
53156,cloudfoundry_uaa,TokenPolicyTest.emptySigningKey,"    @Test(expected = IllegalArgumentException.class)
    public void emptySigningKey() throws Exception {
        TokenPolicy tokenPolicy = new TokenPolicy();
        tokenPolicy.setKeys(Collections.singletonMap(""key-id"", ""             ""));
    }
",non-flaky,5
53157,cloudfoundry_uaa,TokenPolicyTest.nullKeyId,"    @Test(expected = IllegalArgumentException.class)
    public void nullKeyId() throws Exception {
        TokenPolicy tokenPolicy = new TokenPolicy();
        tokenPolicy.setKeys(Collections.singletonMap(null, ""signing-key""));
    }
",non-flaky,5
53158,cloudfoundry_uaa,TokenPolicyTest.emptyKeyId,"    @Test(expected = IllegalArgumentException.class)
    public void emptyKeyId() throws Exception {
        TokenPolicy tokenPolicy = new TokenPolicy();
        tokenPolicy.setKeys(Collections.singletonMap("" "", ""signing-key""));
    }
",non-flaky,5
53159,cloudfoundry_uaa,TokenPolicyTest.deserializationOfTokenPolicyWithVerificationKey_doesNotFail,"    @Test
    public void deserializationOfTokenPolicyWithVerificationKey_doesNotFail() {
        String jsonTokenPolicy = ""{\""keys\"":{\""key-id-1\"":{\""verificationKey\"":\""some-verification-key-1\"",\""signingKey\"":\""some-signing-key-1\""}}}"";
        TokenPolicy tokenPolicy = JsonUtils.readValue(jsonTokenPolicy, TokenPolicy.class);
        assertEquals(tokenPolicy.getKeys().get(""key-id-1""), ""some-signing-key-1"");
    }
",non-flaky,5
53160,cloudfoundry_uaa,TokenPolicyTest.tokenPolicy_whenInvalidUniquenessValue_throwsException,"    @Test
    public void tokenPolicy_whenInvalidUniquenessValue_throwsException() throws Exception {

        TokenPolicy tokenPolicy = new TokenPolicy();
        expectedException.expect(IllegalArgumentException.class);
        expectedException.expectMessage(""Invalid refresh token format invalid. Acceptable values are: [opaque, jwt]"");

        tokenPolicy.setRefreshTokenFormat(""invalid"");
    }
",non-flaky,5
53161,cloudfoundry_uaa,TokenPolicyTest.deserializationOfTokenPolicyWithNoActiveKeyIdWithMultipleKeys_doesNotFail,"    @Test
    public void deserializationOfTokenPolicyWithNoActiveKeyIdWithMultipleKeys_doesNotFail() {
        String jsonTokenPolicy = ""{\""keys\"":{\""key-id-1\"":{\""signingKey\"":\""some-signing-key-1\""},\""key-id-2\"":{\""signingKey\"":\""some-signing-key-2\""}}}"";
        TokenPolicy tokenPolicy = JsonUtils.readValue(jsonTokenPolicy, TokenPolicy.class);
        assertEquals(tokenPolicy.getKeys().get(""key-id-1""), ""some-signing-key-1"");
        assertEquals(tokenPolicy.getKeys().get(""key-id-2""), ""some-signing-key-2"");
    }
",non-flaky,5
53162,cloudfoundry_uaa,ScimGroupTests.testDeSerializeWithoutDescription,"    @Test
    public void testDeSerializeWithoutDescription() {
        group = JsonUtils.readValue(GROUP_BEFORE_DESCRIPTION, ScimGroup.class);
        assertEquals(""id"", group.getId());
        assertEquals(""name"", group.getDisplayName());
        assertEquals(""zoneId"", group.getZoneId());
        assertNull(group.getDescription());
    }
",non-flaky,5
53163,cloudfoundry_uaa,ScimGroupTests.testSerializeWithDescription,"    @Test
    public void testSerializeWithDescription() {
        group.setDescription(""description"");
        String json = JsonUtils.writeValueAsString(group);
        group = JsonUtils.readValue(json, ScimGroup.class);
        assertEquals(""id"", group.getId());
        assertEquals(""name"", group.getDisplayName());
        assertEquals(""zoneId"", group.getZoneId());
        assertEquals(""description"", group.getDescription());
    }
",non-flaky,5
53164,cloudfoundry_uaa,ScimGroupTests.testPatch,"    @Test
    public void testPatch(){
        group.patch(patch);
        assertEquals(patch.getId(), group.getId());
        assertEquals(""NewName"",group.getDisplayName());
        assertEquals(""NewDescription"", group.getDescription());
    }
",non-flaky,5
53165,cloudfoundry_uaa,ScimGroupTests.testPatchZoneIdFails,"    @Test
    public void testPatchZoneIdFails(){
        group.setZoneId(""uaa"");
        patch.setZoneId(""zoneid"");

        assertTrue(group.getZoneId().equals(""uaa""));
        assertTrue(patch.getZoneId().equals(""zoneid""));

        group.patch(patch);

        assertTrue(group.getZoneId().equals(""uaa""));
        assertTrue(patch.getZoneId().equals(""zoneid""));
    }
",non-flaky,5
53166,cloudfoundry_uaa,ScimGroupTests.testPatchDeleteMetaAttributes,"    @Test
    public void testPatchDeleteMetaAttributes(){
        assertEquals(""description"", group.getDescription());
        String[] attributes = new String[]{""description""};
        patch.getMeta().setAttributes(attributes);
        group.patch(patch);
        assertEquals(""NewDescription"", group.getDescription());

        patch.setDescription(null);
        group.patch(patch);
        assertNull(group.getDescription());
    }
",non-flaky,5
53167,cloudfoundry_uaa,ScimGroupTests.testDropDisplayName,"    @Test
    public void testDropDisplayName(){
        patch.setDisplayName(""NewDisplayName"");
        group.setDisplayName(""display"");
        assertEquals(""display"", group.getDisplayName());
        String[] attributes = new String[]{""displayname""};
        patch.getMeta().setAttributes(attributes);
        group.patch(patch);
        assertEquals(""NewDisplayName"", group.getDisplayName());

        patch.setDisplayName(null);
        group.patch(patch);
        assertNull(group.getDisplayName());
    }
",non-flaky,5
53168,cloudfoundry_uaa,ScimGroupTests.cant_drop_zone_id,"    @Test(expected = IllegalArgumentException.class)
    public void cant_drop_zone_id() {
        patch.getMeta().setAttributes(new String[] {""zoneID""});
        group.patch(patch);
    }
",non-flaky,5
53169,cloudfoundry_uaa,ScimGroupTests.cant_drop_id,"    @Test(expected = IllegalArgumentException.class)
    public void cant_drop_id() {
        patch.getMeta().setAttributes(new String[] {""id""});
        group.patch(patch);
    }
",non-flaky,5
53170,cloudfoundry_uaa,ScimGroupTests.testDropAllMembers,"    @Test
    public void testDropAllMembers(){
        group.setMembers(Arrays.asList(member1, member2, member3));
        assertEquals(3, group.getMembers().size());
        patch.getMeta().setAttributes(new String[] {""members""});
        group.patch(patch);
        assertEquals(0, group.getMembers().size());
    }
",non-flaky,5
53171,cloudfoundry_uaa,ScimGroupTests.testDropOneMembers,"    @Test
    public void testDropOneMembers(){
        group.setMembers(Arrays.asList(member1, member2, member3));
        ScimGroupMember member = new ScimGroupMember(member1.getMemberId());
        member.setOperation(""DELETE"");
        patch.setMembers(Arrays.asList(
            member
        ));
        group.patch(patch);
        assertEquals(2, group.getMembers().size());
    }
",non-flaky,5
53172,cloudfoundry_uaa,ScimGroupTests.testDropAllMembersUsingOperation,"    @Test
    public void testDropAllMembersUsingOperation() {
        member1.setOperation(""delete"");
        member2.setOperation(""delete"");
        member3.setOperation(""delete"");
        group.setMembers(Arrays.asList(member1, member2, member3));
        patch.setMembers(group.getMembers());
        assertEquals(3, group.getMembers().size());
        group.patch(patch);
        assertEquals(0, group.getMembers().size());

    }
",non-flaky,5
53173,cloudfoundry_uaa,ScimGroupTests.testAddAllMembers,"    @Test
    public void testAddAllMembers() {
        patch.setMembers(Arrays.asList(member1, member2, member3));
        group.setMembers(emptyList());
        assertEquals(0, group.getMembers().size());
        group.patch(patch);
        assertEquals(3, group.getMembers().size());

    }
",non-flaky,5
53174,cloudfoundry_uaa,ScimGroupTests.testAddOneMember,"    @Test
    public void testAddOneMember() {
        patch.setMembers(Arrays.asList(member1));
        group.setMembers(Arrays.asList(member2, member3));
        assertEquals(2, group.getMembers().size());
        group.patch(patch);
        assertEquals(3, group.getMembers().size());

    }
",non-flaky,5
53175,cloudfoundry_uaa,ScimGroupTests.test_toString,"    @Test
    public void test_toString() {
        group.toString();
    }
",non-flaky,5
53176,cloudfoundry_uaa,JsonDateDeserializerTest.testParsing,"    @Test
    public void testParsing() throws IOException, ParseException {
        Date d = JsonDateDeserializer.getDate(testDateString, new JsonLocation(null, 22, 0, 0));
        Assert.assertEquals(new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"").parse(testDateString).getTime(), (long) d.getTime());
    }
",non-flaky,5
53177,cloudfoundry_uaa,JsonDateDeserializerTest.testParsingParallel,"    @Test
    public void testParsingParallel() throws IOException, InterruptedException {
        Thread[] threadArray = new Thread[1000];
        for (int i = 0; i < 1000; i++) {

            threadArray[i] = new Thread(() -> {
                try {
                    Date d = JsonDateDeserializer.getDate(testDateString, new JsonLocation(null, 22, 0, 0));
                    if(new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"").parse(testDateString).getTime() != d.getTime())
                    {
                        throw new Exception(""Unexpected date"");
                    }
                } catch (Exception e) {
                    exceptionOccured = e;
                }
            });
        }
        for (int i = 0; i < 1000; i++) {
            threadArray[i].start();
        }
        for (int i = 0; i < 1000; i++) {
            threadArray[i].join();
        }
        Assert.assertNull(exceptionOccured);
    }
",non-flaky,5
53178,cloudfoundry_uaa,JsonDateSerializerTest.testFormatting,"    @Test
    public void testFormatting() throws IOException, ParseException {
        Date now = new Date();
        ByteArrayOutputStream bos = new ByteArrayOutputStream();
        JsonGenerator gen = new JsonFactory().createGenerator(bos);
        new JsonDateSerializer().serialize(now, gen, null);
        gen.close();
        Assert.assertEquals(String.format(""\""%s\"""", new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"").format(now)),
                bos.toString());
    }
",non-flaky,5
53179,cloudfoundry_uaa,JsonDateSerializerTest.testFormattingParallel,"    @Test
    public void testFormattingParallel() throws IOException, InterruptedException {
        Thread[] threadArray = new Thread[1000];
        for (int i = 0; i < 1000; i++) {

            threadArray[i] = new Thread(() -> {
                try {
                    Date now = new Date();
                    ByteArrayOutputStream bos = new ByteArrayOutputStream();
                    JsonGenerator gen = new JsonFactory().createGenerator(bos);
                    new JsonDateSerializer().serialize(now, gen, null);
                    gen.close();
                    if (!String.format(""\""%s\"""", new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"").format(now))
                            .equals(bos.toString())) {
                        throw new Exception(""Unexpected date"");
                    }

                } catch (Exception e) {
                    exceptionOccured = e;
                }
            });
        }
        for (

                int i = 0; i < 1000; i++) {
            threadArray[i].start();
        }
        for (int i = 0; i < 1000; i++) {
            threadArray[i].join();
        }
        Assert.assertNull(exceptionOccured);
    }
",non-flaky,5
53180,cloudfoundry_uaa,MfaProviderTest.testSerialize,"    @Test
    public void testSerialize() {

        MfaProvider<GoogleMfaProviderConfig> provider = createValidGoogleMfaProvider();
        provider.setCreated(new Date());
        provider.setLastModified(new Date());
        String string = JsonUtils.writeValueAsString(provider);
        JsonNode output = JsonUtils.readTree(JsonUtils.writeValueAsString(provider));
        assertEquals(output.get(""type"").textValue(), MfaProvider.MfaProviderType.GOOGLE_AUTHENTICATOR.toValue());
        JsonNode config = output.get(""config"");
        assertEquals(config.get(""issuer"").textValue(), ""current-zone"");
        assertEquals(config.get(""providerDescription"").textValue(), ""config description"");
    }
",non-flaky,5
53181,cloudfoundry_uaa,MfaProviderTest.testDeserialize,"    @Test
    public void testDeserialize() {
        String json = ""{\n"" +
                ""  \""type\"" : \""google-authenticator\"",\n"" +
                ""  \""config\"" : {\n"" +
                ""    \""providerDescription\"" : \""ddd\"",\n"" +
                ""    \""issuer\"": \""issuer\"",\n"" +
                ""    \""algorithm\"": \""SHA256\"",\n"" +
                ""    \""digits\"": 8, \n"" +
                ""    \""duration\"": 32 \n"" +
                ""  },\n"" +
                ""  \""name\"" : \""UAA Provider\"",  \n"" +
                ""  \""active\"" : true\n"" +
                ""}"";

        MfaProvider<GoogleMfaProviderConfig> provider = JsonUtils.readValue(json, MfaProvider.class);

        assertEquals(MfaProvider.MfaProviderType.GOOGLE_AUTHENTICATOR, provider.getType());
        assertEquals(""UAA Provider"", provider.getName());
        GoogleMfaProviderConfig config = provider.getConfig();
        assertEquals(""issuer"", config.getIssuer());
        assertEquals(""ddd"", config.getProviderDescription());
    }
",non-flaky,5
53182,cloudfoundry_uaa,MfaProviderTest.testDeserializeInvalidType,"    @Test
    public void testDeserializeInvalidType() {
        String json = ""{\n"" +
                ""  \""type\"" : \""invalid-type\"",\n"" +
                ""  \""config\"" : {\n"" +
                ""    \""providerDescription\"" : \""ddd\"",\n"" +
                ""    \""issuer\"": \""issuer\"",\n"" +
                ""    \""algorithm\"": \""SHA256\"",\n"" +
                ""    \""digits\"": 8, \n"" +
                ""    \""duration\"": 32 \n"" +
                ""  },\n"" +
                ""  \""name\"" : \""UAA Provider\"" \n"" +
                ""}"";

        MfaProvider<GoogleMfaProviderConfig> provider = JsonUtils.readValue(json, MfaProvider.class);

        assertEquals(null, provider.getType());
        assertEquals(""UAA Provider"", provider.getName());
        assertNull(provider.getConfig());
    }
",non-flaky,5
53183,cloudfoundry_uaa,MfaProviderTest.validateProviderActiveSetDefaultToTrue,"    @Test
    public void validateProviderActiveSetDefaultToTrue() {
        MfaProvider provider = createValidGoogleMfaProvider();
    }
",non-flaky,5
53184,cloudfoundry_uaa,GoogleMfaProviderConfigTest.testDefaultConfig,"    @Test
    public void testDefaultConfig() {
        config = new GoogleMfaProviderConfig();
        assertThat(config.getProviderDescription(), is(nullValue()));
        assertThat(config.getIssuer(), is(nullValue()));
    }
",non-flaky,5
53185,cloudfoundry_uaa,OpenIdConfigurationTests.testDefaultClaims,"    @Test
    public void testDefaultClaims() {
        assertEquals(""issuer"", defaultConfig.getIssuer());
        assertEquals(""/uaa/oauth/authorize"", defaultConfig.getAuthUrl());
        assertEquals(""/uaa/oauth/token"", defaultConfig.getTokenUrl());
        assertArrayEquals(new String[]{""client_secret_basic"", ""client_secret_post""}, defaultConfig.getTokenAMR());
        assertArrayEquals(new String[]{""RS256"", ""HS256""}, defaultConfig.getTokenEndpointAuthSigningValues());
        assertEquals(""/uaa/userinfo"", defaultConfig.getUserInfoUrl());
        assertEquals(""/uaa/token_keys"", defaultConfig.getJwksUri());
        assertArrayEquals(new String[]{""openid"", ""profile"", ""email"", ""phone"", ""roles"", ""user_attributes""}, defaultConfig.getScopes());
        assertArrayEquals(new String[]{""code"", ""code id_token"", ""id_token"", ""token id_token""}, defaultConfig.getResponseTypes());
        assertArrayEquals(new String[]{""public""}, defaultConfig.getSubjectTypesSupported());
        assertArrayEquals(new String[]{""RS256"", ""HS256""}, defaultConfig.getIdTokenSigningAlgValues());
        assertArrayEquals(new String[]{""none""}, defaultConfig.getRequestObjectSigningAlgValues());
        assertArrayEquals(new String[]{""normal""}, defaultConfig.getClaimTypesSupported());
        assertArrayEquals(
            new String[]{
                ""sub"", ""user_name"", ""origin"", ""iss"", ""auth_time"",
                ""amr"", ""acr"", ""client_id"", ""aud"", ""zid"", ""grant_type"",
                ""user_id"", ""azp"", ""scope"", ""exp"", ""iat"", ""jti"", ""rev_sig"",
                ""cid"", ""given_name"", ""family_name"", ""phone_number"", ""email""},
            defaultConfig.getClaimsSupported()
        );
        assertFalse(defaultConfig.isClaimsParameterSupported());
        assertEquals(""http://docs.cloudfoundry.org/api/uaa/"", defaultConfig.getServiceDocumentation());
        assertArrayEquals(new String[]{""en-US""}, defaultConfig.getUiLocalesSupported());
    }
",non-flaky,5
53186,cloudfoundry_uaa,UserInfoResponseJsonTests.deserializeTest,"    @Test
    public void deserializeTest() {
        UserInfoResponse response = JsonUtils.readValue(json, UserInfoResponse.class);
        assertEquals(""olds@vmware.com"", response.getEmail());
        assertEquals(""Dale"", response.getGivenName());
        assertEquals(""Olds"", response.getFamilyName());
        assertEquals(""Dale Olds"", response.getFullName());
        assertEquals(""8505551234"", response.getPhoneNumber());
        assertEquals(""12345"", response.getUserId());
        assertEquals(""12345"", response.getSub());
        assertEquals(""olds"", response.getUserName());
        assertEquals(true, response.isEmailVerified());

        assertThat(
            response.getUserAttributes().get(""Key 1""),
            hasItems(CoreMatchers.is(""Val 11""), CoreMatchers.is(""Val 12""))
        );
        assertThat(
            response.getUserAttributes().get(""Key 2""),
            hasItems(CoreMatchers.is(""Val 21""), CoreMatchers.is(""Val 22""))
        );

        assertThat(
            response.getRoles(),
            hasItems(
                CoreMatchers.is(""role12""),
                CoreMatchers.is(""role54""),
                CoreMatchers.is(""role134""),
                CoreMatchers.is(""role812"")
            )
        );
        assertEquals(Long.valueOf(1000L), response.previousLogonSuccess);
    }
",non-flaky,5
53187,cloudfoundry_uaa,UserInfoResponseJsonTests.serializeTest,"    @Test
    public void serializeTest() {
        UserInfoResponse response = JsonUtils.readValue(json, UserInfoResponse.class);
        json = JsonUtils.writeValueAsString(response);
        deserializeTest();
    }
",non-flaky,5
53188,cloudfoundry_uaa,ExternalIdentityProviderDefinitionTest.testEquals,"    @Test
    public void testEquals() {
        ExternalIdentityProviderDefinition definition1 = new ExternalIdentityProviderDefinition();
        definition1.setAddShadowUserOnLogin(true);
        ExternalIdentityProviderDefinition definition2 = new ExternalIdentityProviderDefinition();
        definition2.setAddShadowUserOnLogin(false);

        assertNotEquals(definition1, definition2);
        definition2.setAddShadowUserOnLogin(true);
        assertEquals(definition1, definition2);
    }
",non-flaky,5
53189,cloudfoundry_uaa,ExternalIdentityProviderDefinitionTest.testDefaultValueForStoreCustomAttributes,"    @Test
    public void testDefaultValueForStoreCustomAttributes() {
        assertTrue(definition.isStoreCustomAttributes());
    }
",non-flaky,5
53190,cloudfoundry_uaa,ExternalIdentityProviderDefinitionTest.testEquals2,"    @Test
    public void testEquals2() {
        ExternalIdentityProviderDefinition def = new ExternalIdentityProviderDefinition();
        def.setStoreCustomAttributes(false);
        assertFalse(definition.equals(def));
    }
",non-flaky,5
53191,cloudfoundry_uaa,OIDCIdentityProviderDefinitionTests.serialize_discovery_url,"    @Test
    public void serialize_discovery_url() throws MalformedURLException {
        OIDCIdentityProviderDefinition def = JsonUtils.readValue(defaultJson, OIDCIdentityProviderDefinition.class);
        assertNull(def.getDiscoveryUrl());
        def.setDiscoveryUrl(new URL(url));
        assertEquals(url, def.getDiscoveryUrl().toString());
        String json = JsonUtils.writeValueAsString(def);
        def = JsonUtils.readValue(json, OIDCIdentityProviderDefinition.class);
        assertEquals(url, def.getDiscoveryUrl().toString());
    }
",non-flaky,5
53192,cloudfoundry_uaa,OIDCIdentityProviderDefinitionTests.serialize_prompts,"    @Test
    public void serialize_prompts() {
        OIDCIdentityProviderDefinition def = JsonUtils.readValue(defaultJson, OIDCIdentityProviderDefinition.class);
        assertNull(def.getPrompts());
        List<Prompt> prompts = Arrays.asList(new Prompt(""username"", ""text"", ""Email""),
                new Prompt(""password"", ""password"", ""Password""),
                new Prompt(""passcode"", ""password"", ""Temporary Authentication Code (Get on at /passcode)""));
        def.setPrompts(prompts);
        String json = JsonUtils.writeValueAsString(def);
        def = JsonUtils.readValue(json, OIDCIdentityProviderDefinition.class);
        assertEquals(prompts, def.getPrompts());
    }
",non-flaky,5
53193,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testQRCodeScreen,"    @Test
    public void testQRCodeScreen() throws Exception {
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        String imageSrc = webDriver.findElement(By.id(""qr"")).getAttribute(""src"");

        String secretKey = getSecretFromQrImageString(imageSrc);

        webDriver.findElement(By.id(""Next"")).click();
        verifyCodeOnRegistration(secretKey, ""/"");
    }
",non-flaky,5
53194,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.force_password_happens_after_MFA,"    @Test
    public void force_password_happens_after_MFA() throws Exception {
        IntegrationTestUtils.updateUserToForcePasswordChange(
            getRestTemplate(),
            baseUrl,
            adminAccessToken,
            user.getId(),
            mfaZone.getId()
        );

        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        String imageSrc = webDriver.findElement(By.id(""qr"")).getAttribute(""src"");

        String secretKey = getSecretFromQrImageString(imageSrc);

        webDriver.findElement(By.id(""Next"")).click();
        verifyCodeOnRegistration(secretKey, ""/force_password_change"");


    }
",non-flaky,5
53195,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testQRCodeScreenAfterRegistrationDeletion,"    @Test
    public void testQRCodeScreenAfterRegistrationDeletion() throws Exception {
        // register mfa for user and logout
        testQRCodeScreen();
        webDriver.get(zoneUrl + ""/logout.do"");

        // retrieve user id and delete mfa registration
        RestTemplate client = getRestTemplate();
        HttpHeaders headers = new HttpHeaders();
        headers.add(""Authorization"", ""Bearer "" + zoneAdminToken);
        headers.add(""X-Identity-Zone-Id"", mfaZone.getId());
        headers.add(""Content-Type"", ""application/json"");
        Map<String, String> uriParams = new HashMap<>();
        uriParams.put(""filter"",""userName eq \""""+username+""\"""");
        ResponseEntity<Map> exchange = client.exchange(serverRunning.getUrl(""/Users?attributes=id&filter={filter}""), HttpMethod.GET, new HttpEntity<Void>(
            headers), Map.class, uriParams);
        String userId = (String) ((Map)((java.util.List) exchange.getBody().get(""resources"")).get(0)).get(""id"");

        client.exchange(serverRunning.getUrl(""/Users/{userId}/mfa""), HttpMethod.DELETE, new HttpEntity<Void>(
            headers), Map.class, userId);

        // user login should end up at mfa registration page
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());
    }
",non-flaky,5
53196,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testMfaRegisterPageWithoutLoggingIn,"    @Test
    public void testMfaRegisterPageWithoutLoggingIn() {
        webDriver.get(zoneUrl + ""/logout.do"");
        webDriver.get(zoneUrl + ""/login/mfa/register"");
        assertEquals(zoneUrl + ""/login"", webDriver.getCurrentUrl());
    }
",non-flaky,5
53197,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testMfaVerifyPageWithoutLoggingIn,"    @Test
    public void testMfaVerifyPageWithoutLoggingIn() {
        webDriver.get(zoneUrl + ""/logout.do"");
        webDriver.get(zoneUrl + ""/login/mfa/verify"");
        assertEquals(zoneUrl + ""/login"", webDriver.getCurrentUrl());
    }
",non-flaky,5
53198,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testQRCodeValidation,"    @Test
    public void testQRCodeValidation() {
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        webDriver.findElement(By.id(""Next"")).click();
        assertEquals(zoneUrl + ""/login/mfa/verify"", webDriver.getCurrentUrl());
        webDriver.findElement(By.name(""code"")).sendKeys(""1111111111111111112222"");

        webDriver.findElement(By.id(""verify_code_btn"")).click();
        assertEquals(""Incorrect code, please try again."", webDriver.findElement(By.cssSelector(""form .error-color"")).getText());
    }
",non-flaky,5
53199,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.checkAccessForTotpPage,"    @Test
    public void checkAccessForTotpPage() throws Exception {
        webDriver.get(zoneUrl + ""/logout.do"");
        webDriver.manage().deleteAllCookies();
        webDriver.get(zoneUrl + ""/login/mfa/register"");
        assertEquals(zoneUrl + ""/login"", webDriver.getCurrentUrl());
    }
",non-flaky,5
53200,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testDisplayIdentityZoneNameOnRegisterPage,"    @Test
    public void testDisplayIdentityZoneNameOnRegisterPage() {
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        assertEquals(webDriver.findElement(By.id(""mfa-identity-zone"")).getText(), mfaZone.getName());
    }
",non-flaky,5
53201,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testDisplayIdentityZoneNameOnVerifyPage,"    @Test
    public void testDisplayIdentityZoneNameOnVerifyPage() {
        performLogin(username);
        webDriver.findElement(By.id(""Next"")).click();

        assertEquals(zoneUrl + ""/login/mfa/verify"", webDriver.getCurrentUrl());
        assertEquals(webDriver.findElement(By.id(""mfa-identity-zone"")).getText(), mfaZone.getName());

        webDriver.findElement(By.id(""verify_code_btn"")).click();
        assertEquals(webDriver.findElement(By.id(""mfa-identity-zone"")).getText(), mfaZone.getName());
    }
",non-flaky,5
53202,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testManualMfaRegistrationFlow,"    @Test
    public void testManualMfaRegistrationFlow() {
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        webDriver.findElement(By.linkText(""manual setup instructions"")).click();

        assertEquals(zoneUrl + ""/login/mfa/manual"", webDriver.getCurrentUrl());

        String key = webDriver.findElement(By.id(""key"")).getText();
        String account = webDriver.findElement(By.id(""account"")).getText();
        assertFalse(""secret not found"", key.isEmpty());
        assertFalse(""account not found"", account.isEmpty());

        webDriver.findElement(By.id(""Next"")).click();
        assertEquals(zoneUrl + ""/login/mfa/verify"", webDriver.getCurrentUrl());

        verifyCodeOnRegistration(key, ""/"");
    }
",non-flaky,5
53203,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testQRCodeScreen_ClickManualAndReturn,"    @Test
    public void testQRCodeScreen_ClickManualAndReturn() throws Exception{
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        webDriver.findElement(By.linkText(""manual setup instructions"")).click();
        assertEquals(zoneUrl + ""/login/mfa/manual"", webDriver.getCurrentUrl());

        webDriver.findElement(By.id(""Back"")).click();
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        String imageSrc = webDriver.findElement(By.id(""qr"")).getAttribute(""src"");

        String secretKey = getSecretFromQrImageString(imageSrc);

        webDriver.findElement(By.id(""Next"")).click();
        verifyCodeOnRegistration(secretKey, ""/"");
    }
",non-flaky,5
53204,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testManualMfaRegistrationFlow_ClickBackAndManual,"    @Test
    public void testManualMfaRegistrationFlow_ClickBackAndManual() {
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        webDriver.findElement(By.linkText(""manual setup instructions"")).click();
        assertEquals(zoneUrl + ""/login/mfa/manual"", webDriver.getCurrentUrl());

        webDriver.findElement(By.id(""Back"")).click();
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        webDriver.findElement(By.linkText(""manual setup instructions"")).click();
        assertEquals(zoneUrl + ""/login/mfa/manual"", webDriver.getCurrentUrl());

        String key = webDriver.findElement(By.id(""key"")).getText();
        String account = webDriver.findElement(By.id(""account"")).getText();
        assertFalse(""secret not found"", key.isEmpty());
        assertFalse(""account not found"", account.isEmpty());

        webDriver.findElement(By.id(""Next"")).click();
        assertEquals(zoneUrl + ""/login/mfa/verify"", webDriver.getCurrentUrl());

        verifyCodeOnRegistration(key, ""/"");
    }
",non-flaky,5
53205,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testQRCodeScreen_ClickManualClickNextClickBack,"    @Test
    public void testQRCodeScreen_ClickManualClickNextClickBack() throws Exception{
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        webDriver.findElement(By.linkText(""manual setup instructions"")).click();
        assertEquals(zoneUrl + ""/login/mfa/manual"", webDriver.getCurrentUrl());

        webDriver.findElement(By.id(""Next"")).click();
        assertEquals(zoneUrl + ""/login/mfa/verify"", webDriver.getCurrentUrl());

        webDriver.findElement(By.id(""Back"")).click();
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        String imageSrc = webDriver.findElement(By.id(""qr"")).getAttribute(""src"");

        String secretKey = getSecretFromQrImageString(imageSrc);

        assertFalse(""secret not found"", secretKey.isEmpty());

        webDriver.findElement(By.id(""Next"")).click();
        verifyCodeOnRegistration(secretKey, ""/"");
    }
",non-flaky,5
53206,cloudfoundry_uaa,CfAuthenticationTests.testDefaultScopes,"    @Test
    public void testDefaultScopes() {
        params.set(
                        ""credentials"",
                        String.format(""{\""username\"":\""%s\"",\""password\"":\""%s\""}"", testAccounts.getUserName(),
                                        testAccounts.getPassword()));
        ResponseEntity<Void> response = serverRunning.postForResponse(serverRunning.getAuthorizationUri(), headers,
                        params);
        assertEquals(HttpStatus.FOUND, response.getStatusCode());
        String location = response.getHeaders().getLocation().toString();
        assertTrue(""Not authenticated (no access token): "" + location, location.contains(""access_token""));
    }
",non-flaky,5
53207,cloudfoundry_uaa,CfAuthenticationTests.testInvalidScopes,"    @Test
    public void testInvalidScopes() {
        params.set(
                        ""credentials"",
                        String.format(""{\""username\"":\""%s\"",\""password\"":\""%s\""}"", testAccounts.getUserName(),
                                        testAccounts.getPassword()));
        params.set(""scope"", ""read"");
        ResponseEntity<Void> response = serverRunning.postForResponse(serverRunning.getAuthorizationUri(), headers,
                        params);
        assertEquals(HttpStatus.FOUND, response.getStatusCode());
        String location = response.getHeaders().getLocation().toString();
        // System.err.println(location);
        assertTrue(location.startsWith(params.getFirst(""redirect_uri"")));
        assertTrue(location.contains(""error=invalid_scope""));
        assertFalse(location.contains(""credentials=""));
    }
",non-flaky,5
53208,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.getGroupsWithoutAttributesReturnsAllData,"    @Test
    public void getGroupsWithoutAttributesReturnsAllData() {
        @SuppressWarnings(""rawtypes"")
        ResponseEntity<Map> response = client.getForEntity(serverRunning.getUrl(groupEndpoint), Map.class);

        @SuppressWarnings(""rawtypes"")
        Map results = response.getBody();
        assertEquals(HttpStatus.OK, response.getStatusCode());
        assertTrue(""There should be more than zero users"", (Integer) results.get(""totalResults"") > 0);
        assertTrue(""There should be some resources"", ((Collection<?>) results.get(""resources"")).size() > 0);
        @SuppressWarnings(""rawtypes"")
        Map firstGroup = (Map) ((List) results.get(""resources"")).get(0);
        assertTrue(firstGroup.containsKey(""id""));
        assertTrue(firstGroup.containsKey(""displayName""));
        assertTrue(firstGroup.containsKey(""schemas""));
        assertTrue(firstGroup.containsKey(""meta""));
    }
",non-flaky,5
53209,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.createGroupSucceeds,"    @Test
    public void createGroupSucceeds() throws Exception {
        ScimGroup g1 = createGroup(CFID);
        // Check we can GET the group
        ScimGroup g2 = client.getForObject(serverRunning.getUrl(groupEndpoint + ""/{id}""), ScimGroup.class, g1.getId());
        assertEquals(g1, g2);
    }
",non-flaky,5
53210,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.createGroupWithMembersSucceeds,"    @Test
    public void createGroupWithMembersSucceeds() {
        ScimGroup g1 = createGroup(CFID, JOEL, DALE, VIDYA);
        // Check we can GET the group
        ScimGroup g2 = client.getForObject(serverRunning.getUrl(groupEndpoint + ""/{id}""), ScimGroup.class, g1.getId());
        assertEquals(g1, g2);
        assertEquals(3, g2.getMembers().size());
        assertTrue(g2.getMembers().contains(JOEL));
        assertTrue(g2.getMembers().contains(DALE));
        assertTrue(g2.getMembers().contains(VIDYA));

        // check that User.groups is updated
        validateUserGroups(JOEL.getMemberId(), CFID);
        validateUserGroups(DALE.getMemberId(), CFID);
        validateUserGroups(VIDYA.getMemberId(), CFID);
    }
",non-flaky,5
53211,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.createGroupWithInvalidMembersFailsCorrectly,"    @Test
    public void createGroupWithInvalidMembersFailsCorrectly() {
        ScimGroup g = new ScimGroup(null, CFID, IdentityZoneHolder.get().getId());
        ScimGroupMember m2 = new ScimGroupMember(""wrongid"");
        g.setMembers(Arrays.asList(VIDYA, m2));

        @SuppressWarnings(""rawtypes"")
        ResponseEntity<Map> r = client.postForEntity(serverRunning.getUrl(groupEndpoint), g, Map.class);
        @SuppressWarnings(""unchecked"")
        Map<String, String> g1 = r.getBody();
        assertEquals(HttpStatus.BAD_REQUEST, r.getStatusCode());
        assertTrue(g1.containsKey(""error""));
        assertTrue(g1.containsKey(""message""));
        assertTrue(g1.get(""message"").contains(""Invalid group member""));

        // check that the group was not created
        @SuppressWarnings(""unchecked"")
        Map<String, String> g2 = client.getForObject(
            serverRunning.getUrl(groupEndpoint + ""?filter=displayName eq \""{name}\""""), Map.class, CFID);
        assertTrue(g2.containsKey(""totalResults""));
        assertEquals(0, g2.get(""totalResults""));
    }
",non-flaky,5
53212,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.createGroupWithMemberGroupSucceeds,"    @Test
    public void createGroupWithMemberGroupSucceeds() {
        ScimGroup g1 = createGroup(CFID, VIDYA);
        ScimGroupMember m2 = new ScimGroupMember(g1.getId(), ScimGroupMember.Type.GROUP);
        ScimGroup g2 = createGroup(CF_DEV, m2);

        // Check we can GET the group
        ScimGroup g3 = client.getForObject(serverRunning.getUrl(groupEndpoint + ""/{id}""), ScimGroup.class, g2.getId());
        assertEquals(g2, g3);
        assertEquals(1, g3.getMembers().size());
        assertTrue(g3.getMembers().contains(m2));

        // check that User.groups is updated
        validateUserGroups(VIDYA.getMemberId(), CFID, CF_DEV);
    }
",non-flaky,5
53213,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.createExistingGroupFailsCorrectly,"    @Test
    public void createExistingGroupFailsCorrectly() {
        ScimGroup g1 = createGroup(CFID);
        @SuppressWarnings(""unchecked"")
        Map<String, String> g2 = client.postForEntity(serverRunning.getUrl(groupEndpoint), g1, Map.class).getBody();
        assertTrue(g2.containsKey(""error""));
        assertEquals(""scim_resource_already_exists"", g2.get(""error""));
    }
",non-flaky,5
53214,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.deleteGroupUpdatesUser,"    @Test
    public void deleteGroupUpdatesUser() {
        ScimGroup g1 = createGroup(DELETE_ME, DALE, VIDYA);
        validateUserGroups(DALE.getMemberId(), DELETE_ME);
        validateUserGroups(VIDYA.getMemberId(), DELETE_ME);

        deleteResource(groupEndpoint, g1.getId());

        // check that the group does not exist anymore
        @SuppressWarnings(""unchecked"")
        Map<String, Object> g2 = client.getForObject(
            serverRunning.getUrl(groupEndpoint + ""?filter=displayName eq \""{name}\""""), Map.class, DELETE_ME);
        assertTrue(g2.containsKey(""totalResults""));
        assertEquals(0, g2.get(""totalResults""));

        // check that group membership is updated
        validateUserGroups(DALE.getMemberId());
        validateUserGroups(VIDYA.getMemberId());
    }
",non-flaky,5
53215,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.deleteNonExistentGroupFailsCorrectly,"    @Test
    public void deleteNonExistentGroupFailsCorrectly() {
        @SuppressWarnings(""unchecked"")
        Map<String, Object> g = deleteResource(groupEndpoint, DELETE_ME).getBody();
        assertTrue(g.containsKey(""error""));
        assertEquals(""scim_resource_not_found"", g.get(""error""));
    }
",non-flaky,5
53216,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.deleteMemberGroupUpdatesGroup,"    @Test
    public void deleteMemberGroupUpdatesGroup() {
        ScimGroup g1 = createGroup(CFID, VIDYA);
        ScimGroupMember m2 = new ScimGroupMember(g1.getId(), ScimGroupMember.Type.GROUP);
        ScimGroup g2 = createGroup(CF_DEV, DALE, m2);
        assertTrue(g2.getMembers().contains(m2));
        validateUserGroups(VIDYA.getMemberId(), CFID, CF_DEV);

        deleteResource(groupEndpoint, g1.getId());

        // check that parent group is updated
        ScimGroup g3 = client.getForObject(serverRunning.getUrl(groupEndpoint + ""/{id}""), ScimGroup.class, g2.getId());
        assertEquals(1, g3.getMembers().size());
        assertFalse(g3.getMembers().contains(m2));
    }
",non-flaky,5
53217,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.testDeleteMemberUserUpdatesGroups,"    @Test
    public void testDeleteMemberUserUpdatesGroups() {
        ScimGroupMember toDelete = new ScimGroupMember(createUser(DELETE_ME, ""Passwo3d"").getId());
        ScimGroup g1 = createGroup(CFID, JOEL, DALE, toDelete);
        ScimGroup g2 = createGroup(CF_MGR, DALE, toDelete);
        deleteResource(userEndpoint, toDelete.getMemberId());

        // check that membership has been updated
        ScimGroup g3 = client.getForObject(serverRunning.getUrl(groupEndpoint + ""/{id}""), ScimGroup.class, g1.getId());
        assertEquals(2, g3.getMembers().size());
        assertFalse(g3.getMembers().contains(toDelete));

        g3 = client.getForObject(serverRunning.getUrl(groupEndpoint + ""/{id}""), ScimGroup.class, g2.getId());
        assertEquals(1, g3.getMembers().size());
        assertFalse(g3.getMembers().contains(toDelete));
    }
",non-flaky,5
53218,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.testUpdateGroupUpdatesMemberUsers,"    @Test
    public void testUpdateGroupUpdatesMemberUsers() {
        ScimGroup g1 = createGroup(CFID, JOEL, VIDYA);
        ScimGroup g2 = createGroup(CF_MGR, DALE);
        ScimGroupMember m1 = new ScimGroupMember(g1.getId(), ScimGroupMember.Type.GROUP);
        ScimGroupMember m2 = new ScimGroupMember(g2.getId(), ScimGroupMember.Type.GROUP);
        ScimGroup g3 = createGroup(CF_DEV, m1, m2);

        validateUserGroups(JOEL.getMemberId(), CFID, CF_DEV);
        validateUserGroups(VIDYA.getMemberId(), CFID, CF_DEV);
        validateUserGroups(DALE.getMemberId(), CF_MGR, CF_DEV);

        ScimGroup g4 = updateGroup(g3.getId(), ""new_name"", m1);

        // check that we did not create a new group, but only updated the
        // existing one
        assertEquals(g3, g4);
        // check that member users were updated
        validateUserGroups(DALE.getMemberId(), CF_MGR);
        validateUserGroups(JOEL.getMemberId(), CFID, ""new_name"");
        validateUserGroups(VIDYA.getMemberId(), CFID, ""new_name"");
    }
",non-flaky,5
53219,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.testAccessTokenReflectsGroupMembership,"    @Test
    public void testAccessTokenReflectsGroupMembership() throws Exception {

        createTestClient(DELETE_ME, ""secret"", CFID);
        ScimUser user = createUser(DELETE_ME, ""Passwo3d"");
        createGroup(CFID, new ScimGroupMember(user.getId()));
        OAuth2AccessToken token = getAccessToken(DELETE_ME, ""secret"", DELETE_ME, ""Passwo3d"");
        assertTrue(""Wrong token: "" + token, token.getScope().contains(CFID));

        deleteTestClient(DELETE_ME);
        deleteResource(userEndpoint, user.getId());

    }
",non-flaky,5
53220,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.testAccessTokenReflectsGroupMembershipForPasswordGrant,"    @Test
    public void testAccessTokenReflectsGroupMembershipForPasswordGrant() throws Exception {

        createTestClient(DELETE_ME, ""secret"", CFID);
        ScimUser user = createUser(DELETE_ME, ""Passwo3d"");
        createGroup(CFID, new ScimGroupMember(user.getId()));
        OAuth2AccessToken token = getAccessTokenWithPassword(DELETE_ME, ""secret"", DELETE_ME, ""Passwo3d"");
        assertTrue(""Wrong token: "" + token, token.getScope().contains(CFID));

        deleteTestClient(DELETE_ME);
        deleteResource(userEndpoint, user.getId());

    }
",non-flaky,5
53221,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.testExtremeGroupPagination,"    @Test
    public void testExtremeGroupPagination() {
        for (int i = 0; i < 502; i++) {
            ScimUser user = createUser(""deleteme_"" + new RandomValueStringGenerator().generate().toLowerCase(), ""Passwo3d"");
            scimGroups.add(createGroup(""cfid_"" + new RandomValueStringGenerator().generate().toLowerCase(), new ScimGroupMember(user.getId())));
        }

        ResponseEntity<Map> response = client.getForEntity(serverRunning.getUrl(groupEndpoint + ""?count=502""), Map.class);

        Map results = response.getBody();
        assertThat(response.getStatusCode(), is(HttpStatus.OK));
        assertThat((Integer) results.get(""totalResults""), greaterThan(500));
        assertThat((List<?>) results.get(""resources""), hasSize(500));
        assertThat(results.get(""itemsPerPage""), is(500));
        assertThat(results.get(""startIndex""), is(1));

    }
",non-flaky,5
53222,cloudfoundry_uaa,SamlLoginIT.testContentTypes,"    @Test
    public void testContentTypes() {
        String loginUrl = baseUrl + ""/login"";
        HttpHeaders jsonHeaders = new HttpHeaders();
        jsonHeaders.add(""Accept"", ""application/json"");
        ResponseEntity<Map> jsonResponseEntity = restOperations.exchange(loginUrl,
            HttpMethod.GET,
            new HttpEntity<>(jsonHeaders),
            Map.class);
        assertThat(jsonResponseEntity.getHeaders().get(""Content-Type"").get(0), containsString(APPLICATION_JSON_VALUE));

        HttpHeaders htmlHeaders = new HttpHeaders();
        htmlHeaders.add(""Accept"", ""text/html"");
        ResponseEntity<Void> htmlResponseEntity = restOperations.exchange(loginUrl,
            HttpMethod.GET,
            new HttpEntity<>(htmlHeaders),
            Void.class);
        assertThat(htmlResponseEntity.getHeaders().get(""Content-Type"").get(0), containsString(TEXT_HTML_VALUE));

        HttpHeaders defaultHeaders = new HttpHeaders();
        defaultHeaders.add(""Accept"", ""*/*"");
        ResponseEntity<Void> defaultResponseEntity = restOperations.exchange(loginUrl,
            HttpMethod.GET,
            new HttpEntity<>(defaultHeaders),
            Void.class);
        assertThat(defaultResponseEntity.getHeaders().get(""Content-Type"").get(0), containsString(TEXT_HTML_VALUE));
    }
",non-flaky,5
53223,cloudfoundry_uaa,SamlLoginIT.testSimpleSamlPhpPasscodeRedirect,"    @Test
    public void testSimpleSamlPhpPasscodeRedirect() throws Exception {
        testSimpleSamlLogin(""/passcode"", ""Temporary Authentication Code"");
    }
",non-flaky,5
53224,cloudfoundry_uaa,SamlLoginIT.testSimpleSamlLoginWithAddShadowUserOnLoginFalse,"    @Test
    public void testSimpleSamlLoginWithAddShadowUserOnLoginFalse() throws Exception {
        // Deleting marissa@test.org from simplesamlphp because previous SAML authentications automatically
        // create a UAA user with the email address as the username.
        deleteUser(SAML_ORIGIN, testAccounts.getEmail());

        IdentityProvider provider = IntegrationTestUtils.createIdentityProvider(SAML_ORIGIN, false, baseUrl, serverRunning);
        String clientId = ""app-addnew-false""+ new RandomValueStringGenerator().generate();
        String redirectUri = ""http://nosuchhostname:0/nosuchendpoint"";
        BaseClientDetails client = createClientAndSpecifyProvider(clientId, provider, redirectUri);

        String firstUrl = ""/oauth/authorize?""
                + ""client_id="" + clientId
                + ""&response_type=code""
                + ""&redirect_uri="" + URLEncoder.encode(redirectUri, ""UTF-8"");

        webDriver.get(baseUrl + firstUrl);
        webDriver.findElement(By.xpath(""//h2[contains(text(), 'Enter your username and password')]""));
        webDriver.findElement(By.name(""username"")).clear();
        webDriver.findElement(By.name(""username"")).sendKeys(testAccounts.getUserName());
        webDriver.findElement(By.name(""password"")).sendKeys(testAccounts.getPassword());
        webDriver.findElement(By.xpath(""//input[@value='Login']"")).click();

        // We need to verify the last request URL through the performance log because the redirect
        // URI does not exist. When the webDriver follows the non-existent redirect URI it receives a
        // connection refused error so webDriver.getCurrentURL() will remain as the SAML IdP URL.

        List<LogEntry> logEntries = webDriver.manage().logs().get(LogType.PERFORMANCE).getAll();
        List<String> logMessages = logEntries.stream().map(logEntry -> logEntry.getMessage()).collect(Collectors.toList());

        assertThat(logMessages, hasItem(containsString(redirectUri + ""?error=access_denied&error_description=SAML+user+does+not+exist.+You+can+correct+this+by+creating+a+shadow+user+for+the+SAML+user."")));
    }
",non-flaky,5
53225,cloudfoundry_uaa,SamlLoginIT.failureResponseFromSamlIDP_showErrorFromSaml,"    @Test
    public void failureResponseFromSamlIDP_showErrorFromSaml() throws Exception {
        String zoneId = ""testzone3"";
        String zoneUrl = baseUrl.replace(""localhost"",zoneId+"".localhost"");

        //identity client token
        RestTemplate identityClient = IntegrationTestUtils.getClientCredentialsTemplate(
            IntegrationTestUtils.getClientCredentialsResource(baseUrl, new String[]{""zones.write"", ""zones.read"", ""scim.zones""}, ""identity"", ""identitysecret"")
        );
        RestTemplate adminClient = IntegrationTestUtils.getClientCredentialsTemplate(
            IntegrationTestUtils.getClientCredentialsResource(baseUrl, new String[0], ""admin"", ""adminsecret"")
        );
        //create the zone

        IntegrationTestUtils.createZoneOrUpdateSubdomain(identityClient, baseUrl, zoneId, zoneId, null);

        //create a zone admin user
        String email = new RandomValueStringGenerator().generate() +""@samltesting.org"";
        ScimUser user = IntegrationTestUtils.createUser(adminClient, baseUrl,email ,""firstname"", ""lastname"", email, true);
        String groupId = IntegrationTestUtils.findGroupId(adminClient, baseUrl, ""zones."" + zoneId + "".admin"");
        IntegrationTestUtils.addMemberToGroup(adminClient, baseUrl, user.getId(), groupId);

        //get the zone admin token
        String zoneAdminToken =
            IntegrationTestUtils.getAccessTokenByAuthCode(serverRunning,
                UaaTestAccounts.standard(serverRunning),
                ""identity"",
                ""identitysecret"",
                email,
                ""secr3T"");

        SamlIdentityProviderDefinition samlIdentityProviderDefinition = createSimplePHPSamlIDP(SAML_ORIGIN, ""testzone3"");
        IdentityProvider provider = new IdentityProvider();
        provider.setIdentityZoneId(zoneId);
        provider.setType(OriginKeys.SAML);
        provider.setActive(true);
        provider.setConfig(samlIdentityProviderDefinition);
        provider.setOriginKey(samlIdentityProviderDefinition.getIdpEntityAlias());
        provider.setName(""simplesamlphp for testzone2"");

        IntegrationTestUtils.createOrUpdateProvider(zoneAdminToken, baseUrl, provider);

        webDriver.get(zoneUrl);
        webDriver.findElement(By.linkText(""Login with Simple SAML PHP(simplesamlphp)"")).click();
        webDriver.findElement(By.xpath(""//h2[contains(text(), 'Enter your username and password')]""));
        webDriver.findElement(By.name(""username"")).clear();
        webDriver.findElement(By.name(""username"")).sendKeys(testAccounts.getUserName());
        webDriver.findElement(By.name(""password"")).sendKeys(testAccounts.getPassword());
        webDriver.findElement(By.xpath(""//input[@value='Login']"")).click();

        assertEquals(""No local entity found for alias invalid, verify your configuration."", webDriver.findElement(By.cssSelector(""h2"")).getText());
    }
",non-flaky,5
53226,cloudfoundry_uaa,SamlLoginIT.testSimpleSamlPhpLogin,"    @Test
    public void testSimpleSamlPhpLogin() throws Exception {
        Long beforeTest = System.currentTimeMillis();
        testSimpleSamlLogin(""/login"", ""Where to?"");
        Long afterTest = System.currentTimeMillis();
        String zoneAdminToken = IntegrationTestUtils.getClientCredentialsToken(serverRunning, ""admin"", ""adminsecret"");
        ScimUser user = IntegrationTestUtils.getUser(zoneAdminToken, baseUrl, SAML_ORIGIN, testAccounts.getEmail());
        IntegrationTestUtils.validateUserLastLogon(user, beforeTest, afterTest);
    }
",non-flaky,5
319,liquibase_liquibase,DependencyUtilTest.testIndependentBranchesCase,"@Test
public void testIndependentBranchesCase() {
    graph.add(""a"", ""b"");
    graph.add(""b"", ""c1"");
    graph.add(""b"", ""c2"");
    graph.add(""o"", ""p1"");
    graph.add(""p1"", ""r1"");
    graph.add(""r1"", ""s"");
    graph.add(""o"", ""p2"");
    graph.add(""p2"", ""r2"");
    graph.add(""r2"", ""s2"");
    graph.add(""r2"", ""s3"");
    graph.add(""x"", ""y"");
    graph.computeDependencies();
    List<String> expected =
    Arrays.asList(""a"", ""o"", ""x"", ""b"", ""p1"", ""p2"", ""y"", ""c1"", ""c2"", ""r1"", ""r2"", ""s"", ""s2"", ""s3"");
    Assert.assertEquals(expected, dependencyOrder);
}",unordered collections,3
159612,liquibase_liquibase,MavenIntegrationTest.nothing,"    @Test
    public void nothing() {
        //tests fail when not running a maven based build. need to figure out how to determine that
    }
",non-flaky,5
159613,liquibase_liquibase,MavenIntegrationTest.testUpdate,"//    @Test
//    public void testUpdate() throws Exception{
//        Verifier verifier=createVerifier();
//
//        verifier.executeGoal( ""clean"" );
//        verifier.executeGoal( ""install"" );
//
//        //Verify everithing has gone well.
//        verifier.verifyErrorFreeLog();
//
//        //Reset the streams before executing the verifier
//        verifier.resetStreams();
//    }
",non-flaky,5
159614,liquibase_liquibase,MavenIntegrationTest.testRollbackTag,"//    @Test
//    public void testRollbackTag() throws Exception {
//        Verifier verifier= createVerifier();
//
//
//        verifier.executeGoal(""clean"");
//        verifier.executeGoal(""liquibase:tag"");
//        verifier.executeGoal(""package""); //runs update that is bound to test phase
//        verifier.executeGoal(""liquibase:rollback"");
//        //If we can reupdate rollback has succeded
//        verifier.executeGoal(""liquibase:update"");
//
//        //Verify everithing has gone well.
//        verifier.verifyErrorFreeLog();
//
//        //Reset the streams before executing the verifier
//        verifier.resetStreams();
//    }
",non-flaky,5
159615,liquibase_liquibase,IntXMLChangeLogSAXParserTest.sampleChangeLogs,"    @Test
    public void sampleChangeLogs() throws Exception {
        new XMLChangeLogSAXParser().parse(""changelogs/cache/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/db2/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/derby/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/firebird/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/h2/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/hsqldb/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/maxdb/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/mysql/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/oracle/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/pgsql/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/sybase/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/asany/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/unsupported/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
    }
",non-flaky,5
159616,liquibase_liquibase,MySQLIntegrationTest.testRunChangeLog,"    @Test
    public void testRunChangeLog() throws Exception {
        super.testRunChangeLog();    //To change body of overridden methods use File | Settings | File Templates.
    }
",non-flaky,5
159617,liquibase_liquibase,MySQLIntegrationTest.snapshot,"    @Test
    public void snapshot() throws Exception {
        if (getDatabase() == null) {
            return;
        }


        runCompleteChangeLog();
        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(getDatabase().getDefaultSchema(), getDatabase(), new SnapshotControl(getDatabase()));
        System.out.println(snapshot);
    }
",non-flaky,5
159618,liquibase_liquibase,MySQLIntegrationTest.dateDefaultValue,"    @Test
    public void dateDefaultValue() throws Exception {
        if (getDatabase() == null) {
            return;
        }
        ExecutorService.getInstance().getExecutor(getDatabase()).execute(new RawSqlStatement(""DROP TABLE IF "" +
                                                                                                     ""EXISTS ad""));
        
        try {
            ExecutorService.getInstance().getExecutor(getDatabase()).execute(new RawSqlStatement(""CREATE TABLE ad (\n"" +
                                                                                                         ""ad_id int(10) unsigned NOT NULL AUTO_INCREMENT,\n"" +
                                                                                                         ""advertiser_id int(10) unsigned NOT NULL,\n"" +
                                                                                                         ""ad_type_id int(10) unsigned NOT NULL,\n"" +
                                                                                                         ""name varchar(155) NOT NULL DEFAULT '',\n"" +
                                                                                                         ""label varchar(155)NOT NULL DEFAULT '',\n"" +
                                                                                                         ""description text NOT NULL,\n"" +
                                                                                                         ""active tinyint(1) NOT NULL DEFAULT '0',\n"" +
                                                                                                         ""created datetime NOT NULL DEFAULT '0000-00-00 00:00:00',\n"" +
                                                                                                         ""updated datetime DEFAULT '0000-00-00 00:00:00',\n"" +
                                                                                                         ""PRIMARY KEY (ad_id),\n"" +
                                                                                                         ""KEY active (active)\n"" +
                                                                                                         "")""));
        } catch (DatabaseException e) {
            if (e.getCause() instanceof SQLSyntaxErrorException) {
                Scope.getCurrentScope().getLog(getClass()).warning(LogType.LOG, ""MySQL returned DatabaseException"", e);
                assumeTrue(""MySQL seems to run in strict mode (no datetime literals with 0000-00-00 allowed). "" + ""Cannot run this test"", false);
                
            } else {
                throw e;
            }
        }
        
        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(CatalogAndSchema.DEFAULT, getDatabase(), new SnapshotControl(getDatabase()));
        Column createdColumn = snapshot.get(new Column().setRelation(new Table().setName(""ad"").setSchema(new Schema())).setName(""created""));
        
        Object defaultValue = createdColumn.getDefaultValue();
        assertNotNull(defaultValue);
        assertEquals(""0000-00-00 00:00:00"", defaultValue);
    }
",non-flaky,5
159619,liquibase_liquibase,MariaDBIntegrationTest.testRunChangeLog,"    @Test
    public void testRunChangeLog() throws Exception {
        super.testRunChangeLog();    //To change body of overridden methods use File | Settings | File Templates.
    }
",non-flaky,5
159620,liquibase_liquibase,MariaDBIntegrationTest.snapshot,"    @Test
    public void snapshot() throws Exception {
        if (getDatabase() == null) {
            return;
        }


        runCompleteChangeLog();
        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(getDatabase().getDefaultSchema(), getDatabase(), new SnapshotControl(getDatabase()));
        System.out.println(snapshot);
    }
",non-flaky,5
159621,liquibase_liquibase,MariaDBIntegrationTest.dateDefaultValue,"    @Test
    public void dateDefaultValue() throws Exception {
        if (getDatabase() == null) {
            return;
        }
        ExecutorService.getInstance().getExecutor(getDatabase()).execute(new RawSqlStatement(""DROP TABLE IF "" +
             ""EXISTS ad""));
    
        try {
            ExecutorService.getInstance().getExecutor(getDatabase()).execute(new RawSqlStatement(""CREATE TABLE ad (\n"" +
                    ""ad_id int(10) unsigned NOT NULL AUTO_INCREMENT,\n"" +
                    ""advertiser_id int(10) unsigned NOT NULL,\n"" +
                    ""ad_type_id int(10) unsigned NOT NULL,\n"" +
                    ""name varchar(155) NOT NULL DEFAULT '',\n"" +
                    ""label varchar(155)NOT NULL DEFAULT '',\n"" +
                    ""description text NOT NULL,\n"" +
                    ""active tinyint(1) NOT NULL DEFAULT '0',\n"" +
                    ""created datetime NOT NULL DEFAULT '0000-00-00 00:00:00',\n"" +
                    ""updated datetime DEFAULT '0000-00-00 00:00:00',\n"" +
                    ""PRIMARY KEY (ad_id),\n"" +
                    ""KEY active (active)\n"" +
                    "")""));
        } catch (DatabaseException e) {
            if (e.getCause() instanceof SQLSyntaxErrorException) {
                Scope.getCurrentScope().getLog(getClass()).warning(LogType.LOG, ""MariaDB returned DatabaseException"", e);
                assumeTrue(""MariaDB seems to run in strict mode (no datetime literals with 0000-00-00 allowed). "" + ""Cannot run this test"", false);
                
            } else {
                throw e;
            }
        }
    
        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(CatalogAndSchema.DEFAULT, getDatabase(), new SnapshotControl(getDatabase()));
        Column createdColumn = snapshot.get(new Column().setRelation(new Table().setName(""ad"").setSchema(new Schema())).setName(""created""));

        Object defaultValue = createdColumn.getDefaultValue();
        assertNotNull(defaultValue);
        assertEquals(""0000-00-00 00:00:00"", defaultValue);
    }
",non-flaky,5
159622,liquibase_liquibase,H2IntegrationTest.diffToPrintStream,"    @Test
    public void diffToPrintStream() throws Exception{
        if (getDatabase() == null) {
            return;
        }

        runCompleteChangeLog();

        DiffResult diffResult = DiffGeneratorFactory.getInstance().compare(getDatabase(), null, new CompareControl());
        new DiffToReport(diffResult, System.out).print();
    }
",non-flaky,5
159623,liquibase_liquibase,H2IntegrationTest.diffToChangeLog,"    @Test
    public void diffToChangeLog() throws Exception{
        if (getDatabase() == null) {
            return;
        }

        runCompleteChangeLog();

        DiffResult diffResult = DiffGeneratorFactory.getInstance().compare(getDatabase(), null, new CompareControl());
        File outputFile = new File(""diffToChangeLog_"" + getDatabase().getShortName() + "".log"");
        if (outputFile.exists())
            outputFile.delete();
        PrintStream writer = new PrintStream(outputFile);

        new DiffToChangeLog(diffResult, new DiffOutputControl(true, true, true, null)).print(writer);
        writer.close();


    }
",non-flaky,5
159624,liquibase_liquibase,H2IntegrationTest.snapshot,"    @Test
    public void snapshot() throws Exception {
        if (getDatabase() == null) {
            return;
        }


        runCompleteChangeLog();
        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(getDatabase().getDefaultSchema(), getDatabase(), new SnapshotControl(getDatabase()));
        System.out.println(snapshot);
    }
",non-flaky,5
159625,liquibase_liquibase,H2IntegrationTest.canSpecifyDbmsForIndividualChanges,"    @Test
    public void canSpecifyDbmsForIndividualChanges() throws Exception {
        runChangeLogFile(changeSpecifyDbmsChangeLog);
    }
",non-flaky,5
159626,liquibase_liquibase,H2IntegrationTest.h2IsExcludedFromRunningChangeset,"    @Test
    public void h2IsExcludedFromRunningChangeset() throws Exception {
        runChangeLogFile(dbmsExcludeChangelog);
    }
",non-flaky,5
159627,liquibase_liquibase,H2IntegrationTest.runYamlChangelog,"    @Test
    public void runYamlChangelog() throws Exception {
        if (getDatabase() == null) {
            return;
        }

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        //run again to test changelog testing logic
        liquibase = createLiquibase(""changelogs/yaml/common.tests.changelog.yaml"");
        liquibase.setChangeLogParameter(""loginuser"", getUsername());

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }


    }
",non-flaky,5
159628,liquibase_liquibase,H2IntegrationTest.runJsonChangelog,"    @Test
    public void runJsonChangelog() throws Exception {
        if (getDatabase() == null) {
            return;
        }

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        //run again to test changelog testing logic
        liquibase = createLiquibase(""changelogs/json/common.tests.changelog.json"");
        liquibase.setChangeLogParameter(""loginuser"", getUsername());

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
    }
",non-flaky,5
159629,liquibase_liquibase,H2IntegrationTest.testGenerateChangeLogWithNoChanges,"    @Test
    public void testGenerateChangeLogWithNoChanges() throws Exception {
        super.testGenerateChangeLogWithNoChanges();    //To change body of overridden methods use File | Settings |
        // File Templates.
    }
",non-flaky,5
159630,liquibase_liquibase,SQLiteIntegrationTest.testRunChangeLog,"    @Test
    public void testRunChangeLog() throws Exception {
        super.testRunChangeLog();    //To change body of overridden methods use File | Settings | File Templates.
    }
",non-flaky,5
159631,liquibase_liquibase,SQLiteIntegrationTest.smartDataLoad,"    @Test
    public void smartDataLoad() throws Exception {
        if (this.getDatabase() == null) {
            return;
        }

        Liquibase liquibase = createLiquibase(""changelogs/common/smartDataLoad.changelog.xml"");
        clearDatabase();

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }

        // check that the automatically rollback now works too
        try {
            liquibase.rollback(new Date(0), this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
    }
",non-flaky,5
159632,liquibase_liquibase,SQLiteIntegrationTest.testDiffExternalForeignKeys,"    @Test
    public void testDiffExternalForeignKeys() throws Exception {
        //cross-schema security for oracle is a bother, ignoring test for now
    }
",non-flaky,5
159633,liquibase_liquibase,OracleIntegrationTest.testRunChangeLog,"    @Test
    public void testRunChangeLog() throws Exception {
        super.testRunChangeLog();    //To change body of overridden methods use File | Settings | File Templates.
    }
",non-flaky,5
159634,liquibase_liquibase,OracleIntegrationTest.indexCreatedOnCorrectSchema,"    @Test
    public void indexCreatedOnCorrectSchema() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(this.indexOnSchemaChangeLog);
        clearDatabase();

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }

        Statement queryIndex = ((JdbcConnection) this.getDatabase().getConnection()).getUnderlyingConnection().createStatement();

        ResultSet indexOwner = queryIndex.executeQuery(""SELECT owner FROM ALL_INDEXES WHERE index_name = 'IDX_BOOK_ID'"");

        assertTrue(indexOwner.next());

        String owner = indexOwner.getString(""owner"");

        assertEquals(""LBCAT2"", owner);

        // check that the automatically rollback now works too
        try {
            liquibase.rollback( new Date(0),this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }




    }
",non-flaky,5
159635,liquibase_liquibase,OracleIntegrationTest.viewCreatedOnCorrectSchema,"    @Test
    public void viewCreatedOnCorrectSchema() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(this.viewOnSchemaChangeLog);
        clearDatabase();

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }

        Statement queryIndex = ((JdbcConnection) this.getDatabase().getConnection()).getUnderlyingConnection().createStatement();

        ResultSet indexOwner = queryIndex.executeQuery(""SELECT owner FROM ALL_VIEWS WHERE view_name = 'V_BOOK2'"");

        assertTrue(indexOwner.next());

        String owner = indexOwner.getString(""owner"");

        assertEquals(""LBCAT2"", owner);

        // check that the automatically rollback now works too
        try {
            liquibase.rollback( new Date(0),this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
    }
",non-flaky,5
159636,liquibase_liquibase,OracleIntegrationTest.smartDataLoad,"    @Test
    public void smartDataLoad() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(""changelogs/common/smartDataLoad.changelog.xml"");
        clearDatabase();

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }

        // check that the automatically rollback now works too
        try {
            liquibase.rollback( new Date(0),this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
    }
",non-flaky,5
159637,liquibase_liquibase,OracleIntegrationTest.testDiffExternalForeignKeys,"    @Test
    public void testDiffExternalForeignKeys() throws Exception {
        //cross-schema security for oracle is a bother, ignoring test for now
    }
",non-flaky,5
159638,liquibase_liquibase,AbstractIntegrationTest.testBatchInsert,"    @Test
    public void testBatchInsert() throws Exception {
        if (this.getDatabase() == null) {
            return;
        }
        clearDatabase();

        createLiquibase(""changelogs/common/batchInsert.changelog.xml"").update(this.contexts);
        // ChangeLog already contains the verification code
    }
",non-flaky,5
159639,liquibase_liquibase,AbstractIntegrationTest.testDatabaseIsReachableIfRequired,"    @Test
    public void testDatabaseIsReachableIfRequired() {
        if (isDatabaseProvidedByTravisCI()) {
            assertNotNull(
                    ""This integration test is expected to pass on Travis CI.\n"" +
                            ""If you are running on a dev machine and do not have the required\n"" +
                            ""database installed, you may choose to ignore this failed test.\n"" +
                            ""To run this test on a dev machine, you will need to install the corresponding\n"" +
                            ""database and configure liquibase.integrationtest.local.properties"",
                    getDatabase());
        } else {
            assumeNotNull(this.getDatabase());
        }
    }
",non-flaky,5
159640,liquibase_liquibase,AbstractIntegrationTest.testRunChangeLog,"    @Test
    public void testRunChangeLog() throws Exception {
        assumeNotNull(this.getDatabase());

        runCompleteChangeLog();
    }
",non-flaky,5
159641,liquibase_liquibase,AbstractIntegrationTest.testRunUpdateOnOldChangelogTableFormat,"    @Test
    public void testRunUpdateOnOldChangelogTableFormat() throws Exception {
        assumeNotNull(this.getDatabase());
        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        String nullableKeyword = database.requiresExplicitNullForColumns() ? "" NULL"" : """";

        String sql = ""CREATE TABLE "" +
                database.escapeTableName(
                        database.getDefaultCatalogName(), database.getDefaultSchemaName(), ""DATABASECHANGELOG""
                ) +
                "" (id varchar(150) NOT NULL, "" +
                ""author VARCHAR(150) NOT NULL, "" +
                ""filename VARCHAR(255) NOT NULL, "" +
                ""dateExecuted "" +
                DataTypeFactory.getInstance().fromDescription(
                        ""datetime"", database
                ).toDatabaseDataType(database) + "" NOT NULL, "" +
                ""md5sum VARCHAR(32)"" + nullableKeyword + "", "" +
                ""description VARCHAR(255)"" + nullableKeyword + "", "" +
                ""comments VARCHAR(255)"" + nullableKeyword + "", "" +
                ""tag VARCHAR(255)"" + nullableKeyword + "", "" +
                ""liquibase VARCHAR(10)"" + nullableKeyword + "", "" +
                ""PRIMARY KEY (id, author, filename))"";
        Scope.getCurrentScope().getLog(getClass()).info(LogType.WRITE_SQL, sql);

        Connection conn = ((JdbcConnection) database.getConnection()).getUnderlyingConnection();
        boolean savedAcSetting = conn.getAutoCommit();
        conn.setAutoCommit(false);
        conn.createStatement().execute(sql);
        conn.commit();
        conn.setAutoCommit(savedAcSetting);

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);

    }
",non-flaky,5
159642,liquibase_liquibase,AbstractIntegrationTest.testOutputChangeLog,"    @Test
    public void testOutputChangeLog() throws Exception {
        assumeNotNull(this.getDatabase());

        StringWriter output = new StringWriter();
        Liquibase liquibase;
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter(""loginuser"", getUsername());
        liquibase.update(this.contexts, output);

        String outputResult = output.getBuffer().toString();
        assertNotNull(""generated output change log must not be empty"", outputResult);
        assertTrue(""generated output change log is at least 100 bytes long"", outputResult.length() > 100);

        // TODO should better written to a file so CI servers can pick it up as test artifacts.
        System.out.println(outputResult);
        assertTrue(""create databasechangelog command not found in: \n"" + outputResult, outputResult.contains(""CREATE TABLE ""+database.escapeTableName(database.getLiquibaseCatalogName(), database.getLiquibaseSchemaName(), database.getDatabaseChangeLogTableName())));
        assertTrue(""create databasechangeloglock command not found in: \n"" + outputResult, outputResult.contains(""CREATE TABLE ""+database.escapeTableName(database.getLiquibaseCatalogName(), database.getLiquibaseSchemaName(), database.getDatabaseChangeLogLockTableName())));

        assertTrue(""generated output contains a correctly encoded Euro sign"", outputResult.contains(""â¬""));

        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));
        assertEquals(""no database objects were actually created during creation of the output changelog"",
                0, snapshot.get(Schema.class).iterator().next().getDatabaseObjects(Table.class).size());
    }
",non-flaky,5
159643,liquibase_liquibase,AbstractIntegrationTest.testUpdateTwice,"    @Test
    public void testUpdateTwice() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);
        liquibase.update(this.contexts);
    }
",non-flaky,5
159644,liquibase_liquibase,AbstractIntegrationTest.testUpdateClearUpdate,"    @Test
    public void testUpdateClearUpdate() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);
    }
",non-flaky,5
159645,liquibase_liquibase,AbstractIntegrationTest.testRollbackableChangeLog,"    @Test
    public void testRollbackableChangeLog() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(rollbackChangeLog);
        clearDatabase();

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(this.contexts);

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.rollback(new Date(0), this.contexts);

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(this.contexts);

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.rollback(new Date(0), this.contexts);
    }
",non-flaky,5
159646,liquibase_liquibase,AbstractIntegrationTest.testRollbackableChangeLogScriptOnExistingDatabase,"    @Test
    public void testRollbackableChangeLogScriptOnExistingDatabase() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(rollbackChangeLog);
        clearDatabase();

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(this.contexts);

        StringWriter writer = new StringWriter();

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.rollback(new Date(0), this.contexts, writer);
    }
",non-flaky,5
159647,liquibase_liquibase,AbstractIntegrationTest.testRollbackableChangeLogScriptOnFutureDatabase,"    @Test
    public void testRollbackableChangeLogScriptOnFutureDatabase() throws Exception {
        assumeNotNull(this.getDatabase());

        StringWriter writer = new StringWriter();

        Liquibase liquibase = createLiquibase(rollbackChangeLog);
        clearDatabase();

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.futureRollbackSQL(new Contexts(this.contexts), new LabelExpression(), writer);
    }
",non-flaky,5
159648,liquibase_liquibase,AbstractIntegrationTest.testTag,"    @Test
    public void testTag() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);

        liquibase.tag(""Test Tag"");
    }
",non-flaky,5
159649,liquibase_liquibase,AbstractIntegrationTest.testDiff,"    @Test
    public void testDiff() throws Exception {
        assumeNotNull(this.getDatabase());

        runCompleteChangeLog();

        CompareControl compareControl = new CompareControl();
        compareControl.addSuppressedField(Column.class, ""defaultValue"");  //database returns different data even if the same
        compareControl.addSuppressedField(Column.class, ""autoIncrementInformation""); //database returns different data even if the same
        DiffResult diffResult = DiffGeneratorFactory.getInstance().compare(database, database, compareControl);

        try {
            assertTrue(""comapring a database with itself should return a result of 'DBs are equal'"",
                    diffResult.areEqual());
        } catch (AssertionError e) {
            new DiffToReport(diffResult, System.err).print();
            throw e;
        }
    }
",non-flaky,5
159650,liquibase_liquibase,AbstractIntegrationTest.testRerunDiffChangeLog,"    @Test
    public void testRerunDiffChangeLog() throws Exception {
        assumeNotNull(this.getDatabase());

        for (int run=0; run < 2; run++) { //run once outputting data as insert, once as csv
            boolean outputCsv = run == 1;
            runCompleteChangeLog();

            SnapshotControl snapshotControl = new SnapshotControl(database);

            DatabaseSnapshot originalSnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, snapshotControl);

            CompareControl compareControl = new CompareControl();
            compareControl.addSuppressedField(Column.class, ""defaultValue"");  //database returns different data even if the same
            compareControl.addSuppressedField(Column.class, ""autoIncrementInformation""); //database returns different data even if the same
            if (database instanceof OracleDatabase) {
                compareControl.addSuppressedField(Column.class, ""type""); //database returns different nvarchar2 info even though they are the same
                compareControl.addSuppressedField(Column.class, ""nullable""); // database returns different nullable on views, e.g. v_person.id
            }
            if (database instanceof PostgresDatabase) {
                compareControl.addSuppressedField(Column.class, ""type""); //database returns different nvarchar2 info even though they are the same
            }

            DiffOutputControl diffOutputControl = new DiffOutputControl();
            File tempFile = tempDirectory.getRoot().createTempFile(""liquibase-test"", "".xml"");

            if (outputCsv) {
                diffOutputControl.setDataDir(new File(tempFile.getParentFile(), ""liquibase-data"").getCanonicalPath().replaceFirst(""\\w:"",""""));
            }

            DiffResult diffResult = DiffGeneratorFactory.getInstance().compare(database, null, compareControl);


            FileOutputStream output = new FileOutputStream(tempFile);
            try {
                new DiffToChangeLog(diffResult, new DiffOutputControl()).print(new PrintStream(output));
                output.flush();
            } finally {
                output.close();
            }

            Liquibase liquibase = createLiquibase(tempFile.getName());
            clearDatabase();

            DatabaseSnapshot emptySnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));

            //run again to test changelog testing logic
            liquibase = createLiquibase(tempFile.getName());
            try {
                liquibase.update(this.contexts);
            } catch (ValidationFailedException e) {
                e.printDescriptiveError(System.out);
                throw e;
            }

            DatabaseSnapshot migratedSnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));

            DiffResult finalDiffResult = DiffGeneratorFactory.getInstance().compare(originalSnapshot, migratedSnapshot, compareControl);
            try {
                assertTrue(""recreating the database from the generated change log should cause both 'before' and "" +
                                ""'after' snapshots to be equal."",
                        finalDiffResult.areEqual());
            } catch (AssertionError e) {
                new DiffToReport(finalDiffResult, System.err).print();
                throw e;
            }

            //diff to empty and drop all
            DiffResult emptyDiffResult = DiffGeneratorFactory.getInstance().compare(emptySnapshot, migratedSnapshot, compareControl);
            output = new FileOutputStream(tempFile);
            try {
                new DiffToChangeLog(emptyDiffResult, new DiffOutputControl(true, true, true, null)).print(new PrintStream(output));
                output.flush();
            } finally {
                output.close();
            }

            liquibase = createLiquibase(tempFile.getName());
            Scope.getCurrentScope().getLog(getClass()).info(LogType.LOG, ""updating from ""+tempFile.getCanonicalPath());
            try {
                liquibase.update(this.contexts);
            } catch (LiquibaseException e) {
                throw e;
            }

            DatabaseSnapshot emptyAgainSnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));
            assertEquals(""a database that was 'updated' to an empty snapshot should only have 2 tables left: "" +
                            ""the database change log table and the lock table."",
                    2, emptyAgainSnapshot.get(Table.class).size());
            assertEquals(""a database that was 'updated' to an empty snapshot should not contain any views."",
                    0, emptyAgainSnapshot.get(View.class).size());
        }
    }
",non-flaky,5
159651,liquibase_liquibase,AbstractIntegrationTest.testRerunDiffChangeLogAltSchema,"    @Test
    public void testRerunDiffChangeLogAltSchema() throws Exception {
        assumeNotNull(this.getDatabase());
        if (database.getShortName().equalsIgnoreCase(""mssql"")) {
            return; // not possible on MSSQL.
        }
        if (!database.supportsSchemas()) {
            return;
        }

        Liquibase liquibase = createLiquibase(includedChangeLog);
        database.setDefaultSchemaName(""lbcat2"");
        clearDatabase();


        LockService lockService = LockServiceFactory.getInstance().getLockService(database);
        lockService.forceReleaseLock();

        liquibase.update(includedChangeLog);

        DatabaseSnapshot originalSnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));

        CompareControl compareControl = new CompareControl(
                new CompareControl.SchemaComparison[]{
                        new CompareControl.SchemaComparison(
                                CatalogAndSchema.DEFAULT,
                                new CatalogAndSchema(null, ""lbcat2"")
                        )
                },
                originalSnapshot.getSnapshotControl().getTypesToInclude()
        );
        DiffResult diffResult = DiffGeneratorFactory.getInstance().compare(database, null, compareControl);

        File tempFile = File.createTempFile(""liquibase-test"", "".xml"");

        FileOutputStream output = new FileOutputStream(tempFile);
        try {
            new DiffToChangeLog(diffResult, new DiffOutputControl()).print(new PrintStream(output));
            output.flush();
        } finally {
            output.close();
        }

        liquibase = createLiquibase(tempFile.getName());
        clearDatabase();

        //run again to test changelog testing logic
        Executor executor = ExecutorService.getInstance().getExecutor(database);
        try {
            executor.execute(new DropTableStatement(""lbcat2"", ""lbcat2"", database.getDatabaseChangeLogTableName(), false));
        } catch (DatabaseException e) {
            //ok
        }
        try {
            executor.execute(new DropTableStatement(""lbcat2"", ""lbcat2"", database.getDatabaseChangeLogLockTableName(), false));
        } catch (DatabaseException e) {
            //ok
        }
        database.commit();

        DatabaseConnection connection = DatabaseTestContext.getInstance().getConnection(getJdbcUrl(), username, password);
        database = DatabaseFactory.getInstance().findCorrectDatabaseImplementation(connection);
        database.setDefaultSchemaName(""lbcat2"");
        liquibase = createLiquibase(tempFile.getName());
        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }

        tempFile.deleteOnExit();

        DatabaseSnapshot finalSnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));

        CompareControl finalCompareControl = new CompareControl();
        finalCompareControl.addSuppressedField(Column.class, ""autoIncrementInformation"");
        DiffResult finalDiffResult = DiffGeneratorFactory.getInstance().compare(originalSnapshot, finalSnapshot, finalCompareControl);
        new DiffToReport(finalDiffResult, System.out).print();
        assertTrue(""running the same change log two times against an alternative schema should produce "" +
                        ""equal snapshots."",
                finalDiffResult.areEqual());
    }
",non-flaky,5
159652,liquibase_liquibase,AbstractIntegrationTest.testClearChecksums,"    @Test
    public void testClearChecksums() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);

        liquibase.clearCheckSums();
    }
",non-flaky,5
159653,liquibase_liquibase,AbstractIntegrationTest.testTagEmptyDatabase,"    @Test
    public void testTagEmptyDatabase() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.checkLiquibaseTables(false, null, new Contexts(), new LabelExpression());
        liquibase.tag(""empty"");

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(new Contexts());

        liquibase.rollback(""empty"", new Contexts());

    }
",non-flaky,5
159654,liquibase_liquibase,AbstractIntegrationTest.testUnrunChangeSetsEmptyDatabase,"    @Test
    public void testUnrunChangeSetsEmptyDatabase() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        List<ChangeSet> list = liquibase.listUnrunChangeSets(new Contexts(this.contexts), new LabelExpression());

        assertTrue(""querying the changelog table on an empty target should return at least 1 un-run change set"", !list.isEmpty());

    }
",non-flaky,5
159655,liquibase_liquibase,AbstractIntegrationTest.testAbsolutePathChangeLog,"    @Test
    public void testAbsolutePathChangeLog() throws Exception {
        assumeNotNull(this.getDatabase());

        String fileUrlToChangeLog = getClass().getResource(""/"" + includedChangeLog).toString();
        assertTrue(fileUrlToChangeLog.startsWith(""file:/""));

        String absolutePathOfChangeLog = fileUrlToChangeLog.replaceFirst(""file:\\/"", """");
        if (System.getProperty(""os.name"").startsWith(""Windows "")) {
            absolutePathOfChangeLog = absolutePathOfChangeLog.replace('/', '\\');
        } else {
            absolutePathOfChangeLog = ""/"" + absolutePathOfChangeLog;
        }
        Liquibase liquibase = createLiquibase(absolutePathOfChangeLog, new FileSystemResourceAccessor());
        clearDatabase();

        liquibase.update(this.contexts);

        liquibase.update(this.contexts); //try again, make sure there are no errors

        clearDatabase();
    }
",non-flaky,5
159656,liquibase_liquibase,AbstractIntegrationTest.testRollbackToChange,"    @Test
    public void testRollbackToChange() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(rollbackChangeLog);
        wipeDatabase();

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(this.contexts);

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.rollback(8, this.contexts);

        liquibase.tag(""testRollbackToChange"");

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(this.contexts);

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.rollback(""testRollbackToChange"", this.contexts);
    }
",non-flaky,5
159657,liquibase_liquibase,AbstractIntegrationTest.testDbDoc,"    @Test
    public void testDbDoc() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase;
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);

        Path outputDir = tempDirectory.newFolder().toPath().normalize();
        logger.fine(LogType.LOG, ""Database documentation will be written to this temporary folder: "" + outputDir);

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.generateDocumentation(outputDir.toAbsolutePath().toString(), this.contexts);
    }
",non-flaky,5
159658,liquibase_liquibase,AbstractIntegrationTest.testEncodingUpdating2SQL,"    @Test
    public void testEncodingUpdating2SQL() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(encodingChangeLog);

        StringWriter writer=new StringWriter();
        liquibase.update(this.contexts,writer);
        assertTrue(""Update to SQL preserves encoding"",
            new RegexMatcher(writer.toString(), new String[] {
                //For the UTF-8 encoded cvs
                ""^.*INSERT.*VALUES.*Ã Ã¨Ã¬Ã²Ã¹Ã¡Ã©Ã­Ã³ÃºÃÃÃÃÃÃÃÃÃÃÃ¢ÃªÃ®Ã´Ã»Ã¤Ã«Ã¯Ã¶Ã¼.*?\\)"",
                ""Ã§Ã±Â®"",
                //For the latin1 one
                ""^.*INSERT.*VALUES.*Ã Ã¨Ã¬Ã²Ã¹Ã¡Ã©Ã­Ã³ÃºÃÃÃÃÃÃÃÃÃÃÃ¢ÃªÃ®Ã´Ã»Ã¤Ã«Ã¯Ã¶Ã¼.*?\\)"",
                ""Ã§Ã±Â®""
            }).allMatchedInSequentialOrder());
    }
",non-flaky,5
159659,liquibase_liquibase,AbstractIntegrationTest.testDiffExternalForeignKeys,"   @Test
   public void testDiffExternalForeignKeys() throws Exception {
       assumeNotNull(this.getDatabase());
       clearDatabase();
       Liquibase liquibase = createLiquibase(externalfkInitChangeLog);
       liquibase.update(contexts);

       DiffResult diffResult = liquibase.diff(database, null, new CompareControl());
       DiffResultAssert.assertThat(diffResult).containsMissingForeignKeyWithName(""fk_person_country"");
   }
",non-flaky,5
159660,liquibase_liquibase,AbstractIntegrationTest.testInvalidIncludeDoesntBreakLiquibase,"    @Test
    public void testInvalidIncludeDoesntBreakLiquibase() throws Exception {
        assumeNotNull(this.getDatabase());
        Liquibase liquibase = createLiquibase(invalidReferenceChangeLog);
        try {
            liquibase.update(new Contexts());
            fail(""Did not fail with invalid include"");
        } catch (ChangeLogParseException ignored) {
            //expected
        }

        LockService lockService = LockServiceFactory.getInstance().getLockService(database);
        assertFalse(lockService.hasChangeLogLock());
    }
",non-flaky,5
159661,liquibase_liquibase,AbstractIntegrationTest.testContextsWithHyphensWorkInFormattedSql,"    @Test
    public void testContextsWithHyphensWorkInFormattedSql() throws Exception {
        assumeNotNull(this.getDatabase());
        Liquibase liquibase = createLiquibase(""changelogs/common/sqlstyle/formatted.changelog.sql"");
        liquibase.update(""hyphen-context-using-sql,camelCaseContextUsingSql"");

        SnapshotGeneratorFactory tableSnapshotGenerator = SnapshotGeneratorFactory.getInstance();
        assertNotNull(tableSnapshotGenerator.has(new Table().setName(""hyphen_context""), database));
        assertNotNull(tableSnapshotGenerator.has(new Table().setName(""camel_context""), database));
        assertNotNull(tableSnapshotGenerator.has(new Table().setName(""bar_id""), database));
        assertNotNull(tableSnapshotGenerator.has(new Table().setName(""foo_id""), database));
    }
",non-flaky,5
159662,liquibase_liquibase,AbstractIntegrationTest.testObjectQuotingStrategy,"    @Test
    public void testObjectQuotingStrategy() throws Exception {
        assumeNotNull(this.getDatabase());
        if (!Arrays.asList(""oracle,h2,hsqldb,postgresql,mysql"").contains(database.getShortName())) {
            return;
        }

        Liquibase liquibase = createLiquibase(objectQuotingStrategyChangeLog);
        clearDatabase();
        liquibase.update(contexts);
        clearDatabase();
    }
",non-flaky,5
159663,liquibase_liquibase,AbstractIntegrationTest.testOutputChangeLogIgnoringSchema,"    @Test
    public void testOutputChangeLogIgnoringSchema() throws Exception {
        assumeNotNull(this.getDatabase());

        String schemaName = getDatabase().getDefaultSchemaName();
        if (schemaName == null) {
            return;
        }

        getDatabase().setOutputDefaultSchema(false);
        getDatabase().setOutputDefaultCatalog(false);

        StringWriter output = new StringWriter();
        Liquibase liquibase = createLiquibase(includedChangeLog);
        clearDatabase();

        liquibase = createLiquibase(includedChangeLog);
        liquibase.update(contexts, output);

        String outputResult = output.getBuffer().toString();
        assertNotNull(""generated SQL may not be empty"", outputResult);
        assertTrue(""Expect at least 100 bytes of output in generated SQL"", outputResult.length() > 100);
        CharSequence expected = ""CREATE TABLE ""+getDatabase().escapeTableName(getDatabase().getLiquibaseCatalogName(), getDatabase().getLiquibaseSchemaName(), getDatabase().getDatabaseChangeLogTableName());
        assertTrue(""create databasechangelog command not found in: \n"" + outputResult, outputResult.contains(expected));
        assertTrue(""create databasechangeloglock command not found in: \n"" + outputResult, outputResult.contains(expected));
        assertFalse(""the schema name '"" + schemaName + ""' should be ignored\n\n"" + outputResult, outputResult.contains
                (schemaName+"".""));
    }
",non-flaky,5
159664,liquibase_liquibase,AbstractIntegrationTest.testGenerateChangeLogWithNoChanges,"    @Test
    public void testGenerateChangeLogWithNoChanges() throws Exception {
        assumeNotNull(this.getDatabase());

        runCompleteChangeLog();

        DiffResult diffResult = DiffGeneratorFactory.getInstance().compare(database, database, new CompareControl());

        DiffToChangeLog changeLogWriter = new DiffToChangeLog(diffResult, new DiffOutputControl(false, false, false, null));
        List<ChangeSet> changeSets = changeLogWriter.generateChangeSets();
        assertEquals(""generating two change logs without any changes in between should result in an empty generated "" +
                ""differential change set."", 0, changeSets.size());
    }
",non-flaky,5
159665,liquibase_liquibase,MssqlIntegrationTest.defaultValuesTests,"    @Test
    public void defaultValuesTests() throws Exception {
        clearDatabase();

        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(""changelogs/mssql/issues/default.values.xml"");
        liquibase.update((String) null);

        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(CatalogAndSchema.DEFAULT, this.getDatabase(), new SnapshotControl(getDatabase()));

        for (Table table : snapshot.get(Table.class)) {
            for (Column column : table.getColumns()) {
                if (column.getName().toLowerCase().endsWith(""_default"")) {
                    Object defaultValue = column.getDefaultValue();
                    assertNotNull(""Null default value for "" + table.getName() + ""."" + column.getName(), defaultValue);
                    if (column.getName().toLowerCase().contains(""date"") || column.getName().toLowerCase().contains(""time"")) {
                        if (defaultValue instanceof String) {
                            assertTrue(defaultValue.equals(""2017-12-09 23:52:39.1234567 +01:00""));
                        } else if (defaultValue instanceof DatabaseFunction) {
                            ((DatabaseFunction) defaultValue).getValue().contains(""type datetimeoffset"");
                        } else if (defaultValue instanceof Time) {
                            Calendar calendar = Calendar.getInstance();
                            calendar.setTime(((Date) defaultValue));
                            assertEquals(23, calendar.get(Calendar.HOUR_OF_DAY));
                            assertEquals(52, calendar.get(Calendar.MINUTE));
                            assertEquals(39, calendar.get(Calendar.SECOND));
                        } else {
                            assertTrue(""Unexpected default type ""+defaultValue.getClass().getName()+"" for "" + table.getName() + ""."" + column.getName(), defaultValue instanceof Date);
                            Calendar calendar = Calendar.getInstance();
                            calendar.setTime(((Date) defaultValue));
                            assertEquals(9, calendar.get(Calendar.DAY_OF_MONTH));
                            assertEquals(11, calendar.get(Calendar.MONTH));
                            assertEquals(2017, calendar.get(Calendar.YEAR));
                        }
                    } else if (column.getName().toLowerCase().contains(""char_"")) {
                        assertTrue(""Unexpected default type ""+defaultValue.getClass().getName()+"" for "" + table.getName() + ""."" + column.getName(), defaultValue instanceof String);
                    } else if (column.getName().toLowerCase().contains(""binary_"")) {
                        assertTrue(""Unexpected default type ""+defaultValue.getClass().getName()+"" for "" + table.getName() + ""."" + column.getName(), defaultValue instanceof DatabaseFunction);
                    } else {
                        assertTrue(""Unexpected default type ""+defaultValue.getClass().getName()+"" for "" + table.getName() + ""."" + column.getName(), defaultValue instanceof Number);
                        assertEquals(1, ((Number) defaultValue).intValue());
                    }
                }
            }
        }
    }
",non-flaky,5
159666,liquibase_liquibase,MssqlIntegrationTest.dataTypesTest,"    @Test
    public void dataTypesTest() throws Exception {
        assumeNotNull(this.getDatabase());
        clearDatabase();

        Liquibase liquibase = createLiquibase(""changelogs/mssql/issues/data.types.xml"");
        liquibase.update((String) null);

        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(CatalogAndSchema.DEFAULT, this.getDatabase(), new SnapshotControl(getDatabase()));

        for (Table table : snapshot.get(Table.class)) {
            if (getDatabase().isLiquibaseObject(table)) {
                continue;
            }
            for (Column column : table.getColumns()) {
                String expectedType = column.getName().split(""_"")[0];

                switch(expectedType.toUpperCase()) {
                    // See https://docs.microsoft.com/en-us/sql/t-sql/data-types/ntext-text-and-image-transact-sql
                    // Types text, ntext and image are deprecated and should be translated into
                    // varchar(max), nvarchar(max) and varbinary(max).
                    case ""TEXT"":
                        expectedType=""varchar"";
                        break;
                    case ""NTEXT"":
                        expectedType=""nvarchar"";
                        break;
                    case ""IMAGE"":
                        expectedType=""varbinary"";
                        break;
                    default:
                        // nothing to do
                }

                String foundTypeDefinition = DataTypeFactory.getInstance().from(column.getType(), new MSSQLDatabase()).toDatabaseDataType(getDatabase()).toString();
                // [varbinary] -> varbinary
                foundTypeDefinition = foundTypeDefinition.replaceFirst(""^\\[(.*?)\\]"", ""$1"");
                String foundType = foundTypeDefinition.replaceFirst(""\\(.*"", """").trim();

                assertEquals(""Wrong data type for "" + table.getName() + ""."" + column.getName(),
                    expectedType.toLowerCase(),
                    foundType.toLowerCase()
                );

                if (""varbinary"".equalsIgnoreCase(expectedType)) {
                    if (column.getName().endsWith(""_MAX"")) {
                        assertEquals(""VARBINARY(MAX)"", foundTypeDefinition.toUpperCase());
                    } else {
                        assertEquals(""VARBINARY(1)"", foundTypeDefinition.toUpperCase());
                    }
                }
            }
        }
    }
",non-flaky,5
159667,liquibase_liquibase,MssqlIntegrationTest.dataTypeParamsTest,"    @Test
    public void dataTypeParamsTest() throws Exception {
        assumeNotNull(this.getDatabase());
        clearDatabase();

        Liquibase liquibase = createLiquibase(""changelogs/mssql/issues/data.type.params.xml"");
        liquibase.update((String) null);

        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(CatalogAndSchema.DEFAULT, this.getDatabase(), new SnapshotControl(getDatabase()));

        for (Table table : snapshot.get(Table.class)) {
            if (getDatabase().isLiquibaseObject(table)) {
                continue;
            }
            for (Column column : table.getColumns()) {
                String expectedType = column.getName().split(""_"")[0];

                String foundTypeDefinition = DataTypeFactory.getInstance().from(column.getType(), new MSSQLDatabase()).toDatabaseDataType(getDatabase()).toString();
                assertFalse(""Parameter found in "" + table.getName() + ""."" + column.getName(), foundTypeDefinition.contains(""(""));
            }
        }
    }
",non-flaky,5
159668,liquibase_liquibase,AbstractMssqlIntegrationTest.impossibleDefaultSchema,"    @Test
    public void impossibleDefaultSchema() {
        Exception caughtException = null;
        try {
            getDatabase().setDefaultSchemaName(""lbuser"");
        } catch (Exception ex) {
            caughtException = ex;
        }
        assertNotNull(""Must not allow using a defaultSchemaName that is different from the DB user's login schema."",
            caughtException);

    }
",non-flaky,5
159669,liquibase_liquibase,AbstractMssqlIntegrationTest.smartDataLoad,"    @Test
    public void smartDataLoad() throws Exception {
        assumeNotNull(this.getDatabase());
        Liquibase liquibase = createLiquibase(""changelogs/common/smartDataLoad.changelog.xml"");
        clearDatabase();
        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
        try {
            liquibase.rollback(new Date(0), this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
    }
",non-flaky,5
159670,liquibase_liquibase,UnlockDatabaseChangeLogExecuteTest.generateSql,"    @Test
    public void generateSql() throws Exception {
        this.statementUnderTest = new UnlockDatabaseChangeLogStatement();
        assertCorrect(""update [databasechangeloglock] set [locked] = 0, [lockedby] = null, [lockgranted] = null where [id] = 1"", MSSQLDatabase.class, SybaseDatabase.class);
        assertCorrect(""update [databasechangeloglock] set [locked] = 0, [lockedby] = null, [lockgranted] = null where [id] = 1"", MSSQLDatabase.class, SybaseASADatabase.class);
        assertCorrect(""update [databasechangeloglock] set [locked] = 'f', [lockedby] = null, [lockgranted] = null where [id] = 1"", InformixDatabase.class);
        assertCorrect(""update [databasechangeloglock] set [locked] = false, [lockedby] = null, [lockgranted] = null where [id] = 1"", PostgresDatabase.class, HsqlDatabase.class, H2Database.class);
        assertCorrectOnRest(""update [databasechangeloglock] set [locked] = 0, [lockedby] = null, [lockgranted] = null where [id] = 1"");
    }
",non-flaky,5
159671,liquibase_liquibase,AddColumnExecutorTest.generateSql_autoIncrement,"    @Test
    public void generateSql_autoIncrement() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, ""table_name"", ""column_name"", ""int"", null, new AutoIncrementConstraint(""column_name""));

        assertCorrect(""alter table table_name add column_name serial"", InformixDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int default autoincrement null"", SybaseASADatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] serial"", PostgresDatabase.class);
        assertCorrect(""alter table [dbo].[table_name] add [column_name] int identity"", MSSQLDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int identity null"", SybaseDatabase.class);
        assertCorrect(""not supported. fixme!!"", SQLiteDatabase.class);
        assertCorrect(""alter table table_name add column_name int auto_increment_clause"");
    }
",non-flaky,5
159672,liquibase_liquibase,AddColumnExecutorTest.generateSql_notNull,"    @Test
    public void generateSql_notNull() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, null, ""table_name"", ""column_name"", ""int"", 42, new NotNullConstraint());
        assertCorrect(""alter table [table_name] add [column_name] int default 42 not null"", SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table table_name add column_name int default 42 not null"", PostgresDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] [int] constraint df_table_name_column_name default 42 not null"", MSSQLDatabase.class);
        assertCorrect(""alter table table_name add column_name int default 42 not null"", MySQLDatabase.class);
        assertCorrect(""not supported. fixme!!"", SQLiteDatabase.class);
        assertCorrect(""ALTER TABLE [table_name] ADD [column_name] int DEFAULT 42 NOT NULL"");
    }
",non-flaky,5
159673,liquibase_liquibase,AddColumnExecutorTest.fullNoConstraints,"    @Test
    public void fullNoConstraints() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, null, ""table_name"", ""column_name"", ""int"", 42);


        assertCorrect(""alter table [table_name] add [column_name] int default 42 null"", SybaseDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int constraint df_table_name_column_name default 42"", MSSQLDatabase.class);
//        assertCorrect(""alter table [table_name] add [column_name] integer default 42"", SQLiteDatabase.class);
        assertCorrect(""not supported. fixme!!"", SQLiteDatabase.class);
        assertCorrect(""alter table table_name add column_name int default 42"", PostgresDatabase.class, InformixDatabase.class, OracleDatabase.class, DerbyDatabase.class, HsqlDatabase.class, DB2Database.class, H2Database.class, FirebirdDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int default 42 null"", SybaseASADatabase.class);
        assertCorrect(""alter table table_name add column_name int default 42 null"", MySQLDatabase.class, MariaDBDatabase.class);
        assertCorrectOnRest(""ALTER TABLE [table_name] ADD [column_name] int DEFAULT 42"");
    }
",non-flaky,5
159674,liquibase_liquibase,AddColumnExecutorTest.autoIncrement,"    @Test
    public void autoIncrement() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, TABLE_NAME, ""column_name"", ""int"", null, new AutoIncrementConstraint());

        assertCorrect(""ALTER TABLE [dbo].[table_name] ADD [column_name] int auto_increment_clause"", MSSQLDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int default autoincrement null"", SybaseASADatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int identity null"", SybaseDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] serial"", PostgresDatabase.class, InformixDatabase.class);
        assertCorrect(""not supported. fixme!!"", SQLiteDatabase.class);
        assertCorrectOnRest(""ALTER TABLE [table_name] ADD [column_name] int auto_increment_clause"");
    }
",non-flaky,5
159675,liquibase_liquibase,AddColumnExecutorTest.notNull,"    @Test
    public void notNull() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, null, TABLE_NAME, ""column_name"", ""int"", 42, new NotNullConstraint());

        assertCorrect(""ALTER TABLE [table_name] ADD [column_name] int DEFAULT 42 NOT NULL"", SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table table_name add column_name int default 42 not null"", InformixDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int constraint df_table_name_column_name default 42 not null"", MSSQLDatabase.class);
        assertCorrect(""alter table table_name add column_name int default 42 not null"", OracleDatabase.class, DerbyDatabase.class, HsqlDatabase.class, DB2Database.class, H2Database.class, FirebirdDatabase.class);
        assertCorrect(""not supported. fixme!!"", SQLiteDatabase.class);
        assertCorrectOnRest(""ALTER TABLE [table_name] ADD [column_name] int default 42 not null"");
    }
",non-flaky,5
159676,liquibase_liquibase,AddColumnExecutorTest.generateSql_primaryKey,"    @Test
    public void generateSql_primaryKey() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, ""table_name"", ""column_name"", ""int"", null, new PrimaryKeyConstraint());

        assertCorrect(""alter table [table_name] add [column_name] int not null primary key"", HsqlDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int primary key not null"", SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table [dbo].[table_name] add [column_name] int not null primary key"", MSSQLDatabase.class);
        assertCorrect(""alter table table_name add column_name int not null primary key"", PostgresDatabase.class);
        assertCorrect(""alter table `table_name` add `column_name` int not null primary key"", MySQLDatabase.class);
        assertCorrect(""ALTER TABLE [table_name] ADD [column_name] int PRIMARY KEY NOT NULL"");
    }
",non-flaky,5
159677,liquibase_liquibase,AddColumnExecutorTest.generateSql_foreignKey,"    @Test
    public void generateSql_foreignKey() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, ""table_name"", ""column_name"", ""int"", null, new PrimaryKeyConstraint(), new ForeignKeyConstraint(""fk_test_fk"", ""table_name(column_name)""));

        assertCorrect(new String[] {""alter table [table_name] add [column_name] int not null primary key"", ""alter table [table_name] add constraint [fk_test_fk] foreign key ([column_name]) references [table_name]([column_name])""}, HsqlDatabase.class);
        assertCorrect(new String[] {""alter table [table_name] add [column_name] int primary key not null"", ""alter table [table_name] add constraint [fk_test_fk] foreign key ([column_name]) references [table_name]([column_name])""}, SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(new String[] {""alter table [dbo].[table_name] add [column_name] int not null primary key"", ""alter table [dbo].[table_name] add constraint [fk_test_fk] foreign key ([column_name]) references [dbo].[table_name]([column_name])""}, MSSQLDatabase.class);
        assertCorrect(new String[] {""alter table table_name add column_name int not null primary key"", ""alter table [table_name] add constraint [fk_test_fk] foreign key ([column_name]) references [table_name]([column_name])""}, PostgresDatabase.class);
        assertCorrect(new String[] {""alter table `table_name` add `column_name` int not null primary key"", ""alter table [table_name] add constraint [fk_test_fk] foreign key ([column_name]) references [table_name]([column_name])""}, MySQLDatabase.class);
        assertCorrect(new String[] {""ALTER TABLE [table_name] ADD [column_name] int PRIMARY KEY NOT NULL"", ""alter table [table_name] add constraint  foreign key ([column_name]) references [table_name]([column_name]) constraint [fk_test_fk]""}, InformixDatabase.class);
        assertCorrect(new String[] {""ALTER TABLE [table_name] ADD [column_name] int PRIMARY KEY NOT NULL"", ""alter table [table_name] add constraint [fk_test_fk] foreign key ([column_name]) references [table_name]([column_name])""});
    }
",non-flaky,5
159678,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_noSchema,"    //    @Test
//    public void execute_noSchema() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddUniqueConstraintStatement(null, TABLE_NAME, COLUMN_NAME, ""uq_adduqtest"")) {
//
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertFalse(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        //todo: enable snapshot and assertion when snapshot can check for unique constraints
//                        //snapshot = new DatabaseSnapshotGenerator(snapshot);
//                    	assertTrue(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//                });
//    }
",non-flaky,5
159679,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_withSchema,"//    @Test
//    public void execute_withSchema() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(TestContext.ALT_SCHEMA, new AddUniqueConstraintStatement(TestContext.ALT_SCHEMA, TABLE_NAME, COLUMN_NAME, ""uq_adduqtest"")) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertFalse(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        //todo: enable snapshot and assertion when snapshot can check for unique constraints
//                snapshot = new DatabaseSnapshotGenerator(database, TestContext.ALT_SCHEMA);
//                assertTrue(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//
//                });
//    }
",non-flaky,5
159680,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_withTablespace,"//    @Test
//    public void execute_withTablespace() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddUniqueConstraintStatement(null, TABLE_NAME, COLUMN_NAME, ""uq_adduqtest"").setTablespace(TestContext.ALT_TABLESPACE)) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertFalse(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        //todo: enable snapshot and assertion when snapshot can check for unique constraints
//                        // snapshot = new DatabaseSnapshotGenerator(database);
////                assertTrue(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//                });
//    }
",non-flaky,5
159681,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_noSchema,"    @Test
    public void execute_noSchema() throws Exception {
        this.statementUnderTest = new AddUniqueConstraintStatement(null, null, TABLE_NAME, new ColumnConfig[] { new ColumnConfig().setName(COLUMN_NAME)}, CONSTRAINT_NAME);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", SybaseDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", MSSQLDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", SybaseASADatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", MySQLDatabase.class);
        assertCorrect(""alter table adduqtest add constraint unique (coltomakeuq) constraint uq_test"", InformixDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", OracleDatabase.class);
        assertCorrect(""alter table \""adduqtest\"" add constraint uq_test unique (\""coltomakeuq\"")"", PostgresDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", DerbyDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"");
    }
",non-flaky,5
159682,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_noConstraintName,"    @Test
    public void execute_noConstraintName() throws Exception {
        this.statementUnderTest = new AddUniqueConstraintStatement(null, null, TABLE_NAME, new ColumnConfig[] { new ColumnConfig().setName(COLUMN_NAME)}, null);
        assertCorrect(""alter table adduqtest add unique (coltomakeuq)"", MySQLDatabase.class);
        assertCorrect(""alter table adduqtest add constraint unique (coltomakeuq)"", InformixDatabase.class);
        assertCorrect(""alter table adduqtest add unique (coltomakeuq)"", OracleDatabase.class);
        assertCorrect(""alter table \""adduqtest\"" add unique (\""coltomakeuq\"")"", PostgresDatabase.class);
        assertCorrect(""alter table adduqtest add unique (coltomakeuq)"", DerbyDatabase.class);
        assertCorrect(""alter table [adduqtest] add unique ([coltomakeuq])"", SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table [adduqtest] add unique ([coltomakeuq])"", MSSQLDatabase.class);

        assertCorrect(""alter table [adduqtest] add unique ([coltomakeuq])"");
    }
",non-flaky,5
159683,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_withSchema,"    @Test
    public void execute_withSchema() throws Exception {
        statementUnderTest = new AddUniqueConstraintStatement(
                DatabaseTestContext.ALT_CATALOG,
                DatabaseTestContext.ALT_SCHEMA,
                TABLE_NAME,
                new ColumnConfig[]
                        {new ColumnConfig().setName(COLUMN_NAME)},
                CONSTRAINT_NAME
        );

        assertCorrect(""ALTER TABLE liquibasec.adduqtest ADD CONSTRAINT uq_test UNIQUE (coltomakeuq)"", MySQLDatabase
                .class);
        /*
         * In Informix, this test case is actually impossible. While it is allowed to cross-select data from
          * different databases (using the database:schema.table notation), it is not allowed to send DDL to a
          * different database (even if the database is on the same instance). So, even as the following
          * statement is semantically false, it is syntactically correct.
         */
        assertCorrect(""ALTER TABLE liquibasec:liquibaseb.adduqtest ADD CONSTRAINT UNIQUE (coltomakeuq) CONSTRAINT "" +
                ""uq_test"", InformixDatabase.class);

        assertCorrect(""alter table liquibasec.adduqtest add constraint uq_test unique (coltomakeuq)"", OracleDatabase.class);
        assertCorrect(""alter table liquibaseb.\""adduqtest\"" add constraint uq_test unique (\""coltomakeuq\"")"", PostgresDatabase.class);
        assertCorrect(""alter table liquibasec.adduqtest add constraint uq_test unique (coltomakeuq)"", DerbyDatabase
                .class);
        assertCorrect(""alter table [liquibaseb].[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"",
                SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table [liquibasec].[liquibaseb].[adduqtest] add constraint [uq_test] unique "" +
                ""([coltomakeuq])"", MSSQLDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", FirebirdDatabase.class);

        assertCorrect(""alter table [liquibaseb].[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", HsqlDatabase.class);
        assertCorrect(""alter table \""liquibasec\"".[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", DB2Database.class, Db2zDatabase.class);
        assertCorrect(""alter table [liquibaseb].[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", H2Database.class);
        assertCorrectOnRest(""alter table [liquibasec].[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"");

    }
",non-flaky,5
159684,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_withTablespace,"    @Test
    public void execute_withTablespace() throws Exception {
        statementUnderTest = new AddUniqueConstraintStatement(null, null, TABLE_NAME, new ColumnConfig[] { new ColumnConfig().setName(COLUMN_NAME)}, CONSTRAINT_NAME).setTablespace(TABLESPACE_NAME);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq]) on liquibase2"", MSSQLDatabase.class);
        assertCorrect(""alter table adduqtest add constraint unique (coltomakeuq) constraint uq_test"", InformixDatabase.class);
        assertCorrect(""alter table \""adduqtest\"" add constraint uq_test unique (\""coltomakeuq\"") USING INDEX TABLESPACE "" + TABLESPACE_NAME, PostgresDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", MySQLDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", MariaDBDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", DerbyDatabase.class, HsqlDatabase.class, DB2Database.class, H2Database.class, FirebirdDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", Db2zDatabase.class);
        assertCorrectOnRest(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq]) USING INDEX TABLESPACE "" + TABLESPACE_NAME);
    }
",non-flaky,5
159685,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_withDefferedAndDisabled,"    @Test
    public void execute_withDefferedAndDisabled() throws Exception {
        statementUnderTest = new AddUniqueConstraintStatement(null, null, TABLE_NAME, new ColumnConfig[] { new ColumnConfig().setName(COLUMN_NAME)}, CONSTRAINT_NAME).setDeferrable(true).setInitiallyDeferred(true).setDisabled(true);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", SybaseDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", MSSQLDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", SybaseASADatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", MySQLDatabase.class);
        assertCorrect(""alter table adduqtest add constraint unique (coltomakeuq) constraint uq_test"", InformixDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq) DEFERRABLE INITIALLY "" +
                ""DEFERRED DISABLE"", OracleDatabase.class);
        assertCorrect(""ALTER TABLE \""adduqtest\"" ADD CONSTRAINT uq_test unique (\""coltomakeuq\"") DEFERRABLE INITIALLY"" +
                "" DEFERRED"", PostgresDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", DerbyDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"");
    }
",non-flaky,5
159686,liquibase_liquibase,MarkChangeSetRanExecuteTest.generateSql_insert,"    @Test
    public void generateSql_insert() throws Exception {
        this.statementUnderTest = new MarkChangeSetRanStatement(new ChangeSet(""a"", ""b"", false, false, ""c"", ""e"", ""f"",
                null), ChangeSet.ExecType.EXECUTED);
        String version = LiquibaseUtil.getBuildVersion().replaceAll(""SNAPSHOT"", ""SNP"");
        assertCorrect(""insert into [databasechangelog] ([id], [author], [filename], [dateexecuted], "" +
                        ""[orderexecuted], [md5sum], [description], [comments], [exectype], [contexts], [labels], "" +
                        ""[liquibase], [deployment_id]) values ('a', 'b', 'c', getdate(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                MSSQLDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', systimestamp, 1, '8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', "" +
                        ""'executed', 'e', null, '"" + version + ""', null)"",
                OracleDatabase.class);
        assertCorrect(""insert into [databasechangelog] ([id], [author], [filename], [dateexecuted], "" +
                        ""[orderexecuted], [md5sum], [description], [comments], [exectype], [contexts], [labels], "" +
                        ""[liquibase], [deployment_id]) values ('a', 'b', 'c', getdate(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                SybaseDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', "" +
                        ""current year to fraction(5), 1, '8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', "" +
                        ""'executed', "" +
                        ""'e', null, '"" + version + ""', null)"",
                InformixDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', current timestamp, 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                DB2Database.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', current_timestamp, 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                FirebirdDatabase.class, DerbyDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', now, 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                HsqlDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', now(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                SybaseASADatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, `description`, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', now(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                MySQLDatabase.class, MariaDBDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', now(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                PostgresDatabase.class, H2Database.class);
        assertCorrectOnRest(""insert into databasechangelog (id, author, filename, dateexecuted, "" +
                ""orderexecuted, md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) "" +
                ""values ('a', 'b', 'c', "" +
                ""current timestamp, 1, '8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, "" +
                ""'"" + version + ""', null)"");
    }
",non-flaky,5
159687,liquibase_liquibase,MarkChangeSetRanExecuteTest.generateSql_update,"    @Test
    public void generateSql_update() throws Exception {
        this.statementUnderTest = new MarkChangeSetRanStatement(new ChangeSet(""a"", ""b"", false, false, ""c"", ""e"", ""f"",
                null), ChangeSet.ExecType.RERAN);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = getdate(), [deployment_id] = null, [exectype] "" +
                        ""= 'reran', [md5sum] = '8:d41d8cd98f00b204e9800998ecf8427e', [orderexecuted] = 2 where [id] ="" +
                        "" 'a' and"" +
                        "" [author] = 'b' and [filename] = 'c'"",
                MSSQLDatabase.class);
        assertCorrect(""update databasechangelog set dateexecuted = systimestamp, deployment_id = null, exectype = "" +
                        ""'reran', md5sum = '8:d41d8cd98f00b204e9800998ecf8427e', orderexecuted = 2 where id = 'a' and"" +
                        "" author "" +
                        ""= 'b' and filename = 'c'"",
                OracleDatabase.class);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = getdate(), [deployment_id] = null, [exectype] "" +
                ""= 'reran', [md5sum] = '8:d41d8cd98f00b204e9800998ecf8427e', [orderexecuted] = 2 where [id] = 'a' and"" +
                "" [author] = 'b' and [filename] = 'c'"", SybaseDatabase.class);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = current year to fraction(5), deployment_id = "" +
                ""null, exectype = 'reran', md5sum = '8:d41d8cd98f00b204e9800998ecf8427e', orderexecuted = 2 where id "" +
                ""= 'a' and author = 'b' and filename = 'c'"", InformixDatabase.class);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = current timestamp, deployment_id = null, "" +
                        ""exectype = 'reran', md5sum = '8:d41d8cd98f00b204e9800998ecf8427e', orderexecuted = 2 where "" +
                        ""id = 'a' and author = 'b' and filename = 'c'"",
                DB2Database.class);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = current_timestamp, deployment_id = null, "" +
                        ""exectype = 'reran', md5sum = '8:d41d8cd98f00b204e9800998ecf8427e', orderexecuted = 2 where "" +
                        ""id = 'a' and author = 'b' and filename = 'c'"",
                FirebirdDatabase.class,
                DerbyDatabase.class);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = NOW(), deployment_id = null, exectype = "" +
                        ""'reran', md5sum = '8:d41d8cd98f00b204e9800998ecf8427e', orderexecuted = 2 where id = 'a' and"" +
                        "" author = 'b' and filename = 'c'"",
                SybaseASADatabase.class);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = NOW(), deployment_id = null, exectype = "" +
                        ""'reran', md5sum = '8:d41d8cd98f00b204e9800998ecf8427e', orderexecuted = 2 where id = 'a' and"" +
                        "" author = 'b' and filename = 'c'"",
                MySQLDatabase.class, MariaDBDatabase.class, HsqlDatabase.class, PostgresDatabase.class, H2Database
                        .class);
        assertCorrectOnRest(""update [databasechangelog] set [dateexecuted] = NOW(), [deployment_id] = null, [exectype] = 'reran', [md5sum] = "" +
                ""'8:d41d8cd98f00b204e9800998ecf8427e', [orderexecuted] = 2 where id = 'a' and author = 'b' and filename = 'c'"");
    }
",non-flaky,5
159688,liquibase_liquibase,CreateDatabaseChangeLogLockTableExecuteTest.generate,"    @Test
    public void generate() throws Exception {
        this.statementUnderTest = new CreateDatabaseChangeLogLockTableStatement();

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime, "" +
                ""[lockedby] text, "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""}, SQLiteDatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] bit not null, "" +
                ""[lockgranted] datetime null, "" +
                ""[lockedby] varchar(255) null, "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""}, SybaseDatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] bit not null, "" +
                ""[lockgranted] datetime null, "" +
                ""[lockedby] varchar(255) null, "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""}, SybaseASADatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime, "" +
                ""[lockedby] varchar(255), "" +
                ""primary key (id))""}, InformixDatabase.class);
    
        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] [int] not null, "" +
                ""[locked] [bit] not null, "" +
                ""[lockgranted] [datetime2](3), "" +
                ""[lockedby] [nvarchar](255), "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""}, MSSQLDatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] integer not null, "" +
                ""[locked] smallint not null, "" +
                ""[lockgranted] timestamp, "" +
                ""[lockedby] varchar(255), "" +
                ""constraint [pk_dbchgloglock] primary key ([id]))""}, DB2Database.class);
    
        assertCorrect(new String[]{""create table databasechangeloglock ("" +
                ""id integer not null, "" +
                ""locked number(1) not null, "" +
                ""lockgranted timestamp, "" +
                ""lockedby varchar2(255), "" +
                ""constraint pk_databasechangeloglock primary key (id))""}, OracleDatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime null, "" +
                ""[lockedby] varchar(255) null, "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""}, MySQLDatabase.class);
    
        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime null, "" +
                ""[lockedby] varchar(255) null, "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""}, MariaDBDatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime, "" +
                ""[lockedby] varchar(255), "" +
                ""constraint [databasechangeloglock_pkey] primary key ([id]))""}, PostgresDatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime, "" +
                ""[lockedby] varchar(255), "" +
                ""constraint [pk_dbchgloglock] primary key ([id]))""}, Db2zDatabase.class);

        // all other RDBMS
        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime, "" +
                ""[lockedby] varchar(255), "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""});

    }
",non-flaky,5
159689,liquibase_liquibase,RenameColumnExecuteTest.noSchema,"    @Test
    public void noSchema() throws Exception {
        this.statementUnderTest = new RenameColumnStatement(null, null, TABLE_NAME, COLUMN_NAME, ""new_name"", ""int"");

        assertCorrect(""rename column table_name.column_name to new_name"", DerbyDatabase.class, InformixDatabase.class);
        assertCorrect(""alter table table_name alter column column_name rename to new_name"", H2Database.class, HsqlDatabase.class);
        assertCorrect(""alter table table_name alter column column_name to new_name"", FirebirdDatabase.class);
        assertCorrect(""alter table table_name change column_name new_name int"", MySQLDatabase.class, MariaDBDatabase.class);
        assertCorrect(""exec sp_rename '[table_name].[column_name]', 'new_name'"", MSSQLDatabase.class);
        assertCorrect(""exec sp_rename 'table_name.column_name', 'new_name'"", SybaseDatabase.class);
        assertCorrect(""alter table [table_name] rename column_name to new_name"",SybaseASADatabase.class);
        assertCorrectOnRest(""alter table [table_name] rename column [column_name] to [new_name]"");
    }
",non-flaky,5
159690,liquibase_liquibase,AddAutoIncrementExecuteTest.noSchema,"    @Test
    public void noSchema() throws Exception {
        this.statementUnderTest = new AddAutoIncrementStatement(null, null, TABLE_NAME, COLUMN_NAME, ""int"", null, null, null, null);

        assertCorrect(""alter table [table_name] modify column_name serial"", PostgresDatabase.class);
        assertCorrect(""alter table table_name modify column_name int auto_increment"", MySQLDatabase.class);
        assertCorrect(""ALTER TABLE [table_name] ALTER COLUMN [column_name] SET GENERATED BY DEFAULT AS IDENTITY"", DB2Database.class);
        assertCorrect(""alter table table_name alter column column_name int generated by default as identity"", HsqlDatabase.class);
        assertCorrect(""alter table table_name alter column column_name int auto_increment"", H2Database.class);

        assertCorrect(""ALTER TABLE [table_name] MODIFY [column_name] serial"", InformixDatabase.class);
        assertCorrect(""ALTER TABLE [table_name] ALTER [column_name] SET DEFAULT AUTOINCREMENT"", SybaseASADatabase.class);
        assertCorrect(""ALTER TABLE [table_name] MODIFY [column_name] int identity"", SybaseDatabase.class);
        assertCorrect(""ALTER TABLE [table_name] ALTER column [column_name] SET GENERATED BY DEFAULT AS IDENTITY"", Db2zDatabase.class);

        assertCorrectOnRest(""ALTER TABLE [table_name] MODIFY [column_name] int AUTO_INCREMENT"");
    }
",non-flaky,5
159691,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_stringDefault,"//    @Test
//    public void execute_stringDefault() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddColumnStatement(null, TABLE_NAME, NEW_COLUMN_NAME, ""varchar(50)"", ""new default"")) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                        assertNotNull(columnSnapshot);
//                        assertEquals(NEW_COLUMN_NAME.toUpperCase(), columnSnapshot.getName().toUpperCase());
//                        assertEquals(""varchar"".toUpperCase(), columnSnapshot.getShortName().toUpperCase().replaceAll(""VARCHAR2"", ""VARCHAR""));
//                        assertEquals(50, columnSnapshot.getColumnSize());
//                        assertEquals(""new default"", columnSnapshot.getDefaultValue());
//
//                        assertEquals(true, columnSnapshot.isNullable());
//                    }
//                });
//    }
",non-flaky,5
159692,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_intDefault,"//    @Test
//    public void execute_intDefault() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddColumnStatement(null, TABLE_NAME, NEW_COLUMN_NAME, ""int"", 42)) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                        assertNotNull(columnSnapshot);
//                        assertEquals(NEW_COLUMN_NAME.toUpperCase(), columnSnapshot.getName().toUpperCase());
//                        if (snapshot.getDatabase() instanceof OracleDatabase) {
//                            assertEquals(""NUMBER"", columnSnapshot.getShortName().toUpperCase());
//                        } else {
//                            assertTrue(columnSnapshot.getShortName().toUpperCase().startsWith(""INT""));
//                        }
//                        assertEquals(42, ((Number) columnSnapshot.getDefaultValue()).intValue());
//
//                        assertEquals(true, columnSnapshot.isNullable());
//                    }
//
//                }
//
//        );
//    }
",non-flaky,5
159693,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_floatDefault,"//    @Test
//    public void execute_floatDefault() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddColumnStatement(null, TABLE_NAME, NEW_COLUMN_NAME, ""float"", 42.5)) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                        assertNotNull(columnSnapshot);
//                        assertEquals(NEW_COLUMN_NAME.toUpperCase(), columnSnapshot.getName().toUpperCase());
//                        assertEquals(new Double(42.5), new Double(((Number) columnSnapshot.getDefaultValue()).doubleValue()));
//
//                        assertEquals(true, columnSnapshot.isNullable());
//                    }
//                });
//    }
",non-flaky,5
159694,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_notNull,"//    @Test
//    public void execute_notNull() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddColumnStatement(null, TABLE_NAME, NEW_COLUMN_NAME, ""int"", 42, new NotNullConstraint())) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                        assertNotNull(columnSnapshot);
//                        assertEquals(false, columnSnapshot.isNullable());
//                    }
//                }
//
//        );
//    }
",non-flaky,5
159695,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_primaryKey_nonAutoIncrement,"//    @Test
//    public void execute_primaryKey_nonAutoIncrement() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddColumnStatement(null, TABLE_NAME, NEW_COLUMN_NAME, ""int"", null, new PrimaryKeyConstraint())) {
//
//                    protected boolean expectedException(Database database, DatabaseException exception) {
//                        return (database instanceof DB2Database
//                                || database instanceof DerbyDatabase
//                                || database instanceof H2Database
//                                || database instanceof CacheDatabase);
//                    }
//
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                        assertNotNull(columnSnapshot);
//                        assertEquals(false, columnSnapshot.isNullable());
//                        assertTrue(columnSnapshot.isPrimaryKey());
//                        assertEquals(false, columnSnapshot.isAutoIncrement());
//                    }
//                });
//    }
",non-flaky,5
159696,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_altSchema,"//    @Test
//    public void execute_altSchema() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(TestContext.ALT_SCHEMA, new AddColumnStatement(TestContext.ALT_SCHEMA, TABLE_NAME, NEW_COLUMN_NAME, ""varchar(50)"", ""new default"")) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                        assertNotNull(columnSnapshot);
//                        assertEquals(NEW_COLUMN_NAME.toUpperCase(), columnSnapshot.getName().toUpperCase());
//                        assertEquals(""new default"", columnSnapshot.getDefaultValue());
//
//                        assertEquals(true, columnSnapshot.isNullable());
//                    }
//
//                });
//    }
",non-flaky,5
159697,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_primaryKeyAutoIncrement,"//    @Test
//      public void execute_primaryKeyAutoIncrement() throws Exception {
//          new DatabaseTestTemplate().testOnAvailableDatabases(
//                  new SqlStatementDatabaseTest(null, new AddColumnStatement(null, TABLE_NAME, NEW_COLUMN_NAME, ""int"", null, new PrimaryKeyConstraint(), new AutoIncrementConstraint())) {
//
//                      protected boolean expectedException(Database database, DatabaseException exception) {
//                          return (database instanceof DB2Database
//                                  || database instanceof DerbyDatabase
//                                  || database instanceof H2Database
//                                  || database instanceof CacheDatabase
//                                    || !database.supportsAutoIncrement());
//                      }
//
//                      protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                          assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                      }
//
//                      protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                          Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                          assertNotNull(columnSnapshot);
//                          assertEquals(false, columnSnapshot.isNullable());
//                          assertTrue(columnSnapshot.isPrimaryKey());
//                          assertEquals(true, columnSnapshot.isAutoIncrement());
//                      }
//                  });
//      }
",non-flaky,5
159698,liquibase_liquibase,SelectFromDatabaseChangeLogLockExecutorTest.generateSql,"    @Test
    public void generateSql() throws Exception {
        this.statementUnderTest = new SelectFromDatabaseChangeLogLockStatement(""LOCKED"");
        assertCorrect(""select [locked] from [databasechangeloglock] where [id]=1"", MSSQLDatabase.class, SybaseDatabase.class);
        assertCorrect(""select [locked] from [databasechangeloglock] where [id]=1"", SybaseASADatabase.class);
        assertCorrect(""select [locked] from [databasechangeloglock] where [id]=1 for update"", OracleDatabase.class);
        assertCorrectOnRest(""select [locked] from [databasechangeloglock] where [id]=1"");
    }
",non-flaky,5
159699,liquibase_liquibase,SelectFromDatabaseChangeLogLockExecutorTest.generateSql_count,"    @Test
    public void generateSql_count() throws Exception {
        this.statementUnderTest = new SelectFromDatabaseChangeLogLockStatement(new ColumnConfig().setName(""COUNT(*)"", true));
        assertCorrect(""select count(*) from [databasechangeloglock] where [id]=1"", MSSQLDatabase.class, SybaseDatabase.class);
        assertCorrect(""select count(*) from [databasechangeloglock] where [id]=1"", MSSQLDatabase.class, SybaseASADatabase.class);
        assertCorrect(""select count(*) from [databasechangeloglock] where [id]=1 for update"", OracleDatabase.class);
        assertCorrectOnRest(""select count(*) from [databasechangeloglock] where [id]=1"");
    }
",non-flaky,5
159700,liquibase_liquibase,SelectFromDatabaseChangeLogLockExecutorTest.generateSql_multicolumn,"    @Test
    public void generateSql_multicolumn() throws Exception {
        this.statementUnderTest = new SelectFromDatabaseChangeLogLockStatement(""LOCKED"", ""LOCKEDBY"");
        assertCorrect(""select [locked],[lockedby] from [databasechangeloglock] where [id]=1"", MSSQLDatabase.class, SybaseDatabase.class);
        assertCorrect(""select [locked],[lockedby] from [databasechangeloglock] where [id]=1"", MSSQLDatabase.class, SybaseASADatabase.class);
        assertCorrect(""select [locked],[lockedby] from [databasechangeloglock] where [id]=1 for update"", OracleDatabase.class);
        assertCorrectOnRest(""select [locked],[lockedby] from [databasechangeloglock] where [id]=1"");
    }
",non-flaky,5
159701,liquibase_liquibase,LockServiceExecuteTest.nothing,"    @Test
    public void nothing() {

    }
",non-flaky,5
159702,liquibase_liquibase,LockServiceExecuteTest.performTest,"//    @Test
//    public void waitForLock_twoConnections() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(new DatabaseTest() {
//            public void performTest(Database database) throws Exception {
////                if (database instanceof H2Database) {
////                    return;
////                }
//
//                String url = DatabaseTestContext.getInstance().getTestUrl(database);
//                System.out.println(url);
//                DatabaseConnection connection2 = DatabaseTestContext.getInstance().openDatabaseConnection(url);
//                Database database2 = DatabaseFactory.getInstance().findCorrectDatabaseImplementation(connection2);
//
//                assertTrue(LockService.getInstance(database).acquireLock());
//                assertTrue(LockService.getInstance(database).hasChangeLogLock());
//                assertFalse(LockService.getInstance(database2).hasChangeLogLock());
//
//                assertFalse(LockService.getInstance(database2).acquireLock());
//                assertFalse(LockService.getInstance(database2).acquireLock());
//
//                LockService.getInstance(database).releaseLock();
//                assertTrue(LockService.getInstance(database2).acquireLock());
//
//            }
",non-flaky,5
159703,liquibase_liquibase,LockServiceExecuteTest.performTest,"//    @Test
//    public void waitForLock_severalAquireLocksCalled() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(new DatabaseTest() {
//            public void performTest(Database database) throws Exception {
//                assertTrue(LockService.getInstance(database).acquireLock());
//                assertTrue(LockService.getInstance(database).acquireLock());
//                assertTrue(LockService.getInstance(database).acquireLock());
//                assertTrue(LockService.getInstance(database).acquireLock());
//            }
",non-flaky,5
159704,liquibase_liquibase,LockServiceExecuteTest.performTest,"//    @Test
//    public void waitForLock_emptyDatabase() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new DatabaseTest() {
//
//                    public void performTest(Database database) throws Exception {
//                        Executor executor = ExecutorService.getInstance().getExecutor(database);
//                        try {
//                            LockService.getInstance(database).resetAll();
//
//                            executor.execute(new DropTableStatement(null, database.getDatabaseChangeLogTableName(), false), new ArrayList<SqlVisitor>());
//                        } catch (DatabaseException e) {
//                            ; //must not be there
//                        }
//                        try {
//                            executor.execute(new DropTableStatement(null, database.getDatabaseChangeLogLockTableName(), false), new ArrayList<SqlVisitor>());
//                        } catch (DatabaseException e) {
//                            ; //must not be there
//                        }
//
//                        database.commit();
//
//                        LockService lockManager = LockService.getInstance(database);
//                        lockManager.waitForLock();
//                        lockManager.waitForLock();
//                    }
",non-flaky,5
159705,liquibase_liquibase,LockServiceExecuteTest.performTest,"//    @Test
//    public void waitForLock_loggingDatabase() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new DatabaseTest() {
//
//                    public void performTest(Database database) throws Exception {
//
//                        LockService.getInstance(database).resetAll();
//
//                        Executor executor = ExecutorService.getInstance().getExecutor(database);
//                        try {
//                            executor.execute(new DropTableStatement(null, database.getDatabaseChangeLogTableName(), false), new ArrayList<SqlVisitor>());
//                        } catch (DatabaseException e) {
//                            ; //must not be there
//                        }
//                        try {
//                            executor.execute(new DropTableStatement(null, database.getDatabaseChangeLogLockTableName(), false), new ArrayList<SqlVisitor>());
//                        } catch (DatabaseException e) {
//                            ; //must not be there
//                        }
//
//                        database.commit();
//
//                        ExecutorService.getInstance().setExecutor(database, (new LoggingExecutor(ExecutorService.getInstance().getExecutor(database), new StringWriter(), database)));
//
//                        LockService lockManager = LockService.getInstance(database);
//                        lockManager.waitForLock();
//                    }
",non-flaky,5
159706,liquibase_liquibase,LockServiceExecuteTest.performTest,"//    @Test
//    public void waitForLock_loggingThenExecute() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new DatabaseTest() {
//
//                    public void performTest(Database database) throws Exception {
//
//                        LockService.getInstance(database).resetAll();
//
//                        try {
//                            ExecutorService.getInstance().getExecutor(database).execute(new DropTableStatement(null, database.getDatabaseChangeLogTableName(), false), new ArrayList<SqlVisitor>());
//                        } catch (DatabaseException e) {
//                            ; //must not be there
//                        }
//                        try {
//                            ExecutorService.getInstance().getExecutor(database).execute(new DropTableStatement(null, database.getDatabaseChangeLogLockTableName(), false), new ArrayList<SqlVisitor>());
//                        } catch (DatabaseException e) {
//                            ; //must not be there
//                        }
//
//                        database.commit();
//
////                        Database clearDatabase = database.getClass().getConstructor().newInstance();
////                        clearDatabase.setConnection(database.getConnection());
//
//                        Executor originalTemplate = ExecutorService.getInstance().getExecutor(database);
//                        ExecutorService.getInstance().setExecutor(database, new LoggingExecutor(originalTemplate, new StringWriter(), database));
//
//                        LockService lockManager = LockService.getInstance(database);
//                        lockManager.waitForLock();
//
//                        ExecutorService.getInstance().setExecutor(database, originalTemplate);
//                        lockManager.waitForLock();
//
////                        database.getWriteExecutor().execute(database.getSelectChangeLogLockSQL());
//                    }
",non-flaky,5
159707,liquibase_liquibase,CDILiquibaseTest.shouldntRunWhenShouldRunIsFalse,"    @Test
    public void shouldntRunWhenShouldRunIsFalse() {
        System.setProperty(""liquibase.shouldRun"", ""false"");
        validateRunningState(false);
    }
",non-flaky,5
159708,liquibase_liquibase,CDILiquibaseTest.shouldRunWhenShouldRunIsTrue,"    @Test
    public void shouldRunWhenShouldRunIsTrue() {
        System.setProperty(""liquibase.shouldRun"", ""true"");
        validateRunningState(true);
    }
",non-flaky,5
159709,liquibase_liquibase,CDILiquibaseTest.shouldntRunWhenConfigShouldRunIsFalse,"    @Test
    public void shouldntRunWhenConfigShouldRunIsFalse() {
        System.setProperty(""liquibase.config.shouldRun"", ""false"");
        validateRunningState(false);
    }
",non-flaky,5
159710,liquibase_liquibase,CDILiquibaseTest.shouldRunWhenConfigShouldRunIsTrue,"    @Test
    public void shouldRunWhenConfigShouldRunIsTrue() {
        System.setProperty(""liquibase.config.shouldRun"", ""true"");
        validateRunningState(true);
    }
",non-flaky,5
159711,liquibase_liquibase,SchemesCDIConfigBuilderTest.testCreateCDILiquibaseConfig,"//    @Test
//    public void testCreateCDILiquibaseConfig() throws Exception {
//        Set<Bean<?>> beans = new LinkedHashSet<Bean<?>>();
//        beans.add(mockBean(new A1()));
//        beans.add(mockBean(new B2()));
//
//        when(bm.getBeans(eq(Object.class), eq(new SchemesCDIConfigBuilder.AnnotationLiteralDefault()))).thenReturn(beans);
//
//        CDILiquibaseConfig config = schemesCDIConfigBuilder.createCDILiquibaseConfig();
//
//        Assert.assertNotNull(config);
//        Assert.assertEquals(""liquibase.cdi.schema.xml"", config.getChangeLog());
//    }
",non-flaky,5
99,stanfordnlp_CoreNLP,DirectedMultiGraphTest.testConnectedComponents,"@Test
public void testConnectedComponents() {
    System.out.println(""graph is "" + graph.toString());
    List<Set<Integer>> ccs = graph.getConnectedComponents();
    for (Set<Integer> cc : ccs) {
        System.out.println(""Connected component: "" + cc);
    }
    assertEquals(ccs.size(), 4);
    assertEquals(CollectionUtils.sorted(ccs.get(0)), Arrays.asList(1, 2, 3, 4));
}",unordered collections,3
96007,stanfordnlp_CoreNLP,SemgrexPatternITest.testNERStanfordDependencies,"  @Test
  public void testNERStanfordDependencies() throws Exception{
    String sentence = ""John lives in Washington."";
    Properties props = new Properties();
    props.setProperty(""annotators"",""tokenize, ssplit, pos, lemma, ner, parse"");
    props.setProperty(""parse.originalDependencies"", ""true"");
    StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
    Annotation doc = new Annotation(sentence);
    pipeline.annotate(doc);
    CoreMap sent = doc.get(CoreAnnotations.SentencesAnnotation.class).get(0);
    SemanticGraph graph = sent.get(SemanticGraphCoreAnnotations.CollapsedCCProcessedDependenciesAnnotation.class);
    graph.prettyPrint();
    String patStr = ""({word:/lives/} >/prep_in/ {word:/\\QCalifornia\\E|\\QWashington\\E/} >nsubj {ner:PERSON})"";
    SemgrexPattern pat = SemgrexPattern.compile(patStr);
    SemgrexMatcher mat = pat.matcher(graph, true);
    assertTrue(mat.find());
  }
",non-flaky,5
96008,stanfordnlp_CoreNLP,SemgrexPatternITest.testNERUniversalDependencies,"  @Test
  public void testNERUniversalDependencies() throws Exception{
    String sentence = ""John lives in Washington."";
    Properties props = new Properties();
    props.setProperty(""annotators"",""tokenize, ssplit, pos, lemma, ner, parse"");
    StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
    props.setProperty(""parse.originalDependencies"", ""false"");
    Annotation doc = new Annotation(sentence);
    pipeline.annotate(doc);
    CoreMap sent = doc.get(CoreAnnotations.SentencesAnnotation.class).get(0);
    SemanticGraph graph = sent.get(SemanticGraphCoreAnnotations.CollapsedCCProcessedDependenciesAnnotation.class);
    graph.prettyPrint();
    String patStr = ""({word:/lives/} >/obl:in/ {word:/\\QCalifornia\\E|\\QWashington\\E/} >nsubj {ner:PERSON})"";
    SemgrexPattern pat = SemgrexPattern.compile(patStr);
    SemgrexMatcher mat = pat.matcher(graph, true);
    assertTrue(mat.find());
  }
",non-flaky,5
96009,stanfordnlp_CoreNLP,SUTimeSimpleParserITest.testWorking,"  @Test
  public void testWorking() throws SUTimeSimpleParser.SUTimeParsingError {
    String[] inputs = { ""1972"", ""1972-07-05"", ""Jan 12, 1975 5:30"", ""7:12"", ""0712"", ""1972-04"" };
    String[] outputs = { ""1972-XX-XX"", ""1972-07-05"", ""1975-01-12T05:30"", ""T07:12"", ""712-XX-XX"", ""1972-04"" };
    // todo: second last case is totally bad, but it's what it does at present. But I guess 1930 is ambiguous....
    assertEquals(inputs.length, outputs.length);

    for (int i = 0; i < inputs.length; i++) {
      // System.err.println(""String: "" + inputs[i]);
      SUTime.Temporal timeExpression = parse(inputs[i]);
      // System.err.println(""Parsed: "" + timeExpression);
      assertEquals(outputs[i], timeExpression.toString());
    }
  }
",non-flaky,5
96010,stanfordnlp_CoreNLP,HeidelTimeITest.runHeidelTimeEnglish,"  @Test
  public void runHeidelTimeEnglish() throws Exception {
    String text = ""On Monday, some cataclysmic news about a a release last Christmas was released."";

    Annotation ann = new Annotation(text);
    String date = ""2017-07-07"";
    ann.set(CoreAnnotations.DocDateAnnotation.class, date);

    String heideltimeEnv = System.getenv(""HEIDELTIME_PATH"");
    if (heideltimeEnv == null) {
      heideltimeEnv = DEFAULT_HEIDELTIME_LOCATION;
    }

    Properties defaultProps = new Properties();
    defaultProps.load(IOUtils.getInputStreamFromURLOrClasspathOrFileSystem(""edu/stanford/nlp/pipeline/StanfordCoreNLP.properties""));

    Properties props = new Properties(defaultProps);
    props.setProperty(""customAnnotatorClass.heideltime"", ""edu.stanford.nlp.time.HeidelTimeAnnotator"");
    props.setProperty(HeidelTimeAnnotator.HEIDELTIME_PATH_PROPERTY, heideltimeEnv);
    props.setProperty(HeidelTimeAnnotator.HEIDELTIME_LANGUAGE_PROPERTY, ""english"");
    props.setProperty(""annotators"", ""tokenize,ssplit,heideltime"");

    StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
    pipeline.annotate(ann);

    List<CoreMap> outputs = ann.get(TimeAnnotations.TimexAnnotations.class);
    Assert.assertEquals(2, outputs.size());

    Assert.assertEquals(""Monday"", outputs.get(0).get(TimeAnnotations.TimexAnnotation.class).text());
    Assert.assertEquals(""2017-07-03"", outputs.get(0).get(TimeAnnotations.TimexAnnotation.class).value());

    Assert.assertEquals(""Christmas"", outputs.get(1).get(TimeAnnotations.TimexAnnotation.class).text());
    Assert.assertEquals(""2016-12-25"", outputs.get(1).get(TimeAnnotations.TimexAnnotation.class).value());
  }
",non-flaky,5
96011,stanfordnlp_CoreNLP,HeidelTimeITest.runHeidelTimeSpanish,"  @Test
  public void runHeidelTimeSpanish() throws Exception {
    String text = ""El lunes, algunas noticias cataclÃ­smicas sobre un lanzamiento de la Navidad pasada fueron liberadas."";

    Annotation ann = new Annotation(text);
    String date = ""2017-07-07"";
    ann.set(CoreAnnotations.DocDateAnnotation.class, date);

    String heideltimeEnv = System.getenv(""HEIDELTIME_PATH"");
    if (heideltimeEnv == null) {
      heideltimeEnv = DEFAULT_HEIDELTIME_LOCATION;
    }

    Properties defaultProps = new Properties();
    defaultProps.load(IOUtils.getInputStreamFromURLOrClasspathOrFileSystem(""edu/stanford/nlp/pipeline/StanfordCoreNLP-spanish.properties""));

    Properties props = new Properties(defaultProps);
    props.setProperty(""customAnnotatorClass.heideltime"", ""edu.stanford.nlp.time.HeidelTimeAnnotator"");
    props.setProperty(HeidelTimeAnnotator.HEIDELTIME_PATH_PROPERTY, heideltimeEnv);
    props.setProperty(HeidelTimeAnnotator.HEIDELTIME_LANGUAGE_PROPERTY, ""spanish"");
    props.setProperty(""annotators"", ""tokenize,ssplit,heideltime"");

    StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
    pipeline.annotate(ann);

    List<CoreMap> outputs = ann.get(TimeAnnotations.TimexAnnotations.class);
    Assert.assertEquals(1, outputs.size()); // Unfortunately, HeidelTime doesn't get Navidad :-(

    Assert.assertEquals(""El lunes"", outputs.get(0).get(TimeAnnotations.TimexAnnotation.class).text());
    Assert.assertEquals(""2017-07-03"", outputs.get(0).get(TimeAnnotations.TimexAnnotation.class).value());

    //Assert.assertEquals(""Navidad"", outputs.get(1).get(TimeAnnotations.TimexAnnotation.class).text());
    //Assert.assertEquals(""2016-12-25"", outputs.get(1).get(TimeAnnotations.TimexAnnotation.class).value());
  }
",non-flaky,5
96012,stanfordnlp_CoreNLP,DcorefExactOutputITest.testCoref,"  @Test
  public void testCoref() throws IOException {
    String doc = IOUtils.slurpFile(""edu/stanford/nlp/dcoref/STILLALONEWOLF_20050102.1100.eng.LDC2005E83.sgm"");
    Annotation annotation = pipeline.process(doc);
    Map<Integer, CorefChain> chains = annotation.get(CorefCoreAnnotations.CorefChainAnnotation.class);
    Map<Integer, List<ExpectedMention>> expected = loadExpectedResults(""edu/stanford/nlp/dcoref/STILLALONEWOLF_20050102.1100.eng.LDC2005E83.expectedcoref"");
    compareResults(expected, chains);
  }
",non-flaky,5
96013,stanfordnlp_CoreNLP,DcorefBenchmarkSlowITest.testDcoref,"  @Test
  public void testDcoref() throws Exception {
    Counter<String> results = getCorefResults(runCorefTest(true));

    Counter<String> lowResults = new ClassicCounter<>();
    Counter<String> highResults = new ClassicCounter<>();
    Counter<String> expectedResults = new ClassicCounter<>();

    setLowHighExpected(lowResults, highResults, expectedResults, MENTION_TP, 12400, 12410, 12405);
    setLowHighExpected(lowResults, highResults, expectedResults, MENTION_F1, 50.4, 50.45, 50.42);

    setLowHighExpected(lowResults, highResults, expectedResults, MUC_TP, 6245, 6255, 6250);
    setLowHighExpected(lowResults, highResults, expectedResults, MUC_F1, 60.65, 60.7, 60.66);

    setLowHighExpected(lowResults, highResults, expectedResults, BCUBED_TP, 12440, 12452.25, 12452.25);
    setLowHighExpected(lowResults, highResults, expectedResults, BCUBED_F1, 70.75, 70.85, 70.80);

    setLowHighExpected(lowResults, highResults, expectedResults, CEAFM_TP, 10915, 10930, 10920);
    setLowHighExpected(lowResults, highResults, expectedResults, CEAFM_F1, 59.4, 59.5, 59.42);

    setLowHighExpected(lowResults, highResults, expectedResults, CEAFE_TP, 3830, 3840, 3831.36);
    setLowHighExpected(lowResults, highResults, expectedResults, CEAFE_F1, 47.4, 47.5, 47.45);

    setLowHighExpected(lowResults, highResults, expectedResults, BLANC_F1, 75.35, 75.44, 75.38);

    setLowHighExpected(lowResults, highResults, expectedResults, CONLL_SCORE, 59.6, 59.7, 59.64);

    BenchmarkingHelper.benchmarkResults(results, lowResults, highResults, expectedResults);
  }
",non-flaky,5
96014,stanfordnlp_CoreNLP,SentenceUtilsITest.testRebuildingMWTText,"  @Test
  public void testRebuildingMWTText() throws IOException {
    // set up French properties
    Properties frenchProperties = LanguageInfo.getLanguageProperties(""french"");
    frenchProperties.setProperty(""annotators"", ""tokenize,ssplit,mwt"");
    StanfordCoreNLP frenchPipeline = new StanfordCoreNLP(frenchProperties);
    String frenchText = ""Le but des bandes de roulement est d'augmenter la traction."";
    CoreDocument frenchDoc = new CoreDocument(frenchPipeline.process(frenchText));
    String rebuiltFrenchText = SentenceUtils.listToOriginalTextString(frenchDoc.tokens());
    assertTrue(frenchText.equals(rebuiltFrenchText));
  }
",non-flaky,5
96015,stanfordnlp_CoreNLP,SentenceUtilsITest.testRebuildingText,"  @Test
  public void testRebuildingText() {
    // set up basic English pipeline
    Properties basicProperties = new Properties();
    basicProperties.setProperty(""annotators"", ""tokenize,ssplit"");
    StanfordCoreNLP pipeline = new StanfordCoreNLP(basicProperties);
    String text = ""Let's hope this doesn't not work properly.  Especially across sentences. "";
    CoreDocument doc = new CoreDocument(pipeline.process(text));
    String rebuiltText = SentenceUtils.listToOriginalTextString(doc.tokens());
    assertTrue(text.equals(rebuiltText));
  }
",non-flaky,5
96016,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherValue,"  @Test
  public void testTokenSequenceMatcherValue() throws IOException {
    CoreMap doc = createDocument(testText);

    // Test simple sequence with value
    TokenSequencePattern p = TokenSequencePattern.compile(getOrPatternExpr(
            new Pair<String,Object>(""one"", 1), new Pair<String,Object>(""two"", null), new Pair<String,Object>(""fifty"", 50)));
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));

    boolean match = m.find();
    assertTrue(match);
    assertEquals(""one"", m.group());
    assertEquals(1, m.groupValue());

    match = m.find();
    assertTrue(match);
    assertEquals(""two"", m.group());
    assertNull(m.groupValue());

    match = m.find();
    assertTrue(match);
    assertEquals(""fifty"", m.group());
    assertEquals(50, m.groupValue());

    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96017,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherBeginEnd,"  @Test
  public void testTokenSequenceMatcherBeginEnd() throws IOException {
    CoreMap doc = createDocument(testText);

    // Test simple sequence with begin sequence matching
    TokenSequencePattern p = TokenSequencePattern.compile(""^ [] []"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));

    boolean match = m.find();
    assertTrue(match);
    assertEquals(""the number"", m.group());

    match = m.find();
    assertFalse(match);

    // Test simple sequence with end sequence matching
    p = TokenSequencePattern.compile(""[] [] $"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));

    match = m.find();
    assertTrue(match);
    assertEquals(""fifty."", m.group());

    match = m.find();
    assertFalse(match);

    // Test simple sequence with begin and end sequence matching
    p = TokenSequencePattern.compile(""^ [] [] $"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));

    match = m.find();
    assertFalse(match);

    // Test simple sequence with ^$ in a string regular expression
    p = TokenSequencePattern.compile(""/^number$/"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));

    match = m.find();
    assertTrue(match);
    assertEquals(""number"", m.group());

    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96018,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher1,"  @Test
  public void testTokenSequenceMatcher1() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test simple sequence
    TokenSequencePattern p = TokenSequencePattern.compile(getSequencePatternExpr(""Archbishop"", ""of"", ""Canterbury""));
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(""Archbishop of Canterbury"", m.group());
    match = m.find();
    assertFalse(match);

    m.reset();
    match = m.find();
    assertTrue(match);
    assertEquals(""Archbishop of Canterbury"", m.group());

    m.reset();
    match = m.matches();
    assertFalse(match);

    // Test sequence with or
    p = TokenSequencePattern.compile(
            new SequencePattern.OrPatternExpr(
                    getSequencePatternExpr(""Archbishop"", ""of"", ""Canterbury""),
                    getSequencePatternExpr(""Bishop"", ""of"", ""London"")
            ));
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Bishop of London"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Archbishop of Canterbury"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Bishop of London"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile(
              new SequencePattern.SequencePatternExpr(
                    SequencePattern.SEQ_BEGIN_PATTERN_EXPR,
                    getSequencePatternExpr(""Archbishop"", ""of"", ""Canterbury"")
            ));
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile(
            new SequencePattern.SequencePatternExpr(
                    SequencePattern.SEQ_BEGIN_PATTERN_EXPR,
                    getSequencePatternExpr(""Mellitus"", ""was"", ""the"")
            ));
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Mellitus was the"", m.group());
    match = m.find();
    assertFalse(match);


    p = TokenSequencePattern.compile(
            new SequencePattern.SequencePatternExpr(
                    getSequencePatternExpr(""Archbishop"", ""of"", ""Canterbury""),
                    SequencePattern.SEQ_END_PATTERN_EXPR
                    ));
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile(
            new SequencePattern.SequencePatternExpr(
                    getSequencePatternExpr(""London"", ""in"", ""604"", "".""),
                    SequencePattern.SEQ_END_PATTERN_EXPR
                    ));
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""London in 604."", m.group());
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96019,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher2,"  @Test
  public void testTokenSequenceMatcher2() throws IOException {
    CoreMap doc = createDocument(testText1);
    TokenSequencePattern p = TokenSequencePattern.compile(
                    getSequencePatternExpr("".*"", "".*"", ""of"", "".*""));

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""third Archbishop of Canterbury"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""a member of the"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""as Bishop of London"", m.group());
    match = m.find();
    assertFalse(match);

    // Test sequence with groups
    p = TokenSequencePattern.compile(
                    new SequencePattern.SequencePatternExpr(
                      new SequencePattern.GroupPatternExpr(
                            getSequencePatternExpr("".*"", "".*"")),
                      getNodePatternExpr(""of""),
                      new SequencePattern.GroupPatternExpr(
                            getSequencePatternExpr("".*""))));

    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""third Archbishop of Canterbury"", m.group());
    assertEquals(""third Archbishop"", m.group(1));
    assertEquals(""Canterbury"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""a member of the"", m.group());
    assertEquals(""a member"", m.group(1));
    assertEquals(""the"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""as Bishop of London"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertFalse(match);

  }
",non-flaky,5
96020,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher3,"  @Test
  public void testTokenSequenceMatcher3() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test sequence with groups
    TokenSequencePattern p = TokenSequencePattern.compile(
        new SequencePattern.SequencePatternExpr(
            new SequencePattern.GroupPatternExpr(
                new SequencePattern.RepeatPatternExpr(
                    getSequencePatternExpr(""[A-Za-z]+""), 1, 2)),
            getNodePatternExpr(""of""),
            new SequencePattern.GroupPatternExpr(
                new SequencePattern.RepeatPatternExpr(
                    getSequencePatternExpr(""[A-Za-z]+""), 1, 3))));

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""third Archbishop of Canterbury"", m.group());
    assertEquals(""third Archbishop"", m.group(1));
    assertEquals(""Canterbury"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""a member of the Gregorian mission"", m.group());
    assertEquals(""a member"", m.group(1));
    assertEquals(""the Gregorian mission"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""as Bishop of London in"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London in"", m.group(2));
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile(
        new SequencePattern.SequencePatternExpr(
            new SequencePattern.GroupPatternExpr(
                new SequencePattern.RepeatPatternExpr(
                    getNodePatternExpr(""[A-Za-z]+""), 2, 2)),
            getNodePatternExpr(""of""),
            new SequencePattern.GroupPatternExpr(
                new SequencePattern.RepeatPatternExpr(
                    getNodePatternExpr(""[A-Za-z]+""), 1, 3, false))));

    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""third Archbishop of Canterbury"", m.group());
    assertEquals(""third Archbishop"", m.group(1));
    assertEquals(""Canterbury"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""a member of the"", m.group());
    assertEquals(""a member"", m.group(1));
    assertEquals(""the"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""as Bishop of London"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96021,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherConj,"  @Test
  public void testTokenSequenceMatcherConj() throws IOException {
    CoreMap doc = createDocument(testText1);
    TokenSequencePattern p = TokenSequencePattern.compile(
                  new SequencePattern.AndPatternExpr(
                    new SequencePattern.SequencePatternExpr(
                      new SequencePattern.GroupPatternExpr(
                            new SequencePattern.RepeatPatternExpr(
                                    getNodePatternExpr(""[A-Za-z]+""), 2, 2)),
                      getNodePatternExpr(""of""),
                      new SequencePattern.GroupPatternExpr(
                            new SequencePattern.RepeatPatternExpr(
                                    getNodePatternExpr(""[A-Za-z]+""), 1, 3, false))),
                    new SequencePattern.SequencePatternExpr(
                      new SequencePattern.GroupPatternExpr(
                        new SequencePattern.RepeatPatternExpr(
                            getNodePatternExpr("".*""), 0, -1)),
                      getNodePatternExpr(""Bishop""),
                      new SequencePattern.RepeatPatternExpr(
                            getNodePatternExpr("".*""), 0, -1)
                    )));

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals(""first"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    // TODO: This conjunction has both a greedy and nongreedy pattern
    //  - the greedy will try to match as much as possible
    //  - while the non greedy will try to match less
    //  - currently the greedy overrides the nongreedy so we get an additional in...
    assertEquals(""as Bishop of London in"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London in"", m.group(2));
    assertEquals(""as"", m.group(3));
    match = m.find();
    assertFalse(match);


    // Same as before, but both non-greedy now...
    p = TokenSequencePattern.compile(
                  new SequencePattern.AndPatternExpr(
                    new SequencePattern.SequencePatternExpr(
                      new SequencePattern.GroupPatternExpr(
                            new SequencePattern.RepeatPatternExpr(
                                    getNodePatternExpr(""[A-Za-z]+""), 2, 2)),
                      getNodePatternExpr(""of""),
                      new SequencePattern.GroupPatternExpr(
                            new SequencePattern.RepeatPatternExpr(
                                    getNodePatternExpr(""[A-Za-z]+""), 1, 3, false))),
                    new SequencePattern.SequencePatternExpr(
                      new SequencePattern.GroupPatternExpr(
                        new SequencePattern.RepeatPatternExpr(
                            getNodePatternExpr("".*""), 0, -1)),
                      getNodePatternExpr(""Bishop""),
                      new SequencePattern.RepeatPatternExpr(
                            getNodePatternExpr("".*""), 0, -1, false)
                    )));

    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals(""first"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""as Bishop of London"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals(""as"", m.group(3));
    match = m.find();
    assertFalse(match);


    // Same as before, but compiled from string
    p = TokenSequencePattern.compile(
            ""(?: (/[A-Za-z]+/{2,2}) /of/ (/[A-Za-z]+/{1,3}?) ) & (?: (/.*/*) /Bishop/ /.*/*? )"");

    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals(""first"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""as Bishop of London"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals(""as"", m.group(3));
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96022,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherConj2,"  @Test
  public void testTokenSequenceMatcherConj2() throws IOException {
    String content = ""The cat is sleeping on the floor."";
    String greedyPattern = ""(?: ([]* cat []*) & ([]* sleeping []*))"";

    TokenizerFactory tf = PTBTokenizer.factory(new CoreLabelTokenFactory(), """");
    List<CoreLabel> tokens = tf.getTokenizer(new StringReader(content)).tokenize();
    TokenSequencePattern seqPattern = TokenSequencePattern.compile(greedyPattern);
    TokenSequenceMatcher matcher = seqPattern.getMatcher(tokens);

    boolean entireMatch = matcher.matches();
    assertTrue(entireMatch);

    boolean match = matcher.find();
    assertTrue(match);
    assertEquals(""The cat is sleeping on the floor."", matcher.group());

    String reluctantPattern = ""(?: ([]*? cat []*?) & ([]*? sleeping []*?))"";
    TokenSequencePattern seqPattern2 = TokenSequencePattern.compile(reluctantPattern);
    TokenSequenceMatcher matcher2 = seqPattern2.getMatcher(tokens);

    match = matcher2.find();
    assertTrue(match);
    assertEquals(""The cat is sleeping"", matcher2.group());
  }
",non-flaky,5
96023,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherConjAll,"  @Test
  public void testTokenSequenceMatcherConjAll() throws IOException {
    CoreMap doc = createDocument(testText1);
    TokenSequencePattern p = TokenSequencePattern.compile(
            ""(?: (/[A-Za-z]+/{1,2}) /of/ (/[A-Za-z]+/{1,3}?) ) & (?: (/.*/*) /Bishop/ /.*/*? )"");

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    m.setFindType(SequenceMatcher.FindType.FIND_ALL);
    // Test finding of ALL matching sequences with conjunctions
    // todo: Not all sequences are found for some reason - missing sequences starting with just Bishop....
    boolean match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals(""first"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""Bishop of London"", m.group());
    assertEquals(""Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals("""", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""as Bishop of London"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals(""as"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""as Bishop of London in"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London in"", m.group(2));
    assertEquals(""as"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""Bishop of London"", m.group());
    assertEquals(""Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals("""", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""Bishop of London in"", m.group());
    assertEquals(""Bishop"", m.group(1));
    assertEquals(""London in"", m.group(2));
    assertEquals("""", m.group(3));
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96024,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherAll,"  @Test
  public void testTokenSequenceMatcherAll() throws IOException {
    CoreMap doc = createDocument(testText1);
    TokenSequencePattern p = TokenSequencePattern.compile(
            ""(/[A-Za-z]+/{1,2}) /of/ (/[A-Za-z]+/{1,3}?) "");

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    m.setFindType(SequenceMatcher.FindType.FIND_ALL);
    // Test finding of ALL matching sequences
    // NOTE: when using FIND_ALL greedy/reluctant modifiers are not enforced
    //       perhaps should add syntax where some of them are enforced...
    boolean match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""Bishop of London"", m.group());
    assertEquals(""Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""third Archbishop of Canterbury"", m.group());
    assertEquals(""third Archbishop"", m.group(1));
    assertEquals(""Canterbury"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""Archbishop of Canterbury"", m.group());
    assertEquals(""Archbishop"", m.group(1));
    assertEquals(""Canterbury"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""a member of the"", m.group());
    assertEquals(""a member"", m.group(1));
    assertEquals(""the"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""a member of the Gregorian"", m.group());
    assertEquals(""a member"", m.group(1));
    assertEquals(""the Gregorian"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""a member of the Gregorian mission"", m.group());
    assertEquals(""a member"", m.group(1));
    assertEquals(""the Gregorian mission"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""member of the"", m.group());
    assertEquals(""member"", m.group(1));
    assertEquals(""the"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""member of the Gregorian"", m.group());
    assertEquals(""member"", m.group(1));
    assertEquals(""the Gregorian"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""member of the Gregorian mission"", m.group());
    assertEquals(""member"", m.group(1));
    assertEquals(""the Gregorian mission"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""as Bishop of London"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""as Bishop of London in"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London in"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""Bishop of London"", m.group());
    assertEquals(""Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""Bishop of London in"", m.group());
    assertEquals(""Bishop"", m.group(1));
    assertEquals(""London in"", m.group(2));
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96025,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherAll2,"  @Test
  public void testTokenSequenceMatcherAll2() throws IOException {
    String text = ""DATE1 PROD1 PRICE1 PROD2 PRICE2 PROD3 PRICE3 DATE2 PROD4 PRICE4 PROD5 PRICE5 PROD6 PRICE6"";
    CoreMap doc = createDocument(text);
    TokenSequencePattern p = TokenSequencePattern.compile(
        ""(/DATE.*/) (?: /PROD.*/ /PRICE.*/)* (/PROD.*/) (/PRICE.*/)"");

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    m.setFindType(SequenceMatcher.FindType.FIND_ALL);
    // Test finding of ALL matching sequences
    boolean match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE1"", m.group(1));
    assertEquals(""PROD3"", m.group(2));
    assertEquals(""PRICE3"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE1"", m.group(1));
    assertEquals(""PROD2"", m.group(2));
    assertEquals(""PRICE2"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE1"", m.group(1));
    assertEquals(""PROD1"", m.group(2));
    assertEquals(""PRICE1"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE2"", m.group(1));
    assertEquals(""PROD6"", m.group(2));
    assertEquals(""PRICE6"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE2"", m.group(1));
    assertEquals(""PROD5"", m.group(2));
    assertEquals(""PRICE5"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE2"", m.group(1));
    assertEquals(""PROD4"", m.group(2));
    assertEquals(""PRICE4"", m.group(3));
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96026,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherNonOverlapping,"  @Test
  public void testTokenSequenceMatcherNonOverlapping() throws IOException {
    String text = ""DATE1 PROD1 PRICE1 PROD2 PRICE2 PROD3 PRICE3 DATE2 PROD4 PRICE4 PROD5 PRICE5 PROD6 PRICE6"";
    CoreMap doc = createDocument(text);
    TokenSequencePattern p = TokenSequencePattern.compile(
        ""(/DATE.*/) ((/PROD.*/ /PRICE.*/)+)"");

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE1"", m.group(1));
    assertEquals(""PROD1 PRICE1 PROD2 PRICE2 PROD3 PRICE3"", m.group(2));
    assertEquals(""PROD3 PRICE3"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE2"", m.group(1));
    assertEquals(""PROD4 PRICE4 PROD5 PRICE5 PROD6 PRICE6"", m.group(2));
    assertEquals(""PROD6 PRICE6"", m.group(3));
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96027,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher4,"  @Test
  public void testTokenSequenceMatcher4() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test sequence with groups
    TokenSequencePattern p = TokenSequencePattern.compile(
                      new SequencePattern.RepeatPatternExpr(
                                    getSequencePatternExpr(""[A-Za-z]+""), 1, -1));

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Mellitus was the first Bishop of London"", m.group());

    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""the third Archbishop of Canterbury"", m.group());

    p = TokenSequencePattern.compile(
            new SequencePattern.SequencePatternExpr(
                      new SequencePattern.RepeatPatternExpr(
                              getSequencePatternExpr(""[A-Za-z]+""), 0, -1),
                      getSequencePatternExpr(""Mellitus"", ""was"")));

    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Mellitus was"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile(
            new SequencePattern.SequencePatternExpr(
                      new SequencePattern.RepeatPatternExpr(
                              getSequencePatternExpr(""[A-Za-z]+""), 1, -1),
                      getSequencePatternExpr(""Mellitus"", ""was"")));

    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertFalse(match);

  }
",non-flaky,5
96028,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher5,"  @Test
  public void testTokenSequenceMatcher5() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test simple sequence
    TokenSequencePattern p = TokenSequencePattern.compile("" [ { word:\""Archbishop\"" } ]  [ { word:\""of\"" } ]  [ { word:\""Canterbury\"" } ]"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(""Archbishop of Canterbury"", m.group());
    match = m.find();
    assertFalse(match);

    m.reset();
    match = m.find();
    assertTrue(match);
    assertEquals(""Archbishop of Canterbury"", m.group());

    m.reset();
    match = m.matches();
    assertFalse(match);


    p = TokenSequencePattern.compile("" [ \""Archbishop\"" ]  [ \""of\""  ]  [ \""Canterbury\""  ]"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(""Archbishop of Canterbury"", m.group());
    match = m.find();
    assertFalse(match);

    m.reset();
    match = m.find();
    assertTrue(match);
    assertEquals(""Archbishop of Canterbury"", m.group());

    m.reset();
    match = m.matches();
    assertFalse(match);

    // Test sequence with or
    p = TokenSequencePattern.compile("" [ \""Archbishop\""] [\""of\""] [\""Canterbury\""] |  [ \""Bishop\"" ] [ \""of\"" ]  [ \""London\"" ] "");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Bishop of London"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Archbishop of Canterbury"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Bishop of London"", m.group());
    match = m.find();
    assertFalse(match);

  }
",non-flaky,5
96029,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher6,"  @Test
  public void testTokenSequenceMatcher6() throws IOException {
    CoreMap doc = createDocument(testText1);
    TokenSequencePattern p = TokenSequencePattern.compile(""[ /.*/ ] [ /.*/ ] [/of/] [/.*/]"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""third Archbishop of Canterbury"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""a member of the"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""as Bishop of London"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile(""([ /.*/ ] [ /.*/ ]) [/of/] ([/.*/])"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""third Archbishop of Canterbury"", m.group());
    assertEquals(""third Archbishop"", m.group(1));
    assertEquals(""Canterbury"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""a member of the"", m.group());
    assertEquals(""a member"", m.group(1));
    assertEquals(""the"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""as Bishop of London"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertFalse(match);

  }
",non-flaky,5
96030,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher7,"  @Test
  public void testTokenSequenceMatcher7() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test sequence with groups
    TokenSequencePattern p = TokenSequencePattern.compile("" ( [ /[A-Za-z]+/ ]{1,2} )  [ /of/ ] ( [ /[A-Za-z]+/ ]{1,3} )"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""third Archbishop of Canterbury"", m.group());
    assertEquals(""third Archbishop"", m.group(1));
    assertEquals(""Canterbury"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""a member of the Gregorian mission"", m.group());
    assertEquals(""a member"", m.group(1));
    assertEquals(""the Gregorian mission"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""as Bishop of London in"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London in"", m.group(2));
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( "" ( [ /[A-Za-z]+/ ]{2,2} )  [ /of/ ] ( [ /[A-Za-z]+/ ]{1,3}? )"");

    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""third Archbishop of Canterbury"", m.group());
    assertEquals(""third Archbishop"", m.group(1));
    assertEquals(""Canterbury"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""a member of the"", m.group());
    assertEquals(""a member"", m.group(1));
    assertEquals(""the"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""as Bishop of London"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96031,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher8,"  @Test
  public void testTokenSequenceMatcher8() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test sequence with groups
    TokenSequencePattern p = TokenSequencePattern.compile( ""[ /[A-Za-z]+/ ]*"");

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Mellitus was the first Bishop of London"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""the third Archbishop of Canterbury"", m.group());

    p = TokenSequencePattern.compile( ""[ /[A-Za-z]+/ ]*  [\""Mellitus\""] [ \""was\""]"");

    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Mellitus was"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""[ /[A-Za-z]+/ ]+  [\""Mellitus\""] [ \""was\""]"");

    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertFalse(match);

  }
",non-flaky,5
96032,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher9,"  @Test
  public void testTokenSequenceMatcher9() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test sequence with groups
//    TokenSequencePattern p = TokenSequencePattern.compile( ""(?$contextprev /.*/) (?$treat [{{treat}} & /.*/]) (?$contextnext [/.*/])"");
    TokenSequencePattern p = TokenSequencePattern.compile(""(?$contextprev /.*/) (?$test [{tag:NNP} & /.*/]) (?$contextnext [/.*/])"");

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""first Bishop of"", m.group());

    assertEquals(""first"", m.group(1));
    assertEquals(""Bishop"", m.group(2));
    assertEquals(""of"", m.group(3));
    assertEquals(""first"", m.group(""$contextprev""));
    assertEquals(""Bishop"", m.group(""$test""));
    assertEquals(""of"", m.group(""$contextnext""));
    assertEquals(""first"", m.group("" $contextprev""));
    assertEquals(""Bishop"", m.group(""$test ""));
    assertEquals(null, m.group(""$contex tnext""));

    assertEquals(3, m.start(""$contextprev""));
    assertEquals(4, m.end(""$contextprev""));
    assertEquals(4, m.start(""$test""));
    assertEquals(5, m.end(""$test""));
    assertEquals(5, m.start(""$contextnext""));
    assertEquals(6, m.end(""$contextnext""));
  }
",non-flaky,5
96033,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher10,"  @Test
  public void testTokenSequenceMatcher10() throws IOException {
    CoreMap doc = createDocument(""the number is five or 5 or 5.0 or but not 5x or -5 or 5L."");

    // Test simplified pattern with number
    TokenSequencePattern p = TokenSequencePattern.compile( ""(five|5|5x|5.0|-5|5L)"");

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""five"", m.group(1));

    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""5"", m.group(1));

    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""5.0"", m.group(1));

    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""5x"", m.group(1));

    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""-5"", m.group(1));

    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""5L"", m.group(1));

    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96034,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceOptimizeOrString,"  @Test
  public void testTokenSequenceOptimizeOrString() throws IOException {
    CoreMap doc = createDocument(""atropine we need to have many many words here but we don't sweating"");

    // Test simplified pattern with number
    TokenSequencePattern p = TokenSequencePattern.compile( ""(?$dt \""atropine\"") []{0,15} "" +
            ""(?$se  \""social\"" \""avoidant\"" \""behaviour\""|\""dysuria\""|\""hyperglycaemia\""| \""mental\"" \""disorder\""|\""vertigo\""|\""flutter\""| \""chest\"" \""pain\""| \""elevated\"" \""blood\"" \""pressure\""|\""mania\""| \""rash\"" \""erythematous\""|\""manic\""| \""papular\"" \""rash\""|\""death\""| \""atrial\"" \""arrhythmia\""| \""dry\"" \""eyes\""| \""loss\"" \""of\"" \""libido\""| \""rash\"" \""papular\""|\""hypersensitivity\""| \""blood\"" \""pressure\"" \""increased\""|\""dyspepsia\""| \""accommodation\"" \""disorder\""| \""reflexes\"" \""increased\""|\""lesions\""|\""asthenia\""| \""gastrointestinal\"" \""pain\""|\""excitement\""| \""breast\"" \""feeding\""|\""hypokalaemia\""| \""cerebellar\"" \""syndrome\""|\""nervousness\""| \""pulmonary\"" \""oedema\""| \""inspiratory\"" \""stridor\""| \""taste\"" \""altered\""|\""paranoia\""| \""psychotic\"" \""disorder\""| \""open\"" \""angle\"" \""glaucoma\""|\""photophobia\""| \""dry\"" \""eye\""|\""osteoarthritis\""| \""keratoconjunctivitis\"" \""sicca\""| \""haemoglobin\"" \""increased\""| \""ventricular\"" \""extrasystoles\""|\""hallucinations\""|\""conjunctivitis\""|\""paralysis\""| \""qrs\"" \""complex\""|\""anxiety\""| \""conjunctival\"" \""disorder\""|\""coma\""|\""strabismus\""|\""thirst\""|\""para\""| \""sicca\"" \""syndrome\""| \""atrioventricular\"" \""dissociation\""|\""desquamation\""|\""crusting\""| \""abdominal\"" \""distension\""|\""blindness\""|\""hypotension\""|\""dermatitis\""| \""sinus\"" \""tachycardia\""| \""abdominal\"" \""distention\""| \""lacrimation\"" \""decreased\""|\""sicca\""| \""paralytic\"" \""ileus\""| \""urinary\"" \""hesitation\""|\""withdrawn\""| \""erectile\"" \""dysfunction\""|\""keratoconjunctivitis\""|\""anaphylaxis\""| \""psychiatric\"" \""disorders\""| \""altered\"" \""taste\""|\""somnolence\""|\""extrasystoles\""|\""ageusia\""| \""intraocular\"" \""pressure\"" \""increased\""| \""left\"" \""ventricular\"" \""failure\""|\""impotence\""|\""drowsiness\""|\""conjunctiva\""| \""delayed\"" \""gastric\"" \""emptying\""| \""gastrointestinal\"" \""sounds\"" \""abnormal\""| \""qt\"" \""prolonged\""| \""supraventricular\"" \""tachycardia\""|\""weakness\""|\""hypertonia\""| \""confusional\"" \""state\""|\""anhidrosis\""|\""myopia\""|\""dyspnoea\""| \""speech\"" \""impairment\"" \""nos\""| \""rash\"" \""maculo\"" \""papular\""|\""petechiae\""|\""tachypnea\""| \""acute\"" \""angle\"" \""closure\"" \""glaucoma\""| \""gastrooesophageal\"" \""reflux\"" \""disease\""|\""hypokalemia\""| \""left\"" \""heart\"" \""failure\""| \""myocardial\"" \""infarction\""| \""site\"" \""reaction\""| \""ventricular\"" \""fibrillation\""|\""fibrillation\""| \""maculopapular\"" \""rash\""| \""impaired\"" \""gastric\"" \""emptying\""|\""amnesia\""| \""labored\"" \""respirations\""| \""decreased\"" \""lacrimation\""|\""mydriasis\""|\""headache\""| \""dry\"" \""mouth\""|\""scab\""| \""cardiac\"" \""syncope\""| \""visual\"" \""acuity\"" \""reduced\""|\""tension\""| \""blurred\"" \""vision\""| \""bloated\"" \""feeling\""| \""labored\"" \""breathing\""| \""stridor\"" \""inspiratory\""| \""skin\"" \""exfoliation\""| \""memory\"" \""loss\""|\""syncope\""| \""rash\"" \""scarlatiniform\""|\""hyperpyrexia\""| \""cardiac\"" \""flutter\""|\""heartburn\""| \""bowel\"" \""sounds\"" \""decreased\""|\""blepharitis\""|\""tachycardia\""| \""excessive\"" \""thirst\""|\""confusion\""| \""rash\"" \""macular\""| \""taste\"" \""loss\""| \""respiratory\"" \""failure\""|\""hesitancy\""|\""dysmetria\""|\""disorientation\""| \""decreased\"" \""hemoglobin\""| \""atrial\"" \""fibrillation\""| \""urinary\"" \""retention\""| \""dry\"" \""skin\""|\""dehydration\""|\""hyponatraemia\""|\""dysgeusia\""|\""disorder\""| \""increased\"" \""intraocular\"" \""pressure\""| \""speech\"" \""disorder\""| \""feeling\"" \""abnormal\""|\""pain\""| \""anaphylactic\"" \""shock\""|\""hallucination\""| \""abdominal\"" \""pain\""| \""junctional\"" \""tachycardia\""| \""bun\"" \""increased\""| \""ventricular\"" \""flutter\""| \""scarlatiniform\"" \""rash\""|\""agitation\""| \""feeling\"" \""hot\""|\""hyponatremia\""| \""decreased\"" \""bowel\"" \""sounds\""|\""cyanosis\""|\""dysarthria\""| \""heat\"" \""intolerance\""|\""hyperglycemia\""|\""reflux\""| \""angle\"" \""closure\"" \""glaucoma\""| \""electrocardiogram\"" \""qt\"" \""prolonged\""| \""vision\"" \""blurred\""| \""blood\"" \""urea\"" \""increased\""|\""dizziness\""|\""arrhythmia\""|\""erythema\""|\""vomiting\""| \""difficulty\"" \""in\"" \""micturition\""|\""infarction\""|\""laryngospasm\""|\""hypoglycaemia\""|\""hypoglycemia\""| \""elevated\"" \""hemoglobin\""| \""skin\"" \""warm\""| \""ventricular\"" \""arrhythmia\""|\""dissociation\""| \""warm\"" \""skin\""| \""follicular\"" \""conjunctivitis\""|\""urticaria\""|\""fatigue\""| \""cardiac\"" \""fibrillation\""| \""decreased\"" \""sweating\""| \""decreased\"" \""visual\"" \""acuity\""|\""lethargy\""| \""acute\"" \""angle\"" \""closure\"" \""glaucoma\""| \""nodal\"" \""rhythm\""|\""borborygmi\""|\""hyperreflexia\""| \""respiratory\"" \""depression\""|\""diarrhea\""|\""leukocytosis\""| \""speech\"" \""disturbance\""|\""ataxia\""|\""cycloplegia\""|\""tachypnoea\""|\""eczema\""| \""supraventricular\"" \""extrasystoles\""|\""ileus\""| \""cardiac\"" \""arrest\""| \""ventricular\"" \""tachycardia\""|\""laryngitis\""|\""delirium\""|\""lactation\""|\""glaucoma\""|\""obstruction\""|\""hypohidrosis\""|\""parity\""|\""palpitations\""| \""temperature\"" \""intolerance\""|\""constipation\""|\""cyclophoria\""| \""acute\"" \""coronary\"" \""syndrome\""| \""arrhythmia\"" \""supraventricular\""|\""arrest\""|\""lesion\""|\""nausea\""| \""sweating\"" \""decreased\""|\""keratitis\""|\""dyskinesia\""| \""pulmonary\"" \""function\"" \""test\"" \""decreased\""|\""stridor\""|\""swelling\""|\""dysphagia\""| \""haemoglobin\"" \""decreased\""|\""diarrhoea\""| \""ileus\"" \""paralytic\""|\""clonus\""|\""insomnia\""| \""electrocardiogram\"" \""qrs\"" \""complex\""| \""nasal\"" \""congestion\""| \""nasal\"" \""dryness\""|\""sweating\""|\""rash\""| \""nodal\"" \""arrhythmia\""|\""irritability\""|\""hyperhidrosis\""| \""ventricular\"" \""failure\"")"");

    Timing timing = new Timing();
    timing.start();
    for (int i = 0; i < 100; i++) {
      TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
      boolean match = m.find();
      assertTrue(match);
      assertEquals(""atropine we need to have many many words here but we don't sweating"", m.group(0));

      match = m.find();
      assertFalse(match);
    }
    timing.stop(""testTokenSequenceOptimizeOrString matched"");


    CoreMap docNoMatch = createDocument(""atropine we need to have many many words here but we don't, many many many words but still no match"");
    timing.start();
    for (int i = 0; i < 100; i++) {
      TokenSequenceMatcher m = p.getMatcher(docNoMatch.get(CoreAnnotations.TokensAnnotation.class));
      boolean match = m.find();
      assertFalse(match);
    }
    timing.stop(""testTokenSequenceOptimizeOrString no match"");
  }
",non-flaky,5
96035,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testMultiplePatterns,"  @Test
  public void testMultiplePatterns() throws IOException {
    TokenSequencePattern p1 = TokenSequencePattern.compile(""(?$dt \""atropine\"") []{0,15} "" +
        ""(?$se  \""social\"" \""avoidant\"" \""behaviour\""|\""dysuria\""|\""hyperglycaemia\""| \""mental\"" \""disorder\""|\""vertigo\""|\""flutter\""| \""chest\"" \""pain\""| \""elevated\"" \""blood\"" \""pressure\""|\""mania\""| \""rash\"" \""erythematous\""|\""manic\""| \""papular\"" \""rash\""|\""death\""| \""atrial\"" \""arrhythmia\""| \""dry\"" \""eyes\""| \""loss\"" \""of\"" \""libido\""| \""rash\"" \""papular\""|\""hypersensitivity\""| \""blood\"" \""pressure\"" \""increased\""|\""dyspepsia\""| \""accommodation\"" \""disorder\""| \""reflexes\"" \""increased\""|\""lesions\""|\""asthenia\""| \""gastrointestinal\"" \""pain\""|\""excitement\""| \""breast\"" \""feeding\""|\""hypokalaemia\""| \""cerebellar\"" \""syndrome\""|\""nervousness\""| \""pulmonary\"" \""oedema\""| \""inspiratory\"" \""stridor\""| \""taste\"" \""altered\""|\""paranoia\""| \""psychotic\"" \""disorder\""| \""open\"" \""angle\"" \""glaucoma\""|\""photophobia\""| \""dry\"" \""eye\""|\""osteoarthritis\""| \""keratoconjunctivitis\"" \""sicca\""| \""haemoglobin\"" \""increased\""| \""ventricular\"" \""extrasystoles\""|\""hallucinations\""|\""conjunctivitis\""|\""paralysis\""| \""qrs\"" \""complex\""|\""anxiety\""| \""conjunctival\"" \""disorder\""|\""coma\""|\""strabismus\""|\""thirst\""|\""para\""| \""sicca\"" \""syndrome\""| \""atrioventricular\"" \""dissociation\""|\""desquamation\""|\""crusting\""| \""abdominal\"" \""distension\""|\""blindness\""|\""hypotension\""|\""dermatitis\""| \""sinus\"" \""tachycardia\""| \""abdominal\"" \""distention\""| \""lacrimation\"" \""decreased\""|\""sicca\""| \""paralytic\"" \""ileus\""| \""urinary\"" \""hesitation\""|\""withdrawn\""| \""erectile\"" \""dysfunction\""|\""keratoconjunctivitis\""|\""anaphylaxis\""| \""psychiatric\"" \""disorders\""| \""altered\"" \""taste\""|\""somnolence\""|\""extrasystoles\""|\""ageusia\""| \""intraocular\"" \""pressure\"" \""increased\""| \""left\"" \""ventricular\"" \""failure\""|\""impotence\""|\""drowsiness\""|\""conjunctiva\""| \""delayed\"" \""gastric\"" \""emptying\""| \""gastrointestinal\"" \""sounds\"" \""abnormal\""| \""qt\"" \""prolonged\""| \""supraventricular\"" \""tachycardia\""|\""weakness\""|\""hypertonia\""| \""confusional\"" \""state\""|\""anhidrosis\""|\""myopia\""|\""dyspnoea\""| \""speech\"" \""impairment\"" \""nos\""| \""rash\"" \""maculo\"" \""papular\""|\""petechiae\""|\""tachypnea\""| \""acute\"" \""angle\"" \""closure\"" \""glaucoma\""| \""gastrooesophageal\"" \""reflux\"" \""disease\""|\""hypokalemia\""| \""left\"" \""heart\"" \""failure\""| \""myocardial\"" \""infarction\""| \""site\"" \""reaction\""| \""ventricular\"" \""fibrillation\""|\""fibrillation\""| \""maculopapular\"" \""rash\""| \""impaired\"" \""gastric\"" \""emptying\""|\""amnesia\""| \""labored\"" \""respirations\""| \""decreased\"" \""lacrimation\""|\""mydriasis\""|\""headache\""| \""dry\"" \""mouth\""|\""scab\""| \""cardiac\"" \""syncope\""| \""visual\"" \""acuity\"" \""reduced\""|\""tension\""| \""blurred\"" \""vision\""| \""bloated\"" \""feeling\""| \""labored\"" \""breathing\""| \""stridor\"" \""inspiratory\""| \""skin\"" \""exfoliation\""| \""memory\"" \""loss\""|\""syncope\""| \""rash\"" \""scarlatiniform\""|\""hyperpyrexia\""| \""cardiac\"" \""flutter\""|\""heartburn\""| \""bowel\"" \""sounds\"" \""decreased\""|\""blepharitis\""|\""tachycardia\""| \""excessive\"" \""thirst\""|\""confusion\""| \""rash\"" \""macular\""| \""taste\"" \""loss\""| \""respiratory\"" \""failure\""|\""hesitancy\""|\""dysmetria\""|\""disorientation\""| \""decreased\"" \""hemoglobin\""| \""atrial\"" \""fibrillation\""| \""urinary\"" \""retention\""| \""dry\"" \""skin\""|\""dehydration\""|\""hyponatraemia\""|\""dysgeusia\""|\""disorder\""| \""increased\"" \""intraocular\"" \""pressure\""| \""speech\"" \""disorder\""| \""feeling\"" \""abnormal\""|\""pain\""| \""anaphylactic\"" \""shock\""|\""hallucination\""| \""abdominal\"" \""pain\""| \""junctional\"" \""tachycardia\""| \""bun\"" \""increased\""| \""ventricular\"" \""flutter\""| \""scarlatiniform\"" \""rash\""|\""agitation\""| \""feeling\"" \""hot\""|\""hyponatremia\""| \""decreased\"" \""bowel\"" \""sounds\""|\""cyanosis\""|\""dysarthria\""| \""heat\"" \""intolerance\""|\""hyperglycemia\""|\""reflux\""| \""angle\"" \""closure\"" \""glaucoma\""| \""electrocardiogram\"" \""qt\"" \""prolonged\""| \""vision\"" \""blurred\""| \""blood\"" \""urea\"" \""increased\""|\""dizziness\""|\""arrhythmia\""|\""erythema\""|\""vomiting\""| \""difficulty\"" \""in\"" \""micturition\""|\""infarction\""|\""laryngospasm\""|\""hypoglycaemia\""|\""hypoglycemia\""| \""elevated\"" \""hemoglobin\""| \""skin\"" \""warm\""| \""ventricular\"" \""arrhythmia\""|\""dissociation\""| \""warm\"" \""skin\""| \""follicular\"" \""conjunctivitis\""|\""urticaria\""|\""fatigue\""| \""cardiac\"" \""fibrillation\""| \""decreased\"" \""sweating\""| \""decreased\"" \""visual\"" \""acuity\""|\""lethargy\""| \""acute\"" \""angle\"" \""closure\"" \""glaucoma\""| \""nodal\"" \""rhythm\""|\""borborygmi\""|\""hyperreflexia\""| \""respiratory\"" \""depression\""|\""diarrhea\""|\""leukocytosis\""| \""speech\"" \""disturbance\""|\""ataxia\""|\""cycloplegia\""|\""tachypnoea\""|\""eczema\""| \""supraventricular\"" \""extrasystoles\""|\""ileus\""| \""cardiac\"" \""arrest\""| \""ventricular\"" \""tachycardia\""|\""laryngitis\""|\""delirium\""|\""lactation\""|\""glaucoma\""|\""obstruction\""|\""hypohidrosis\""|\""parity\""|\""palpitations\""| \""temperature\"" \""intolerance\""|\""constipation\""|\""cyclophoria\""| \""acute\"" \""coronary\"" \""syndrome\""| \""arrhythmia\"" \""supraventricular\""|\""arrest\""|\""lesion\""|\""nausea\""| \""sweating\"" \""decreased\""|\""keratitis\""|\""dyskinesia\""| \""pulmonary\"" \""function\"" \""test\"" \""decreased\""|\""stridor\""|\""swelling\""|\""dysphagia\""| \""haemoglobin\"" \""decreased\""|\""diarrhoea\""| \""ileus\"" \""paralytic\""|\""clonus\""|\""insomnia\""| \""electrocardiogram\"" \""qrs\"" \""complex\""| \""nasal\"" \""congestion\""| \""nasal\"" \""dryness\""|\""sweating\""|\""rash\""| \""nodal\"" \""arrhythmia\""|\""irritability\""|\""hyperhidrosis\""| \""ventricular\"" \""failure\"")"");
    TokenSequencePattern p2 = TokenSequencePattern.compile( ""(?$dt \""disease\"") []{0,15} "" +
            ""(?$se  \""social\"" \""avoidant\"" \""behaviour\""|\""dysuria\""|\""hyperglycaemia\""| \""mental\"" \""disorder\""|\""vertigo\""|\""flutter\""| \""chest\"" \""pain\""| \""elevated\"" \""blood\"" \""pressure\""|\""mania\""| \""rash\"" \""erythematous\""|\""manic\""| \""papular\"" \""rash\""|\""death\""| \""atrial\"" \""arrhythmia\""| \""dry\"" \""eyes\""| \""loss\"" \""of\"" \""libido\""| \""rash\"" \""papular\""|\""hypersensitivity\""| \""blood\"" \""pressure\"" \""increased\""|\""dyspepsia\""| \""accommodation\"" \""disorder\""| \""reflexes\"" \""increased\""|\""lesions\""|\""asthenia\""| \""gastrointestinal\"" \""pain\""|\""excitement\""| \""breast\"" \""feeding\""|\""hypokalaemia\""| \""cerebellar\"" \""syndrome\""|\""nervousness\""| \""pulmonary\"" \""oedema\""| \""inspiratory\"" \""stridor\""| \""taste\"" \""altered\""|\""paranoia\""| \""psychotic\"" \""disorder\""| \""open\"" \""angle\"" \""glaucoma\""|\""photophobia\""| \""dry\"" \""eye\""|\""osteoarthritis\""| \""keratoconjunctivitis\"" \""sicca\""| \""haemoglobin\"" \""increased\""| \""ventricular\"" \""extrasystoles\""|\""hallucinations\""|\""conjunctivitis\""|\""paralysis\""| \""qrs\"" \""complex\""|\""anxiety\""| \""conjunctival\"" \""disorder\""|\""coma\""|\""strabismus\""|\""thirst\""|\""para\""| \""sicca\"" \""syndrome\""| \""atrioventricular\"" \""dissociation\""|\""desquamation\""|\""crusting\""| \""abdominal\"" \""distension\""|\""blindness\""|\""hypotension\""|\""dermatitis\""| \""sinus\"" \""tachycardia\""| \""abdominal\"" \""distention\""| \""lacrimation\"" \""decreased\""|\""sicca\""| \""paralytic\"" \""ileus\""| \""urinary\"" \""hesitation\""|\""withdrawn\""| \""erectile\"" \""dysfunction\""|\""keratoconjunctivitis\""|\""anaphylaxis\""| \""psychiatric\"" \""disorders\""| \""altered\"" \""taste\""|\""somnolence\""|\""extrasystoles\""|\""ageusia\""| \""intraocular\"" \""pressure\"" \""increased\""| \""left\"" \""ventricular\"" \""failure\""|\""impotence\""|\""drowsiness\""|\""conjunctiva\""| \""delayed\"" \""gastric\"" \""emptying\""| \""gastrointestinal\"" \""sounds\"" \""abnormal\""| \""qt\"" \""prolonged\""| \""supraventricular\"" \""tachycardia\""|\""weakness\""|\""hypertonia\""| \""confusional\"" \""state\""|\""anhidrosis\""|\""myopia\""|\""dyspnoea\""| \""speech\"" \""impairment\"" \""nos\""| \""rash\"" \""maculo\"" \""papular\""|\""petechiae\""|\""tachypnea\""| \""acute\"" \""angle\"" \""closure\"" \""glaucoma\""| \""gastrooesophageal\"" \""reflux\"" \""disease\""|\""hypokalemia\""| \""left\"" \""heart\"" \""failure\""| \""myocardial\"" \""infarction\""| \""site\"" \""reaction\""| \""ventricular\"" \""fibrillation\""|\""fibrillation\""| \""maculopapular\"" \""rash\""| \""impaired\"" \""gastric\"" \""emptying\""|\""amnesia\""| \""labored\"" \""respirations\""| \""decreased\"" \""lacrimation\""|\""mydriasis\""|\""headache\""| \""dry\"" \""mouth\""|\""scab\""| \""cardiac\"" \""syncope\""| \""visual\"" \""acuity\"" \""reduced\""|\""tension\""| \""blurred\"" \""vision\""| \""bloated\"" \""feeling\""| \""labored\"" \""breathing\""| \""stridor\"" \""inspiratory\""| \""skin\"" \""exfoliation\""| \""memory\"" \""loss\""|\""syncope\""| \""rash\"" \""scarlatiniform\""|\""hyperpyrexia\""| \""cardiac\"" \""flutter\""|\""heartburn\""| \""bowel\"" \""sounds\"" \""decreased\""|\""blepharitis\""|\""tachycardia\""| \""excessive\"" \""thirst\""|\""confusion\""| \""rash\"" \""macular\""| \""taste\"" \""loss\""| \""respiratory\"" \""failure\""|\""hesitancy\""|\""dysmetria\""|\""disorientation\""| \""decreased\"" \""hemoglobin\""| \""atrial\"" \""fibrillation\""| \""urinary\"" \""retention\""| \""dry\"" \""skin\""|\""dehydration\""|\""hyponatraemia\""|\""dysgeusia\""|\""disorder\""| \""increased\"" \""intraocular\"" \""pressure\""| \""speech\"" \""disorder\""| \""feeling\"" \""abnormal\""|\""pain\""| \""anaphylactic\"" \""shock\""|\""hallucination\""| \""abdominal\"" \""pain\""| \""junctional\"" \""tachycardia\""| \""bun\"" \""increased\""| \""ventricular\"" \""flutter\""| \""scarlatiniform\"" \""rash\""|\""agitation\""| \""feeling\"" \""hot\""|\""hyponatremia\""| \""decreased\"" \""bowel\"" \""sounds\""|\""cyanosis\""|\""dysarthria\""| \""heat\"" \""intolerance\""|\""hyperglycemia\""|\""reflux\""| \""angle\"" \""closure\"" \""glaucoma\""| \""electrocardiogram\"" \""qt\"" \""prolonged\""| \""vision\"" \""blurred\""| \""blood\"" \""urea\"" \""increased\""|\""dizziness\""|\""arrhythmia\""|\""erythema\""|\""vomiting\""| \""difficulty\"" \""in\"" \""micturition\""|\""infarction\""|\""laryngospasm\""|\""hypoglycaemia\""|\""hypoglycemia\""| \""elevated\"" \""hemoglobin\""| \""skin\"" \""warm\""| \""ventricular\"" \""arrhythmia\""|\""dissociation\""| \""warm\"" \""skin\""| \""follicular\"" \""conjunctivitis\""|\""urticaria\""|\""fatigue\""| \""cardiac\"" \""fibrillation\""| \""decreased\"" \""sweating\""| \""decreased\"" \""visual\"" \""acuity\""|\""lethargy\""| \""acute\"" \""angle\"" \""closure\"" \""glaucoma\""| \""nodal\"" \""rhythm\""|\""borborygmi\""|\""hyperreflexia\""| \""respiratory\"" \""depression\""|\""diarrhea\""|\""leukocytosis\""| \""speech\"" \""disturbance\""|\""ataxia\""|\""cycloplegia\""|\""tachypnoea\""|\""eczema\""| \""supraventricular\"" \""extrasystoles\""|\""ileus\""| \""cardiac\"" \""arrest\""| \""ventricular\"" \""tachycardia\""|\""laryngitis\""|\""delirium\""|\""lactation\""|\""glaucoma\""|\""obstruction\""|\""hypohidrosis\""|\""parity\""|\""palpitations\""| \""temperature\"" \""intolerance\""|\""constipation\""|\""cyclophoria\""| \""acute\"" \""coronary\"" \""syndrome\""| \""arrhythmia\"" \""supraventricular\""|\""arrest\""|\""lesion\""|\""nausea\""| \""sweating\"" \""decreased\""|\""keratitis\""|\""dyskinesia\""| \""pulmonary\"" \""function\"" \""test\"" \""decreased\""|\""stridor\""|\""swelling\""|\""dysphagia\""| \""haemoglobin\"" \""decreased\""|\""diarrhoea\""| \""ileus\"" \""paralytic\""|\""clonus\""|\""insomnia\""| \""electrocardiogram\"" \""qrs\"" \""complex\""| \""nasal\"" \""congestion\""| \""nasal\"" \""dryness\""|\""sweating\""|\""rash\""| \""nodal\"" \""arrhythmia\""|\""irritability\""|\""hyperhidrosis\""| \""ventricular\"" \""failure\"")"");
    CoreMap doc = createDocument(""atropine we need to have many many words here but we don't sweating"");
    MultiPatternMatcher<CoreMap> multiPatternMatcher = TokenSequencePattern.getMultiPatternMatcher(p1, p2);
    List<String> expected = new ArrayList<String>();
    expected.add(""atropine we need to have many many words here but we don't sweating"");
    Iterator<String> expectedIter = expected.iterator();

    Iterable<SequenceMatchResult<CoreMap>> matches =
            multiPatternMatcher.findAllNonOverlappingMatchesPerPattern(doc.get(CoreAnnotations.TokensAnnotation.class));
    for (SequenceMatchResult<CoreMap> match:matches) {
     assertEquals(expectedIter.next(), match.group());
    }
    assertFalse(expectedIter.hasNext());
  }
",non-flaky,5
96036,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherPosNNP,"  @Test
  public void testTokenSequenceMatcherPosNNP() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test sequence with groups
    TokenSequencePattern p = TokenSequencePattern.compile( ""[ { tag:\""NNP\"" } ]+"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Mellitus"", m.group());

    p = TokenSequencePattern.compile( ""[ { tag:\""NNP\"" } ] [ /is|was/ ] []*? [ { tag:\""NNP\"" } ]+ "");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Mellitus was the first Bishop"", m.group());

    TokenSequencePattern nnpPattern = TokenSequencePattern.compile( ""[ { tag:\""NNP\"" } ]"" );
    Env env = TokenSequencePattern.getNewEnv();
    env.bind(""$NNP"", nnpPattern);
    p = TokenSequencePattern.compile(env, "" $NNP [ /is|was/ ] []*? $NNP+ [ \""of\"" ] $NNP+ "");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Mellitus was the first Bishop of London"", m.group());

    p = TokenSequencePattern.compile(env, "" ($NNP) /is|was/ []*? ($NNP)+ \""of\"" ($NNP)+ "");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""Mellitus was the first Bishop of London"", m.group());
    assertEquals(""Mellitus"", m.group(1));
    assertEquals(""Bishop"", m.group(2));
    assertEquals(""London"", m.group(3));


    nnpPattern = TokenSequencePattern.compile( "" ( [ { tag:\""NNP\"" } ] )"" );
    env.bind(""$NNP"", nnpPattern);
    p = TokenSequencePattern.compile(env, "" $NNP /is|was/ []*? $NNP+ \""of\"" $NNP+ "");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""Mellitus was the first Bishop of London"", m.group());
    assertEquals(""Mellitus"", m.group(1));
    assertEquals(""Bishop"", m.group(2));
    assertEquals(""London"", m.group(3));


    // Same as above but without extra ""{}""
    nnpPattern = TokenSequencePattern.compile( "" ( [ tag:\""NNP\"" ] )"" );
    env.bind(""$NNP"", nnpPattern);
    p = TokenSequencePattern.compile(env, "" $NNP /is|was/ []*? $NNP+ \""of\"" $NNP+ "");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""Mellitus was the first Bishop of London"", m.group());
    assertEquals(""Mellitus"", m.group(1));
    assertEquals(""Bishop"", m.group(2));
    assertEquals(""London"", m.group(3));

    // Same as above but using ""pos""
    nnpPattern = TokenSequencePattern.compile( "" ( [ pos:\""NNP\"" ] )"" );
    env.bind(""$NNP"", nnpPattern);
    p = TokenSequencePattern.compile(env, "" $NNP /is|was/ []*? $NNP+ \""of\"" $NNP+ "");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""Mellitus was the first Bishop of London"", m.group());
    assertEquals(""Mellitus"", m.group(1));
    assertEquals(""Bishop"", m.group(2));
    assertEquals(""London"", m.group(3));
  }
",non-flaky,5
96037,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherNumber,"  @Test
  public void testTokenSequenceMatcherNumber() throws IOException {
    CoreMap doc = createDocument(""It happened on January 3, 2002"");

    // Test sequence with groups
    TokenSequencePattern p = TokenSequencePattern.compile( ""[ { word::IS_NUM } ]+"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""3"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""2002"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""[ { word>=2002 } ]+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""2002"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""[ { word>2002 } ]+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertFalse(match);

    // Check no {} with or
    p = TokenSequencePattern.compile( ""[ word > 2002 | word==2002 ]+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""2002"", m.group());
    match = m.find();
    assertFalse(match);

    // Check no {} with and
    p = TokenSequencePattern.compile( ""[ word>2002 & word==2002 ]+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""[ { word>2000 } ]+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""2002"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""[ { word<=2002 } ]+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""3"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""2002"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""[ { word<2002 } ]+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""3"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""[ { word==2002 } ]+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""2002"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""[ { ner:DATE } ]+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""January 3, 2002"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""[ { ner::NOT_NIL } ]+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""January 3, 2002"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""[ { ner::IS_NIL } ]+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""It happened on"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""[ {{ word=~/2002/ }} ]+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""2002"", m.group());
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96038,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherNested,"  @Test
  public void testTokenSequenceMatcherNested() throws IOException {
    CoreMap doc = createDocument(""A A A B B B B B B C C"");

    // Test sequence with groups
    TokenSequencePattern p = TokenSequencePattern.compile( ""( /B/+ )+"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""B B B B B B"", m.group());
    assertEquals(""B B B B B B"", m.group(1));
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96039,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherAAs,"  @Test
  public void testTokenSequenceMatcherAAs() throws IOException {
    StringBuilder s = new StringBuilder();
 //   Timing timing = new Timing();
    for (int i = 1; i <= 10; i++) {
      s.append(""A "");
      CoreMap doc = createDocument(s.toString());
      TokenSequencePattern p = TokenSequencePattern.compile(""(A?)"" + ""{"" + i + ""} "" + ""A"" + ""{"" + i + ""}"");
//      TokenSequencePattern p = TokenSequencePattern.compile( ""(A?)"" + ""{"" + i + ""}"");
      TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
//      timing.start();
      boolean match = m.matches();
      assertTrue(match);
//      timing.stop(""matched: "" + match + "" "" + i);
    }
  }
",non-flaky,5
96040,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceFindsWildcard,"  @Test
  public void testTokenSequenceFindsWildcard() throws IOException {
    CoreMap doc = createDocument(""word1 word2"");

    // Test sequence with groups
    TokenSequencePattern p = TokenSequencePattern.compile( ""[]{2}|[]"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""word1 word2"", m.group());
    match = m.find();
    assertFalse(match);

    // Reverse order
    p = TokenSequencePattern.compile( ""[]|[]{2}"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""word1 word2"", m.group());
    match = m.find();
    assertFalse(match);

    // Using {1,2}
    p = TokenSequencePattern.compile( ""[]{2}"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""word1 word2"", m.group());
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96041,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatchesWildcard,"  @Test
  public void testTokenSequenceMatchesWildcard() throws IOException {
    CoreMap doc = createDocument(""word1 word2"");

    // Test sequence with groups
    TokenSequencePattern p = TokenSequencePattern.compile( ""[]{2}|[]"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean matches = m.matches();
    assertTrue(matches);

    // Reverse order
    p = TokenSequencePattern.compile( ""[]|[]{2}"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    matches = m.matches();
    assertTrue(matches);

    // Using {1,2}
    p = TokenSequencePattern.compile( ""[]{1,2}"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    matches = m.matches();
    assertTrue(matches);
  }
",non-flaky,5
96042,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherABs,"  @Test
  public void testTokenSequenceMatcherABs() throws IOException {
    CoreMap doc = createDocument(""A A A A A A A B A A B A C A E A A A A A A A A A A A B A A A"");

    // Test sequence with groups
    TokenSequencePattern p = TokenSequencePattern.compile( ""/A/+ B"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""A A A A A A A B"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""A A B"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""A A A A A A A A A A A B"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""(/A/+ B)+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""A A A A A A A B A A B"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""A A A A A A A A A A A B"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""( A+ ( /B/+ )? )*"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""A A A A A A A B A A B A"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""A"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""A A A A A A A A A A A B A A A"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""(/A/+ /B/+ )+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""A A A A A A A B A A B"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""A A A A A A A A A A A B"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""(/A/+ /C/? /A/* )+"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""A A A A A A A"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""A A"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""A C A"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""A A A A A A A A A A A"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""A A A"", m.group());
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96043,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherMultiNodePattern,"  @Test
  public void testTokenSequenceMatcherMultiNodePattern() throws IOException {
    CoreMap doc = createDocument(""blah four-years blah blah four - years"");

    // Test sequence with groups
    CoreMapNodePattern nodePattern  = CoreMapNodePattern.valueOf(""four\\s*-?\\s*years"");
    SequencePattern.MultiNodePatternExpr expr = new SequencePattern.MultiNodePatternExpr(
            new MultiCoreMapNodePattern(nodePattern));
    TokenSequencePattern p = TokenSequencePattern.compile(expr);
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""four-years"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""four - years"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile(""(?m) /four\\s*-?\\s*years/"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""four-years"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""four - years"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile(""(?m){2,3} /four\\s*-?\\s*years/"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""four - years"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""(?m){1,2} /four\\s*-?\\s*years/"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""four-years"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile(""(?m){1,3} /four\\s*-?\\s*years/ ==> &annotate( { ner=YEAR } )"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""four-years"", m.group());
    p.getAction().apply(m, 0);
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""four - years"", m.group());
    SequenceMatchResult<CoreMap> res = p.getAction().apply(m, 0);
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile( ""[ { ner:YEAR } ]+"");
    m = p.getMatcher(res.elements());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""four-years"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""four - years"", m.group());
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96044,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherMultiNodePattern2,"  @Test
  public void testTokenSequenceMatcherMultiNodePattern2() throws IOException {
    CoreMap doc = createDocument(""Replace the lamp with model wss.32dc55c3e945384dbc5e533ab711fd24"");

    // Greedy
    TokenSequencePattern p = TokenSequencePattern.compile(""/model/ ((?m){1,4}/\\w+\\.\\w+/)"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""model wss.32dc55c3e945384dbc5e533ab711fd24"", m.group());
    assertEquals(""wss.32dc55c3e945384dbc5e533ab711fd24"", m.group(1));
    match = m.find();
    assertFalse(match);

    // Reluctant
    p = TokenSequencePattern.compile(""/model/ ((?m){1,4}?/\\w+\\.\\w+/)"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""model wss.32"", m.group());
    assertEquals(""wss.32"", m.group(1));
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
96045,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherBackRef,"  @Test
  public void testTokenSequenceMatcherBackRef() throws IOException {
    CoreMap doc = createDocument(""A A A A A A A B A A B A C A E A A A A A A A A A A A B A A A"");

    // Test sequence with groups
    TokenSequencePattern p = TokenSequencePattern.compile( ""(/A/+) B \\1"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""A A B A A"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""A A A B A A A"", m.group());
    match = m.find();
    assertFalse(match);

  }
",non-flaky,5
96046,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testMultiPatternMatcher,"  @Test
  public void testMultiPatternMatcher() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test simple sequence
    TokenSequencePattern p1 = TokenSequencePattern.compile(""/Archbishop/ /of/ /Canterbury/"");
    p1.setPriority(1);
    TokenSequencePattern p2 = TokenSequencePattern.compile(""/[a-zA-Z]+/{1,2}  /of/ /[a-zA-Z]+/+"");
    MultiPatternMatcher<CoreMap> m = new MultiPatternMatcher<CoreMap>(p2,p1);
    List<SequenceMatchResult<CoreMap>> matched = m.findNonOverlapping(doc.get(CoreAnnotations.TokensAnnotation.class));
    assertEquals(4, matched.size());
    assertEquals(""first Bishop of London"", matched.get(0).group());
    assertEquals(""Archbishop of Canterbury"", matched.get(1).group());
    assertEquals(""a member of the Gregorian mission sent to England to convert the"", matched.get(2).group());
    assertEquals(""as Bishop of London in"", matched.get(3).group());
  }
",non-flaky,5
96047,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testStringPatternMatchCaseInsensitive,"  @Test
  public void testStringPatternMatchCaseInsensitive() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test simple sequence
    Env env = TokenSequencePattern.getNewEnv();
    env.setDefaultStringPatternFlags(Pattern.CASE_INSENSITIVE);
    TokenSequencePattern p = TokenSequencePattern.compile(env, ""/archbishop/ /of/ /canterbury/"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    assertTrue(m.find());
    assertEquals(""Archbishop of Canterbury"", m.group());
    assertFalse(m.find());

    p = TokenSequencePattern.compile(env, ""/ARCHBISHOP/ /OF/ /CANTERBURY/"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    assertTrue(m.find());
    assertEquals(""Archbishop of Canterbury"", m.group());
    assertFalse(m.find());
  }
",non-flaky,5
96048,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testStringMatchCaseInsensitive,"  @Test
  public void testStringMatchCaseInsensitive() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test simple sequence
    Env env = TokenSequencePattern.getNewEnv();
    env.setDefaultStringMatchFlags(NodePattern.CASE_INSENSITIVE);
    TokenSequencePattern p = TokenSequencePattern.compile(env, ""archbishop of canterbury"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    assertTrue(m.find());
    assertEquals(""Archbishop of Canterbury"", m.group());
    assertFalse(m.find());

    p = TokenSequencePattern.compile(env, ""ARCHBISHOP OF CANTERBURY"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    assertTrue(m.find());
    assertEquals(""Archbishop of Canterbury"", m.group());
    assertFalse(m.find());
  }
",non-flaky,5
96049,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testCompile,"  @Test
  public void testCompile() {
    String s = ""(?$se \""matching\"" \""this\""|\""don't\"")"";
    CoreMap doc = createDocument(""does this do matching this"");
    TokenSequencePattern p = TokenSequencePattern.compile(s);
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    //assertEquals(m.group(), ""matching this"");
  }
",non-flaky,5
96050,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testBindingCompile,"  @Test
  public void testBindingCompile(){
    Env env = TokenSequencePattern.getNewEnv();
    env.bind(""wordname"",CoreAnnotations.TextAnnotation.class);
    String s = ""[wordname:\""name\""]{1,2}"";
    TokenSequencePattern p = TokenSequencePattern.compile(env, s);
  }
",non-flaky,5
96051,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testNoBindingCompile,"//  @Test
//  public void testNoBindingCompile(){
//    Env env = TokenSequencePattern.getNewEnv();
//    String s = ""["" + CoreAnnotations.TextAnnotation.class.getName()+"":\""name\""]{1,2}"";
//    TokenSequencePattern p = TokenSequencePattern.compile(env, s);
//  }
",non-flaky,5
96052,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testCaseInsensitive1,"  @Test
  public void testCaseInsensitive1(){
    Env env = TokenSequencePattern.getNewEnv();
    env.setDefaultStringPatternFlags(Pattern.CASE_INSENSITIVE);
    env.setDefaultStringMatchFlags(NodePattern.CASE_INSENSITIVE);
    String s = ""for /President/"";
    CoreMap doc = createDocument(""for president"");
    TokenSequencePattern p = TokenSequencePattern.compile(env, s);
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
  }
",non-flaky,5
96053,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testCaseInsensitive2,"  @Test
  public void testCaseInsensitive2(){
    Env env = TokenSequencePattern.getNewEnv();
    env.setDefaultStringPatternFlags(Pattern.CASE_INSENSITIVE);
    env.setDefaultStringMatchFlags(NodePattern.CASE_INSENSITIVE);

    String s = ""for president"";
    CoreMap doc = createDocument(""for President"");

    TokenSequencePattern p = TokenSequencePattern.compile(env, s);
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
  }
",non-flaky,5
96054,stanfordnlp_CoreNLP,TSVSentenceIteratorITest.testOnlyGloss,"  // @Test
  public void testOnlyGloss() {
    List<List<String>> entries = Collections.singletonList(
            Arrays.asList(""124"", ""docid1"", ""1"", ""This is a test document.""));

    TSVSentenceIterator it = new TSVSentenceIterator(entries.iterator(),
            Arrays.asList(SentenceField.ID, SentenceField.DOC_ID, SentenceField.SENTENCE_INDEX, SentenceField.GLOSS));
    Sentence sentence = it.next();
    Assert.assertEquals(1, sentence.sentenceIndex());
    Assert.assertEquals(""This is a test document.""  , sentence.text());
    Assert.assertEquals(""docid1"", sentence.asCoreMap().get(CoreAnnotations.DocIDAnnotation.class));
    Assert.assertEquals(""124"", sentence.asCoreMap().get(CoreAnnotations.SentenceIDAnnotation.class));
  }
",non-flaky,5
96055,stanfordnlp_CoreNLP,TSVSentenceIteratorITest.testFullTokens,"  @Test
  public void testFullTokens() {
    List<List<String>> entries = Collections.singletonList(
            Arrays.asList(
                    ""3424"",
                    ""d2-s1-a1"",
                    ""0"",
                    ""{Chess,is,not,a,predominantly,physical,sport,\""\"",\""\"",yet,neither,are,shooting,and,curling,-LRB-,which,\""\"",\""\"",in,fact,\""\"",\""\"",has,been,nicknamed,``,chess,on,ice,'',5,),.}"",
                    ""{chess,be,not,a,predominantly,physical,sport,\""\"",\""\"",yet,neither,be,shooting,and,curling,-lrb-,which,\""\"",\""\"",in,fact,\""\"",\""\"",have,be,nickname,``,chess,on,ice,'',5,),.}"",
                    ""{NN,VBZ,RB,DT,RB,JJ,NN,\""\"",\""\"",RB,DT,VBP,JJ,CC,NN,-LRB-,WDT,\""\"",\""\"",IN,NN,\""\"",\""\"",VBZ,VBN,VBN,``,NN,IN,NN,'',LS,-RRB-,.}"",
                    ""{O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,NUMBER,O,O}"",
                    ""{0,6,9,13,15,29,38,43,45,49,57,61,70,74,82,83,88,90,93,97,99,103,108,118,119,125,128,131,132,133,134}"",
                    ""{5,8,12,14,28,37,43,44,48,56,60,69,73,81,83,88,89,92,97,98,102,107,117,119,124,127,131,132,133,134,135}""	,
                    //""[{\""\""dependent\""\"": 7, \""\""dep\""\"": \""\""ROOT\""\"", \""\""governorGloss\""\"": \""\""ROOT\""\"", \""\""governor\""\"": 0, \""\""dependentGloss\""\"": \""\""sport\""\""}, {\""\""dependent\""\"": 1, \""\""dep\""\"": \""\""nsubj\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""Chess\""\""}, {\""\""dependent\""\"": 2, \""\""dep\""\"": \""\""cop\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""is\""\""}, {\""\""dependent\""\"": 3, \""\""dep\""\"": \""\""neg\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""not\""\""}, {\""\""dependent\""\"": 4, \""\""dep\""\"": \""\""det\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""a\""\""}, {\""\""dependent\""\"": 5, \""\""dep\""\"": \""\""advmod\""\"", \""\""governorGloss\""\"": \""\""physical\""\"", \""\""governor\""\"": 6, \""\""dependentGloss\""\"": \""\""predominantly\""\""}, {\""\""dependent\""\"": 6, \""\""dep\""\"": \""\""amod\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""physical\""\""}, {\""\""dependent\""\"": 9, \""\""dep\""\"": \""\""advmod\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""yet\""\""}, {\""\""dependent\""\"": 10, \""\""dep\""\"": \""\""nsubj\""\"", \""\""governorGloss\""\"": \""\""shooting\""\"", \""\""governor\""\"": 12, \""\""dependentGloss\""\"": \""\""neither\""\""}, {\""\""dependent\""\"": 11, \""\""dep\""\"": \""\""cop\""\"", \""\""governorGloss\""\"": \""\""shooting\""\"", \""\""governor\""\"": 12, \""\""dependentGloss\""\"": \""\""are\""\""}, {\""\""dependent\""\"": 12, \""\""dep\""\"": \""\""parataxis\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""shooting\""\""}, {\""\""dependent\""\"": 13, \""\""dep\""\"": \""\""cc\""\"", \""\""governorGloss\""\"": \""\""shooting\""\"", \""\""governor\""\"": 12, \""\""dependentGloss\""\"": \""\""and\""\""}, {\""\""dependent\""\"": 14, \""\""dep\""\"": \""\""parataxis\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""curling\""\""}, {\""\""dependent\""\"": 14, \""\""dep\""\"": \""\""conj:and\""\"", \""\""governorGloss\""\"": \""\""shooting\""\"", \""\""governor\""\"": 12, \""\""dependentGloss\""\"": \""\""curling\""\""}, {\""\""dependent\""\"": 16, \""\""dep\""\"": \""\""nsubjpass\""\"", \""\""governorGloss\""\"": \""\""nicknamed\""\"", \""\""governor\""\"": 23, \""\""dependentGloss\""\"": \""\""which\""\""}, {\""\""dependent\""\"": 18, \""\""dep\""\"": \""\""case\""\"", \""\""governorGloss\""\"": \""\""fact\""\"", \""\""governor\""\"": 19, \""\""dependentGloss\""\"": \""\""in\""\""}, {\""\""dependent\""\"": 19, \""\""dep\""\"": \""\""nmod:in\""\"", \""\""governorGloss\""\"": \""\""nicknamed\""\"", \""\""governor\""\"": 23, \""\""dependentGloss\""\"": \""\""fact\""\""}, {\""\""dependent\""\"": 21, \""\""dep\""\"": \""\""aux\""\"", \""\""governorGloss\""\"": \""\""nicknamed\""\"", \""\""governor\""\"": 23, \""\""dependentGloss\""\"": \""\""has\""\""}, {\""\""dependent\""\"": 22, \""\""dep\""\"": \""\""auxpass\""\"", \""\""governorGloss\""\"": \""\""nicknamed\""\"", \""\""governor\""\"": 23, \""\""dependentGloss\""\"": \""\""been\""\""}, {\""\""dependent\""\"": 23, \""\""dep\""\"": \""\""dep\""\"", \""\""governorGloss\""\"": \""\""shooting\""\"", \""\""governor\""\"": 12, \""\""dependentGloss\""\"": \""\""nicknamed\""\""}, {\""\""dependent\""\"": 25, \""\""dep\""\"": \""\""dobj\""\"", \""\""governorGloss\""\"": \""\""nicknamed\""\"", \""\""governor\""\"": 23, \""\""dependentGloss\""\"": \""\""chess\""\""}, {\""\""dependent\""\"": 26, \""\""dep\""\"": \""\""case\""\"", \""\""governorGloss\""\"": \""\""ice\""\"", \""\""governor\""\"": 27, \""\""dependentGloss\""\"": \""\""on\""\""}, {\""\""dependent\""\"": 27, \""\""dep\""\"": \""\""nmod:on\""\"", \""\""governorGloss\""\"": \""\""chess\""\"", \""\""governor\""\"": 25, \""\""dependentGloss\""\"": \""\""ice\""\""}, {\""\""dependent\""\"": 29, \""\""dep\""\"": \""\""amod\""\"", \""\""governorGloss\""\"": \""\""chess\""\"", \""\""governor\""\"": 25, \""\""dependentGloss\""\"": \""\""5\""\""}]"",
                    ""Chess is not a predominantly physical sport, yet neither are shooting and curling (which, in fact, has been nicknamed âchess on iceâ5).""
            ));

    TSVSentenceIterator it = new TSVSentenceIterator(entries.iterator(), Arrays.asList(
            SentenceField.ID,
            SentenceField.DOC_ID,
            SentenceField.SENTENCE_INDEX,
            SentenceField.WORDS,
            SentenceField.LEMMAS,
            SentenceField.POS_TAGS,
            SentenceField.NER_TAGS,
            SentenceField.DOC_CHAR_BEGIN,
            SentenceField.DOC_CHAR_END,
            SentenceField.GLOSS
    ));

    Sentence sentence = it.next();
    Assert.assertEquals(""3424"", sentence.sentenceid().orElse(""-1""));
    Assert.assertEquals(""d2-s1-a1"", sentence.document.docid().orElse(""???""));
    Assert.assertEquals(0, sentence.sentenceIndex());
    Assert.assertEquals(""Chess is not a predominantly physical sport, yet neither are shooting and curling (which, in fact, has been nicknamed âchess on iceâ5)."" , sentence.text());
    Assert.assertArrayEquals(new String[]{
            ""Chess"",""is"",""not"",""a"",""predominantly"",""physical"",""sport"","","",""yet"",""neither"",""are"",""shooting"",""and"",""curling"",""-LRB-"",""which"","","",""in"",""fact"","","",""has"",""been"",""nicknamed"",""``"",""chess"",""on"",""ice"",""''"",""5"","")"","".""
    }, sentence.words().toArray());
    Assert.assertArrayEquals(new String[]{
            ""chess"",""be"",""not"",""a"",""predominantly"",""physical"",""sport"","","",""yet"",""neither"",""be"",""shooting"",""and"",""curling"",""-lrb-"",""which"","","",""in"",""fact"","","",""have"",""be"",""nickname"",""``"",""chess"",""on"",""ice"",""''"",""5"","")"","".""
    }, sentence.lemmas().toArray());
    Assert.assertArrayEquals(new String[]{
            ""NN"",""VBZ"",""RB"",""DT"",""RB"",""JJ"",""NN"","","",""RB"",""DT"",""VBP"",""JJ"",""CC"",""NN"",""-LRB-"",""WDT"","","",""IN"",""NN"","","",""VBZ"",""VBN"",""VBN"",""``"",""NN"",""IN"",""NN"",""''"",""LS"",""-RRB-"","".""
    }, sentence.posTags().toArray());
    Assert.assertArrayEquals(new String[]{
            ""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""O"",""NUMBER"",""O"",""O""
    }, sentence.nerTags().toArray());
    Assert.assertArrayEquals(new Integer[]{
            0,6,9,13,15,29,38,43,45,49,57,61,70,74,82,83,88,90,93,97,99,103,108,118,119,125,128,131,132,133,134
    }, sentence.characterOffsetBegin().toArray());
    Assert.assertArrayEquals(new Integer[]{
            5,8,12,14,28,37,43,44,48,56,60,69,73,81,83,88,89,92,97,98,102,107,117,119,124,127,131,132,133,134,135
    }, sentence.characterOffsetEnd().toArray());
  }
",non-flaky,5
96056,stanfordnlp_CoreNLP,TSVSentenceIteratorITest.testParseArray,"  @Test
  public void testParseArray() {
    String in = ""{Chess,is,not,a,predominantly,physical,sport,\""\"",\""\"",yet,neither,are,shooting,and,curling,-LRB-,which,\""\"",\""\"",in,fact,\""\"",\""\"",has,been,nicknamed,``,chess,on,ice,'',5,-RRB-,.}"";
    String[] out = {""Chess"",""is"",""not"",""a"",""predominantly"",""physical"",""sport"","","",""yet"",""neither"",""are"",""shooting"",""and"",""curling"",""-LRB-"",""which"","","",""in"",""fact"","","",""has"",""been"",""nicknamed"",""``"",""chess"",""on"",""ice"",""''"",""5"",""-RRB-"","".""};

    // System.err.println(in);
    // System.err.println(Arrays.asList(out));
    // System.err.println(Arrays.asList(TSVUtils.parseArray(in).toArray()));
    Assert.assertArrayEquals(out, TSVUtils.parseArray(in).toArray());

    String in2 = ""{Chess,is,not,a,predominantly,physical,sport,\""\"",\""\"",yet,neither,are,shooting,and,curling,(,which,\""\"",\""\"",in,fact,\""\"",\""\"",has,been,nicknamed,``,chess,on,ice,'',5,),.}"";
    String[] out2 = {""Chess"",""is"",""not"",""a"",""predominantly"",""physical"",""sport"","","",""yet"",""neither"",""are"",""shooting"",""and"",""curling"",""("",""which"","","",""in"",""fact"","","",""has"",""been"",""nicknamed"",""``"",""chess"",""on"",""ice"",""''"",""5"","")"","".""};

    Assert.assertArrayEquals(out2, TSVUtils.parseArray(in2).toArray());
  }
",non-flaky,5
96057,stanfordnlp_CoreNLP,TSVSentenceIteratorITest.testParseTrees,"  @Test
  public void testParseTrees() {
    List<List<String>> entries = Collections.singletonList(
            Arrays.asList(
                    ""3424"",
                    ""d2-s1-a1"",
                    ""0"",
                    ""{Chess,is,not,a,predominantly,physical,sport,\""\"",\""\"",yet,neither,are,shooting,and,curling,-LRB-,which,\""\"",\""\"",in,fact,\""\"",\""\"",has,been,nicknamed,``,chess,on,ice,'',5,-RRB-,.}"",
                    ""{chess,be,not,a,predominantly,physical,sport,\""\"",\""\"",yet,neither,be,shooting,and,curling,-lrb-,which,\""\"",\""\"",in,fact,\""\"",\""\"",have,be,nickname,``,chess,on,ice,'',5,-rrb-,.}"",
                    ""{NN,VBZ,RB,DT,RB,JJ,NN,\""\"",\""\"",RB,DT,VBP,JJ,CC,NN,-LRB-,WDT,\""\"",\""\"",IN,NN,\""\"",\""\"",VBZ,VBN,VBN,``,NN,IN,NN,'',LS,-RRB-,.}"",
                    ""{O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,NUMBER,O,O}"",
                    ""{0,6,9,13,15,29,38,43,45,49,57,61,70,74,82,83,88,90,93,97,99,103,108,118,119,125,128,131,132,133,134}"",
                    ""{5,8,12,14,28,37,43,44,48,56,60,69,73,81,83,88,89,92,97,98,102,107,117,119,124,127,131,132,133,134,135}""	,
                    ""[{\""\""dependent\""\"": 7, \""\""dep\""\"": \""\""ROOT\""\"", \""\""governorGloss\""\"": \""\""ROOT\""\"", \""\""governor\""\"": 0, \""\""dependentGloss\""\"": \""\""sport\""\""}, {\""\""dependent\""\"": 1, \""\""dep\""\"": \""\""nsubj\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""Chess\""\""}, {\""\""dependent\""\"": 2, \""\""dep\""\"": \""\""cop\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""is\""\""}, {\""\""dependent\""\"": 3, \""\""dep\""\"": \""\""neg\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""not\""\""}, {\""\""dependent\""\"": 4, \""\""dep\""\"": \""\""det\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""a\""\""}, {\""\""dependent\""\"": 5, \""\""dep\""\"": \""\""advmod\""\"", \""\""governorGloss\""\"": \""\""physical\""\"", \""\""governor\""\"": 6, \""\""dependentGloss\""\"": \""\""predominantly\""\""}, {\""\""dependent\""\"": 6, \""\""dep\""\"": \""\""amod\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""physical\""\""}, {\""\""dependent\""\"": 9, \""\""dep\""\"": \""\""advmod\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""yet\""\""}, {\""\""dependent\""\"": 10, \""\""dep\""\"": \""\""nsubj\""\"", \""\""governorGloss\""\"": \""\""shooting\""\"", \""\""governor\""\"": 12, \""\""dependentGloss\""\"": \""\""neither\""\""}, {\""\""dependent\""\"": 11, \""\""dep\""\"": \""\""cop\""\"", \""\""governorGloss\""\"": \""\""shooting\""\"", \""\""governor\""\"": 12, \""\""dependentGloss\""\"": \""\""are\""\""}, {\""\""dependent\""\"": 12, \""\""dep\""\"": \""\""parataxis\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""shooting\""\""}, {\""\""dependent\""\"": 13, \""\""dep\""\"": \""\""cc\""\"", \""\""governorGloss\""\"": \""\""shooting\""\"", \""\""governor\""\"": 12, \""\""dependentGloss\""\"": \""\""and\""\""}, {\""\""dependent\""\"": 14, \""\""dep\""\"": \""\""parataxis\""\"", \""\""governorGloss\""\"": \""\""sport\""\"", \""\""governor\""\"": 7, \""\""dependentGloss\""\"": \""\""curling\""\""}, {\""\""dependent\""\"": 14, \""\""dep\""\"": \""\""conj:and\""\"", \""\""governorGloss\""\"": \""\""shooting\""\"", \""\""governor\""\"": 12, \""\""dependentGloss\""\"": \""\""curling\""\""}, {\""\""dependent\""\"": 16, \""\""dep\""\"": \""\""nsubjpass\""\"", \""\""governorGloss\""\"": \""\""nicknamed\""\"", \""\""governor\""\"": 23, \""\""dependentGloss\""\"": \""\""which\""\""}, {\""\""dependent\""\"": 18, \""\""dep\""\"": \""\""case\""\"", \""\""governorGloss\""\"": \""\""fact\""\"", \""\""governor\""\"": 19, \""\""dependentGloss\""\"": \""\""in\""\""}, {\""\""dependent\""\"": 19, \""\""dep\""\"": \""\""nmod:in\""\"", \""\""governorGloss\""\"": \""\""nicknamed\""\"", \""\""governor\""\"": 23, \""\""dependentGloss\""\"": \""\""fact\""\""}, {\""\""dependent\""\"": 21, \""\""dep\""\"": \""\""aux\""\"", \""\""governorGloss\""\"": \""\""nicknamed\""\"", \""\""governor\""\"": 23, \""\""dependentGloss\""\"": \""\""has\""\""}, {\""\""dependent\""\"": 22, \""\""dep\""\"": \""\""auxpass\""\"", \""\""governorGloss\""\"": \""\""nicknamed\""\"", \""\""governor\""\"": 23, \""\""dependentGloss\""\"": \""\""been\""\""}, {\""\""dependent\""\"": 23, \""\""dep\""\"": \""\""dep\""\"", \""\""governorGloss\""\"": \""\""shooting\""\"", \""\""governor\""\"": 12, \""\""dependentGloss\""\"": \""\""nicknamed\""\""}, {\""\""dependent\""\"": 25, \""\""dep\""\"": \""\""dobj\""\"", \""\""governorGloss\""\"": \""\""nicknamed\""\"", \""\""governor\""\"": 23, \""\""dependentGloss\""\"": \""\""chess\""\""}, {\""\""dependent\""\"": 26, \""\""dep\""\"": \""\""case\""\"", \""\""governorGloss\""\"": \""\""ice\""\"", \""\""governor\""\"": 27, \""\""dependentGloss\""\"": \""\""on\""\""}, {\""\""dependent\""\"": 27, \""\""dep\""\"": \""\""nmod:on\""\"", \""\""governorGloss\""\"": \""\""chess\""\"", \""\""governor\""\"": 25, \""\""dependentGloss\""\"": \""\""ice\""\""}, {\""\""dependent\""\"": 29, \""\""dep\""\"": \""\""amod\""\"", \""\""governorGloss\""\"": \""\""chess\""\"", \""\""governor\""\"": 25, \""\""dependentGloss\""\"": \""\""5\""\""}]"",
                    ""Chess is not a predominantly physical sport, yet neither are shooting and curling (which, in fact, has been nicknamed âchess on iceâ5)."")
    );

    TSVSentenceIterator it = new TSVSentenceIterator(entries.iterator(), Arrays.asList(
            SentenceField.ID,
            SentenceField.DOC_ID,
            SentenceField.SENTENCE_INDEX,
            SentenceField.WORDS,
            SentenceField.LEMMAS,
            SentenceField.POS_TAGS,
            SentenceField.NER_TAGS,
            SentenceField.DOC_CHAR_BEGIN,
            SentenceField.DOC_CHAR_END,
            SentenceField.DEPENDENCIES_BASIC,
            SentenceField.GLOSS
    ));
    Sentence sentence = it.next();
    sentence.dependencyGraph();
    sentence.openieTriples();
  }
",non-flaky,5
96058,stanfordnlp_CoreNLP,MorphaAnnotatorITest.testMorphaAnnotator,"  @Test
  public void testMorphaAnnotator() {
    Annotation document = new Annotation(text);
    fullPipeline.annotate(document);
    checkResult(document.get(CoreAnnotations.TokensAnnotation.class));
  }
",non-flaky,5
96059,stanfordnlp_CoreNLP,MorphaAnnotatorITest.testSentencesAnnotation,"  @Test
  public void testSentencesAnnotation() {
    List<CoreLabel> words = getTestWords();

    CoreMap sentence = new ArrayCoreMap();
    sentence.set(CoreAnnotations.TokensAnnotation.class, words);
    List<CoreMap> sentences = new ArrayList<>();
    sentences.add(sentence);
    Annotation document = new Annotation(text);
    document.set(CoreAnnotations.SentencesAnnotation.class, sentences);

    shortPipeline.annotate(document);
    checkResult(words);
  }
",non-flaky,5
96060,stanfordnlp_CoreNLP,CoNLLUOutputterITest.testInvalidOutputter,"    @Test
    public void testInvalidOutputter() throws IOException {
        try {
            Annotation ann = new Annotation(""CoNLL-U is neat. Better than XML."");
            pipeline.annotate(ann);
            String actual = new CoNLLUOutputter(""this should fail"").print(ann);
            throw new AssertionError(""This should have failed"");
        } catch (IllegalArgumentException e) {
            // yay
        }
    }
",non-flaky,5
96061,stanfordnlp_CoreNLP,CoNLLUOutputterITest.testSimpleSentence,"    @Test
    public void testSimpleSentence() throws IOException {
        Annotation ann = new Annotation(""CoNLL-U is neat. Better than XML."");
        pipeline.annotate(ann);
        String actual = new CoNLLUOutputter(""enhanced"").print(ann);
        String expected = ""1\tCoNLL\tconll\tNOUN\tNN\tNumber=Sing\t3\tcompound\t3:compound\t_\n"" +
            ""2\t-\t-\tPUNCT\tHYPH\t_\t3\tpunct\t3:punct\t_\n"" +
            ""3\tU\tu\tNOUN\tNN\tNumber=Sing\t5\tnsubj\t5:nsubj\t_\n"" +
            ""4\tis\tbe\tVERB\tVBZ\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t5\tcop\t5:cop\t_\n"" +
            ""5\tneat\tneat\tADJ\tJJ\tDegree=Pos\t0\troot\t0:root\t_\n"" +
            ""6\t.\t.\tPUNCT\t.\t_\t5\tpunct\t5:punct\t_\n"" +
            ""\n"" +
            ""1\tBetter\tbetter\tADJ\tJJR\tDegree=Cmp\t0\troot\t0:root\t_\n"" +
            ""2\tthan\tthan\tADP\tIN\t_\t3\tcase\t3:case\t_\n"" +
            ""3\tXML\txml\tNOUN\tNN\tNumber=Sing\t1\tobl\t1:obl:than\t_\n"" +
            ""4\t.\t.\tPUNCT\t.\t_\t1\tpunct\t1:punct\t_\n\n"";
        assertEquals(expected, actual);
    }
",non-flaky,5
96062,stanfordnlp_CoreNLP,ChineseSerializationITest.testChineseSerialization,"  @Test
  public void testChineseSerialization() {

    try {
      AnnotationSerializer serializer = new ProtobufAnnotationSerializer();
      // write Chinese doc
      String sampleChineseDocument = ""å·´æåÂ·å¥¥å·´é©¬æ¯ç¾å½æ»ç»ãä»å¨2008å¹´å½é"";
      Properties chineseProperties = StringUtils.argsToProperties(""-props"",
              ""StanfordCoreNLP-chinese.properties"");
      Annotation doc = new StanfordCoreNLP(chineseProperties).process(sampleChineseDocument);

      // fake having a section in the annotation so the test passes.
      // todo [2017] clean up the status of sections.
      doc.set(CoreAnnotations.SectionsAnnotation.class, new ArrayList<CoreMap>());

      ByteArrayOutputStream ks = new ByteArrayOutputStream();
      serializer.write(doc, ks).close();
      // read
      InputStream kis = new ByteArrayInputStream(ks.toByteArray());
      Pair<Annotation, InputStream> pair = serializer.read(kis);
      pair.second.close();
      Annotation readDoc = pair.first;
      kis.close();
      // check characters are equal
      List<CoreLabel> docChars = doc.get(SegmenterCoreAnnotations.CharactersAnnotation.class);
      List<CoreLabel> readDocChars = doc.get(SegmenterCoreAnnotations.CharactersAnnotation.class);
      assertEquals(docChars.size(),readDocChars.size());
      int numChars = docChars.size();
      int currChar = 0;
      while (currChar < numChars) {
        assertEquals(docChars.get(currChar),readDocChars.get(currChar));
        currChar++;
      }
      // check that sentences are equal
      /*int sentenceCount = 0;
      while (sentenceCount < doc.get(CoreAnnotations.SentencesAnnotation.class).size()) {
        assertEquals(doc.get(CoreAnnotations.SentencesAnnotation.class).get(sentenceCount),
                readDoc.get(CoreAnnotations.SentencesAnnotation.class).get(sentenceCount));
        sentenceCount++;
      }*/
      // check JSON output is same
      String docJSON = JSONOutputter.jsonPrint(doc);
      String readDocJSON = JSONOutputter.jsonPrint(readDoc);
      assertEquals(docJSON,readDocJSON);
    } catch (Exception e) { throw new RuntimeException(e); }
  }
",non-flaky,5
96063,stanfordnlp_CoreNLP,TokensRegexNERAnnotatorITest.testTokensRegexSyntax,"  @Test
  public void testTokensRegexSyntax() throws Exception {
    String[][] regexes =
      new String[][]{
        new String[]{""( /University/ /of/ [ {ner:LOCATION} ] )"", ""SCHOOL""}
        // TODO: TokensRegex literal string patterns ignores ignoreCase settings
        //new String[]{""( University of [ {ner:LOCATION} ] )"", ""SCHOOL""}
    };
    Annotator annotatorCased = getTokensRegexNerAnnotator(regexes, false);

    String str = ""University of Alaska is located in Alaska."";
    Annotation document = createDocument(str);
    annotatorCased.annotate(document);
    List<CoreLabel> tokens = document.get(CoreAnnotations.TokensAnnotation.class);

    checkNerTags(tokens,
      ""ORGANIZATION"", ""ORGANIZATION"", ""ORGANIZATION"", ""O"", ""O"", ""O"", ""LOCATION"", ""O"");

    reannotate(tokens, CoreAnnotations.NamedEntityTagAnnotation.class,
            ""O"", ""O"", ""LOCATION"", ""O"", ""O"", ""O"", ""LOCATION"", ""O"");
    annotatorCased.annotate(document);

    checkNerTags(tokens,
      ""SCHOOL"", ""SCHOOL"", ""SCHOOL"", ""O"", ""O"", ""O"", ""LOCATION"", ""O"");

    // Try lowercase
    Annotator annotatorCaseless = getTokensRegexNerAnnotator(regexes, true);

    str = ""university of alaska is located in alaska."";
    document = createDocument(str);
    tokens = document.get(CoreAnnotations.TokensAnnotation.class);
    checkNerTags(tokens,
      ""O"", ""O"", ""LOCATION"", ""O"", ""O"", ""O"", ""LOCATION"", ""O"");
    annotatorCased.annotate(document);
    checkNerTags(tokens,
      ""O"", ""O"", ""LOCATION"", ""O"", ""O"", ""O"", ""LOCATION"", ""O"");
    annotatorCaseless.annotate(document);
    checkNerTags(tokens,
      ""SCHOOL"", ""SCHOOL"", ""SCHOOL"", ""O"", ""O"", ""O"", ""LOCATION"", ""O"");
  }
",non-flaky,5
96064,stanfordnlp_CoreNLP,TokensRegexNERAnnotatorITest.testTokensRegexMatchGroup,"  @Test
  public void testTokensRegexMatchGroup() throws Exception {
    String[][] regexes =
      new String[][]{
        new String[]{""( /the/? /movie/ (/[A-Z].*/+) )"", ""MOVIE"", """", ""0"", ""1""}
      };
    Annotator annotatorCased = getTokensRegexNerAnnotator(regexes, false);

    String str = ""the movie Mud was very muddy"";
    Annotation document = createDocument(str);
    annotatorCased.annotate(document);
    List<CoreLabel> tokens = document.get(CoreAnnotations.TokensAnnotation.class);

    checkNerTags(tokens,
      ""O"", ""O"", ""MOVIE"", ""O"", ""O"", ""O"");

  }
",non-flaky,5
96065,stanfordnlp_CoreNLP,TokensRegexNERAnnotatorITest.testTokensRegexNormalizedAnnotate,"  @Test
  public void testTokensRegexNormalizedAnnotate() throws Exception {
    Properties props = new Properties();
    props.setProperty(REGEX_ANNOTATOR_NAME + "".mapping.header"", ""pattern,ner,normalized,overwrite,priority,group"");

    String[][] regexes =
      new String[][]{
        new String[]{""blue"",  ""COLOR"", ""B"", """", ""0""},
        new String[]{""red"",   ""COLOR"", ""R"", """", ""0""},
        new String[]{""green"", ""COLOR"", ""G"", """", ""0""}
      };
    Annotator annotatorCased = getTokensRegexNerAnnotator(props, regexes, false);

    String str = ""These are all colors: blue, red, and green."";
    Annotation document = createDocument(str);
    annotatorCased.annotate(document);
    List<CoreLabel> tokens = document.get(CoreAnnotations.TokensAnnotation.class);

    checkTags(tokens, CoreAnnotations.TextAnnotation.class, ""These"", ""are"", ""all"", ""colors"", "":"", ""blue"", "","", ""red"", "","", ""and"", ""green"", ""."");
    checkTags(tokens, CoreAnnotations.NamedEntityTagAnnotation.class,  ""O"", ""O"", ""O"", ""O"", ""O"", ""COLOR"", ""O"", ""COLOR"", ""O"", ""O"", ""COLOR"", ""O"");
    checkTags(tokens, CoreAnnotations.NormalizedNamedEntityTagAnnotation.class,  null, null, null, null, null, ""B"", null, ""R"", null, null, ""G"", null);
  }
",non-flaky,5
96066,stanfordnlp_CoreNLP,TokensRegexNERAnnotatorITest.testTokensRegexCustomAnnotate,"  @Test
  public void testTokensRegexCustomAnnotate() throws Exception {

    Properties props = new Properties();
    props.setProperty(REGEX_ANNOTATOR_NAME + "".mapping.header"", ""pattern,test,overwrite,priority,group"");
    props.setProperty(REGEX_ANNOTATOR_NAME + "".mapping.field.test"", ""edu.stanford.nlp.pipeline.TokensRegexNERAnnotatorITest$TestAnnotation"");
    String[][] regexes =
      new String[][]{
        new String[]{""test"", ""TEST"", """", ""0""}
      };
    Annotator annotatorCased = getTokensRegexNerAnnotator(props, regexes, true);

    String str = ""Marking all test as test"";
    Annotation document = createDocument(str);
    annotatorCased.annotate(document);
    List<CoreLabel> tokens = document.get(CoreAnnotations.TokensAnnotation.class);

    checkTags(tokens, CoreAnnotations.TextAnnotation.class, ""Marking"", ""all"", ""test"", ""as"", ""test"");
    checkTags(tokens, TestAnnotation.class, null, null, ""TEST"", null, ""TEST"");
  }
",non-flaky,5
96067,stanfordnlp_CoreNLP,TokensRegexNERAnnotatorITest.testBasicMatching,"  @Test
  public void testBasicMatching() {
    String str = ""President Barack Obama lives in Chicago , Illinois , "" +
    ""and is a practicing Christian ."";
    Annotation document = createDocument(str);
    annotator.annotate(document);
    List<CoreLabel> tokens = document.get(CoreAnnotations.TokensAnnotation.class);

    checkNerTags(tokens,
      ""TITLE"", ""PERSON"", ""PERSON"", ""O"", ""O"", ""LOCATION"", ""O"", ""STATE_OR_PROVINCE"",
      ""O"", ""O"", ""O"", ""O"", ""O"", ""IDEOLOGY"", ""O"");

  }
",non-flaky,5
96068,stanfordnlp_CoreNLP,TokensRegexNERAnnotatorITest.testOverwrite,"  @Test
  public void testOverwrite() {
    String str = ""I like Ontario Bank and Ontario Lake , and I like the Native American Church , too ."";
    Annotation document = createDocument(str);
    annotator.annotate(document);
    List<CoreLabel> tokens = document.get(CoreAnnotations.TokensAnnotation.class);

    checkNerTags(tokens, ""O"", ""O"", ""ORGANIZATION"", ""ORGANIZATION"", ""O"", ""STATE_OR_PROVINCE"", ""LOCATION"", ""O"", ""O"", ""O"", ""O"", ""O"", ""RELIGION"",
      ""RELIGION"", ""RELIGION"", ""O"", ""O"", ""O"");

  }
",non-flaky,5
96069,stanfordnlp_CoreNLP,TokensRegexNERAnnotatorITest.testPriority,"  @Test
  public void testPriority() {
    String str = ""Christianity is of higher regex priority than Early Christianity . "";
    Annotation document = createDocument(str);
    annotator.annotate(document);
    List<CoreLabel> tokens = document.get(CoreAnnotations.TokensAnnotation.class);
    checkNerTags(tokens, ""RELIGION"", ""O"", ""O"", ""O"", ""O"", ""O"", ""O"", ""O"", ""RELIGION"", ""O"");
  }
",non-flaky,5
96070,stanfordnlp_CoreNLP,TokensRegexNERAnnotatorITest.testEmptyAnnotation,"  @Test
  public void testEmptyAnnotation() {
    try {
      annotator.annotate(new Annotation(""""));
    } catch(RuntimeException e) {
      return;
    }
    Assert.fail(""Never expected to get this far... the annotator should have thrown an exception by now"");
  }
",non-flaky,5
96071,stanfordnlp_CoreNLP,QuantifiableEntityNormalizingAnnotatorITest.testQuantifiableEntityNormalizingAnnotator,"  @Test
  public void testQuantifiableEntityNormalizingAnnotator() {
    Annotation document = new Annotation(text);
    pipeline.annotate(document);

    int i = 0;
    for (CoreMap sentence: document.get(CoreAnnotations.SentencesAnnotation.class)) {
        List<CoreLabel> tokens = sentence.get(CoreAnnotations.TokensAnnotation.class);
        for (CoreLabel token : tokens) {
          System.out.println(token.get(CoreAnnotations.TextAnnotation.class) + "": "" + token.get(CoreAnnotations.NamedEntityTagAnnotation.class) + "", "" + token.get(CoreAnnotations.NormalizedNamedEntityTagAnnotation.class));
        }
      for (CoreLabel token : tokens) {
        String normalization = token.get(CoreAnnotations.NormalizedNamedEntityTagAnnotation.class);
        if (normalization != null) {
          Assert.assertEquals(answer_text[i], token.get(CoreAnnotations.OriginalTextAnnotation.class));
          Assert.assertEquals(answer_time[i], normalization);
          i++;
        }
      }
    }
    Assert.assertEquals(answer_text.length, i);
    Assert.assertEquals(answer_time.length, i);
  }
",non-flaky,5
96072,stanfordnlp_CoreNLP,RequirementsCorrectSlowITest.testDefaultPipeline,"  @Test
  public void testDefaultPipeline() {
    testAnnotatorSequence(Arrays.asList(""tokenize"", ""ssplit"", ""pos"", ""lemma"", ""ner"", ""gender"", ""parse"", ""coref""));
  }
",non-flaky,5
96073,stanfordnlp_CoreNLP,RequirementsCorrectSlowITest.testDepparsePipeline,"  @Test
  public void testDepparsePipeline() {
    testAnnotatorSequence(Arrays.asList(""tokenize"", ""ssplit"", ""pos"", ""depparse""));
  }
",non-flaky,5
96074,stanfordnlp_CoreNLP,RequirementsCorrectSlowITest.testQuotePipeline,"  @Test
  public void testQuotePipeline() {
    testAnnotatorSequence(Arrays.asList(""tokenize"",""ssplit"",""pos"",""lemma"",""ner"",""depparse"",""coref"",""quote""));
  }
",non-flaky,5
96075,stanfordnlp_CoreNLP,RequirementsCorrectSlowITest.testTrueCasePipeline,"   @Test
   public void testTrueCasePipeline() {
     testAnnotatorSequence(Arrays.asList(""tokenize"",""ssplit"",""pos"",""lemma"",""truecase""));
   }
",non-flaky,5
96076,stanfordnlp_CoreNLP,RequirementsCorrectSlowITest.testOpenIEPipeline,"  @Test
  public void testOpenIEPipeline() {
    testAnnotatorSequence(Arrays.asList(""tokenize"",""ssplit"",""pos"",""lemma"",""depparse"",""natlog"",""openie""));
  }
",non-flaky,5
96077,stanfordnlp_CoreNLP,RequirementsCorrectSlowITest.testMentionRegression,"  @Test
  public void testMentionRegression() {
    testAnnotatorSequence(Arrays.asList());
  }
",non-flaky,5
96078,stanfordnlp_CoreNLP,PipelineITest.testPipeline,"  @Test
  public void testPipeline() throws Exception {
    // create pipeline
    AnnotationPipeline pipeline = new AnnotationPipeline();
    pipeline.addAnnotator(new TokenizerAnnotator(false, ""en""));
    pipeline.addAnnotator(new WordsToSentencesAnnotator(false));
    pipeline.addAnnotator(new POSTaggerAnnotator(false));
    pipeline.addAnnotator(new MorphaAnnotator(false));
    pipeline.addAnnotator(new NERCombinerAnnotator(false));
    pipeline.addAnnotator(new ParserAnnotator(false, -1));
    //pipeline.addAnnotator(new CorefAnnotator(null, null, null, false));
    //pipeline.addAnnotator(new SRLAnnotator(false));

    // create annotation with text
    String text = ""Dan Ramage is working for\nMicrosoft. He's in Seattle! \n"";
    Annotation document = new Annotation(text);
    Assert.assertEquals(text, document.toString());
    Assert.assertEquals(text, document.get(CoreAnnotations.TextAnnotation.class));

    // annotate text with pipeline
    pipeline.annotate(document);

    // demonstrate typical usage
    for (CoreMap sentence: document.get(CoreAnnotations.SentencesAnnotation.class)) {

      // get the tree for the sentence
      Tree tree = sentence.get(TreeCoreAnnotations.TreeAnnotation.class);

      // get the tokens for the sentence and iterate over them
      for (CoreLabel token: sentence.get(CoreAnnotations.TokensAnnotation.class)) {

        // get token attributes
        String tokenText = token.get(CoreAnnotations.TextAnnotation.class);
        String tokenPOS = token.get(CoreAnnotations.PartOfSpeechAnnotation.class);
        String tokenLemma = token.get(CoreAnnotations.LemmaAnnotation.class);
        String tokenNE = token.get(CoreAnnotations.NamedEntityTagAnnotation.class);

        // text, pos, lemma and name entity tag should be defined
        Assert.assertNotNull(tokenText);
        Assert.assertNotNull(tokenPOS);
        Assert.assertNotNull(tokenLemma);
        Assert.assertNotNull(tokenNE);
      }
      // tree should be defined
      Assert.assertNotNull(tree);
    }

    // get tokens
    List<CoreLabel> tokens = document.get(CoreAnnotations.TokensAnnotation.class);
    String tokensText = ""Dan Ramage is working for Microsoft . He 's in Seattle !"";
    Assert.assertNotNull(tokens);
    Assert.assertEquals(12, tokens.size());
    Assert.assertEquals(tokensText, join(tokens));
    Assert.assertEquals(0, (int)tokens.get(0).get(CoreAnnotations.CharacterOffsetBeginAnnotation.class));
    Assert.assertEquals(3, (int)tokens.get(0).get(CoreAnnotations.CharacterOffsetEndAnnotation.class));
    Assert.assertEquals(""NNP"", tokens.get(0).get(CoreAnnotations.PartOfSpeechAnnotation.class));
    Assert.assertEquals(""VBZ"", tokens.get(2).get(CoreAnnotations.PartOfSpeechAnnotation.class));
    Assert.assertEquals(""."", tokens.get(11).get(CoreAnnotations.PartOfSpeechAnnotation.class));
    Assert.assertEquals(""Ramage"", tokens.get(1).get(CoreAnnotations.LemmaAnnotation.class));
    Assert.assertEquals(""be"", tokens.get(2).get(CoreAnnotations.LemmaAnnotation.class));
    Assert.assertEquals(""PERSON"", tokens.get(0).get(CoreAnnotations.NamedEntityTagAnnotation.class));
    Assert.assertEquals(""PERSON"", tokens.get(1).get(CoreAnnotations.NamedEntityTagAnnotation.class));
    Assert.assertEquals(""CITY"", tokens.get(10).get(CoreAnnotations.NamedEntityTagAnnotation.class));

    // get sentences
    List<CoreMap> sentences = document.get(CoreAnnotations.SentencesAnnotation.class);
    Assert.assertNotNull(sentences);
    Assert.assertEquals(2, sentences.size());

    // sentence 1
    String text1 = ""Dan Ramage is working for\nMicrosoft."";
    CoreMap sentence1 = sentences.get(0);
    Assert.assertEquals(text1, sentence1.toString());
    Assert.assertEquals(text1, sentence1.get(CoreAnnotations.TextAnnotation.class));
    Assert.assertEquals(0, (int)sentence1.get(CoreAnnotations.CharacterOffsetBeginAnnotation.class));
    Assert.assertEquals(36, (int)sentence1.get(CoreAnnotations.CharacterOffsetEndAnnotation.class));
    Assert.assertEquals(0, (int)sentence1.get(CoreAnnotations.TokenBeginAnnotation.class));
    Assert.assertEquals(7, (int)sentence1.get(CoreAnnotations.TokenEndAnnotation.class));

    // sentence 1 tree
    Tree tree1 = Tree.valueOf(""(ROOT (S (NP (NNP Dan) (NNP Ramage)) (VP (VBZ is) "" +
        ""(VP (VBG working) (PP (IN for) (NP (NNP Microsoft))))) (. .)))"");
    Assert.assertEquals(tree1, sentence1.get(TreeCoreAnnotations.TreeAnnotation.class));

    // sentence 1 tokens
    String tokenText1 = ""Dan Ramage is working for Microsoft ."";
    List<CoreLabel> tokens1 = sentence1.get(CoreAnnotations.TokensAnnotation.class);
    Assert.assertNotNull(tokens1);
    Assert.assertEquals(7, tokens1.size());
    Assert.assertEquals(tokenText1, join(tokens1));
    Assert.assertEquals(4, (int)tokens1.get(1).get(CoreAnnotations.CharacterOffsetBeginAnnotation.class));
    Assert.assertEquals(10, (int)tokens1.get(1).get(CoreAnnotations.CharacterOffsetEndAnnotation.class));
    Assert.assertEquals(""IN"", tokens1.get(4).get(CoreAnnotations.PartOfSpeechAnnotation.class));
    Assert.assertEquals(""NNP"", tokens1.get(5).get(CoreAnnotations.PartOfSpeechAnnotation.class));
    Assert.assertEquals(""work"", tokens1.get(3).get(CoreAnnotations.LemmaAnnotation.class));
    Assert.assertEquals(""."", tokens1.get(6).get(CoreAnnotations.LemmaAnnotation.class));
    Assert.assertEquals(""ORGANIZATION"", tokens1.get(5).get(CoreAnnotations.NamedEntityTagAnnotation.class));

    // sentence 2
    String text2 = ""He's in Seattle!"";
    CoreMap sentence2 = sentences.get(1);
    Assert.assertEquals(text2, sentence2.toString());
    Assert.assertEquals(text2, sentence2.get(CoreAnnotations.TextAnnotation.class));
    Assert.assertEquals(37, (int)sentence2.get(CoreAnnotations.CharacterOffsetBeginAnnotation.class));
    Assert.assertEquals(53, (int)sentence2.get(CoreAnnotations.CharacterOffsetEndAnnotation.class));
    Assert.assertEquals(7, (int)sentence2.get(CoreAnnotations.TokenBeginAnnotation.class));
    Assert.assertEquals(12, (int)sentence2.get(CoreAnnotations.TokenEndAnnotation.class));

    // sentence 2 tree (note error on Seattle, caused by part of speech tagger)
    Tree tree2 = Tree.valueOf(""(ROOT (S (NP (PRP He)) (VP (VBZ 's) (PP (IN in) "" +
        ""(NP (NNP Seattle)))) (. !)))"");
    Assert.assertEquals(tree2, sentence2.get(TreeCoreAnnotations.TreeAnnotation.class));

    // sentence 2 tokens
    String tokenText2 = ""He 's in Seattle !"";
    List<CoreLabel> tokens2 = sentence2.get(CoreAnnotations.TokensAnnotation.class);
    Assert.assertNotNull(tokens2);
    Assert.assertEquals(5, tokens2.size());
    Assert.assertEquals(tokenText2, join(tokens2));
    Assert.assertEquals(39, (int)tokens2.get(1).get(CoreAnnotations.CharacterOffsetBeginAnnotation.class));
    Assert.assertEquals(41, (int)tokens2.get(1).get(CoreAnnotations.CharacterOffsetEndAnnotation.class));
    Assert.assertEquals(""VBZ"", tokens2.get(1).get(CoreAnnotations.PartOfSpeechAnnotation.class));
    Assert.assertEquals(""be"", tokens2.get(1).get(CoreAnnotations.LemmaAnnotation.class));
    Assert.assertEquals(""CITY"", tokens2.get(3).get(CoreAnnotations.NamedEntityTagAnnotation.class));
  }
",non-flaky,5
96079,stanfordnlp_CoreNLP,PipelinePropertiesITest.buildFrenchPipeline,"  @Test
  public void buildFrenchPipeline() {
    // expected output
    List<String> expectedTokens = Arrays.asList(""Emmanuel"", ""Macron"", ""est"", ""le"", ""prÃ©sident"", ""de"", ""la"", ""France"", ""."");
    List<String> expectedTags = Arrays.asList(""PROPN"", ""PROPN"", ""AUX"", ""DET"", ""NOUN"", ""ADP"", ""DET"", ""PROPN"", ""PUNCT"");
    List<String> expectedNER = Arrays.asList(""I-PER"", ""I-PER"", ""O"", ""O"", ""O"", ""O"", ""I-LOC"", ""I-LOC"", ""O"");
    String expectedDependencyParse = ""root(ROOT-0, prÃ©sident-5)\n"" +
        ""nsubj(prÃ©sident-5, Emmanuel-1)\n"" +
        ""flat:name(Emmanuel-1, Macron-2)\n"" +
        ""cop(prÃ©sident-5, est-3)\n"" +
        ""det(prÃ©sident-5, le-4)\n"" +
        ""case(France-8, de-6)\n"" +
        ""det(France-8, la-7)\n"" +
        ""nmod:de(prÃ©sident-5, France-8)\n"" +
        ""punct(prÃ©sident-5, .-9)\n"";
    // build doc
    CoreDocument doc = new CoreDocument(""Emmanuel Macron est le prÃ©sident de la France."");
    // build pipeline with language name
    StanfordCoreNLP frenchPipeline = new StanfordCoreNLP(""french"");
    // annotate
    frenchPipeline.annotate(doc);
    // compare results
    assertEquals(expectedTokens, doc.tokens().stream().map(w -> w.word()).collect(Collectors.toList()));
    assertEquals(expectedTags, doc.tokens().stream().map(w -> w.tag()).collect(Collectors.toList()));
    assertEquals(expectedNER, doc.tokens().stream().map(w -> w.ner()).collect(Collectors.toList()));
    assertEquals(expectedDependencyParse, doc.sentences().get(0).dependencyParse().toList());
  }
",non-flaky,5
96080,stanfordnlp_CoreNLP,CoreQuoteSanityITest.testCoreQuote,"  @Test
  public void testCoreQuote() {
    // make the core document
    CoreDocument testDoc = new CoreDocument(testDocText);
    // annotate
    pipeline.annotate(testDoc);
    // test canonical entity mention is correct
    // ""Joe Smith"" should be first entity mention
    CoreMap canonicalEntityMention =
        testDoc.annotation().get(CoreAnnotations.MentionsAnnotation.class).get(1);
    // test canonical mention is correct
    assertEquals(""Joe Smith"", canonicalEntityMention.get(CoreAnnotations.TextAnnotation.class));
    assertEquals(14,
        canonicalEntityMention.get(CoreAnnotations.CharacterOffsetBeginAnnotation.class).intValue());
    assertEquals(23,
        canonicalEntityMention.get(CoreAnnotations.CharacterOffsetEndAnnotation.class).intValue());
    // test the CoreQuote has the correct entity mention for the canonical speaker
    assertEquals(canonicalEntityMention, testDoc.quotes().get(0).canonicalSpeakerEntityMention().get().coreMap());
  }
",non-flaky,5
96081,stanfordnlp_CoreNLP,CustomAnnotationSerializerITest.testSimple,"  @Test
  public void testSimple() throws IOException {
    Annotation annotation = new Annotation(""This is a test"");
    fullPipeline.annotate(annotation);
    runTest(annotation);
  }
",non-flaky,5
96082,stanfordnlp_CoreNLP,CustomAnnotationSerializerITest.testCollapsedGraphs,"  @Test
  public void testCollapsedGraphs() throws IOException {
    Annotation annotation = new Annotation(""I bought a bone for my dog."");
    fullPipeline.annotate(annotation);
    runTest(annotation);
  }
",non-flaky,5
96083,stanfordnlp_CoreNLP,CustomAnnotationSerializerITest.testTwoSentences,"  @Test
  public void testTwoSentences() throws IOException {
    Annotation annotation = new Annotation(""I bought a bone for my dog.  He chews it every day."");
    fullPipeline.annotate(annotation);
    runTest(annotation);
  }
",non-flaky,5
96084,stanfordnlp_CoreNLP,CustomAnnotationSerializerITest.testCopyWordGraphs,"  @Test
  public void testCopyWordGraphs() throws IOException {
    Annotation annotation = new Annotation(""I went over the river and through the woods"");
    fullPipeline.annotate(annotation);
    runTest(annotation);
  }
",non-flaky,5
96085,stanfordnlp_CoreNLP,StanfordCoreNLPServerITest.testLive,"  @Test
  public void testLive() {
    String result = IOUtils.slurpURLNoExceptions(""http://localhost:"" + port + ""/live"");
    Assert.assertNotNull(result);
    Assert.assertEquals(""live"", result.trim());
  }
",non-flaky,5
96086,stanfordnlp_CoreNLP,StanfordCoreNLPServerITest.testReady,"  @Test
  public void testReady() {
    String result = IOUtils.slurpURLNoExceptions(""http://localhost:"" + port + ""/ready"");
    Assert.assertNotNull(result);
    Assert.assertEquals(""ready"", result.trim());
  }
",non-flaky,5
96087,stanfordnlp_CoreNLP,StanfordCoreNLPServerITest.testClient,"  @Test
  public void testClient() {
    String query = ""The dog ate a fish"";
    Properties props = new Properties();
    props.setProperty(""annotators"", ""tokenize,ssplit,pos,parse"");
    StanfordCoreNLPClient client = new StanfordCoreNLPClient(props, ""http://localhost"", port);
    // if something goes wrong, we don't want the unittest waiting forever for a response
    client.setTimeoutMilliseconds(30 * 1000);
    Annotation annotation = client.process(query);
    Throwable t = annotation.get(CoreAnnotations.ExceptionAnnotation.class);
    Assert.assertNull(t);

    List<CoreMap> sentences = annotation.get(CoreAnnotations.SentencesAnnotation.class);
    Assert.assertEquals(1, sentences.size());
  }
",non-flaky,5
96088,stanfordnlp_CoreNLP,StanfordCoreNLPServerITest.testClientFailure,"  @Test
  public void testClientFailure() {
    String query = ""The dog ate a fish"";
    Properties props = new Properties();
    props.setProperty(""annotators"", ""tokenize,ssplit,pos,parse"");
    //StanfordCoreNLPClient client = new StanfordCoreNLPClient(props, ""http://localhost"", port);
    StanfordCoreNLPClient client = new StanfordCoreNLPClient(props, ""localhost"", port);
    client.setTimeoutMilliseconds(1000);
    Annotation annotation = client.process(query);
    Throwable t = annotation.get(CoreAnnotations.ExceptionAnnotation.class);
    Assert.assertNotNull(t);
  }
",non-flaky,5
96089,stanfordnlp_CoreNLP,StanfordCoreNLPServerITest.testTregexJson,"  @Test
  public void testTregexJson() throws IOException {

    String expected=""{\""sentences\"":[{\""0\"":{\""sentIndex\"":0,\""characterOffsetBegin\"":4,\""characterOffsetEnd\"":7,\""match\"":\""(NNdog)\\n\"",\""spanString\"":\""dog\"",\""namedNodes\"":[]},\""1\"":{\""sentIndex\"":0,\""characterOffsetBegin\"":14,\""characterOffsetEnd\"":18,\""match\"":\""(NNfish)\\n\"",\""spanString\"":\""fish\"",\""namedNodes\"":[]}}]}"".replaceAll("" "", """");

    String query = ""The dog ate a fish"";
    byte[] message = query.getBytes(""utf-8"");
    Properties props = new Properties();
    props.setProperty(""annotators"", ""tokenize,ssplit,pos,parse"");
    String queryParams = String.format(""pattern=NN&properties=%s"",
                                       URLEncoder.encode(PropertiesUtils.propsAsJsonString(props), ""utf-8""));
    URL serverURL = new URL(""http"", ""localhost"", port, ""/tregex?"" + queryParams);
    String response = slurpURL(serverURL, message);

    Assert.assertEquals(expected, response.replaceAll("" "", """").replaceAll(""\n"", """"));
  }
",non-flaky,5
96090,stanfordnlp_CoreNLP,StanfordCoreNLPServerITest.testSemgrexJson,"  @Test
  public void testSemgrexJson() throws IOException {
    String expected=""{ \""sentences\"": [ { \""0\"": { \""text\"": \""ate\"", \""begin\"": 2, \""end\"": 3, \""$obj\"": { \""text\"": \""fish\"", \""begin\"": 4, \""end\"": 5 }, \""$verb\"": { \""text\"": \""ate\"", \""begin\"": 2, \""end\"": 3 } }, \""length\"": 1 }  ]}"".replaceAll("" "", """");

    String query = ""The dog ate a fish"";
    byte[] message = query.getBytes(""utf-8"");
    Properties props = new Properties();
    props.setProperty(""annotators"", ""tokenize,ssplit,pos,parse"");
    String queryParams = String.format(""pattern=%s&properties=%s"",
                                       URLEncoder.encode(""{}=verb >obj {}=obj"", ""utf-8""),
                                       URLEncoder.encode(PropertiesUtils.propsAsJsonString(props), ""utf-8""));
    URL serverURL = new URL(""http"", ""localhost"", port, ""/semgrex?"" + queryParams);
    String response = slurpURL(serverURL, message);

    Assert.assertEquals(expected, response.replaceAll("" "", """").replaceAll(""\n"", """"));
  }
",non-flaky,5
96091,stanfordnlp_CoreNLP,StanfordCoreNLPServerITest.testSemgrexAnnotation,"  @Test
  public void testSemgrexAnnotation() throws IOException {
    String expected = ""result { result { match { matchIndex: 3 node { name: \""obj\"" matchIndex: 5 } node { name: \""verb\"" matchIndex: 3 } } }}"".replaceAll("" "", """");
    String query = ""The dog ate a fish"";
    byte[] message = query.getBytes(""utf-8"");
    Properties props = new Properties();
    props.setProperty(""annotators"", ""tokenize,ssplit,pos,parse"");
    String queryParams = String.format(""pattern=%s&properties=%s&outputFormat=serialized"",
                                       URLEncoder.encode(""{}=verb >obj {}=obj"", ""utf-8""),
                                       URLEncoder.encode(PropertiesUtils.propsAsJsonString(props), ""utf-8""));
    URL serverURL = new URL(""http"", ""localhost"", port, ""/semgrex?"" + queryParams);
    InputStream is = postURL(serverURL, message);
    CoreNLPProtos.SemgrexResponse response = CoreNLPProtos.SemgrexResponse.parseFrom(is);

    Assert.assertEquals(expected, response.toString().replaceAll("" "", """").replaceAll(""\n"", """"));
  }
",non-flaky,5
96092,stanfordnlp_CoreNLP,StanfordCoreNLPServerITest.testSemgrexFilter,"  @Test
  public void testSemgrexFilter() throws IOException {
    String expected=""{ \""sentences\"": [ true, false ]}"".replaceAll("" "", """");

    String query = ""The dog ate a fish.  He went home."";
    byte[] message = query.getBytes(""utf-8"");
    Properties props = new Properties();
    props.setProperty(""annotators"", ""tokenize,ssplit,pos,parse"");
    String queryParams = String.format(""pattern=%s&properties=%s&filter=true"",
                                       URLEncoder.encode(""{}=verb >obj {}=obj"", ""utf-8""),
                                       URLEncoder.encode(PropertiesUtils.propsAsJsonString(props), ""utf-8""));
    URL serverURL = new URL(""http"", ""localhost"", port, ""/semgrex?"" + queryParams);
    String response = slurpURL(serverURL, message);

    Assert.assertEquals(expected, response.replaceAll("" "", """").replaceAll(""\n"", """"));
  }
",non-flaky,5
96093,stanfordnlp_CoreNLP,MWTProtobufSerializationITest.testBasicExample,"  @Test
  public void testBasicExample() throws ClassNotFoundException, IOException {
    // set up document
    CoreDocument sampleDocument = new CoreDocument(sampleText);
    // annotate
    pipeline.annotate(sampleDocument);
    // serialize
    ByteArrayOutputStream ks = new ByteArrayOutputStream();
    serializer.writeCoreDocument(sampleDocument, ks).close();
    // Read
    InputStream kis = new ByteArrayInputStream(ks.toByteArray());
    Pair<Annotation, InputStream> pair = serializer.read(kis);
    pair.second.close();
    Annotation readAnnotation = pair.first;
    kis.close();
    ProtobufAnnotationSerializerSlowITest.sameAsRead(sampleDocument.annotation(), readAnnotation);
  }
",non-flaky,5
96094,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testMentions,"  @Test
  public void testMentions() {
    testAnnotators(""tokenize,ssplit,pos,lemma,ner,entitymentions"");
  }
",non-flaky,5
96095,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testSentiment,"  @Test
  public void testSentiment() {
    testAnnotators(""tokenize,ssplit,pos,parse,sentiment"");
  }
",non-flaky,5
96096,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testOpenie,"  @Test
  public void testOpenie() {
    testAnnotators(""tokenize,ssplit,pos,lemma,depparse,natlog,openie"");
  }
",non-flaky,5
96097,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testQuote,"  @Test
  public void testQuote() {
    testAnnotators(""quote"");
    testAnnotators(""tokenize,quote"");
    testAnnotators(""tokenize,ssplit,quote"");
    testAnnotators(""tokenize,ssplit,quote"");
    testAnnotators(""tokenize,ssplit,pos,lemma,ner,depparse,coref,quote"");
  }
",non-flaky,5
96098,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testGetPossibleAnnotators,"  @Test
  public void testGetPossibleAnnotators() {
    assertNotNull(possibleAnnotators());
    assertNotEquals(0, possibleAnnotators().length);
  }
",non-flaky,5
96099,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testSave,"  @Test
  public void testSave() throws IOException {
    ByteArrayOutputStream os = new ByteArrayOutputStream();
    new ProtobufAnnotationSerializer().write(mkAnnotation(), os).close();
    String json = new String(os.toByteArray(), ""UTF-8"").trim();
    assertNotNull(json);
  }
",non-flaky,5
96100,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testSaveLarge,"  @Test
  public void testSaveLarge() throws IOException {
    ByteArrayOutputStream os = new ByteArrayOutputStream();
    new ProtobufAnnotationSerializer().write(mkLargeAnnotation(), os).close();
    String json = new String(os.toByteArray(), ""UTF-8"");
    assertNotNull(json);
  }
",non-flaky,5
96101,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testSaveSize,"  @Test
  public void testSaveSize() throws IOException {
    // Annotate
    ByteArrayOutputStream os = new ByteArrayOutputStream();
    ByteArrayOutputStream compressedImpl = new ByteArrayOutputStream();
    GZIPOutputStream compressed = new GZIPOutputStream(compressedImpl);
    new ProtobufAnnotationSerializer().write(mkLargeAnnotation(), os).close();
    new ProtobufAnnotationSerializer().write(mkLargeAnnotation(), compressed).close();
    byte[] uncompressedProto = os.toByteArray();
    byte[] compressedProto = compressedImpl.toByteArray();
    assertNotNull(uncompressedProto);
    assertNotNull(compressedProto);

    // Check size
    assertTrue(""Length too long: "" + compressedProto.length, compressedProto.length < 460000);
    assertTrue(""Length too long: "" + uncompressedProto.length, uncompressedProto.length < 2800000);
  }
",non-flaky,5
96102,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testCanWriteRead,"  @Test
  public void testCanWriteRead() {
    try {
      AnnotationSerializer serializer = new ProtobufAnnotationSerializer();
      // Write
      StanfordCoreNLP pipe = new StanfordCoreNLP(new Properties());
      Annotation doc = pipe.process(prideAndPrejudiceFirstBit);
      ByteArrayOutputStream ks = new ByteArrayOutputStream();
      serializer.write(doc, ks).close();

      // Read
      InputStream kis = new ByteArrayInputStream(ks.toByteArray());
      Pair<Annotation, InputStream> pair = serializer.read(kis);
      pair.second.close();
      Annotation readDoc = pair.first;
      kis.close();

      sameAsRead(doc, readDoc);
    } catch (Exception e) { throw new RuntimeException(e); }
  }
",non-flaky,5
96103,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testCanWriteReadCleanXML,"  @Test
  public void testCanWriteReadCleanXML() {
    try {
      AnnotationSerializer serializer = new ProtobufAnnotationSerializer();
      // Write
      Properties props = new Properties();
      props.setProperty(""annotators"", ""tokenize,cleanxml"");
      StanfordCoreNLP pipe = new StanfordCoreNLP(props);
      Annotation doc = pipe.process(prideAndPrejudiceFirstBit);
      ByteArrayOutputStream ks = new ByteArrayOutputStream();
      serializer.write(doc, ks).close();

      // Read
      InputStream kis = new ByteArrayInputStream(ks.toByteArray());
      Pair<Annotation, InputStream> pair = serializer.read(kis);
      pair.second.close();
      Annotation readDoc = pair.first;
      kis.close();

      sameAsRead(doc, readDoc);
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
  }
",non-flaky,5
96104,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testCanWriteReadWriteReadLargeFile,"  @Test
  public void testCanWriteReadWriteReadLargeFile() {
    try {
      AnnotationSerializer serializer = new ProtobufAnnotationSerializer();
      // Write
      StanfordCoreNLP pipe = new StanfordCoreNLP(new Properties());
      Annotation doc = pipe.process(prideAndPrejudiceChapters1to5);

      ByteArrayOutputStream ks = new ByteArrayOutputStream();
      serializer.write(doc, ks).close();

      // Read
      InputStream kis = new ByteArrayInputStream(ks.toByteArray());
      Pair<Annotation, InputStream> pair1 = serializer.read(kis);
      pair1.second.close();
      Annotation readDoc = pair1.first;
      kis.close();

      for (int i = 0 ; i < doc.get(CoreAnnotations.MentionsAnnotation.class).size() ; i++) {
        CoreMap cm1 = doc.get(CoreAnnotations.MentionsAnnotation.class).get(i);
        CoreMap cm2 = readDoc.get(CoreAnnotations.MentionsAnnotation.class).get(i);
        diffCoreMaps(i,cm1,cm2);
      }

      sameAsRead(doc, readDoc);

      // Write 2
      ByteArrayOutputStream ks2 = new ByteArrayOutputStream();
      serializer.write(readDoc, ks2).close();

      // Read 2
      InputStream kis2 = new ByteArrayInputStream(ks2.toByteArray());
      Pair<Annotation, InputStream> pair = serializer.read(kis2);
      pair.second.close();
      Annotation readDoc2 = pair.first;
      kis2.close();

      sameAsRead(readDoc, readDoc2);
      sameAsRead(doc, readDoc2);
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
  }
",non-flaky,5
96105,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testSerializeLanguage,"  @Test
  public void testSerializeLanguage() {
    testAnnotators(""tokenize,ssplit,parse"");
    testAnnotators(""tokenize,ssplit,pos,depparse"");
  }
",non-flaky,5
96106,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testRelation,"  @Test
  public void testRelation() {
    testAnnotators(""tokenize,ssplit,pos,lemma,ner,parse,relation"");
  }
",non-flaky,5
124,spotify_docker-client,DefaultDockerClientTest.testListTaskWithCriteria,"@Test
public void testListTaskWithCriteria() throws Exception {
    requireDockerApiVersionAtLeast(""1.24"", ""swarm support"");
    final ServiceSpec spec = createServiceSpec(randomName());
    assertThat(sut.listTasks().size(), is(0));
    sut.createService(spec);
    await().until(numberOfTasks(sut), is(greaterThan(0)));
    final Task task = sut.listTasks().get(1);
    final List<Task> tasksWithId = sut.listTasks(Task.find().taskId(task.id()).build());
    assertThat(tasksWithId.size(), is(1));
    assertThat(tasksWithId.get(0), equalTo(task));
    final List<Task> tasksWithServiceName = sut.listTasks(Task.find().serviceName(spec.name()).build());
    assertThat(tasksWithServiceName.size(), is(greaterThanOrEqualTo(1)));
    final Set<String> taskIds = Sets.newHashSet(Lists.transform(tasksWithServiceName, new Function<Task, String>()));
    assertThat(task.id(), isIn(taskIds));
}",async wait,0
98256,spotify_docker-client,PushPullIT.testPushImageToPrivateAuthedRegistryWithoutAuth,"  @Test
  public void testPushImageToPrivateAuthedRegistryWithoutAuth() throws Exception {
    registryContainerId = startAuthedRegistry(client);

    // Make a DockerClient without RegistryAuth
    final DefaultDockerClient client = DefaultDockerClient.fromEnv().build();

    // Push an image to the private registry and check it fails
    final String dockerDirectory = Resources.getResource(""dockerDirectory"").getPath();
    client.build(Paths.get(dockerDirectory), LOCAL_IMAGE);

    exception.expect(ImagePushFailedException.class);
    client.push(LOCAL_IMAGE);
  }
",non-flaky,5
98257,spotify_docker-client,PushPullIT.testPushImageToPrivateAuthedRegistryWithAuth,"  @Test
  public void testPushImageToPrivateAuthedRegistryWithAuth() throws Exception {
    registryContainerId = startAuthedRegistry(client);

    // Push an image to the private registry and check it succeeds
    final String dockerDirectory = Resources.getResource(""dockerDirectory"").getPath();
    client.build(Paths.get(dockerDirectory), LOCAL_IMAGE);
    client.tag(LOCAL_IMAGE, LOCAL_IMAGE_2);
    client.push(LOCAL_IMAGE);

    // Push the same image again under a different user
    final RegistryAuth registryAuth = RegistryAuth.builder()
        .username(LOCAL_AUTH_USERNAME_2)
        .password(LOCAL_AUTH_PASSWORD_2)
        .build();
    client.push(LOCAL_IMAGE_2, registryAuth);

    // We should be able to pull it again
    client.pull(LOCAL_IMAGE);
    client.pull(LOCAL_IMAGE_2);
  }
",non-flaky,5
98258,spotify_docker-client,PushPullIT.testPushImageToPrivateUnauthedRegistryWithoutAuth,"  @Test
  public void testPushImageToPrivateUnauthedRegistryWithoutAuth() throws Exception {
    registryContainerId = startUnauthedRegistry(client);

    // Make a DockerClient without RegistryAuth
    final DefaultDockerClient client = DefaultDockerClient.fromEnv().build();

    // Push an image to the private registry and check it succeeds
    final String dockerDirectory = Resources.getResource(""dockerDirectory"").getPath();
    client.build(Paths.get(dockerDirectory), LOCAL_IMAGE);
    client.push(LOCAL_IMAGE);
    // We should be able to pull it again
    client.pull(LOCAL_IMAGE);
  }
",non-flaky,5
98259,spotify_docker-client,PushPullIT.testPushImageToPrivateUnauthedRegistryWithAuth,"  @Test
  public void testPushImageToPrivateUnauthedRegistryWithAuth() throws Exception {
    registryContainerId = startUnauthedRegistry(client);

    // Push an image to the private registry and check it succeeds
    final String dockerDirectory = Resources.getResource(""dockerDirectory"").getPath();
    client.build(Paths.get(dockerDirectory), LOCAL_IMAGE);
    client.push(LOCAL_IMAGE);
    // We should be able to pull it again
    client.pull(LOCAL_IMAGE);
  }
",non-flaky,5
98260,spotify_docker-client,PushPullIT.testPushHubPublicImageWithAuth,"  @Test
  public void testPushHubPublicImageWithAuth() throws Exception {
    // Push an image to a public repo on Docker Hub and check it succeeds
    final String dockerDirectory = Resources.getResource(""dockerDirectory"").getPath();
    final DockerClient client = DefaultDockerClient
        .fromEnv()
        .registryAuth(RegistryAuth.builder()
                        .username(HUB_AUTH_USERNAME)
                        .password(HUB_AUTH_PASSWORD)
                        .build())
        .build();

    client.build(Paths.get(dockerDirectory), HUB_PUBLIC_IMAGE);
    client.push(HUB_PUBLIC_IMAGE);
  }
",non-flaky,5
98261,spotify_docker-client,PushPullIT.testPushHubPrivateImageWithAuth,"  @Test
  public void testPushHubPrivateImageWithAuth() throws Exception {
    // Push an image to a private repo on Docker Hub and check it succeeds
    final String dockerDirectory = Resources.getResource(""dockerDirectory"").getPath();
    final DockerClient client = DefaultDockerClient
        .fromEnv()
        .registryAuth(RegistryAuth.builder()
                        .username(HUB_AUTH_USERNAME)
                        .password(HUB_AUTH_PASSWORD)
                        .build())
        .build();

    client.build(Paths.get(dockerDirectory), HUB_PRIVATE_IMAGE);
    client.push(HUB_PRIVATE_IMAGE);
  }
",non-flaky,5
98262,spotify_docker-client,PushPullIT.testPullHubPrivateRepoWithBadAuth,"  @Test
  public void testPullHubPrivateRepoWithBadAuth() throws Exception {
    final RegistryAuth badRegistryAuth = RegistryAuth.builder()
        .username(HUB_AUTH_USERNAME2)
        .password(""foobar"")
        .build();
    exception.expect(DockerException.class);
    exception.expectCause(isA(NotAuthorizedException.class));
    client.pull(CIRROS_PRIVATE_LATEST, badRegistryAuth);
  }
",non-flaky,5
98263,spotify_docker-client,PushPullIT.testBuildHubPrivateRepoWithAuth,"  @Test
  public void testBuildHubPrivateRepoWithAuth() throws Exception {
    final String dockerDirectory = Resources.getResource(""dockerDirectoryNeedsAuth"").getPath();
    final RegistryAuth registryAuth = RegistryAuth.builder()
        .username(HUB_AUTH_USERNAME2)
        .password(HUB_AUTH_PASSWORD2)
        .build();

    final DefaultDockerClient client = DefaultDockerClient.fromEnv()
        .registryAuth(registryAuth)
        .build();

    client.build(Paths.get(dockerDirectory), ""testauth"", BuildParam.pullNewerImage());
  }
",non-flaky,5
98264,spotify_docker-client,PushPullIT.testPullHubPrivateRepoWithAuth,"  @Test
  public void testPullHubPrivateRepoWithAuth() throws Exception {
    final RegistryAuth registryAuth = RegistryAuth.builder()
        .username(HUB_AUTH_USERNAME2)
        .password(HUB_AUTH_PASSWORD2)
        .build();
    client.pull(""dxia2/scratch-private:latest"", registryAuth);
  }
",non-flaky,5
98265,spotify_docker-client,ContainerStatsTest.test1_26,"  @Test
  public void test1_26() throws Exception {
    objectMapper.readValue(fixture(""fixtures/1.26/containerStats.json""), ContainerStats.class);
  }
",non-flaky,5
98266,spotify_docker-client,ContainerStateTest.testLoadFromRandomFixture,"  @Test
  public void testLoadFromRandomFixture() throws Exception {
    final ContainerState containerState = objectMapper
        .readValue(fixture(""fixtures/container-state-random.json""), ContainerState.class);
    assertThat(containerState.paused(), is(false));
    assertThat(containerState.restarting(), is(false));
    assertThat(containerState.running(), is(true));
    assertThat(containerState.exitCode(), is(0));
    assertThat(containerState.pid(), is(27629));
    assertThat(containerState.startedAt(), is(new Date(1412236798929L)));
    assertThat(containerState.finishedAt(), is(new Date(-62135769600000L)));
    assertThat(containerState.error(), is(""this is an error""));
    assertThat(containerState.oomKilled(), is(false));
    assertThat(containerState.status(), is(""running""));
    
    ContainerState.Health health = containerState.health();
    assertThat(health.failingStreak(), is(1));
    assertThat(health.status(), is(""starting""));
    assertThat(health.log().size(), is(1));
    
    ContainerState.HealthLog log = health.log().get(0);
    assertThat(log.start(), is(new Date(1412236801547L)));
    assertThat(log.end(), is(new Date(1412236802697L)));
    assertThat(log.exitCode(), is(1));
    assertThat(log.output(), is(""output""));
  }
",non-flaky,5
98267,spotify_docker-client,ContainerStateTest.testLoadFromRandomFixtureMissingProperty,"  @Test
  public void testLoadFromRandomFixtureMissingProperty() throws Exception {
    objectMapper.readValue(fixture(""fixtures/container-state-missing-property.json""),
                           ContainerState.class);
  }
",non-flaky,5
98268,spotify_docker-client,ContainerStateTest.testLoadInvalidConatainerStateJson,"  @Test
  public void testLoadInvalidConatainerStateJson() throws Exception {
    expectedException.expect(JsonMappingException.class);
    objectMapper.readValue(fixture(""fixtures/container-state-invalid.json""), ContainerState.class);

  }
",non-flaky,5
98269,spotify_docker-client,ContainerStateTest.testLoadInvalidJson,"  @Test
  public void testLoadInvalidJson() throws Exception {
    expectedException.expect(JsonParseException.class);
    objectMapper.readValue(fixture(""fixtures/invalid.json""), ContainerState.class);

  }
",non-flaky,5
98270,spotify_docker-client,ContainerInfoTest.test1_22,"  @Test
  public void test1_22() throws Exception {
    objectMapper.readValue(fixture(""fixtures/1.22/containerInfo.json""), ContainerInfo.class);
  }
",non-flaky,5
98271,spotify_docker-client,ContainerInfoTest.test1_24,"  @Test
  public void test1_24() throws Exception {
    objectMapper.readValue(fixture(""fixtures/1.24/containerInfo.json""), ContainerInfo.class);
  }
",non-flaky,5
98272,spotify_docker-client,HostConfigTest.testJsonAlways,"  @Test
  public void testJsonAlways() throws Exception {
    final HostConfig hostConfig = objectMapper
        .readValue(fixture(""fixtures/hostConfig/restartPolicyAlways.json""),
                   HostConfig.class);
    assertThat(hostConfig.restartPolicy(), is(HostConfig.RestartPolicy.always()));
  }
",non-flaky,5
98273,spotify_docker-client,HostConfigTest.testJsonUnlessStopped,"  @Test
  public void testJsonUnlessStopped() throws Exception {
    final HostConfig hostConfig = objectMapper
        .readValue(fixture(""fixtures/hostConfig/restartPolicyUnlessStopped.json""),
                   HostConfig.class);
    assertThat(hostConfig.restartPolicy(), is(HostConfig.RestartPolicy.unlessStopped()));
  }
",non-flaky,5
98274,spotify_docker-client,HostConfigTest.testJsonOnFailure,"  @Test
  public void testJsonOnFailure() throws Exception {
    final HostConfig hostConfig = objectMapper
        .readValue(fixture(""fixtures/hostConfig/restartPolicyOnFailure.json""),
                   HostConfig.class);
    assertThat(hostConfig.restartPolicy(), is(HostConfig.RestartPolicy.onFailure(5)));
  }
",non-flaky,5
98275,spotify_docker-client,HostConfigTest.testReplaceBinds,"  @Test
  public void testReplaceBinds() {
    final List<String> initialBinds = ImmutableList.of(""/one:/one"", ""/two:/two"");
    final HostConfig hostConfig = HostConfig.builder()
        .binds(initialBinds)
        .binds(initialBinds)
        .build();

    assertThat(""Calling .binds() multiple times should replace the list each time"",
               hostConfig.binds(), is(initialBinds));
  }
",non-flaky,5
98276,spotify_docker-client,HostConfigTest.testAppendBinds,"  @Test
  public void testAppendBinds() {
    final List<String> initialBinds = ImmutableList.of(""/one:/one"", ""/two:/two"");
    final HostConfig hostConfig = HostConfig.builder()
        .binds(initialBinds)
        .appendBinds(""/three:/three"")
        .appendBinds(""/four:/four"")
        .build();

    final List<String> expected = ImmutableList.<String>builder()
        .addAll(initialBinds)
        .add(""/three:/three"")
        .add(""/four:/four"")
        .build();

    assertThat(""Calling .appendBinds should append to the list, not replace"",
               hostConfig.binds(), is(expected));
  }
",non-flaky,5
98277,spotify_docker-client,HostConfigTest.testPreventDuplicateBinds,"  @Test
  public void testPreventDuplicateBinds() {
    final HostConfig hostConfig = HostConfig.builder()
        .appendBinds(""/one:/one"")
        .appendBinds(""/one:/one"")
        .appendBinds(""/one:/one"")
        .build();

    assertThat(hostConfig.binds(), contains(""/one:/one""));
  }
",non-flaky,5
98278,spotify_docker-client,ImageInfoTest.test1_24,"  @Test
  public void test1_24() throws Exception {
    objectMapper.readValue(fixture(""fixtures/1.24/imageInfo.json""), ImageInfo.class);
  }
",non-flaky,5
98279,spotify_docker-client,ProgressMessageTest.testNotADigest,"  @Test
  public void testNotADigest() throws Exception {
    assertNull(readMessage(""not-a-digest"").digest());
  }
",non-flaky,5
98280,spotify_docker-client,ProgressMessageTest.testDigest_Docker16,"  @Test
  public void testDigest_Docker16() throws Exception {
    assertEquals(digest, readMessage(""Digest: "" + digest).digest());
  }
",non-flaky,5
98281,spotify_docker-client,ProgressMessageTest.testDigest_Docker18,"  @Test
  public void testDigest_Docker18() throws Exception {
    final String status = ""some-image-tag: digest: "" + digest + "" size: 1234"";
    assertEquals(digest, readMessage(status).digest());
  }
",non-flaky,5
98282,spotify_docker-client,EventTest.serializationRoundTripTest,"  @Test
  public void serializationRoundTripTest() throws Exception {
    // Test serializing and deserializing the same Event instance works and preserves data
    final Event event = Event.create(""create"", ""foo"", ""nginx"", Event.Type.CONTAINER, ""create"",
        Event.Actor.create(""bar"", ImmutableMap.of(""image"", ""nginx"", ""name"", ""docker-nginx"")),
        new Date(1487356000), 100L);

    final ObjectMapper mapper = ObjectMapperProvider.objectMapper();

    final String json = mapper.writeValueAsString(event);

    final Event event2 = mapper.readValue(json, Event.class);
    assertThat(event, equalTo(event2));
  }
",non-flaky,5
98283,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_FullConfig,"  @Test
  public void testFromDockerConfig_FullConfig() throws Exception {
    final RegistryAuth registryAuth = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/fullConfig.json"")).build();
    assertThat(registryAuth, equalTo(DOCKER_AUTH_CONFIG));
  }
",non-flaky,5
98284,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_FullDockerCfg,"  @Test
  public void testFromDockerConfig_FullDockerCfg() throws Exception {
    final RegistryAuth registryAuth = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/fullDockerCfg"")).build();
    assertThat(registryAuth, equalTo(DOCKER_AUTH_CONFIG));
  }
",non-flaky,5
98285,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_IdentityToken,"  @Test
  public void testFromDockerConfig_IdentityToken() throws Exception {
    final RegistryAuth authConfig = RegistryAuth.fromDockerConfig(getTestFilePath(
            ""dockerConfig/identityTokenConfig.json"")).build();
    assertThat(authConfig, equalTo(IDENTITY_TOKEN_AUTH_CONFIG));
  }
",non-flaky,5
98286,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_IncompleteConfig,"  @Test
  public void testFromDockerConfig_IncompleteConfig() throws Exception {
    final RegistryAuth registryAuth = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/incompleteConfig.json"")).build();
    assertThat(registryAuth, equalTo(EMPTY_AUTH_CONFIG));
  }
",non-flaky,5
98287,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_WrongConfigs,"  @Test
  public void testFromDockerConfig_WrongConfigs() throws Exception {
    final RegistryAuth registryAuth1 = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/wrongConfig1.json"")).build();
    assertThat(registryAuth1, equalTo(EMPTY_AUTH_CONFIG));

    final RegistryAuth registryAuth2 = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/wrongConfig2.json"")).build();
    assertThat(registryAuth2, equalTo(EMPTY_AUTH_CONFIG));
  }
",non-flaky,5
98288,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_MissingConfigFile,"  @Test
  public void testFromDockerConfig_MissingConfigFile() throws Exception {
    final Path randomPath = Paths.get(RandomStringUtils.randomAlphanumeric(16) + "".json"");
    expectedException.expect(FileNotFoundException.class);
    RegistryAuth.fromDockerConfig(randomPath).build();
  }
",non-flaky,5
98289,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_MultiConfig,"  @Test
  public void testFromDockerConfig_MultiConfig() throws Exception {
    final RegistryAuth myDockParsed = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/multiConfig.json""), ""https://narnia.mydock.io/v1/"").build();
    assertThat(myDockParsed, equalTo(MY_AUTH_CONFIG));
    final RegistryAuth dockerIoParsed = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/multiConfig.json""), ""https://index.docker.io/v1/"").build();
    assertThat(dockerIoParsed, equalTo(DOCKER_AUTH_CONFIG));
  }
",non-flaky,5
98290,spotify_docker-client,ContainerTest.testLoadFromFixture,"  @Test
  public void testLoadFromFixture() throws Exception {
    final Container container = objectMapper
        .readValue(fixture(""fixtures/container-ports-as-string.json""), Container.class);
    assertThat(container.portsAsString(), is(""0.0.0.0:80->88/tcp""));
  }
",non-flaky,5
98291,spotify_docker-client,ContainerTest.testLoadFromFixtureMissingPorts,"  @Test
  public void testLoadFromFixtureMissingPorts() throws Exception {
    final Container container = objectMapper
            .readValue(fixture(""fixtures/container-no-ports-or-names.json""), Container.class);
    assertThat(container.id(), is(""1009""));
  }
",non-flaky,5
98292,spotify_docker-client,DockerDateFormatTest.testHandlesMillisecondPrecision,"  @Test
  public void testHandlesMillisecondPrecision() throws Exception {
    assertThat(dockerDateFormat.parse(millisecondDateString), equalTo(expected));
  }
",non-flaky,5
98293,spotify_docker-client,DockerDateFormatTest.testHandlesNanosecondPrecision,"  @Test
  public void testHandlesNanosecondPrecision() throws Exception {
    assertThat(dockerDateFormat.parse(""2015-09-18T17:44:28.145855389Z""), equalTo(expected));
  }
",non-flaky,5
98294,spotify_docker-client,DockerDateFormatTest.testHandlesNanosecondWithLessThanNineDigits,"  @Test
  public void testHandlesNanosecondWithLessThanNineDigits() throws Exception {
    assertThat(dockerDateFormat.parse(""2015-09-18T17:44:28.1458553Z""), equalTo(expected));
  }
",non-flaky,5
98295,spotify_docker-client,DockerDateFormatTest.otherTimeZones,"  @Test
  public void otherTimeZones() throws Exception {
    final Date expected =
        new DateTime(2016, 6, 3, 6, 57, 17, 478, DateTimeZone.forOffsetHours(-4)).toDate();
    assertThat(dockerDateFormat.parse(""2016-06-03T06:57:17.4782869-04:00""), equalTo(expected));
  }
",non-flaky,5
98296,spotify_docker-client,CompressedDirectoryTest.testFile,"  @Test
  public void testFile() throws Exception {
    // note: Paths.get(someURL.toUri()) is the platform-neutral way to convert a URL to a Path
    final URL dockerDirectory = Resources.getResource(""dockerDirectory"");
    try (CompressedDirectory dir = CompressedDirectory.create(Paths.get(dockerDirectory.toURI()));
         BufferedInputStream fileIn = new BufferedInputStream(Files.newInputStream(dir.file()));
         GzipCompressorInputStream gzipIn = new GzipCompressorInputStream(fileIn);
         TarArchiveInputStream tarIn = new TarArchiveInputStream(gzipIn)) {

      final List<String> names = new ArrayList<>();
      TarArchiveEntry entry;
      while ((entry = tarIn.getNextTarEntry()) != null) {
        final String name = entry.getName();
        names.add(name);
      }
      assertThat(names,
                 containsInAnyOrder(""Dockerfile"", ""bin/"", ""bin/date.sh"",
                                    ""innerDir/"", ""innerDir/innerDockerfile""));
    }
  }
",non-flaky,5
98297,spotify_docker-client,CompressedDirectoryTest.testFileWithIgnore,"  @Test
  public void testFileWithIgnore() throws Exception {
    // note: Paths.get(someURL.toUri()) is the platform-neutral way to convert a URL to a Path
    final URL dockerDirectory = Resources.getResource(""dockerDirectoryWithIgnore"");
    try (CompressedDirectory dir = CompressedDirectory.create(Paths.get(dockerDirectory.toURI()));
         BufferedInputStream fileIn = new BufferedInputStream(Files.newInputStream(dir.file()));
         GzipCompressorInputStream gzipIn = new GzipCompressorInputStream(fileIn);
         TarArchiveInputStream tarIn = new TarArchiveInputStream(gzipIn)) {

      final List<String> names = new ArrayList<>();
      TarArchiveEntry entry;
      while ((entry = tarIn.getNextTarEntry()) != null) {
        final String name = entry.getName();
        names.add(name);
      }
      assertThat(names, containsInAnyOrder(""Dockerfile"", ""bin/"", ""bin/date.sh"", ""subdir2/"",
                                           ""subdir2/keep.me"", ""subdir2/do-not.ignore"",
                                           ""subdir3/do.keep"", "".dockerignore""));
    }
  }
",non-flaky,5
98298,spotify_docker-client,CompressedDirectoryTest.testFileWithEmptyDirectory,"  @Test
  public void testFileWithEmptyDirectory() throws Exception {
    Path tempDir = Files.createTempDirectory(""dockerDirectoryEmptySubdirectory"");
    tempDir.toFile().deleteOnExit();
    assertThat(new File(tempDir.toFile(), ""emptySubDir"").mkdir(), is(true));

    try (CompressedDirectory dir = CompressedDirectory.create(tempDir);
         BufferedInputStream fileIn = new BufferedInputStream(Files.newInputStream(dir.file()));
         GzipCompressorInputStream gzipIn = new GzipCompressorInputStream(fileIn);
         TarArchiveInputStream tarIn = new TarArchiveInputStream(gzipIn)) {

      final List<String> names = new ArrayList<>();
      TarArchiveEntry entry;
      while ((entry = tarIn.getNextTarEntry()) != null) {
        final String name = entry.getName();
        names.add(name);
      }
      assertThat(names, contains(""emptySubDir/""));
    }
  }
",non-flaky,5
98299,spotify_docker-client,UnixTimestampDeserializerTest.testFromString,"  @Test
  public void testFromString() throws Exception {
    final String json = toJson(""{\""date\"": \""%s\""}"");

    final TestClass value = OBJECT_MAPPER.readValue(json, TestClass.class);
    assertThat(value.getDate(), equalTo(referenceDateTime.toDate()));
  }
",non-flaky,5
98300,spotify_docker-client,UnixTimestampDeserializerTest.testFromNumber,"  @Test
  public void testFromNumber() throws Exception {
    final String json = toJson(""{\""date\"": %s}"");

    final TestClass value = OBJECT_MAPPER.readValue(json, TestClass.class);
    assertThat(value.getDate(), equalTo(referenceDateTime.toDate()));
  }
",non-flaky,5
98301,spotify_docker-client,UnixTimestampSerializerTest.testToString,"  @Test
  public void testToString() throws Exception {
    final long timestamp = 1487357474682L;
    final String expectedJson = ""{\""date\"":1487357474}"";
    final TestClass testClass = new TestClass(new Date(timestamp));

    final String json = OBJECT_MAPPER.writeValueAsString(testClass);
    assertThat(json, equalTo(expectedJson));
  }
",non-flaky,5
98302,spotify_docker-client,DefaultLogStreamTest.testAttach,"  @Test
  public void testAttach() throws Exception {
    when(reader.nextMessage()).thenReturn(
        logMessage(LogMessage.Stream.STDOUT, ""hello\n""),
        logMessage(LogMessage.Stream.STDERR, ""oops\n""),
        logMessage(LogMessage.Stream.STDOUT, ""world!\n""),
        // need to return null to signal end of stream
        null
    );

    final ByteArrayOutputStream stdout = new ByteArrayOutputStream();
    final ByteArrayOutputStream stderr = new ByteArrayOutputStream();
    logStream.attach(stdout, stderr);

    assertThat(stdout.toString(), is(""hello\nworld!\n""));
    assertThat(stderr.toString(), is(""oops\n""));
  }
",non-flaky,5
98303,spotify_docker-client,DockerRequestExceptionTest.testExceptionMessageWithResponseBody,"  @Test
  public void testExceptionMessageWithResponseBody() {
    final URI uri = URI.create(""http://example.com"");
    final String responseBody = ""uh oh"";
    final DockerRequestException ex =
        new DockerRequestException(""GET"", uri, 500, responseBody, new RuntimeException());

    assertEquals(ex.getMessage(), ""Request error: GET http://example.com: 500, body: uh oh"");
  }
",non-flaky,5
98304,spotify_docker-client,DockerRequestExceptionTest.testExceptionMessageWhenNoResponseBody,"  @Test
  public void testExceptionMessageWhenNoResponseBody() {
    final URI uri = URI.create(""http://example.com"");
    final String responseBody = null;
    final DockerRequestException ex =
        new DockerRequestException(""GET"", uri, 500, responseBody, new RuntimeException());

    assertEquals(ex.getMessage(), ""Request error: GET http://example.com: 500"");
  }
",non-flaky,5
98305,spotify_docker-client,CompressedDirectoryMatchFilepathTest.testMatchFilepath,"  @Test
  public void testMatchFilepath() {
    if (exception != null) {
      expectedException.expect(exception);
    }

    final Path path = fs.getPath(pathString);
    final boolean result = CompressedDirectory.goPathMatcher(fs, pattern).matches(path);

    final String description;
    if (matched) {
      description = MessageFormat.format(""the pattern {0} to match {1}"", pattern, pathString);
    } else {
      description = MessageFormat.format(""the pattern {0} not to match {1}"", pattern, pathString);
    }

    assertThat(result, describedAs(description, is(matched)));
  }
",non-flaky,5
98306,spotify_docker-client,ImageRefTest.testImageWithoutTag,"  @Test
  public void testImageWithoutTag() {
    final ImageRef sut = new ImageRef(""foobar"");
    assertThat(sut.getImage(), equalTo(""foobar""));
    assertThat(sut.getTag(), is(nullValue()));
  }
",non-flaky,5
98307,spotify_docker-client,ImageRefTest.testImageWithTag,"  @Test
  public void testImageWithTag() {
    final ImageRef sut = new ImageRef(""foobar:12345"");
    assertThat(sut.getImage(), equalTo(""foobar""));
    assertThat(sut.getTag(), is(""12345""));
  }
",non-flaky,5
98308,spotify_docker-client,ImageRefTest.testImageWithTagAndRegistry,"  @Test
  public void testImageWithTagAndRegistry() {
    final ImageRef sut = new ImageRef(""registry:4711/foo/bar:12345"");
    assertThat(sut.getImage(), equalTo(""registry:4711/foo/bar""));
    assertThat(sut.getTag(), is(""12345""));
  }
",non-flaky,5
98309,spotify_docker-client,ImageRefTest.testImageWithDigest,"  @Test
  public void testImageWithDigest() {
    final ImageRef sut = new ImageRef(""bar@sha256:12345"");
    assertThat(sut.getImage(), equalTo(""bar@sha256:12345""));
  }
",non-flaky,5
98310,spotify_docker-client,ImageRefTest.testImageWithDigestAndRegistry,"  @Test
  public void testImageWithDigestAndRegistry() {
    final ImageRef sut = new ImageRef(""registry:4711/foo/bar@sha256:12345"");
    assertThat(sut.getImage(), equalTo(""registry:4711/foo/bar@sha256:12345""));
  }
",non-flaky,5
98311,spotify_docker-client,DefaultDockerClientUnitTest.testHostForUnixSocket,"  @Test
  public void testHostForUnixSocket() {
    final DefaultDockerClient client = DefaultDockerClient.builder()
        .uri(""unix:///var/run/docker.sock"").build();
    assertThat(client.getHost(), equalTo(""localhost""));
  }
",non-flaky,5
98312,spotify_docker-client,DefaultDockerClientUnitTest.testHostForLocalHttps,"  @Test
  public void testHostForLocalHttps() {
    final DefaultDockerClient client = DefaultDockerClient.builder()
        .uri(""https://localhost:2375"").build();
    assertThat(client.getHost(), equalTo(""localhost""));
  }
",non-flaky,5
98313,spotify_docker-client,DefaultDockerClientUnitTest.testHostForFqdnHttps,"  @Test
  public void testHostForFqdnHttps() {
    final DefaultDockerClient client = DefaultDockerClient.builder()
        .uri(""https://perdu.com:2375"").build();
    assertThat(client.getHost(), equalTo(""perdu.com""));
  }
",non-flaky,5
98314,spotify_docker-client,DefaultDockerClientUnitTest.testHostForIpHttps,"  @Test
  public void testHostForIpHttps() {
    final DefaultDockerClient client = DefaultDockerClient.builder()
        .uri(""https://192.168.53.103:2375"").build();
    assertThat(client.getHost(), equalTo(""192.168.53.103""));
  }
",non-flaky,5
98315,spotify_docker-client,DefaultDockerClientUnitTest.testNoHeaders,"  @Test
  public void testNoHeaders() throws Exception {
    final DefaultDockerClient dockerClient = new DefaultDockerClient(
        builder, clientBuilderSupplier);
    dockerClient.info();

    verify(builderMock, never()).header(anyString(), anyString());
  }
",non-flaky,5
98316,spotify_docker-client,DefaultDockerClientUnitTest.testOneHeader,"  @Test
  public void testOneHeader() throws Exception {
    builder.header(""foo"", 1);

    final DefaultDockerClient dockerClient = new DefaultDockerClient(
        builder, clientBuilderSupplier);
    dockerClient.info();

    final ArgumentCaptor<String> keyArgument = ArgumentCaptor.forClass(String.class);
    final ArgumentCaptor<Object> valueArgument = ArgumentCaptor.forClass(Object.class);
    verify(builderMock, times(1)).header(keyArgument.capture(), valueArgument.capture());

    Assert.assertEquals(""foo"", keyArgument.getValue());
    Assert.assertEquals(1, valueArgument.getValue());
  }
",non-flaky,5
98317,spotify_docker-client,DefaultDockerClientUnitTest.testMultipleHeaders,"  @Test
  public void testMultipleHeaders() throws Exception {
    final Map<String, Object> headers = Maps.newHashMap();
    headers.put(""int"", 1);
    headers.put(""string"", ""2"");
    headers.put(""list"", Lists.newArrayList(""a"", ""b"", ""c""));

    for (final Map.Entry<String, Object> entry : headers.entrySet()) {
      builder.header(entry.getKey(), entry.getValue());
    }

    final DefaultDockerClient dockerClient = new DefaultDockerClient(
        builder, clientBuilderSupplier);
    dockerClient.info();

    final ArgumentCaptor<String> nameCaptor = ArgumentCaptor.forClass(String.class);
    final ArgumentCaptor<String> valueCaptor = ArgumentCaptor.forClass(String.class);
    verify(builderMock, times(headers.size())).header(nameCaptor.capture(), valueCaptor.capture());

    int idx = 0;
    for (final Map.Entry<String, Object> entry : headers.entrySet()) {
      Assert.assertEquals(entry.getKey(), nameCaptor.getAllValues().get(idx));
      Assert.assertEquals(entry.getValue(), valueCaptor.getAllValues().get(idx));
      ++idx;
    }
  }
",non-flaky,5
98318,spotify_docker-client,DefaultDockerClientUnitTest.testCapAddAndDrop,"  @Test
  public void testCapAddAndDrop() throws Exception {
    final DefaultDockerClient dockerClient = new DefaultDockerClient(
        builder, clientBuilderSupplier);

    final HostConfig hostConfig = HostConfig.builder()
        .capAdd(ImmutableList.of(""foo"", ""bar""))
        .capAdd(ImmutableList.of(""baz"", ""qux""))
        .build();

    final ContainerConfig containerConfig = ContainerConfig.builder()
        .hostConfig(hostConfig)
        .build();

    //noinspection unchecked
    when(asyncInvoker.method(
        anyString(), any(Entity.class), any(Class.class)))
        .thenReturn(Futures.immediateFuture(ContainerCreation.builder().build()));

    dockerClient.createContainer(containerConfig);

    final ArgumentCaptor<String> methodArg = ArgumentCaptor.forClass(String.class);
    final ArgumentCaptor<Entity> entityArg = ArgumentCaptor.forClass(Entity.class);
    final ArgumentCaptor<Class> classArg = ArgumentCaptor.forClass(Class.class);

    //noinspection unchecked
    verify(asyncInvoker, times(1)).method(
        methodArg.capture(), entityArg.capture(), classArg.capture());

    final Entity expectedEntity = Entity.entity(
        containerConfig, new Variant(MediaType.valueOf(APPLICATION_JSON), (String) null, null));

    // Check that we've called the right method on the underlying AsyncInvoker with the right params
    assertThat(methodArg.getValue(), equalTo(""POST""));
    assertThat(entityArg.getValue(), equalTo(expectedEntity));
    assertThat(classArg.getValue(), instanceOf(Class.class));
  }
",non-flaky,5
98319,spotify_docker-client,DockerHostTest.testDefaultDockerEndpoint,"  @Test
  public void testDefaultDockerEndpoint() throws Exception {
    when(systemDelegate.getProperty(""os.name"")).thenReturn(""linux"", ""mac"", ""other"");
    DockerHost.setSystemDelegate(systemDelegate);

    assertThat(DockerHost.defaultDockerEndpoint(), equalTo(""unix:///var/run/docker.sock""));
    assertThat(DockerHost.defaultDockerEndpoint(), equalTo(""unix:///var/run/docker.sock""));
    assertThat(DockerHost.defaultDockerEndpoint(), equalTo(""localhost:2375""));
  }
",non-flaky,5
98320,spotify_docker-client,DockerHostTest.testEndpointFromEnv,"  @Test
  public void testEndpointFromEnv() throws Exception {
    when(systemDelegate.getenv(""DOCKER_HOST"")).thenReturn(""foo"", (String) null);
    when(systemDelegate.getProperty(""os.name"")).thenReturn(""linux"");
    DockerHost.setSystemDelegate(systemDelegate);

    assertThat(DockerHost.endpointFromEnv(), equalTo(""foo""));
    assertThat(DockerHost.endpointFromEnv(), equalTo(""unix:///var/run/docker.sock""));
  }
",non-flaky,5
98321,spotify_docker-client,DockerHostTest.testDefaultUnixEndpoint,"  @Test
  public void testDefaultUnixEndpoint() throws Exception {
    assertThat(DockerHost.defaultUnixEndpoint(), equalTo(""unix:///var/run/docker.sock""));
  }
",non-flaky,5
98322,spotify_docker-client,DockerHostTest.testDefaultAddress,"  @Test
  public void testDefaultAddress() throws Exception {
    assertThat(DockerHost.defaultAddress(), equalTo(""localhost""));
  }
",non-flaky,5
98323,spotify_docker-client,DockerHostTest.testDefaultPort,"  @Test
  public void testDefaultPort() throws Exception {
    assertThat(DockerHost.defaultPort(), equalTo(2375));
  }
",non-flaky,5
98324,spotify_docker-client,DockerHostTest.testPortFromEnv,"  @Test
  public void testPortFromEnv() throws Exception {
    when(systemDelegate.getenv(""DOCKER_PORT"")).thenReturn(""1234"", (String) null);
    DockerHost.setSystemDelegate(systemDelegate);

    assertThat(DockerHost.portFromEnv(), equalTo(1234));
    assertThat(DockerHost.portFromEnv(), equalTo(2375));
  }
",non-flaky,5
98325,spotify_docker-client,DockerHostTest.testDefaultCertPath,"  @Test
  public void testDefaultCertPath() throws Exception {
    when(systemDelegate.getProperty(""user.home"")).thenReturn(""foobar"");
    DockerHost.setSystemDelegate(systemDelegate);

    assertThat(DockerHost.defaultCertPath(), equalTo(""foobar/.docker""));
  }
",non-flaky,5
98326,spotify_docker-client,DockerHostTest.testCertPathFromEnv,"  @Test
  public void testCertPathFromEnv() throws Exception {
    when(systemDelegate.getenv(""DOCKER_CERT_PATH"")).thenReturn(""foo"", (String) null);
    when(systemDelegate.getProperty(""user.home"")).thenReturn(""bar"");
    DockerHost.setSystemDelegate(systemDelegate);

    assertThat(DockerHost.certPathFromEnv(), equalTo(""foo""));
    assertThat(DockerHost.certPathFromEnv(), nullValue());
  }
",non-flaky,5
98327,spotify_docker-client,DockerHostTest.testFromUnixSocket,"  @Test
  public void testFromUnixSocket() throws Exception {
    final String unixSocket = ""unix:///var/run/docker.sock"";
    final String certPath = ""/path/to/cert"";
    final URI unixSocketUri = new URI(unixSocket);

    final DockerHost dockerHost = DockerHost.from(unixSocket, certPath);
    assertThat(dockerHost.host(), equalTo(unixSocket));
    assertThat(dockerHost.uri(), equalTo(unixSocketUri));
    assertThat(dockerHost.bindUri(), equalTo(unixSocketUri));
    assertThat(dockerHost.port(), equalTo(0));
    assertThat(dockerHost.address(), equalTo(""localhost""));
    assertThat(dockerHost.dockerCertPath(), equalTo(certPath));
  }
",non-flaky,5
98328,spotify_docker-client,DockerHostTest.testFromTcpSocketNoCert,"  @Test
  public void testFromTcpSocketNoCert() throws Exception {
    final String tcpSocket = ""tcp://127.0.0.1:2375"";
    final DockerHost dockerHost = DockerHost.from(tcpSocket, null);

    assertThat(dockerHost.host(), equalTo(""127.0.0.1:2375""));
    assertThat(dockerHost.uri(), equalTo(new URI(""http://127.0.0.1:2375"")));
    assertThat(dockerHost.bindUri(), equalTo(new URI(tcpSocket)));
    assertThat(dockerHost.port(), equalTo(2375));
    assertThat(dockerHost.address(), equalTo(""127.0.0.1""));
    assertThat(dockerHost.dockerCertPath(), nullValue());
  }
",non-flaky,5
98329,spotify_docker-client,DockerHostTest.testFromTcpSocketWithCert,"  @Test
  public void testFromTcpSocketWithCert() throws Exception {
    final String tcpSocket = ""tcp://127.0.0.1:2375"";
    final String certPath = ""/path/to/cert"";

    final DockerHost dockerHost = DockerHost.from(tcpSocket, certPath);
    assertThat(dockerHost.host(), equalTo(""127.0.0.1:2375""));
    assertThat(dockerHost.uri(), equalTo(new URI(""https://127.0.0.1:2375"")));
    assertThat(dockerHost.bindUri(), equalTo(new URI(tcpSocket)));
    assertThat(dockerHost.port(), equalTo(2375));
    assertThat(dockerHost.address(), equalTo(""127.0.0.1""));
    assertThat(dockerHost.dockerCertPath(), equalTo(certPath));
  }
",non-flaky,5
98330,spotify_docker-client,DockerHostTest.testFromEnv,"  @Test
  public void testFromEnv() throws Exception {
    when(systemDelegate.getProperty(""os.name"")).thenReturn(""linux"");
    DockerHost.setSystemDelegate(systemDelegate);

    final String dockerHostEnvVar = DockerHost.defaultDockerEndpoint();
    final boolean isUnixSocket = dockerHostEnvVar.startsWith(""unix://"");
    final URI dockerHostUri = new URI(dockerHostEnvVar);

    final String dockerHostAndPort;
    final URI dockerHostHttpUri;
    final URI dockerTcpUri;
    final int dockerHostPort;
    final String dockerHostHost;
    if (isUnixSocket) {
      dockerHostAndPort = dockerHostEnvVar;
      dockerHostHttpUri = dockerHostUri;
      dockerTcpUri = dockerHostUri;
      dockerHostPort = 0;
      dockerHostHost = ""localhost"";
    } else {
      dockerHostAndPort = dockerHostUri.getHost() + "":"" + dockerHostUri.getPort();
      dockerHostHttpUri = new URI(""http://"" + dockerHostAndPort);
      dockerTcpUri = new URI(""tcp://"" + dockerHostAndPort);
      dockerHostPort = dockerHostUri.getPort();
      dockerHostHost = dockerHostUri.getHost();
    }

    final DockerHost dockerHost = DockerHost.fromEnv();
    assertThat(dockerHost.host(), equalTo(dockerHostAndPort));
    assertThat(dockerHost.uri(), equalTo(dockerHostHttpUri));
    assertThat(dockerHost.bindUri(), equalTo(dockerTcpUri));
    assertThat(dockerHost.port(), equalTo(dockerHostPort));
    assertThat(dockerHost.address(), equalTo(dockerHostHost));
    assertThat(dockerHost.dockerCertPath(), nullValue());
  }
",non-flaky,5
98331,spotify_docker-client,DockerCertificatesTest.testBadDockerCertificates,"  @Test(expected = DockerCertificateException.class)
  public void testBadDockerCertificates() throws Exception {
    // try building a DockerCertificates with specifying a cert path to something that
    // isn't a cert
    DockerCertificates.builder()
        .dockerCertPath(getResourceFile(""dockerInvalidSslDirectory""))
        .build();
  }
",non-flaky,5
98332,spotify_docker-client,DockerCertificatesTest.testNoDockerCertificatesInDir,"  @Test
  public void testNoDockerCertificatesInDir() throws Exception {
    final Path certDir = Paths.get(System.getProperty(""java.io.tmpdir""));
    final Optional<DockerCertificatesStore> result = DockerCertificates.builder()
        .dockerCertPath(certDir)
        .build();
    assertThat(result.isPresent(), is(false));
  }
",non-flaky,5
98333,spotify_docker-client,DockerCertificatesTest.testDefaultDockerCertificates,"  @Test
  public void testDefaultDockerCertificates() throws Exception {
    DockerCertificates.builder()
        .dockerCertPath(getCertPath())
        .sslFactory(factory)
        .build();

    verify(factory).newSslContext(keyStore.capture(), password.capture(), trustStore.capture());

    final KeyStore.PrivateKeyEntry pkEntry = (KeyStore.PrivateKeyEntry) keyStore.getValue()
        .getEntry(""key"", new KeyStore.PasswordProtection(password.getValue()));

    final KeyStore caKeyStore = trustStore.getValue();

    assertNotNull(pkEntry);
    assertNotNull(pkEntry.getCertificate());
    assertNotNull(caKeyStore.getCertificate(""o=boot2docker""));
  }
",non-flaky,5
98334,spotify_docker-client,DockerCertificatesTest.testDockerCertificatesWithMultiCa,"  @Test
  public void testDockerCertificatesWithMultiCa() throws Exception {
    DockerCertificates.builder()
        .dockerCertPath(getCertPath())
        .caCertPath(getVariant(""ca-multi.pem""))
        .sslFactory(factory)
        .build();

    verify(factory).newSslContext(keyStore.capture(), password.capture(), trustStore.capture());

    final KeyStore.PrivateKeyEntry pkEntry = (KeyStore.PrivateKeyEntry) keyStore.getValue()
        .getEntry(""key"", new KeyStore.PasswordProtection(password.getValue()));

    assertNotNull(pkEntry);
    assertNotNull(pkEntry.getCertificate());
    assertNotNull(trustStore.getValue().getCertificate(
        ""cn=ca-test,o=internet widgits pty ltd,st=some-state,c=cr""));
    assertNotNull(trustStore.getValue().getCertificate(
        ""cn=ca-test-2,o=internet widgits pty ltd,st=some-state,c=cr""));
  }
",non-flaky,5
98335,spotify_docker-client,DockerCertificatesTest.testReadPrivateKeyPkcs1,"  @Test
  public void testReadPrivateKeyPkcs1() throws Exception {
    DockerCertificates.builder()
        .dockerCertPath(getCertPath())
        .clientKeyPath(getVariant(""key-pkcs1.pem""))
        .sslFactory(factory)
        .build();

    verify(factory).newSslContext(keyStore.capture(), password.capture(), trustStore.capture());

    final KeyStore.PrivateKeyEntry pkEntry = (KeyStore.PrivateKeyEntry) keyStore.getValue()
        .getEntry(""key"", new KeyStore.PasswordProtection(password.getValue()));

    assertNotNull(pkEntry.getPrivateKey());
  }
",non-flaky,5
98336,spotify_docker-client,DockerCertificatesTest.testReadPrivateKeyPkcs8,"  @Test
  public void testReadPrivateKeyPkcs8() throws Exception {
    DockerCertificates.builder()
        .dockerCertPath(getCertPath())
        .clientKeyPath(getVariant(""key-pkcs8.pem""))
        .sslFactory(factory)
        .build();

    verify(factory).newSslContext(keyStore.capture(), password.capture(), trustStore.capture());

    final KeyStore.PrivateKeyEntry pkEntry = (KeyStore.PrivateKeyEntry) keyStore.getValue()
        .getEntry(""key"", new KeyStore.PasswordProtection(password.getValue()));

    assertNotNull(pkEntry.getPrivateKey());
  }
",non-flaky,5
70,OpenLCB_OpenLCB_Java,MemoryConfigurationServiceInterfaceTest.testReadWithTimeoutInterleaved,"@Test
public void testReadWithTimeoutInterleaved() {
    int space = 0xfd;
    long address = 0x12345678;
    int length = 4;
    MemoryConfigurationService.McsReadHandler hnd = mock(McsReadHandler.class);
    MemoryConfigurationService.McsReadHandler hnd2 = mock(McsReadHandler.class);
    iface.getDatagramMeteringBuffer().setTimeout(30);
    iface.getMemoryConfigurationService().setTimeoutMillis(30);
    {
        iface.getMemoryConfigurationService().requestRead(farID, space, address, length, hnd);
        expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x78, 4 }));
        System.err.println(""Expect 'Never received reply' here -->"");
        delay(50);
        System.err.println(""<--"");
        verify(hnd).handleFailure(0x100);
        verifyNoMoreInteractions(hnd);
        iface.getMemoryConfigurationService().requestRead(farID, space, address + 1, length, hnd2);
        expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 }));
        sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80));
        consumeMessages();
        sendMessage(new DatagramRejectedMessage(farID, hereID, 0x2020));
        consumeMessages();
        System.err.println(""Expect 'unexpected response datagram' here -->"");
        sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x78, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID));
        System.err.println(""<--"");
        expectNoMessages();
        delay(50);
        expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 }));
        sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80));
        consumeMessages();
        sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80));
        consumeMessages();
        sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x79, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID));
        verify(hnd2).handleReadData(farID, space, address + 1, new byte[]{ ((byte) (0xaa)) });
        verifyNoMoreInteractions(hnd2);
    }
    System.err.println(""Sending another request..."");
    sendAnother(space, address + 5);
}",async wait,0
91367,OpenLCB_OpenLCB_Java,StreamDataSendMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        int data[]={0x00,0x00,0x00,0x00};
        StreamDataSendMessage t = new StreamDataSendMessage(id1,id2,data);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91368,OpenLCB_OpenLCB_Java,TractionProxyReplyMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID src = new NodeID(new byte[]{6,5,5,4,4,3});
        NodeID dst = new NodeID(new byte[]{2,2,2,4,4,4});
        byte[] payload = new byte[]{0x40,0x01,0x00}; // Traciton Management Reply message
        TractionProxyReplyMessage t = new TractionProxyReplyMessage(src,dst,payload);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91369,OpenLCB_OpenLCB_Java,TractionProxyRequestMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID src = new NodeID(new byte[]{6,5,5,4,4,3});
        NodeID dst = new NodeID(new byte[]{2,2,2,4,4,4});
        byte[] payload = new byte[]{0x40,0x01,0x00}; // Traciton Management Reply message
        TractionProxyRequestMessage t = new TractionProxyRequestMessage(src,dst,payload);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91370,OpenLCB_OpenLCB_Java,TractionControlReplyMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID src = new NodeID(new byte[]{6,5,5,4,4,3});
        NodeID dst = new NodeID(new byte[]{2,2,2,4,4,4});
        byte[] payload = new byte[]{0x40,0x01,0x00}; // Traciton Management Reply message
        TractionControlReplyMessage t = new TractionControlReplyMessage(src,dst,payload);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91371,OpenLCB_OpenLCB_Java,TractionControlReplyMessageTest.testGetcommand,"    @Test
    public void testGetcommand(){
        NodeID src = new NodeID(new byte[]{6,5,5,4,4,3});
        NodeID dst = new NodeID(new byte[]{2,2,2,4,4,4});
        byte[] payload = new byte[]{0x40,0x01,0x00}; // Traciton Management Reply message
        TractionControlReplyMessage t = new TractionControlReplyMessage(src,dst,payload);
        Assert.assertEquals(""command"",0x40,t.getCmd());
    }
",non-flaky,5
91372,OpenLCB_OpenLCB_Java,StreamDataCompleteMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        StreamDataCompleteMessage t = new StreamDataCompleteMessage(id1,id2,(byte)0x00,(byte)0x00);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91373,OpenLCB_OpenLCB_Java,CommonIdentifiersTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        CommonIdentifiers t = new CommonIdentifiers();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91374,OpenLCB_OpenLCB_Java,StreamDataProceedMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        StreamDataProceedMessage t = new StreamDataProceedMessage(id1,id2,(byte)0x00,(byte)0x00);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91375,OpenLCB_OpenLCB_Java,BlueGoldExtendedEngineTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        ScatterGather sg = new ScatterGather();
        EventID eid = new EventID(new byte[]{1,2,3,4,5,6,7,8});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91376,OpenLCB_OpenLCB_Java,VersionOutOfDateExceptionTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        VersionOutOfDateException t = new VersionOutOfDateException();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91377,OpenLCB_OpenLCB_Java,ThrottleFunctionDatagramTest.testCTor,"    @Test
    public void testCTor() {
        ThrottleFunctionDatagram t = new ThrottleFunctionDatagram(0,0);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91378,OpenLCB_OpenLCB_Java,TractionThrottleTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91379,OpenLCB_OpenLCB_Java,TrainNodeCacheTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91380,OpenLCB_OpenLCB_Java,RemoteDccProxyTest.testCTor,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        RemoteDccProxy t = new RemoteDccProxy(nodeID);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91381,OpenLCB_OpenLCB_Java,FdiParserTest.testCTor,"    @Test
    public void testCTor() {
        Element e = new Element(""root"");
        Element segment = new Element(""segment"");
        segment.setAttribute(""space"",""5"");
        segment.setAttribute(""origin"",""0"");
        e.addContent(segment);
        Element group = new Element(""group"");
        group.setAttribute(""offset"",""0"");
        Element fm = new Element(""function"");
        Element fmn = new Element(""name"");
        fmn.addContent(""F1"");
        fm.addContent(fmn);
        fm.setAttribute(""size"",""1"");
        fm.setAttribute(""kind"",""momentary"");
        group.addContent(fm);
        Element ft = new Element(""function"");
        Element ftn = new Element(""name"");
        ftn.addContent(""F2"");
        ft.addContent(ftn);
        ft.setAttribute(""size"",""1"");
        ft.setAttribute(""kind"",""toggle"");
        group.addContent(ft);
        Element fa = new Element(""function"");
        Element fan = new Element(""name"");
        fan.addContent(""F3"");
        fa.addContent(fan);
        fa.setAttribute(""size"",""1"");
        fa.setAttribute(""kind"",""analog"");
        group.addContent(fa);
        e.addContent(group);
        FdiParser t = new FdiParser(e);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91382,OpenLCB_OpenLCB_Java,FdiParserTest.testReadFromFile,"    @Test
    public void testReadFromFile() throws Exception {
        FileReader r = new FileReader(""test/org/openlcb/implementations/throttle/FdiTestFile.xml"");
        Element e = org.openlcb.cdi.jdom.XmlHelper.parseXmlFromReader(r);
        FdiParser t = new FdiParser(e);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91383,OpenLCB_OpenLCB_Java,FakeMemoryConfigurationServiceTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91384,OpenLCB_OpenLCB_Java,MemoryConfigSpaceRetrieverTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91385,OpenLCB_OpenLCB_Java,SingleConsumerTest.put,"    @Test
    public void testCTor() {
        NodeID nid = new NodeID(new byte[]{1,2,3,4,5,6});
        EventID eid = new EventID(new byte[]{1,2,3,4,5,6,7,8});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91386,OpenLCB_OpenLCB_Java,SingleProducerTest.put,"    @Test
    public void testCTor() {
        NodeID nid = new NodeID(new byte[]{1,2,3,4,5,6});
        EventID eid = new EventID(new byte[]{1,2,3,4,5,6,7,8});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91387,OpenLCB_OpenLCB_Java,OlcbInterfaceTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91388,OpenLCB_OpenLCB_Java,BackupConfigTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        BackupConfig t = new BackupConfig();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91389,OpenLCB_OpenLCB_Java,RestoreConfigTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        RestoreConfig t = new RestoreConfig();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91390,OpenLCB_OpenLCB_Java,UtilTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        Util t = new Util();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91391,OpenLCB_OpenLCB_Java,MemorySpaceCacheTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91392,OpenLCB_OpenLCB_Java,DemoReadWriteAccessTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        DemoReadWriteAccess t = new DemoReadWriteAccess();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91393,OpenLCB_OpenLCB_Java,JdomCdiReaderTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        JdomCdiReader t = new JdomCdiReader();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91394,OpenLCB_OpenLCB_Java,XmlHelperTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        XmlHelper t = new XmlHelper();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91395,OpenLCB_OpenLCB_Java,DatagramRejectedMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        DatagramRejectedMessage t = new DatagramRejectedMessage(id1,id2,1);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91396,OpenLCB_OpenLCB_Java,NodeTreeRepTest.put,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        MimicNodeStore store = null;
        NodeID nid1 = new NodeID(new byte[]{1,3,3,4,5,6});
        NodeID nid2 = new NodeID(new byte[]{2,3,3,4,5,6});
    
        ProducerIdentifiedMessage pim1 = new ProducerIdentifiedMessage(nid1, 
                                         new EventID(new byte[]{1,0,0,0,0,0,1,0}), EventState.Unknown);
        Connection connection = new AbstractConnection() {
            public void put(Message msg, Connection sender) {
            }
",non-flaky,5
91397,OpenLCB_OpenLCB_Java,ConsumerPaneTest.put,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        EventID eventID = new EventID(new byte[]{1,0,0,0,0,0,1,0});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection sender) {
            }
",non-flaky,5
91398,OpenLCB_OpenLCB_Java,NodeIdTextFieldTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        NodeIdTextField t = new NodeIdTextField();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91399,OpenLCB_OpenLCB_Java,ProducerPaneTest.put,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        EventID eventID = new EventID(new byte[]{1,0,0,0,0,0,1,0});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection sender) {
            }
",non-flaky,5
91400,OpenLCB_OpenLCB_Java,GridConnectOutputTest.run,"    @Test
    public void testCTor() {
        GridConnectOutput t = new GridConnectOutput(new java.io.ByteArrayOutputStream(), new Runnable(){
    public void run(){
    }
",non-flaky,5
91401,OpenLCB_OpenLCB_Java,GridConnectInputTest.run,"    @Test
    public void testCTor() {
        java.io.BufferedReader br = new java.io.BufferedReader(new java.io.StringReader(""""));
        GridConnectInput t = new GridConnectInput(br, new CanFrameListenerScaffold(), new Runnable(){
    public void run(){
    }
",non-flaky,5
91402,OpenLCB_OpenLCB_Java,OlcbConnectionTest.onConnect,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        OlcbConnection t = new OlcbConnection(nodeID,""test"",5,new OlcbConnection.ConnectionListener(){
            @Override
            public void onConnect(){
            }
",non-flaky,5
91403,OpenLCB_OpenLCB_Java,CanInterfaceTest.testCTor,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        CanInterface t = new CanInterface(nodeID, new CanFrameListenerScaffold() );
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91404,OpenLCB_OpenLCB_Java,DefaultPropertyListenerSupportTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        DefaultPropertyListenerSupport t = new DefaultPropertyListenerSupport();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91405,OpenLCB_OpenLCB_Java,HubTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        Hub t = new Hub();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91406,OpenLCB_OpenLCB_Java,StreamInitiateReplyMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        StreamInitiateReplyMessage t = new StreamInitiateReplyMessage(id1,id2,0,(byte)0x00,(byte)0x00);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91407,OpenLCB_OpenLCB_Java,DatagramAcknowledgedMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        DatagramAcknowledgedMessage t = new DatagramAcknowledgedMessage(id1,id2);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91408,OpenLCB_OpenLCB_Java,VerifyNodeIdHandlerTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91409,OpenLCB_OpenLCB_Java,StreamInitiateRequestMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        StreamInitiateRequestMessage t = new StreamInitiateRequestMessage(id1,id2,0,(byte)0x00,(byte)0x00);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91410,OpenLCB_OpenLCB_Java,CollapsiblePanelTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        CollapsiblePanel t = new CollapsiblePanel(""test"",new javax.swing.JPanel());
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91411,OpenLCB_OpenLCB_Java,GridLayout2Test.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        GridLayout2 t = new GridLayout2();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
322,triplea-game_triplea,close,"@Test
void close() throws Exception {
    when(webSocketClient.getConnection()).thenReturn(webSocket);
    when(webSocketClient.isOpen()).thenReturn(true);
    webSocketConnection.close();
    Thread.sleep(10);
    verify(webSocket).close();
}",async wait,0
160320,triplea-game_triplea,AbstractPropertyReaderTestCase.setupPropertyReader,"    @BeforeEach
    public void setupPropertyReader() throws Exception {
      propertyReader = newSingletonPropertyReader(PRESENT_PROPERTY_VALUE);
    }
",non-flaky,5
160321,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldThrowExceptionWhenKeyIsNull,"    @Test
    public void shouldThrowExceptionWhenKeyIsNull() {
      assertThrows(NullPointerException.class, () -> propertyReader.readProperty(null));
    }
",non-flaky,5
160322,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldThrowExceptionWhenKeyIsEmptyOrOnlyWhitespace,"    @Test
    public void shouldThrowExceptionWhenKeyIsEmptyOrOnlyWhitespace() {
      assertThrows(IllegalArgumentException.class, () -> propertyReader.readProperty(""""));
      assertThrows(IllegalArgumentException.class, () -> propertyReader.readProperty(""    ""));
    }
",non-flaky,5
160323,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldReturnValueWhenKeyIsPresent,"    @Test
    public void shouldReturnValueWhenKeyIsPresent() {
      assertThat(propertyReader.readProperty(PRESENT_PROPERTY_KEY), is(PRESENT_PROPERTY_VALUE));
    }
",non-flaky,5
160324,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldReturnTrimmedValueWhenKeyIsPresentAndValueHasLeadingAndTrailingWhitespace,"    @Test
    public void shouldReturnTrimmedValueWhenKeyIsPresentAndValueHasLeadingAndTrailingWhitespace()
        throws Exception {
      final PropertyReader propertyReader =
          newSingletonPropertyReader(""  "" + PRESENT_PROPERTY_VALUE + ""  "");

      assertThat(propertyReader.readProperty(PRESENT_PROPERTY_KEY), is(PRESENT_PROPERTY_VALUE));
    }
",non-flaky,5
160325,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldReturnEmptyWhenKeyIsAbsent,"    @Test
    public void shouldReturnEmptyWhenKeyIsAbsent() {
      assertThat(propertyReader.readProperty(ABSENT_PROPERTY_KEY), is(emptyString()));
    }
",non-flaky,5
160326,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldReturnValueWhenKeyIsPresent,"    @Test
    public void shouldReturnValueWhenKeyIsPresent() throws Exception {
      final String value = ""value"";
      final PropertyReader propertyReader = newSingletonPropertyReader(value);

      assertThat(
          propertyReader.readPropertyOrDefault(PRESENT_PROPERTY_KEY, ""defaultValue""), is(value));
    }
",non-flaky,5
160327,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldReturnDefaultValueWhenKeyIsAbsent,"    @Test
    public void shouldReturnDefaultValueWhenKeyIsAbsent() throws Exception {
      final String defaultValue = ""defaultValue"";
      final PropertyReader propertyReader = newEmptyPropertyReader();

      assertThat(
          propertyReader.readPropertyOrDefault(ABSENT_PROPERTY_KEY, defaultValue),
          is(defaultValue));
    }
",non-flaky,5
160328,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldReturnValueWhenKeyIsPresent,"    @Test
    public void shouldReturnValueWhenKeyIsPresent() throws Exception {
      final boolean value = true;
      final PropertyReader propertyReader = newSingletonPropertyReader(String.valueOf(value));

      assertThat(
          propertyReader.readBooleanPropertyOrDefault(PRESENT_PROPERTY_KEY, false), is(value));
    }
",non-flaky,5
160329,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldReturnDefaultValueWhenKeyIsAbsent,"    @Test
    public void shouldReturnDefaultValueWhenKeyIsAbsent() throws Exception {
      final boolean defaultValue = true;
      final PropertyReader propertyReader = newEmptyPropertyReader();

      assertThat(
          propertyReader.readBooleanPropertyOrDefault(ABSENT_PROPERTY_KEY, defaultValue),
          is(defaultValue));
    }
",non-flaky,5
160330,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldReturnValueWhenKeyIsPresent,"    @Test
    public void shouldReturnValueWhenKeyIsPresent() throws Exception {
      final int value = 42;
      final PropertyReader propertyReader = newSingletonPropertyReader(String.valueOf(value));

      assertThat(propertyReader.readIntegerPropertyOrDefault(PRESENT_PROPERTY_KEY, -1), is(value));
    }
",non-flaky,5
160331,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldReturnDefaultValueWhenKeyIsPresentAndValueIsNotAnInteger,"    @Test
    public void shouldReturnDefaultValueWhenKeyIsPresentAndValueIsNotAnInteger() throws Exception {
      final int defaultValue = 777;
      final PropertyReader propertyReader = newSingletonPropertyReader(""other"");

      assertThat(
          propertyReader.readIntegerPropertyOrDefault(PRESENT_PROPERTY_KEY, defaultValue),
          is(defaultValue));
    }
",non-flaky,5
160332,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldReturnDefaultValueWhenKeyIsAbsent,"    @Test
    public void shouldReturnDefaultValueWhenKeyIsAbsent() throws Exception {
      final int defaultValue = 777;
      final PropertyReader propertyReader = newEmptyPropertyReader();

      assertThat(
          propertyReader.readIntegerPropertyOrDefault(ABSENT_PROPERTY_KEY, defaultValue),
          is(defaultValue));
    }
",non-flaky,5
160333,triplea-game_triplea,MessengerIntegrationTest.connectionRemoved,"  @Test
          public void connectionRemoved(final INode to) {
            serverCount.decrementAndGet();
          }
",non-flaky,5
160334,triplea-game_triplea,MessengerIntegrationTest.messageReceived,"  @Test
    public void messageReceived(final Serializable msg, final INode from) {
      synchronized (lock) {
        messages.add(msg);
        senders.add(from);
        lock.notifyAll();
      }
    }
",non-flaky,5
160335,triplea-game_triplea,ChatIntegrationTest.updatePlayerList,"  @Test
    public void updatePlayerList(final Collection<ChatParticipant> players) {
      playerCount.set(players.size());
    }
",non-flaky,5
160336,triplea-game_triplea,RemoteMessengerTest.increment,"  @Test
    public int increment(final int testVal) {
      senderNode = MessageContext.getSender();
      return testVal + 1;
    }
",non-flaky,5
160337,triplea-game_triplea,ChannelMessengerTest.testNoParams,"  @Test
    public void testNoParams() {
      incrementCount();
    }
",non-flaky,5
160338,triplea-game_triplea,ThreadPoolTest.run,"  @Test
    public void run() {
      Interruptibles.sleep(0L, 1);
      done = true;
    }
",non-flaky,5
160339,triplea-game_triplea,LobbyLoginValidatorTest.createLobbyLoginValidator,"    @BeforeEach
    public void createLobbyLoginValidator() throws Exception {
      lobbyLoginValidator =
          new LobbyLoginValidator(
              databaseDao,
              new RsaAuthenticator(TestSecurityUtils.loadRsaKeyPair()),
              () -> bcryptSalt,
              failedLoginThrottle,
              tempPasswordVerification,
              new AllowLoginRules(databaseDao),
              AllowCreateUserRules.builder()
                  .userDao(userDao)
                  .nameValidator(PlayerNameValidation::validate)
                  .emailValidator(PlayerEmailValidation::validate)
                  .build());
    }
",non-flaky,5
160340,triplea-game_triplea,LobbyLoginValidatorTest.givenNoBans,"    @BeforeEach
    public void givenNoBans() {
      givenNoMacIsBanned();
      givenNoUsernameIsBanned();
      when(databaseDao.getBadWordDao()).thenReturn(badWordDao);
    }
",non-flaky,5
216,julianghionoiu_dpnt-coverage,CoverageDatapointAcceptanceTest.create_repo_and_uploads_commits,"@Test
public void create_repo_and_uploads_commits() throws Exception {
    String challengeId = ""TCH"";
    String participantId = generateId();
    String s3destination = String.format(""%s/%s/file.srcs"", challengeId, participantId);
    TestSrcsFile srcsForTestChallenge = new TestSrcsFile(""HmmmLang_R1Cov33_R2Cov44.srcs"");
    S3Event s3Event = localS3Bucket.putObject(srcsForTestChallenge.asFile(), s3destination);
    coverageUploadHandler.handleRequest(convertToMap(wrapAsSNSEvent(s3Event)),NO_CONTEXT);
    waitForQueueToReceiveEvents();
    assertThat(languageDetectedEvents.size(), equalTo(1));
    System.out.println(""Received language detected events: ""+languageDetectedEvents);
    ProgrammingLanguageDetectedEvent languageEvent = languageDetectedEvents.get(0);
    assertThat(languageEvent.getParticipant(), equalTo(participantId));
    assertThat(languageEvent.getChallengeId(), equalTo(challengeId));
    assertThat(languageEvent.getProgrammingLanguage(), equalTo(""HmmmLang""));
    assertThat(coverageComputedEvents.size(), equalTo(2));
    System.out.println(""Received coverage events: ""+coverageComputedEvents);
    coverageComputedEvents.sort(Comparator.comparing(CoverageComputedEvent::getRoundId));
    CoverageComputedEvent coverageRound1 = coverageComputedEvents.get(0);
    assertThat(coverageRound1.getParticipant(), equalTo(participantId));
    assertThat(coverageRound1.getRoundId(), equalTo(challengeId+""_R1""));
    assertThat(coverageRound1.getCoverage(), equalTo(33));
    CoverageComputedEvent coverageRound2 = coverageComputedEvents.get(1);
    assertThat(coverageRound2.getParticipant(), equalTo(participantId));
    assertThat(coverageRound2.getRoundId(), equalTo(challengeId+""_R2""));
    assertThat(coverageRound2.getCoverage(), equalTo(44));
}",async wait,0
133893,julianghionoiu_dpnt-coverage,EventSupportTest.correctly_create_s3_event,"    @Test
    public void correctly_create_s3_event() throws JsonProcessingException {
        S3Event s3Event = new S3Event(""my_bucket"", ""my_key"");

        String output = objectMapper.writeValueAsString(s3Event.asJsonNode());

        assertThat(output, equalTo(""{\""Records\"":[{\""s3\"":"" +
                ""{\""bucket\"":{\""name\"":\""my_bucket\""},"" +
                ""\""object\"":{\""key\"":\""my_key\""}}}"" +
                ""]}""));
    }
",non-flaky,5
133894,julianghionoiu_dpnt-coverage,EventSupportTest.correctly_create_sns_event,"    @Test
    public void correctly_create_sns_event() throws JsonProcessingException {
        SNSEvent snsEvent = new SNSEvent(""{ \""key\"": \""value\"" }"");

        String output = objectMapper.writeValueAsString(snsEvent.asJsonNode());

        assertThat(output, equalTo(""{\""Records\"":[{\""Sns\"":"" +
                ""{\""Message\"":\""{ \\\""key\\\"": \\\""value\\\"" }\""}}"" +
                ""]}""));
    }
",non-flaky,5
133895,julianghionoiu_dpnt-coverage,LanguageTest.should_identify_language_based_on_key,"    @Test
    public void should_identify_language_based_on_key() throws IllegalLanguageException {
        assertThat(Language.of(""java""), is(JAVA));
    }
",non-flaky,5
133896,julianghionoiu_dpnt-coverage,LanguageTest.should_identify_language_based_on_alternative_name,"    @Test
    public void should_identify_language_based_on_alternative_name() throws IllegalLanguageException {
        assertThat(Language.of(""js""), is(JAVASCRIPT));
        assertThat(Language.of(""C#""), is(CSHARP));
    }
",non-flaky,5
133897,julianghionoiu_dpnt-coverage,LanguageTest.should_ignore_spaces_and_capitalisation_when_matching,"    @Test
    public void should_ignore_spaces_and_capitalisation_when_matching() throws IllegalLanguageException {
        assertThat(Language.of(""  JaVa \n  ""), is(JAVA));
    }
",non-flaky,5
133898,julianghionoiu_dpnt-coverage,LanguageTest.should_throw_exception_if_language_not_recognised,"    @Test
    public void should_throw_exception_if_language_not_recognised() throws IllegalLanguageException {
        thrown.expect(IllegalLanguageException.class);
        Language.of(""none"");
    }
",non-flaky,5
16,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireObjectEvent,"@Test
public void testFireObjectEvent() throws Exception {
    final NamingEventCoordinator coordinator = new NamingEventCoordinator();
    final CollectingListener objectListener = new CollectingListener(1);
    coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
    final CollectingListener subtreeListener = new CollectingListener(0);
    coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
    final CollectingListener oneLevelListener = new CollectingListener(0);
    coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);
    coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE);
    objectListener.latch.await(1, TimeUnit.SECONDS);
    assertEquals(1, objectListener.capturedEvents.size());
    assertTrue(oneLevelListener.capturedEvents.isEmpty());
    assertTrue(subtreeListener.capturedEvents.isEmpty());
}",test order dependency,4
29,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testCreateSubcontext,"@Test
public void testCreateSubcontext() throws Exception {
    assertTrue(namingContext.createSubcontext(new CompositeName(""test"")) instanceof NamingContext);
    assertTrue(testActionPermission(JndiPermission.ACTION_CREATE_SUBCONTEXT, namingContext, ""securitytest"") instanceof NamingContext);
}",test order dependency,4
35,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupContextLink,"@Test
public void testLookupContextLink() throws Exception {
    final Name name = new CompositeName(""test/value"");
    namingStore.bind(name, ""testValue"");
    final Name linkName = new CompositeName(""link"");
    namingStore.bind(linkName, new LinkRef(""./test""));
    Object result = namingContext.lookup(""link/value"");
    assertEquals(""testValue"", result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup""),
    new JndiPermission(""test/value"", ""lookup"")), namingContext, ""link/value"");
    assertEquals(""testValue"", result);
}",test order dependency,4
44,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupEmptyName,"@Test
public void testLookupEmptyName() throws Exception {
    Object result = namingContext.lookup(new CompositeName());
    assertTrue(result instanceof NamingContext);
    result = namingContext.lookup(new CompositeName(""""));
    assertTrue(result instanceof NamingContext);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, null);
    assertTrue(result instanceof NamingContext);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, """");
    assertTrue(result instanceof NamingContext);
}",test order dependency,4
50,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testCompositeBindingOps,"@Test
public void testCompositeBindingOps() throws Exception {
    final KernelServices services = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build();
    final ModelNode addr = Operations.createAddress(ModelDescriptionConstants.SUBSYSTEM, NamingExtension.SUBSYSTEM_NAME, NamingSubsystemModel.BINDING, ""java:global/alookup"");
    final ModelNode addOp = Operations.createAddOperation(addr);
    addOp.get(NamingSubsystemModel.BINDING_TYPE).set(NamingSubsystemModel.LOOKUP);
    final ModelNode compositeOp = Operations.CompositeOperationBuilder.create().addStep(addOp).addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.LOOKUP, ""java:global/a"")).build().getOperation();
    ModelTestUtils.checkOutcome(services.executeOperation(compositeOp));
}",test order dependency,4
58,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBindAndRetrieveObjectFactoryFromNamingContext,"@Test
public void testBindAndRetrieveObjectFactoryFromNamingContext() throws Exception {
    final Reference reference = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null);
    namingStore.bind(new CompositeName(""test""), reference);
    final Object result = namingContext.lookup(""test"");
    assertTrue(result instanceof String);
    assertEquals(""Test ParsedResult"", result);
}",test order dependency,4
62,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testJavaContext,"@Test
public void testJavaContext() throws Exception {
    System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
    System.setProperty(Context.URL_PKG_PREFIXES, ""org.jboss.as.naming.interfaces"");
    InitialContext initialContext = new InitialContext();
    Context context = (Context) initialContext.lookup(""java:"");
    assertTrue(context instanceof NamingContext);
}",test order dependency,4
63,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupWithContinuation,"@Test
public void testLookupWithContinuation() throws Exception {
    namingStore.bind(new CompositeName(""comp/nested""), ""test"");
    final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""nns"", ""comp""), TestObjectFactoryWithNameResolution.class.getName(), null);
    namingStore.bind(new CompositeName(""test""), reference);
    Object result = namingContext.lookup(new CompositeName(""test/nested""));
    assertEquals(""test"", result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""comp/nested"", ""lookup"")), namingContext, ""test/nested"");
    assertEquals(""test"", result);
}",test order dependency,4
65,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testInitialFactory,"@Test
public void testInitialFactory() throws Exception {
    System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
    InitialContext initialContext = new InitialContext();
    Context context = (Context) initialContext.lookup("""");
    assertTrue(context instanceof NamingContext);
    if (!NamingManager.hasInitialContextFactoryBuilder()) {
        NamingManager.setInitialContextFactoryBuilder(new InitialContextFactoryBuilder());
    }
    initialContext = new InitialContext();
    context = (Context) initialContext.lookup("""");
    assertTrue(context instanceof NamingContext);
}",test order dependency,4
74,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBind.2,"@Test
public void testBind() throws Exception {
    final Name name = new CompositeName(""test"");
    final Object value = new Object();
    WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
    try {
        store.bind(name, value);
    } finally {
        WritableServiceBasedNamingStore.popOwner();
    }
    assertEquals(value, store.lookup(name));
}",test order dependency,4
79,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRejectionEAP6,"@Test
public void testRejectionsEAP6() throws Exception {
    testTransformer(""subsystem.xml"", ModelTestControllerVersion.EAP_6_4_0, ModelVersion.create(1, 3),""jboss-as-naming"");
}",test order dependency,4
82,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupLink,"@Test
public void testLookupLink() throws Exception {
    final Name name = new CompositeName(""test"");
    namingStore.bind(name, ""testValue"", String.class);
    final Name linkName = new CompositeName(""link"");
    namingStore.bind(linkName, new LinkRef(""./test""));
    Object result = namingContext.lookup(linkName);
    assertEquals(""testValue"", result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link"");
    assertEquals(""testValue"", result);
    System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
    namingStore.rebind(linkName, new LinkRef(name));
    result = namingContext.lookup(linkName);
    assertEquals(""testValue"", result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link"");
    assertEquals(""testValue"", result);
}",test order dependency,4
89,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupReference,"@Test
public void testLookupReference() throws Exception {
    final Name name = new CompositeName(""test"");
    final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""blah"", ""test""), TestObjectFactory.class.getName(), null);
    namingStore.bind(name, reference);
    Object result = namingContext.lookup(name);
    assertEquals(""test"", result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
    assertEquals(""test"", result);
}",test order dependency,4
104,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListNameNotFound,"@Test
public void testListNameNotFound() throws Exception {
    try {
        namingContext.list(new CompositeName(""test""));
        fail(""Should have thrown and NameNotFoundException"");
    } catch (NameNotFoundException expected) {
    }
    try {
        testActionPermission(JndiPermission.ACTION_LIST, namingContext, ""test"");
        fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
    } catch (NameNotFoundException expected) {
    }
}",test order dependency,4
149,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testCompositeBindingUpdate,"@Test
public void testCompositeBindingUpdate() throws Exception {
    final KernelServices services = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build();
    final ModelNode addr = Operations.createAddress(ModelDescriptionConstants.SUBSYSTEM, NamingExtension.SUBSYSTEM_NAME, NamingSubsystemModel.BINDING, ""java:global/a"");
    final ModelNode compositeOp = Operations.CompositeOperationBuilder.create()
    .addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.BINDING_TYPE, NamingSubsystemModel.LOOKUP))
    .addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.LOOKUP, ""java:global/b""))
    .build().getOperation();
    ModelTestUtils.checkOutcome(services.executeOperation(compositeOp));
}",test order dependency,4
157,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testStoredContext,"@Test
public void testStoredContext() throws Exception {
    final ServiceName bindingName = ServiceName.JBOSS.append(""foo-stored"").append(""again"");
    bindObject(bindingName, new Context() {
        @Override
        public Object lookup(Name name) throws NamingException {
            if (""blah/blah2"".equals(name.toString())) {
                return new Integer(5);
            }
            return null;
        }
        @Override
        public Object lookup(String name) throws NamingException {
            return lookup(new CompositeName(name));
        }
        @Override
        public void bind(Name name, Object obj) throws NamingException {
        }
        @Override
        public void bind(String name, Object obj) throws NamingException {
        }
        @Override
        public void rebind(Name name, Object obj) throws NamingException {
        }
        @Override
        public void rebind(String name, Object obj) throws NamingException {
        }
        @Override
        public void unbind(Name name) throws NamingException {
        }
        @Override
        public void unbind(String name) throws NamingException {
        }
        @Override
        public void rename(Name oldName, Name newName) throws NamingException {
        }
        @Override
        public void rename(String oldName, String newName) throws NamingException {
        }
        @Override
        public NamingEnumeration<NameClassPair> list(Name name) throws NamingException {
            return null;
        }
        @Override
        public NamingEnumeration<NameClassPair> list(String name) throws NamingException {
            return null;
        }
        @Override
        public NamingEnumeration<Binding> listBindings(Name name) throws NamingException {
            if (!""hi/there"".equals(name.toString()))
            throw new IllegalArgumentException(""Expected hi/there"");
            return null;
        }
        @Override
        public NamingEnumeration<Binding> listBindings(String name) throws NamingException {
            return null;
        }
        @Override
        public void destroySubcontext(Name name) throws NamingException {
        }
        @Override
        public void destroySubcontext(String name) throws NamingException {
        }
        @Override
        public Context createSubcontext(Name name) throws NamingException {
            return null;
        }
        @Override
        public Context createSubcontext(String name) throws NamingException {
            return null;
        }
        @Override
        public Object lookupLink(Name name) throws NamingException {
            return null;
        }
        @Override
        public Object lookupLink(String name) throws NamingException {
            return null;
        }
        @Override
        public NameParser getNameParser(Name name) throws NamingException {
            return null;
        }
        @Override
        public NameParser getNameParser(String name) throws NamingException {
            return null;
        }
        @Override
        public Name composeName(Name name, Name prefix) throws NamingException {
            return null;
        }
        @Override
        public String composeName(String name, String prefix) throws NamingException {
            return null;
        }
        @Override
        public Object addToEnvironment(String propName, Object propVal) throws NamingException {
            return null;
        }
        @Override
        public Object removeFromEnvironment(String propName) throws NamingException {
            return null;
        }
        @Override
        public Hashtable<?, ?> getEnvironment() throws NamingException {
            return null;
        }
        @Override
        public void close() throws NamingException {
        }
        @Override
        public String getNameInNamespace() throws NamingException {
            return null;
        }
    });
    final NamingContext ctx = new NamingContext(new CompositeName(), store, null);
    final Object obj = ctx.lookup(new CompositeName(""foo-stored/again/blah/blah2""));
    ctx.listBindings(""foo-stored/again/hi/there"");
    assertNotNull(obj);
    assertEquals(new Integer(5), obj);
}",test order dependency,4
158,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBindAndRetrieveObjectFactoryFromInitialContext,"@Test
public void testBindAndRetrieveObjectFactoryFromInitialContext() throws Exception {
    final Reference reference = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null);
    namingStore.bind(new CompositeName(""test""), reference);
    final InitialContext initialContext = new InitialContext();
    final Object result = initialContext.lookup(""test"");
    assertTrue(result instanceof String);
    assertEquals(""Test ParsedResult"", result);
}",test order dependency,4
159,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireOneLevelEvent,"@Test
public void testFireOneLevelEvent() throws Exception {
    final NamingEventCoordinator coordinator = new NamingEventCoordinator();
    final CollectingListener objectListener = new CollectingListener(0);
    coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
    final CollectingListener subtreeListener = new CollectingListener(0);
    coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
    final CollectingListener oneLevelListener = new CollectingListener(1);
    coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);
    coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.ONELEVEL_SCOPE);
    oneLevelListener.latch.await(1, TimeUnit.SECONDS);
    assertTrue(objectListener.capturedEvents.isEmpty());
    assertTrue(subtreeListener.capturedEvents.isEmpty());
    assertEquals(1, oneLevelListener.capturedEvents.size());
}",test order dependency,4
162,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupWitResolveResult,"@Test
public void testLookupWitResolveResult() throws Exception {
    namingStore.bind(new CompositeName(""test/nested""), ""test"");
    final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""blahh"", ""test""), TestObjectFactoryWithNameResolution.class.getName(), null);
    namingStore.bind(new CompositeName(""comp""), reference);
    Object result = namingContext.lookup(new CompositeName(""comp/nested""));
    assertEquals(""test"", result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test/nested"", ""lookup"")), namingContext, ""comp/nested"");
    assertEquals(""test"", result);
}",test order dependency,4
166,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRejectionEAP7,"@Test
public void testRejectionsEAP7() throws Exception {
    testTransformer(""subsystem.xml"", ModelTestControllerVersion.EAP_7_0_0, ModelVersion.create(2, 0), ""wildfly-naming"");
}",test order dependency,4
169,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBindNested,"@Test
public void testBindNested() throws Exception {
    final Name name = new CompositeName(""nested/test"");
    final Object value = new Object();
    WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
    try {
        store.bind(name, value);
    } finally {
        WritableServiceBasedNamingStore.popOwner();
    }
    assertEquals(value, store.lookup(name));
}",test order dependency,4
188,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupBindingUsingNestedContext,"@Test
public void testLookupBindingUsingNestedContext() throws Exception {
    final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean"");
    final Object value = new Object();
    bindObject(bindingName, value);
    Object context = store.lookup(new CompositeName(""foo""));
    assertNotNull(context);
    assertTrue(context instanceof Context);
    Object obj = Context.class.cast(context).lookup(new CompositeName(""bar/baz/TestBean""));
    assertNotNull(obj);
    assertEquals(value, obj);
    context = Context.class.cast(context).lookup(new CompositeName(""bar""));
    obj = Context.class.cast(context).lookup(new CompositeName(""baz/TestBean""));
    assertNotNull(obj);
    assertEquals(value, obj);
    context = Context.class.cast(context).lookup(new CompositeName(""baz""));
    obj = Context.class.cast(context).lookup(new CompositeName(""TestBean""));
    assertNotNull(obj);
    assertEquals(value, obj);
}",test order dependency,4
196,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBind,"@Test
public void testBind() throws Exception {
    Name name = new CompositeName(""test"");
    final Object value = new Object();
    namingContext.bind(name, value);
    assertEquals(value, namingStore.lookup(name));
    name = new CompositeName(""securitytest"");
    testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""securitytest"", value);
    assertEquals(value, namingStore.lookup(name));
}",test order dependency,4
201,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupBinding.2.,"@Test
public void testLookupBinding() throws Exception {
    final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"");
    final Object value = new Object();
    bindObject(bindingName, value);
    final Object obj = store.lookup(new CompositeName(""foo/bar""));
    assertNotNull(obj);
    assertEquals(value, obj);
}",test order dependency,4
210,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBindReferenceable,"@Test
public void testBindReferenceable() throws Exception {
    Name name = new CompositeName(""test"");
    final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr"");
    namingContext.bind(name, referenceable);
    Object result = namingContext.lookup(name);
    assertEquals(referenceable.addr, result);
    name = new CompositeName(""securitytest"");
    testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""securitytest"", referenceable);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""securitytest"");
    assertEquals(referenceable.addr, result);
}",test order dependency,4
217,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireAllEvent,"@Test
public void testFireAllEvent() throws Exception {
    final NamingEventCoordinator coordinator = new NamingEventCoordinator();
    final CollectingListener objectListener = new CollectingListener(1);
    coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
    final CollectingListener subtreeListener = new CollectingListener(1);
    coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
    final CollectingListener oneLevelListener = new CollectingListener(1);
    coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);
    coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE, EventContext.ONELEVEL_SCOPE, EventContext.SUBTREE_SCOPE);
    objectListener.latch.await(1, TimeUnit.SECONDS);
    oneLevelListener.latch.await(1, TimeUnit.SECONDS);
    subtreeListener.latch.await(1, TimeUnit.SECONDS);
    assertEquals(1, objectListener.capturedEvents.size());
    assertEquals(1, subtreeListener.capturedEvents.size());
    assertEquals(1, oneLevelListener.capturedEvents.size());
}",test order dependency,4
220,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRebind,"@Test
public void testRebind() throws Exception {
    final Name name = new CompositeName(""test"");
    final Object value = new Object();
    namingStore.bind(name, value);
    Object newValue = new Object();
    namingContext.rebind(name, newValue);
    assertEquals(newValue, namingStore.lookup(name));
    newValue = new Object();
    testActionPermission(JndiPermission.ACTION_REBIND, namingContext, ""test"", newValue);
    assertEquals(newValue, namingStore.lookup(name));
}",test order dependency,4
223,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testList,"@Test
public void testList() throws Exception {
    bindList();
    NamingEnumeration<NameClassPair> results = namingContext.list(new CompositeName());
    checkListResults(results);
    results = (NamingEnumeration<NameClassPair>) testActionPermission(JndiPermission.ACTION_LIST, namingContext, null);
    checkListResults(results);
}",test order dependency,4
231,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListBindings,"@Test
public void testListBindings() throws Exception {
    bindList();
    NamingEnumeration<Binding> results = namingContext.listBindings(new CompositeName());
    checkListResults(results);
    results = (NamingEnumeration<Binding>) testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, namingContext, null);
    checkListResults(results);
}",test order dependency,4
232,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListWithContinuation,"@Test
public void testListWithContinuation() throws Exception {
    bindListWithContinuations();
    NamingEnumeration<NameClassPair> results = namingContext.list(new CompositeName(""comp""));
    checkListWithContinuationsResults(results);
    results = (NamingEnumeration<NameClassPair>) testActionPermission(JndiPermission.ACTION_LIST, Arrays.asList(
    new JndiPermission(""test"", ""list"")), namingContext, ""comp"");
    checkListWithContinuationsResults(results);
}",test order dependency,4
246,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupNameNotFound,"@Test
public void testLookupNameNotFound() throws Exception {
    try {
        namingContext.lookup(new CompositeName(""test""));
        fail(""Should have thrown and NameNotFoundException"");
    } catch (NameNotFoundException expected) {
    }
    try {
        testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
        fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
    } catch (NameNotFoundException expected) {
    }
}",test order dependency,4
260,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRebindReferenceable,"@Test
public void testRebindReferenceable() throws Exception {
    final Name name = new CompositeName(""test"");
    final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr"");
    namingContext.bind(name, referenceable);
    TestObjectReferenceable newReferenceable = new TestObjectReferenceable(""newAddr"");
    namingContext.rebind(name, newReferenceable);
    Object result = namingContext.lookup(name);
    assertEquals(newReferenceable.addr, result);
    newReferenceable = new TestObjectReferenceable(""yetAnotherNewAddr"");
    testActionPermission(JndiPermission.ACTION_REBIND, namingContext, ""test"", newReferenceable);
    result = namingContext.lookup(name);
    assertEquals(newReferenceable.addr, result);
}",test order dependency,4
268,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRebind.2,"@Test
public void testRebind() throws Exception {
    final Name name = new CompositeName(""test"");
    final Object value = new Object();
    final Object newValue = new Object();
    WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
    try {
        store.bind(name, value);
        store.rebind(name, newValue);
    } finally {
        WritableServiceBasedNamingStore.popOwner();
    }
    assertEquals(newValue, store.lookup(name));
}",test order dependency,4
269,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testUnbind,"@Test
public void testUnbind() throws Exception {
    final Name name = new CompositeName(""test"");
    final Object value = new Object();
    namingStore.bind(name, value);
    namingContext.unbind(name);
    try {
        namingStore.lookup(name);
        fail(""Should have thrown name not found"");
    } catch (NameNotFoundException expect) {}
    testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""test"", value);
    testActionPermission(JndiPermission.ACTION_UNBIND, namingContext, ""test"");
    try {
        namingStore.lookup(name);
        fail(""Should have thrown name not found"");
    } catch (NameNotFoundException expect) {}
}",test order dependency,4
273,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireMultipleLevelEvent,"@Test
public void testFireMultiLevelEvent() throws Exception {
    final NamingEventCoordinator coordinator = new NamingEventCoordinator();
    final CollectingListener subtreeListener = new CollectingListener(1);
    coordinator.addListener(""foo"", EventContext.SUBTREE_SCOPE, subtreeListener);
    final CollectingListener subtreeListenerTwo = new CollectingListener(1);
    coordinator.addListener(""foo/bar"", EventContext.SUBTREE_SCOPE, subtreeListenerTwo);
    final CollectingListener subtreeListenerThree = new CollectingListener(1);
    coordinator.addListener(""foo/bar/baz"", EventContext.SUBTREE_SCOPE, subtreeListenerThree);
    coordinator.fireEvent(context, new CompositeName(""foo/bar/baz/boo""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE, EventContext.ONELEVEL_SCOPE, EventContext.SUBTREE_SCOPE);
    subtreeListener.latch.await(1, TimeUnit.SECONDS);
    subtreeListenerTwo.latch.await(1, TimeUnit.SECONDS);
    subtreeListenerThree.latch.await(1, TimeUnit.SECONDS);
    assertEquals(1, subtreeListener.capturedEvents.size());
    assertEquals(1, subtreeListenerTwo.capturedEvents.size());
    assertEquals(1, subtreeListenerThree.capturedEvents.size());
}",test order dependency,4
278,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireSubTreeEvent,"@Test
public void testFireSubTreeEvent() throws Exception {
    final NamingEventCoordinator coordinator = new NamingEventCoordinator();
    final CollectingListener objectListener = new CollectingListener(0);
    coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
    final CollectingListener subtreeListener = new CollectingListener(1);
    coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
    final CollectingListener oneLevelListener = new CollectingListener(0);
    coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);
    coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.SUBTREE_SCOPE);
    subtreeListener.latch.await(1, TimeUnit.SECONDS);
    assertTrue(objectListener.capturedEvents.isEmpty());
    assertTrue(oneLevelListener.capturedEvents.isEmpty());
    assertEquals(1, subtreeListener.capturedEvents.size());
}",test order dependency,4
290,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListBindingsNameNotFound,"@Test
public void testListBindingsNameNotFound() throws Exception {
    try {
        namingContext.listBindings(new CompositeName(""test""));
        fail(""Should have thrown and NameNotFoundException"");
    } catch (NameNotFoundException expected) {
    }
    try {
        testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, namingContext, ""test"");
        fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
    } catch (NameNotFoundException expected) {
    }
}",test order dependency,4
297,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRegisterURLSchemeHandler,"@Test
public void testRegisterURLSchemeHandler() throws Exception {
    InitialContext ictx = new InitialContext(null);
    try {
        ictx.lookup(""foobar:something"");
        Assert.fail(""Precondition: the foobar: scheme should not yet be registered"");
    } catch (NamingException ne) {
    }
    ObjectFactory tof = new TestObjectFactory();
    InitialContext.addUrlContextFactory(""foobar"", tof);
    String something = (String) ictx.lookup(""foobar:something"");
    Assert.assertTrue(""The object should now be provided by our TestObjectFactory"", something.startsWith(""TestObject:""));
    try {
        InitialContext.removeUrlContextFactory(""foobar:"", new TestObjectFactory());
        Assert.fail(""Should throw an IllegalArgumentException since the associated factory object doesn't match the registration"");
    } catch (IllegalArgumentException iae) {
    }
    Assert.assertEquals(""The foobar: scheme should still be registered"", something, ictx.lookup(""foobar:something""));
    InitialContext.removeUrlContextFactory(""foobar"", tof);
    try {
        ictx.lookup(""foobar:something"");
        Assert.fail(""The foobar: scheme should not be registered any more"");
    } catch (NamingException ne) {
    }
}",test order dependency,4
337,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testOnlyExternalContextAllowsCache,"@Test
public void testOnlyExternalContextAllowsCache() throws Exception {
    KernelServices services = createKernelServicesBuilder(AdditionalInitialization.MANAGEMENT)
    .build();
    Assert.assertTrue(services.isSuccessfulBoot());
    List<ModelNode> list = parse(ModelTestUtils.readResource(this.getClass(), ""subsystem.xml""));
    for (ModelNode addOp : list) {
        PathAddress addr = PathAddress.pathAddress(addOp.require(ModelDescriptionConstants.OP_ADDR));
        if (addr.size() == 2 && addr.getLastElement().getKey().equals(NamingSubsystemModel.BINDING) && BindingType.forName(addOp.get(NamingBindingResourceDefinition.BINDING_TYPE.getName()).asString()) != BindingType.EXTERNAL_CONTEXT) {
            addOp.get(NamingBindingResourceDefinition.CACHE.getName()).set(true);
            services.executeForFailure(addOp);
            addOp.remove(NamingBindingResourceDefinition.CACHE.getName());
            ModelTestUtils.checkOutcome(services.executeOperation(addOp));
            ModelTestUtils.checkFailed(services.executeOperation(Util.getWriteAttributeOperation(addr, NamingBindingResourceDefinition.CACHE.getName(), new ModelNode(true))));
        } else {
            ModelTestUtils.checkOutcome(services.executeOperation(addOp));
        }
    }",test order dependency,4
357,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookup,"@Test
public void testLookup() throws Exception {
    final Name name = new CompositeName(""test"");
    final Object object = new Object();
    namingStore.bind(name, object);
    Object result = namingContext.lookup(name);
    assertEquals(object, result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
    assertEquals(object, result);
}",test order dependency,4
361,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListBindings.2.,"@Test
public void testListBindings() throws Exception {
    final Object value = new Object();
    bindObject(ServiceName.JBOSS.append(""TestBean""), value);
    bindObject(ServiceName.JBOSS.append(""foo"", ""TestBean""), value);
    bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""TestBean""), value);
    bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean""), value);
    store.add(ServiceName.JBOSS.append(""foos"", ""bar""));
    store.add(ServiceName.JBOSS.append(""fo"", ""bar""));
    store.add(ServiceName.JBOSS.append(""foo"", ""ba"", ""baz""));
    store.add(ServiceName.JBOSS.append(""foo"", ""bart"", ""baz""));
    store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""ba""));
    store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""bazt""));
    store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""art""));
    store.add(ServiceName.JBOSS.append(""other"", ""one""));
    List<Binding> list = store.listBindings(new CompositeName(""""));
    assertEquals(5, list.size());
    assertContains(list, ""TestBean"", Object.class);
    assertContains(list, ""foo"", NamingContext.class);
    assertContains(list, ""fo"", NamingContext.class);
    assertContains(list, ""foos"", NamingContext.class);
    assertContains(list, ""other"", NamingContext.class);
    list = store.listBindings(new CompositeName(""foo""));
    assertEquals(4, list.size());
    assertContains(list, ""TestBean"", Object.class);
    assertContains(list, ""ba"", NamingContext.class);
    assertContains(list, ""bart"", NamingContext.class);
    assertContains(list, ""bar"", NamingContext.class);
    for (Binding binding : list) {
        if (binding.getName().equals(""bar"")) {
            final Object bean = Context.class.cast(binding.getObject()).lookup(""TestBean"");
            assertNotNull(bean);
            assertEquals(value, bean);
        }
    }
}",test order dependency,4
365,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListBindingsWithContinuation,"@Test
public void testListBindingsWithContinuation() throws Exception {
    bindListWithContinuations();
    NamingEnumeration<Binding> results = namingContext.listBindings(new CompositeName(""comp""));
    checkListWithContinuationsResults(results);
    results = (NamingEnumeration<Binding>) testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, Arrays.asList(
    new JndiPermission(""test"", ""listBindings"")), namingContext, ""comp"");
    checkListWithContinuationsResults(results);
}",test order dependency,4
26827,wildfly_wildfly,JndiPermissionTestCase.testNameImplies,"    @Test
    public void testNameImplies() {
        // check the compat <<ALL BINDINGS>> name
        assertEquals(new JndiPermission(""<<ALL BINDINGS>>"", ""*""), new JndiPermission(""-"", ""*""));

        // check the root - name
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission(""-"", ""*"")));
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission("""", ""*"")));
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission(""foo"", ""*"")));
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission(""foo/"", ""*"")));
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission(""foo/bar/baz/zap"", ""*"")));
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission(""java:foo"", ""*"")));

        // check the non-root - name
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""/-"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""/"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""//"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""////"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""/foo/"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""/foo/bar/baz/zap"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""java:/foo"", ""*"")));

        assertTrue(new JndiPermission(""foo/-"", ""*"").implies(new JndiPermission(""foo/-"", ""*"")));
        assertTrue(new JndiPermission(""foo/-"", ""*"").implies(new JndiPermission(""foo/foo"", ""*"")));
        assertTrue(new JndiPermission(""foo/-"", ""*"").implies(new JndiPermission(""foo/foo"", ""*"")));
        assertTrue(new JndiPermission(""foo/-"", ""*"").implies(new JndiPermission(""foo/foo/"", ""*"")));
        assertTrue(new JndiPermission(""foo/-"", ""*"").implies(new JndiPermission(""foo/foo/bar/baz/zap"", ""*"")));
        assertTrue(new JndiPermission(""foo/-"", ""*"").implies(new JndiPermission(""java:foo/foo"", ""*"")));

        // check the * name
        assertTrue(new JndiPermission(""*"", ""*"").implies(new JndiPermission("""", ""*"")));
        assertTrue(new JndiPermission(""*"", ""*"").implies(new JndiPermission(""foo"", ""*"")));
        assertFalse(new JndiPermission(""*"", ""*"").implies(new JndiPermission(""foo/bar"", ""*"")));
        assertFalse(new JndiPermission(""*"", ""*"").implies(new JndiPermission(""foo/"", ""*"")));
        assertFalse(new JndiPermission(""*"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));
        assertTrue(new JndiPermission(""*/*"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));
        assertTrue(new JndiPermission(""/*"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));
        assertTrue(new JndiPermission(""*/foo"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));

        // check java: support
        assertEquals(new JndiPermission(""java:"", ""*""), new JndiPermission("""", ""*""));
        assertEquals(new JndiPermission(""java:/"", ""*""), new JndiPermission(""/"", ""*""));
        assertEquals(new JndiPermission(""java:-"", ""*""), new JndiPermission(""-"", ""*""));
        assertEquals(new JndiPermission(""java:*"", ""*""), new JndiPermission(""*"", ""*""));
    }
",non-flaky,5
26828,wildfly_wildfly,JndiPermissionTestCase.testActions,"    @Test
    public void testActions() {
        assertEquals(new JndiPermission(""foo"", ""*""), new JndiPermission(""foo"", ""all""));
        assertEquals(new JndiPermission(""foo"", ""*""), new JndiPermission(""foo"", ""lookup,bind,rebind,unbind,list,listBindings,createSubcontext,destroySubcontext,addNamingListener""));
        assertEquals(new JndiPermission(""foo"", ""*""), new JndiPermission(""foo"", ""unbind,list,listBindings,createSubcontext,destroySubcontext,addNamingListener,lookup,bind,rebind""));

        assertTrue(new JndiPermission(""foo"", ""*"").implies(new JndiPermission(""foo"", ""lookup"")));
        assertTrue(new JndiPermission(""foo"", """").implies(new JndiPermission(""foo"", """")));
        assertTrue(new JndiPermission(""foo"", ""*"").implies(new JndiPermission(""foo"", """")));
        assertFalse(new JndiPermission(""foo"", """").implies(new JndiPermission(""foo"", ""bind"")));
        assertTrue(new JndiPermission(""foo"", """").withActions(""bind"").implies(new JndiPermission(""foo"", ""bind"")));
        assertFalse(new JndiPermission(""foo"", ""unbind"").withoutActions(""unbind"").implies(new JndiPermission(""foo"", ""unbind"")));
    }
",non-flaky,5
26829,wildfly_wildfly,JndiPermissionTestCase.testCollection,"    @Test
    public void testCollection() {
        final PermissionCollection permissionCollection = new JndiPermission("""", """").newPermissionCollection();
        Enumeration<Permission> e;
        permissionCollection.add(new JndiPermission(""foo/bar"", ""lookup,bind""));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind"")));
        assertFalse(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind,unbind"")));
        assertFalse(permissionCollection.implies(new JndiPermission(""foo/bar"", ""unbind"")));
        assertNotNull(e = permissionCollection.elements());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""foo/bar"", ""lookup,bind""), e.nextElement());
        assertFalse(e.hasMoreElements());
        permissionCollection.add(new JndiPermission(""foo/bar"", ""unbind""));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind,unbind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""unbind"")));
        assertNotNull(e = permissionCollection.elements());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""foo/bar"", ""lookup,bind,unbind""), e.nextElement());
        assertFalse(e.hasMoreElements());
        permissionCollection.add(new JndiPermission(""-"", ""lookup""));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind,unbind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""unbind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""baz/zap"", ""lookup"")));
        assertTrue(permissionCollection.implies(new JndiPermission("""", ""lookup"")));
        assertFalse(permissionCollection.implies(new JndiPermission(""baz/zap"", ""lookup,bind,unbind"")));
        assertFalse(permissionCollection.implies(new JndiPermission(""baz/zap"", ""unbind"")));
        assertNotNull(e = permissionCollection.elements());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""foo/bar"", ""lookup,bind,unbind""), e.nextElement());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""-"", ""lookup""), e.nextElement());
        assertFalse(e.hasMoreElements());
        permissionCollection.add(new JndiPermission(""-"", ""bind,unbind""));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind,unbind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""unbind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""baz/zap"", ""lookup"")));
        assertTrue(permissionCollection.implies(new JndiPermission("""", ""lookup"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""baz/zap"", ""lookup,bind,unbind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""baz/zap"", ""unbind"")));
        assertNotNull(e = permissionCollection.elements());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""-"", ""lookup,bind,unbind""), e.nextElement());
        assertFalse(e.hasMoreElements());
    }
",non-flaky,5
26830,wildfly_wildfly,JndiPermissionTestCase.testSecurity,"    @Test
    public void testSecurity() {
        assertEquals(new JndiPermission(""-"", Integer.MAX_VALUE).getActionBits(), JndiPermission.ACTION_ALL);
        assertEquals(new JndiPermission(""-"", Integer.MAX_VALUE), new JndiPermission(""-"", ""*""));
    }
",non-flaky,5
26831,wildfly_wildfly,JndiPermissionTestCase.testSerialization,"    @Test
    public void testSerialization() {
        final JndiPermission jndiPermission = new JndiPermission(""foo/blap/-"", ""bind,lookup"");
        assertEquals(jndiPermission, ((SerializedJndiPermission)jndiPermission.writeReplace()).readResolve());
    }
",non-flaky,5
26832,wildfly_wildfly,JndiPermissionTestCase.testCollectionSecurity,"    @Test
    public void testCollectionSecurity() {
        final PermissionCollection permissionCollection = new JndiPermission("""", """").newPermissionCollection();
        permissionCollection.add(new JndiPermission(""foo/bar"", ""unbind,rebind""));
        permissionCollection.setReadOnly();
        try {
            permissionCollection.add(new JndiPermission(""fob/baz"", ""unbind,rebind""));
            fail(""Expected exception"");
        } catch (SecurityException ignored) {
        }
    }
",non-flaky,5
26833,wildfly_wildfly,JndiPermissionTestCase.testCollectionSerialization,"    @Test
    public void testCollectionSerialization() {
        final PermissionCollection permissionCollection = new JndiPermission("""", """").newPermissionCollection();
        permissionCollection.add(new JndiPermission(""foo/bar"", ""createSubcontext,rebind""));
        permissionCollection.add(new JndiPermission(""foo"", ""addNamingListener""));
        permissionCollection.add(new JndiPermission(""-"", ""lookup,rebind""));
        final PermissionCollection other = (PermissionCollection) ((SerializedJndiPermissionCollection) ((JndiPermissionCollection)permissionCollection).writeReplace()).readResolve();
        Enumeration<Permission> e;
        assertNotNull(e = other.elements());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""foo/bar"", ""createSubcontext,rebind""), e.nextElement());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""foo"", ""addNamingListener""), e.nextElement());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""-"", ""lookup,rebind""), e.nextElement());
        assertFalse(e.hasMoreElements());
    }
",non-flaky,5
26834,wildfly_wildfly,ExternalContextsNavigableSetTestCase.testGetParentContext,"    @Test
    public void testGetParentContext() throws Exception {
        final ServiceName nameA = ServiceName.JBOSS.append(""a"");
        final ServiceName nameP = ServiceName.JBOSS.append(""p"");
        final ServiceName namePC = ServiceName.JBOSS.append(""p"",""c"");
        final ServiceName nameZ = ServiceName.JBOSS.append(""z"");
        ExternalContextsNavigableSet set = new ExternalContextsNavigableSet();
        set.addExternalContext(nameP);
        assertNull(set.getParentExternalContext(nameA));
        assertNull(set.getParentExternalContext(nameP));
        assertNotNull(set.getParentExternalContext(namePC));
        assertEquals(nameP, set.getParentExternalContext(namePC));
        assertNull(set.getParentExternalContext(nameZ));
    }
",non-flaky,5
26835,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testBindNoOwner,"    @Test
    public void testBindNoOwner() throws Exception {
        try {
            store.bind(new CompositeName(""test""), new Object());
            fail(""Should have failed with a read-only context exception"");
        } catch (UnsupportedOperationException expected) {
        }
    }
",non-flaky,5
26836,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testBind,"    @Test
    public void testBind() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object value = new Object();
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.bind(name, value);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
        assertEquals(value, store.lookup(name));
    }
",non-flaky,5
26837,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testBindNested,"    @Test
    public void testBindNested() throws Exception {
        final Name name = new CompositeName(""nested/test"");
        final Object value = new Object();
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.bind(name, value);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
        assertEquals(value, store.lookup(name));
    }
",non-flaky,5
26838,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testUnbind,"    @Test
    public void testUnbind() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object value = new Object();
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.bind(name, value);
            store.unbind(name);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
        try {
            store.lookup(name);
            fail(""Should have thrown name not found"");
        } catch (NameNotFoundException expect) {
        }
    }
",non-flaky,5
26839,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testUnBindNoOwner,"    @Test
    public void testUnBindNoOwner() throws Exception {
        try {
            store.unbind(new CompositeName(""test""));
            fail(""Should have failed with a read-only context exception"");
        } catch (UnsupportedOperationException expected) {
        }
    }
",non-flaky,5
26840,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testCreateSubcontext,"    @Test
    public void testCreateSubcontext() throws Exception {
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            assertTrue(((NamingContext) store.createSubcontext(new CompositeName(""test""))).getNamingStore() instanceof WritableServiceBasedNamingStore);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
    }
",non-flaky,5
26841,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testCreateSubContextNoOwner,"    @Test
    public void testCreateSubContextNoOwner() throws Exception {
        try {
            store.createSubcontext(new CompositeName(""test""));
            fail(""Should have failed with a read-only context exception"");
        } catch (UnsupportedOperationException expected) {
        }
    }
",non-flaky,5
26842,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testRebind,"    @Test
    public void testRebind() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object value = new Object();
        final Object newValue = new Object();
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.bind(name, value);
            store.rebind(name, newValue);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
        assertEquals(newValue, store.lookup(name));
    }
",non-flaky,5
26843,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testRebindNoOwner,"    @Test
    public void testRebindNoOwner() throws Exception {
        try {
            store.rebind(new CompositeName(""test""), new Object());
            fail(""Should have failed with a read-only context exception"");
        } catch (UnsupportedOperationException expected) {
        }
    }
",non-flaky,5
26844,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testPermissions,"    @Test
    public void testPermissions() throws Exception {

        final NamingContext namingContext = new NamingContext(store, null);
        final String name = ""a/b"";
        final Object value = new Object();
        ArrayList<JndiPermission> permissions = new ArrayList<JndiPermission>();

        // simple bind test, note that permission must have absolute path
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            permissions.add(new JndiPermission(store.getBaseName()+""/""+name,""bind,list,listBindings""));
            store.bind(new CompositeName(name), value);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }

        // all of these lookup should work
        permissions.set(0,new JndiPermission(store.getBaseName()+""/""+name,JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name));
        permissions.set(0,new JndiPermission(store.getBaseName()+""/-"",JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name));
                permissions.set(0,new JndiPermission(store.getBaseName()+""/a/*"",JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name));
        permissions.set(0,new JndiPermission(store.getBaseName()+""/a/-"",JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name));
        permissions.set(0,new JndiPermission(""<<ALL BINDINGS>>"",JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name));
        permissions.set(0,new JndiPermission(store.getBaseName()+""/""+name,JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, store.getBaseName()+""/""+name));
        NamingContext aNamingContext = (NamingContext) namingContext.lookup(""a"");
        permissions.set(0,new JndiPermission(store.getBaseName()+""/""+name,JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, aNamingContext, ""b""));
        // this lookup should not work, no permission
        try {
            testActionWithPermission(JndiPermission.ACTION_LOOKUP, Collections.<JndiPermission>emptyList(), namingContext, name);
            fail(""Should have failed due to missing permission"");
        } catch (AccessControlException e) {

        }
        // a permission which only allows entries in store.getBaseName()
        try {
            permissions.set(0,new JndiPermission(store.getBaseName()+""/*"",JndiPermission.ACTION_LOOKUP));
            testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name);
            fail(""Should have failed due to missing permission"");
        } catch (AccessControlException e) {

        }
        // permissions which are not absolute paths (do not include store base name, i.e. java:)
        try {
            permissions.set(0,new JndiPermission(name,JndiPermission.ACTION_LOOKUP));
            testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name);
            fail(""Should have failed due to missing permission"");
        } catch (AccessControlException e) {

        }
        if (! ""java:"".equals(store.getBaseName().toString())) {
            try {
                permissions.set(0,new JndiPermission(""/""+name,JndiPermission.ACTION_LOOKUP));
                testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name);
                fail(""Should have failed due to missing permission"");
            } catch (AccessControlException e) {

            }
            try {
                permissions.set(0,new JndiPermission(""/-"",JndiPermission.ACTION_LOOKUP));
                testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name);
                fail(""Should have failed due to missing permission"");
            } catch (AccessControlException e) {
            }
        }
    }
",non-flaky,5
26845,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testOwnerBindingReferences,"    @Test
    public void testOwnerBindingReferences() throws Exception {
        final Name name = new CompositeName(""test"");
        final ServiceName serviceName = store.buildServiceName(name);
        final Object value = new Object();

        // ensure bind does not exists
        try {
            store.lookup(name);
            fail(""Should have thrown name not found"");
        } catch (NameNotFoundException expect) {
        }
        final RuntimeBindReleaseService.References duBindingReferences = (RuntimeBindReleaseService.References) container.getService(JndiNamingDependencyProcessor.serviceName(OWNER_FOO)).getValue();
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.bind(name, value);
            // Foo's RuntimeBindReleaseService should now have a reference to the new bind
            assertTrue(duBindingReferences.contains(serviceName));

            store.rebind(name, value);
            // after rebind, Foo's RuntimeBindReleaseService should continue to have a reference to the bind
            assertTrue(duBindingReferences.contains(serviceName));

            store.unbind(name);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
    }
",non-flaky,5
26846,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testMultipleOwnersBindingReferences,"    @Test
    public void testMultipleOwnersBindingReferences() throws Exception {
        final Name name = new CompositeName(""test"");
        final ServiceName serviceName = store.buildServiceName(name);
        final Object value = new Object();

        // ensure bind does not exists
        try {
            store.lookup(name);
            fail(""Should have thrown name not found"");
        } catch (NameNotFoundException expect) {
        }
        // ensure the owners RuntimeBindReleaseService have no reference to the future bind
        final RuntimeBindReleaseService.References fooDuBindingReferences = (RuntimeBindReleaseService.References) container.getService(JndiNamingDependencyProcessor.serviceName(OWNER_FOO)).getValue();
        assertFalse(fooDuBindingReferences.contains(serviceName));
        final RuntimeBindReleaseService.References barDuBindingReferences = (RuntimeBindReleaseService.References) container.getService(JndiNamingDependencyProcessor.serviceName(OWNER_BAR)).getValue();
        assertFalse(barDuBindingReferences.contains(serviceName));

        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.bind(name, value);
            // Foo's RuntimeBindReleaseService should now have a reference to the new bind
            assertTrue(fooDuBindingReferences.contains(serviceName));
            // Bar's RuntimeBindReleaseService reference to the bind should not exist
            assertFalse(barDuBindingReferences.contains(serviceName));
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }

        WritableServiceBasedNamingStore.pushOwner(OWNER_BAR);
        try {
            store.rebind(name, value);
            // after rebind, Foo's RuntimeBindReleaseService reference to the bind should still exist
            assertTrue(fooDuBindingReferences.contains(serviceName));
            // after rebind, Bar's RuntimeBindReleaseService reference to the bind should now exist
            assertTrue(barDuBindingReferences.contains(serviceName));
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }

        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.unbind(name);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
    }
",non-flaky,5
26847,wildfly_wildfly,NamingSubsystemTestCase.testSchemaOfSubsystemTemplates,"    @Test
    public void testSchemaOfSubsystemTemplates() throws Exception {
        super.testSchemaOfSubsystemTemplates();
    }
",non-flaky,5
26848,wildfly_wildfly,NamingSubsystemTestCase.testOnlyExternalContextAllowsCache,"    @Test
    public void testOnlyExternalContextAllowsCache() throws Exception {
        KernelServices services = createKernelServicesBuilder(AdditionalInitialization.MANAGEMENT)
                .build();
        Assert.assertTrue(services.isSuccessfulBoot());

        List<ModelNode> list = parse(ModelTestUtils.readResource(this.getClass(), ""subsystem.xml""));

        for (ModelNode addOp : list) {
            PathAddress addr = PathAddress.pathAddress(addOp.require(ModelDescriptionConstants.OP_ADDR));
            if (addr.size() == 2 && addr.getLastElement().getKey().equals(NamingSubsystemModel.BINDING) && BindingType.forName(addOp.get(NamingBindingResourceDefinition.BINDING_TYPE.getName()).asString()) != BindingType.EXTERNAL_CONTEXT) {
                //Add the cache attribute and make sure it fails
                addOp.get(NamingBindingResourceDefinition.CACHE.getName()).set(true);
                services.executeForFailure(addOp);

                //Remove the cache attribute and make sure it succeeds
                addOp.remove(NamingBindingResourceDefinition.CACHE.getName());
                ModelTestUtils.checkOutcome(services.executeOperation(addOp));

                //Try to write the cache attribute, which should fail
                ModelTestUtils.checkFailed(services.executeOperation(Util.getWriteAttributeOperation(addr, NamingBindingResourceDefinition.CACHE.getName(), new ModelNode(true))));

            } else {
                ModelTestUtils.checkOutcome(services.executeOperation(addOp));
            }
        }


    }
",non-flaky,5
26849,wildfly_wildfly,NamingSubsystemTestCase.testCompositeBindingOps,"    @Test
    public void testCompositeBindingOps() throws Exception {
        final KernelServices services = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build();
        // add binding 'alookup' through composite op
        // note that a binding-type of 'lookup' requires 'lookup' attr value, which in this case is set by a followup step
        final ModelNode addr = Operations.createAddress(ModelDescriptionConstants.SUBSYSTEM, NamingExtension.SUBSYSTEM_NAME, NamingSubsystemModel.BINDING, ""java:global/alookup"");
        final ModelNode addOp = Operations.createAddOperation(addr);
        addOp.get(NamingSubsystemModel.BINDING_TYPE).set(NamingSubsystemModel.LOOKUP);
        final ModelNode compositeOp = Operations.CompositeOperationBuilder.create()
                .addStep(addOp)
                .addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.LOOKUP, ""java:global/a""))
                .build().getOperation();
        ModelTestUtils.checkOutcome(services.executeOperation(compositeOp));
    }
",non-flaky,5
26850,wildfly_wildfly,NamingSubsystemTestCase.testCompositeBindingUpdate,"    @Test
    public void testCompositeBindingUpdate() throws Exception {
        final KernelServices services = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build();
        // updates binding 'a' through composite op
        // binding-type used is lookup, op should succeed even if lookup value is set by a followup step
        final ModelNode addr = Operations.createAddress(ModelDescriptionConstants.SUBSYSTEM, NamingExtension.SUBSYSTEM_NAME, NamingSubsystemModel.BINDING, ""java:global/a"");
        final ModelNode compositeOp = Operations.CompositeOperationBuilder.create()
                .addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.BINDING_TYPE, NamingSubsystemModel.LOOKUP))
                .addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.LOOKUP, ""java:global/b""))
                .build().getOperation();
        ModelTestUtils.checkOutcome(services.executeOperation(compositeOp));
    }
",non-flaky,5
26851,wildfly_wildfly,NamingSubsystemTestCase.testRejectionsEAP7,"    @Test
    public void testRejectionsEAP7() throws Exception {
        testTransformer(""subsystem.xml"", ModelTestControllerVersion.EAP_7_0_0, ModelVersion.create(2, 0), ""wildfly-naming"");
    }
",non-flaky,5
26852,wildfly_wildfly,NamingSubsystemTestCase.testRejectionsEAP6,"    @Test
    public void testRejectionsEAP6() throws Exception {
        testTransformer(""subsystem.xml"", ModelTestControllerVersion.EAP_6_4_0, ModelVersion.create(1, 3),""jboss-as-naming"");
    }
",non-flaky,5
26853,wildfly_wildfly,ObjectFactoryTestCase.testBindAndRetrieveObjectFactoryFromNamingContext,"    @Test
    public void testBindAndRetrieveObjectFactoryFromNamingContext() throws Exception {
        final Reference reference = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null);
        namingStore.bind(new CompositeName(""test""), reference);

        final Object result = namingContext.lookup(""test"");
        assertTrue(result instanceof String);
        assertEquals(""Test ParsedResult"", result);
    }
",non-flaky,5
26854,wildfly_wildfly,ObjectFactoryTestCase.testBindAndRetrieveObjectFactoryFromInitialContext,"    @Test
    public void testBindAndRetrieveObjectFactoryFromInitialContext() throws Exception {
        final Reference reference = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null);
        namingStore.bind(new CompositeName(""test""), reference);

        final InitialContext initialContext = new InitialContext();
        final Object result = initialContext.lookup(""test"");
        assertTrue(result instanceof String);
        assertEquals(""Test ParsedResult"", result);
    }
",non-flaky,5
26855,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testLookupBase,"    @Test
    public void testLookupBase() throws Exception {
        final Object obj = store.lookup(new CompositeName());
        assertNotNull(obj);
    }
",non-flaky,5
26856,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testLookupBinding,"    @Test
    public void testLookupBinding() throws Exception {
        final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"");
        final Object value = new Object();
        bindObject(bindingName, value);

        final Object obj = store.lookup(new CompositeName(""foo/bar""));
        assertNotNull(obj);
        assertEquals(value, obj);
    }
",non-flaky,5
26857,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testLookupParentContext,"    @Test
    public void testLookupParentContext() throws Exception {
        final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"");
        store.add(bindingName);
        final Object obj = store.lookup(new CompositeName(""foo""));
        assertNotNull(obj);
        assertTrue(obj instanceof Context);
    }
",non-flaky,5
26858,wildfly_wildfly,ServiceBasedNamingStoreTestCase.lookup,"    @Test
    public void testStoredContext() throws Exception {
        final ServiceName bindingName = ServiceName.JBOSS.append(""foo-stored"").append(""again"");
        bindObject(bindingName, new Context() {
            @Override
            public Object lookup(Name name) throws NamingException {
                if (""blah/blah2"".equals(name.toString())) {
                    return new Integer(5);
                }

                return null;
            }
",non-flaky,5
26859,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testLookupNestedContext,"    @Test
    public void testLookupNestedContext() throws Exception {
        final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean"");
        store.add(bindingName);
        store.add(ServiceName.JBOSS.append(""foos"", ""bar""));
        store.add(ServiceName.JBOSS.append(""fo"", ""bar""));
        store.add(ServiceName.JBOSS.append(""foo"", ""ba""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bart""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""ba""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""bazt""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""art""));

        Object obj = store.lookup(new CompositeName(""foo""));
        assertNotNull(obj);
        assertTrue(obj instanceof Context);

        obj = Context.class.cast(obj).lookup(new CompositeName(""bar""));
        assertNotNull(obj);
        assertTrue(obj instanceof Context);

        obj = Context.class.cast(obj).lookup(new CompositeName(""baz""));
        assertNotNull(obj);
        assertTrue(obj instanceof Context);
    }
",non-flaky,5
26860,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testLookupBindingUsingNestedContext,"    @Test
    public void testLookupBindingUsingNestedContext() throws Exception {
        final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean"");
        final Object value = new Object();
        bindObject(bindingName, value);

        Object context = store.lookup(new CompositeName(""foo""));
        assertNotNull(context);
        assertTrue(context instanceof Context);

        Object obj = Context.class.cast(context).lookup(new CompositeName(""bar/baz/TestBean""));
        assertNotNull(obj);
        assertEquals(value, obj);

        context = Context.class.cast(context).lookup(new CompositeName(""bar""));
        obj = Context.class.cast(context).lookup(new CompositeName(""baz/TestBean""));
        assertNotNull(obj);
        assertEquals(value, obj);


        context = Context.class.cast(context).lookup(new CompositeName(""baz""));
        obj = Context.class.cast(context).lookup(new CompositeName(""TestBean""));
        assertNotNull(obj);
        assertEquals(value, obj);
    }
",non-flaky,5
26861,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testList,"    @Test
    public void testList() throws Exception {
        final Object value = new Object();
        bindObject(ServiceName.JBOSS.append(""TestBean""), value);
        bindObject(ServiceName.JBOSS.append(""foo"", ""TestBean""), value);
        bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""TestBean""), value);
        bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean""), value);

        store.add(ServiceName.JBOSS.append(""foos"", ""bar""));
        store.add(ServiceName.JBOSS.append(""fo"", ""bar""));
        store.add(ServiceName.JBOSS.append(""foo"", ""ba"", ""baz""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bart"", ""baz""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""ba""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""bazt""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""art""));
        store.add(ServiceName.JBOSS.append(""other"", ""one""));

        List<NameClassPair> list = store.list(new CompositeName(""""));
        assertEquals(5, list.size());
        assertContains(list, ""TestBean"", Object.class);
        assertContains(list, ""foo"", Context.class);
        assertContains(list, ""fo"", Context.class);
        assertContains(list, ""foos"", Context.class);
        assertContains(list, ""other"", Context.class);


        list = store.list(new CompositeName(""foo""));
        assertEquals(4, list.size());
        assertContains(list, ""TestBean"", Object.class);
        assertContains(list, ""ba"", Context.class);
        assertContains(list, ""bart"", Context.class);
        assertContains(list, ""bar"", Context.class);
    }
",non-flaky,5
26862,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testListBindings,"    @Test
    public void testListBindings() throws Exception {
        final Object value = new Object();
        bindObject(ServiceName.JBOSS.append(""TestBean""), value);
        bindObject(ServiceName.JBOSS.append(""foo"", ""TestBean""), value);
        bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""TestBean""), value);
        bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean""), value);

        store.add(ServiceName.JBOSS.append(""foos"", ""bar""));
        store.add(ServiceName.JBOSS.append(""fo"", ""bar""));
        store.add(ServiceName.JBOSS.append(""foo"", ""ba"", ""baz""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bart"", ""baz""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""ba""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""bazt""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""art""));
        store.add(ServiceName.JBOSS.append(""other"", ""one""));

        List<Binding> list = store.listBindings(new CompositeName(""""));
        assertEquals(5, list.size());
        assertContains(list, ""TestBean"", Object.class);
        assertContains(list, ""foo"", NamingContext.class);
        assertContains(list, ""fo"", NamingContext.class);
        assertContains(list, ""foos"", NamingContext.class);
        assertContains(list, ""other"", NamingContext.class);


        list = store.listBindings(new CompositeName(""foo""));
        assertEquals(4, list.size());
        assertContains(list, ""TestBean"", Object.class);
        assertContains(list, ""ba"", NamingContext.class);
        assertContains(list, ""bart"", NamingContext.class);
        assertContains(list, ""bar"", NamingContext.class);

        for (Binding binding : list) {
            if (binding.getName().equals(""bar"")) {
                final Object bean = Context.class.cast(binding.getObject()).lookup(""TestBean"");
                assertNotNull(bean);
                assertEquals(value, bean);
            }
        }
    }
",non-flaky,5
26863,wildfly_wildfly,InitialContextTestCase.testRegisterURLSchemeHandler,"    @Test
    public void testRegisterURLSchemeHandler() throws Exception {
        InitialContext ictx = new InitialContext(null);

        try {
            ictx.lookup(""foobar:something"");
            Assert.fail(""Precondition: the foobar: scheme should not yet be registered"");
        } catch (NamingException ne) {
            // good
        }

        ObjectFactory tof = new TestObjectFactory();
        InitialContext.addUrlContextFactory(""foobar"", tof);
        String something = (String) ictx.lookup(""foobar:something"");
        Assert.assertTrue(""The object should now be provided by our TestObjectFactory"", something.startsWith(""TestObject:""));

        try {
            InitialContext.removeUrlContextFactory(""foobar:"", new TestObjectFactory());
            Assert.fail(""Should throw an IllegalArgumentException since the associated factory object doesn't match the registration"");
        } catch (IllegalArgumentException iae) {
            // good;
        }

        Assert.assertEquals(""The foobar: scheme should still be registered"", something, ictx.lookup(""foobar:something""));

        InitialContext.removeUrlContextFactory(""foobar"", tof);
        try {
            ictx.lookup(""foobar:something"");
            Assert.fail(""The foobar: scheme should not be registered any more"");
        } catch (NamingException ne) {
            // good
        }
    }
",non-flaky,5
26864,wildfly_wildfly,NamingEventCoordinatorTestCase.testFireObjectEvent,"    @Test
    public void testFireObjectEvent() throws Exception {
        final NamingEventCoordinator coordinator = new NamingEventCoordinator();

        final CollectingListener objectListener = new CollectingListener(1);
        coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
        final CollectingListener subtreeListener = new CollectingListener(0);
        coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
        final CollectingListener oneLevelListener = new CollectingListener(0);
        coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);

        coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE);

        objectListener.latch.await(1, TimeUnit.SECONDS);

        assertEquals(1, objectListener.capturedEvents.size());
        assertTrue(oneLevelListener.capturedEvents.isEmpty());
        assertTrue(subtreeListener.capturedEvents.isEmpty());
    }
",non-flaky,5
26865,wildfly_wildfly,NamingEventCoordinatorTestCase.testFireSubTreeEvent,"    @Test
    public void testFireSubTreeEvent() throws Exception {
        final NamingEventCoordinator coordinator = new NamingEventCoordinator();

        final CollectingListener objectListener = new CollectingListener(0);
        coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
        final CollectingListener subtreeListener = new CollectingListener(1);
        coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
        final CollectingListener oneLevelListener = new CollectingListener(0);
        coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);

        coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.SUBTREE_SCOPE);

        subtreeListener.latch.await(1, TimeUnit.SECONDS);

        assertTrue(objectListener.capturedEvents.isEmpty());
        assertTrue(oneLevelListener.capturedEvents.isEmpty());
        assertEquals(1, subtreeListener.capturedEvents.size());
    }
",non-flaky,5
26866,wildfly_wildfly,NamingEventCoordinatorTestCase.testFireOneLevelEvent,"    @Test
    public void testFireOneLevelEvent() throws Exception {
        final NamingEventCoordinator coordinator = new NamingEventCoordinator();

        final CollectingListener objectListener = new CollectingListener(0);
        coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
        final CollectingListener subtreeListener = new CollectingListener(0);
        coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
        final CollectingListener oneLevelListener = new CollectingListener(1);
        coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);

        coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.ONELEVEL_SCOPE);

        oneLevelListener.latch.await(1, TimeUnit.SECONDS);

        assertTrue(objectListener.capturedEvents.isEmpty());
        assertTrue(subtreeListener.capturedEvents.isEmpty());
        assertEquals(1, oneLevelListener.capturedEvents.size());
    }
",non-flaky,5
26867,wildfly_wildfly,NamingEventCoordinatorTestCase.testFireAllEvent,"    @Test
    public void testFireAllEvent() throws Exception {
        final NamingEventCoordinator coordinator = new NamingEventCoordinator();

        final CollectingListener objectListener = new CollectingListener(1);
        coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
        final CollectingListener subtreeListener = new CollectingListener(1);
        coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
        final CollectingListener oneLevelListener = new CollectingListener(1);
        coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);

        coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE, EventContext.ONELEVEL_SCOPE, EventContext.SUBTREE_SCOPE);

        objectListener.latch.await(1, TimeUnit.SECONDS);
        oneLevelListener.latch.await(1, TimeUnit.SECONDS);
        subtreeListener.latch.await(1, TimeUnit.SECONDS);

        assertEquals(1, objectListener.capturedEvents.size());
        assertEquals(1, subtreeListener.capturedEvents.size());
        assertEquals(1, oneLevelListener.capturedEvents.size());
    }
",non-flaky,5
26868,wildfly_wildfly,NamingEventCoordinatorTestCase.testFireMultiLevelEvent,"    @Test
    public void testFireMultiLevelEvent() throws Exception {
        final NamingEventCoordinator coordinator = new NamingEventCoordinator();

        final CollectingListener subtreeListener = new CollectingListener(1);
        coordinator.addListener(""foo"", EventContext.SUBTREE_SCOPE, subtreeListener);

        final CollectingListener subtreeListenerTwo = new CollectingListener(1);
        coordinator.addListener(""foo/bar"", EventContext.SUBTREE_SCOPE, subtreeListenerTwo);

        final CollectingListener subtreeListenerThree = new CollectingListener(1);
        coordinator.addListener(""foo/bar/baz"", EventContext.SUBTREE_SCOPE, subtreeListenerThree);

        coordinator.fireEvent(context, new CompositeName(""foo/bar/baz/boo""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE, EventContext.ONELEVEL_SCOPE, EventContext.SUBTREE_SCOPE);

        subtreeListener.latch.await(1, TimeUnit.SECONDS);
        subtreeListenerTwo.latch.await(1, TimeUnit.SECONDS);
        subtreeListenerThree.latch.await(1, TimeUnit.SECONDS);

        assertEquals(1, subtreeListener.capturedEvents.size());
        assertEquals(1, subtreeListenerTwo.capturedEvents.size());
        assertEquals(1, subtreeListenerThree.capturedEvents.size());
    }
",non-flaky,5
26869,wildfly_wildfly,NamingContextTestCase.testLookup,"    @Test
    public void testLookup() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        namingStore.bind(name, object);

        Object result = namingContext.lookup(name);
        assertEquals(object, result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
        assertEquals(object, result);
    }
",non-flaky,5
26870,wildfly_wildfly,NamingContextTestCase.testLookupReference,"    @Test
    public void testLookupReference() throws Exception {
        final Name name = new CompositeName(""test"");
        final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""blah"", ""test""), TestObjectFactory.class.getName(), null);
        namingStore.bind(name, reference);

        Object result = namingContext.lookup(name);
        assertEquals(""test"", result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
        assertEquals(""test"", result);
    }
",non-flaky,5
26871,wildfly_wildfly,NamingContextTestCase.testLookupWithContinuation,"    @Test
    public void testLookupWithContinuation() throws Exception {
        namingStore.bind(new CompositeName(""comp/nested""), ""test"");

        final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""nns"", ""comp""), TestObjectFactoryWithNameResolution.class.getName(), null);
        namingStore.bind(new CompositeName(""test""), reference);

        Object result = namingContext.lookup(new CompositeName(""test/nested""));
        assertEquals(""test"", result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""comp/nested"", ""lookup"")), namingContext, ""test/nested"");
        assertEquals(""test"", result);
    }
",non-flaky,5
26872,wildfly_wildfly,NamingContextTestCase.testLookupWitResolveResult,"    @Test
    public void testLookupWitResolveResult() throws Exception {
        namingStore.bind(new CompositeName(""test/nested""), ""test"");

        final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""blahh"", ""test""), TestObjectFactoryWithNameResolution.class.getName(), null);
        namingStore.bind(new CompositeName(""comp""), reference);

        Object result = namingContext.lookup(new CompositeName(""comp/nested""));
        assertEquals(""test"", result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test/nested"", ""lookup"")), namingContext, ""comp/nested"");
        assertEquals(""test"", result);
    }
",non-flaky,5
26873,wildfly_wildfly,NamingContextTestCase.testLookupLink,"    @Test
    public void testLookupLink() throws Exception {
        final Name name = new CompositeName(""test"");
        namingStore.bind(name, ""testValue"", String.class);
        final Name linkName = new CompositeName(""link"");
        namingStore.bind(linkName, new LinkRef(""./test""));
        Object result = namingContext.lookup(linkName);
        assertEquals(""testValue"", result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link"");
        assertEquals(""testValue"", result);

        System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
        namingStore.rebind(linkName, new LinkRef(name));
        result = namingContext.lookup(linkName);
        assertEquals(""testValue"", result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link"");
        assertEquals(""testValue"", result);
    }
",non-flaky,5
26874,wildfly_wildfly,NamingContextTestCase.testLookupContextLink,"    @Test
    public void testLookupContextLink() throws Exception {
        final Name name = new CompositeName(""test/value"");
        namingStore.bind(name, ""testValue"");
        final Name linkName = new CompositeName(""link"");
        namingStore.bind(linkName, new LinkRef(""./test""));
        Object result = namingContext.lookup(""link/value"");
        assertEquals(""testValue"", result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup""),
                new JndiPermission(""test/value"", ""lookup"")), namingContext, ""link/value"");

        assertEquals(""testValue"", result);
    }
",non-flaky,5
26875,wildfly_wildfly,NamingContextTestCase.testLookupNameNotFound,"    @Test
    public void testLookupNameNotFound() throws Exception {
        try {
            namingContext.lookup(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch (NameNotFoundException expected) {
        }

        //the same with security permissions
        try {
            testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
            fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
        } catch (NameNotFoundException expected) {
        }
    }
",non-flaky,5
26876,wildfly_wildfly,NamingContextTestCase.testLookupEmptyName,"    @Test
    public void testLookupEmptyName() throws Exception {
        Object result = namingContext.lookup(new CompositeName());
        assertTrue(result instanceof NamingContext);
        result = namingContext.lookup(new CompositeName(""""));
        assertTrue(result instanceof NamingContext);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, null);
        assertTrue(result instanceof NamingContext);
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, """");
        assertTrue(result instanceof NamingContext);
    }
",non-flaky,5
26877,wildfly_wildfly,NamingContextTestCase.testBind,"    @Test
    public void testBind() throws Exception {
        Name name = new CompositeName(""test"");
        final Object value = new Object();
        namingContext.bind(name, value);
        assertEquals(value, namingStore.lookup(name));

        //the same with security permissions
        name = new CompositeName(""securitytest"");
        testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""securitytest"", value);
        assertEquals(value, namingStore.lookup(name));
    }
",non-flaky,5
26878,wildfly_wildfly,NamingContextTestCase.testBindReferenceable,"    @Test
    public void testBindReferenceable() throws Exception {
        Name name = new CompositeName(""test"");
        final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr"");
        namingContext.bind(name, referenceable);
        Object result = namingContext.lookup(name);
        assertEquals(referenceable.addr, result);

        //the same with security permissions
        name = new CompositeName(""securitytest"");
        testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""securitytest"", referenceable);
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""securitytest"");
        assertEquals(referenceable.addr, result);
    }
",non-flaky,5
26879,wildfly_wildfly,NamingContextTestCase.testUnbind,"    @Test
    public void testUnbind() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object value = new Object();
        namingStore.bind(name, value);
        namingContext.unbind(name);
        try {
            namingStore.lookup(name);
            fail(""Should have thrown name not found"");
        } catch (NameNotFoundException expect) {}

        //the same with security permissions
        testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""test"", value);
        testActionPermission(JndiPermission.ACTION_UNBIND, namingContext, ""test"");
        try {
            namingStore.lookup(name);
            fail(""Should have thrown name not found"");
        } catch (NameNotFoundException expect) {}
    }
",non-flaky,5
26880,wildfly_wildfly,NamingContextTestCase.testCreateSubcontext,"    @Test
    public void testCreateSubcontext() throws Exception {
        assertTrue(namingContext.createSubcontext(new CompositeName(""test"")) instanceof NamingContext);

        //the same with security permissions
        assertTrue(testActionPermission(JndiPermission.ACTION_CREATE_SUBCONTEXT, namingContext, ""securitytest"") instanceof NamingContext);
    }
",non-flaky,5
26881,wildfly_wildfly,NamingContextTestCase.testRebind,"    @Test
    public void testRebind() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object value = new Object();
        namingStore.bind(name, value);
        Object newValue = new Object();
        namingContext.rebind(name, newValue);
        assertEquals(newValue, namingStore.lookup(name));

        //the same with security permissions
        newValue = new Object();
        testActionPermission(JndiPermission.ACTION_REBIND, namingContext, ""test"", newValue);
        assertEquals(newValue, namingStore.lookup(name));
    }
",non-flaky,5
26882,wildfly_wildfly,NamingContextTestCase.testRebindReferenceable,"    @Test
    public void testRebindReferenceable() throws Exception {
        final Name name = new CompositeName(""test"");
        final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr"");
        namingContext.bind(name, referenceable);
        TestObjectReferenceable newReferenceable = new TestObjectReferenceable(""newAddr"");
        namingContext.rebind(name, newReferenceable);
        Object result = namingContext.lookup(name);
        assertEquals(newReferenceable.addr, result);

        //the same with security permissions
        newReferenceable = new TestObjectReferenceable(""yetAnotherNewAddr"");
        testActionPermission(JndiPermission.ACTION_REBIND, namingContext, ""test"", newReferenceable);
        result = namingContext.lookup(name);
        assertEquals(newReferenceable.addr, result);
    }
",non-flaky,5
26883,wildfly_wildfly,NamingContextTestCase.testListNameNotFound,"    @Test
    public void testListNameNotFound() throws Exception {
        try {
            namingContext.list(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch (NameNotFoundException expected) {
        }

        //the same with security permissions
        try {
            testActionPermission(JndiPermission.ACTION_LIST, namingContext, ""test"");
            fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
        } catch (NameNotFoundException expected) {
        }
    }
",non-flaky,5
26884,wildfly_wildfly,NamingContextTestCase.testList,"    @Test
    public void testList() throws Exception {
        bindList();

        NamingEnumeration<NameClassPair> results = namingContext.list(new CompositeName());
        checkListResults(results);

        //the same with security permissions
        results = (NamingEnumeration<NameClassPair>) testActionPermission(JndiPermission.ACTION_LIST, namingContext, null);
        checkListResults(results);
    }
",non-flaky,5
26885,wildfly_wildfly,NamingContextTestCase.testListWithContinuation,"    @Test
    public void testListWithContinuation() throws Exception {
        bindListWithContinuations();

        NamingEnumeration<NameClassPair> results = namingContext.list(new CompositeName(""comp""));
        checkListWithContinuationsResults(results);

        //the same with security permissions
        results = (NamingEnumeration<NameClassPair>) testActionPermission(JndiPermission.ACTION_LIST, Arrays.asList(
                new JndiPermission(""test"", ""list"")), namingContext, ""comp"");

        checkListWithContinuationsResults(results);
    }
",non-flaky,5
26886,wildfly_wildfly,NamingContextTestCase.testListBindingsNameNotFound,"    @Test
    public void testListBindingsNameNotFound() throws Exception {
        try {
            namingContext.listBindings(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch (NameNotFoundException expected) {
        }

        //the same with security permissions
        try {
            testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, namingContext, ""test"");
            fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
        } catch (NameNotFoundException expected) {
        }
    }
",non-flaky,5
26887,wildfly_wildfly,NamingContextTestCase.testListBindings,"    @Test
    public void testListBindings() throws Exception {
        bindList();

        NamingEnumeration<Binding> results = namingContext.listBindings(new CompositeName());
        checkListResults(results);

        //the same with security permissions
        results = (NamingEnumeration<Binding>) testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, namingContext, null);
        checkListResults(results);
    }
",non-flaky,5
26888,wildfly_wildfly,NamingContextTestCase.testListBindingsWithContinuation,"    @Test
    public void testListBindingsWithContinuation() throws Exception {
        bindListWithContinuations();

        NamingEnumeration<Binding> results = namingContext.listBindings(new CompositeName(""comp""));
        checkListWithContinuationsResults(results);

        //the same with security permissions
        results = (NamingEnumeration<Binding>) testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, Arrays.asList(
                new JndiPermission(""test"", ""listBindings"")), namingContext, ""comp"");

        checkListWithContinuationsResults(results);
    }
",non-flaky,5
26889,wildfly_wildfly,InMemoryNamingStoreTestCase.testBindEmptyName,"    @Test
    public void testBindEmptyName() throws Exception {
        try {
            nameStore.bind(new CompositeName(), new Object(), Object.class);
            fail(""Should have thrown and InvalidNameException"");
        } catch(InvalidNameException expected){}

        try {
            nameStore.bind(new CompositeName(""""), new Object(), Object.class);
            fail(""Should have thrown and InvalidNameException"");
        } catch(InvalidNameException expected){}
    }
",non-flaky,5
26890,wildfly_wildfly,InMemoryNamingStoreTestCase.testBindAndLookup,"    @Test
    public void testBindAndLookup() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        nameStore.bind(name, object, Object.class);
        final Object result = nameStore.lookup(name);
        assertEquals(object, result);
    }
",non-flaky,5
26891,wildfly_wildfly,InMemoryNamingStoreTestCase.testLookupNameNotFound,"    @Test
    public void testLookupNameNotFound() throws Exception {
        try {
            nameStore.lookup(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch(NameNotFoundException expected) {}
    }
",non-flaky,5
26892,wildfly_wildfly,InMemoryNamingStoreTestCase.testLookupEmptyName,"    @Test
    public void testLookupEmptyName() throws Exception {
        Object result = nameStore.lookup(new CompositeName());
        assertTrue(result instanceof NamingContext);
        result = nameStore.lookup(new CompositeName(""""));
        assertTrue(result instanceof NamingContext);
    }
",non-flaky,5
26893,wildfly_wildfly,InMemoryNamingStoreTestCase.testBindAndLookupResolveResult,"    @Test
    public void testBindAndLookupResolveResult() throws Exception {
        final Name name = new CompositeName(""test"");
        final Reference reference = new Reference(Context.class.getName());
        nameStore.bind(name, reference, Context.class);
        final Object result = nameStore.lookup(new CompositeName(""test/value""));
        assertTrue(result instanceof ResolveResult);
    }
",non-flaky,5
26894,wildfly_wildfly,InMemoryNamingStoreTestCase.testUnbindNotFound,"    @Test
    public void testUnbindNotFound() throws Exception {
        try {
            nameStore.unbind(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch(NameNotFoundException expected) {}
    }
",non-flaky,5
26895,wildfly_wildfly,InMemoryNamingStoreTestCase.testBindUnbindLookup,"    @Test
    public void testBindUnbindLookup() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        nameStore.bind(name, object, Object.class);
        final Object result = nameStore.lookup(name);
        assertEquals(object, result);
        nameStore.unbind(name);
        try {
            nameStore.lookup(name);
            fail(""Should have thrown and NameNotFoundException"");
        } catch(NameNotFoundException expected) {}
    }
",non-flaky,5
26896,wildfly_wildfly,InMemoryNamingStoreTestCase.testRebindEmptyName,"    @Test
    public void testRebindEmptyName() throws Exception {
        try {
            nameStore.rebind(new CompositeName(), new Object(), Object.class);
            fail(""Should have thrown and InvalidNameException"");
        } catch(InvalidNameException expected){}

        try {
            nameStore.rebind(new CompositeName(""""), new Object(), Object.class);
            fail(""Should have thrown and InvalidNameException"");
        } catch(InvalidNameException expected){}
    }
",non-flaky,5
26897,wildfly_wildfly,InMemoryNamingStoreTestCase.testRebindInvalidContext,"    @Test
    public void testRebindInvalidContext() throws Exception {
        try {
            nameStore.rebind(new CompositeName(""subcontext/test""), new Object(), Object.class);
            fail(""Should have thrown and NameNotFoundException"");
        } catch(NameNotFoundException expected){}
    }
",non-flaky,5
26898,wildfly_wildfly,InMemoryNamingStoreTestCase.testRebindAndLookup,"    @Test
    public void testRebindAndLookup() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        nameStore.rebind(name, object, Object.class);
        final Object result = nameStore.lookup(name);
        assertEquals(object, result);
    }
",non-flaky,5
26899,wildfly_wildfly,InMemoryNamingStoreTestCase.testBindAndRebind,"    @Test
    public void testBindAndRebind() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        nameStore.bind(name, object, Object.class);
        assertEquals(object, nameStore.lookup(name));
        final Object objectTwo = new Object();
        nameStore.rebind(name, objectTwo, Object.class);
        assertEquals(objectTwo, nameStore.lookup(name));
    }
",non-flaky,5
26900,wildfly_wildfly,InMemoryNamingStoreTestCase.testListNameNotFound,"    @Test
    public void testListNameNotFound() throws Exception {
        try {
            nameStore.list(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch(NameNotFoundException expected) {}
    }
",non-flaky,5
26901,wildfly_wildfly,InMemoryNamingStoreTestCase.testList,"    @Test
    public void testList() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        nameStore.bind(name, object, Object.class);
        final Name nameTwo = new CompositeName(""testTwo"");
        final Object objectTwo = new Object();
        nameStore.bind(nameTwo, objectTwo, Object.class);
        final Name nameThree = new CompositeName(""testThree"");
        final Object objectThree = new Object();
        nameStore.bind(nameThree, objectThree, Object.class);

        nameStore.bind(new CompositeName(""testContext/test""), ""test"");

        final List<NameClassPair> results = nameStore.list(new CompositeName());
        assertEquals(4, results.size());
        final Set<String> expected = new HashSet<String>(Arrays.asList(""test"", ""testTwo"", ""testThree"", ""testContext""));
        for(NameClassPair result : results) {
            final String resultName = result.getName();
            if(""test"".equals(resultName) || ""testTwo"".equals(resultName) || ""testThree"".equals(resultName)) {
                assertEquals(Object.class.getName(), result.getClassName());
            } else if(""testContext"".equals(resultName)) {
                assertEquals(Context.class.getName(), result.getClassName());
            } else {
                fail(""Unknown result name: "" + resultName);
            }
            expected.remove(resultName);
        }
        assertTrue(""Not all expected results were returned"", expected.isEmpty());
    }
",non-flaky,5
26902,wildfly_wildfly,InMemoryNamingStoreTestCase.testListBindingsNameNotFound,"    @Test
    public void testListBindingsNameNotFound() throws Exception {
        try {
            nameStore.listBindings(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch(NameNotFoundException expected) {}
    }
",non-flaky,5
26903,wildfly_wildfly,InMemoryNamingStoreTestCase.testListBindings,"    @Test
    public void testListBindings() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        nameStore.bind(name, object);
        final Name nameTwo = new CompositeName(""testTwo"");
        final Object objectTwo = new Object();
        nameStore.bind(nameTwo, objectTwo);
        final Name nameThree = new CompositeName(""testThree"");
        final Object objectThree = new Object();
        nameStore.bind(nameThree, objectThree);

        nameStore.bind(new CompositeName(""testContext/test""), ""test"");

        final List<Binding> results = nameStore.listBindings(new CompositeName());
        assertEquals(4, results.size());
        final Set<String> expected = new HashSet<String>(Arrays.asList(""test"", ""testTwo"", ""testThree"", ""testContext""));
        for(Binding result : results) {
            final String resultName = result.getName();
            if(""test"".equals(resultName)) {
                assertEquals(Object.class.getName(), result.getClassName());
                assertEquals(object, result.getObject());
            } else if(""testTwo"".equals(resultName)) {
                assertEquals(Object.class.getName(), result.getClassName());
                assertEquals(objectTwo, result.getObject());
            } else if(""testThree"".equals(resultName)) {
                assertEquals(Object.class.getName(), result.getClassName());
                assertEquals(objectThree, result.getObject());
            } else if(""testContext"".equals(resultName)) {
                assertEquals(Context.class.getName(), result.getClassName());
            } else {
                fail(""Unknown result name: "" + resultName);
            }
            expected.remove(resultName);
        }
        assertTrue(""Not all expected results were returned"", expected.isEmpty());
    }
",non-flaky,5
26904,wildfly_wildfly,InMemoryNamingStoreTestCase.testAutoRemove,"    @Test
    public void testAutoRemove() throws Exception {
        nameStore.bind(new CompositeName(""test/item""), new Object());

        assertNotNull(nameStore.lookup(new CompositeName(""test/item"")));
        assertNotNull(nameStore.lookup(new CompositeName(""test"")));

        nameStore.unbind(new CompositeName(""test/item""));

        try {
            nameStore.lookup(new CompositeName(""test""));
            fail(""Should have throw name not found exception"");
        } catch (NameNotFoundException expected){}
    }
",non-flaky,5
26905,wildfly_wildfly,InitialContextFactoryTestCase.testInitialFactory,"    @Test
    public void testInitialFactory() throws Exception {
        // Test with sys prop
        System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
        InitialContext initialContext = new InitialContext();
        Context context = (Context) initialContext.lookup("""");
        assertTrue(context instanceof NamingContext);

        // Test with builder
        if (!NamingManager.hasInitialContextFactoryBuilder()) {
            NamingManager.setInitialContextFactoryBuilder(new InitialContextFactoryBuilder());
        }
        initialContext = new InitialContext();
        context = (Context) initialContext.lookup("""");
        assertTrue(context instanceof NamingContext);
    }
",non-flaky,5
26906,wildfly_wildfly,InitialContextFactoryTestCase.testJavaContext,"    @Test
    public void testJavaContext() throws Exception {
        System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
        System.setProperty(Context.URL_PKG_PREFIXES, ""org.jboss.as.naming.interfaces"");
        InitialContext initialContext = new InitialContext();
        Context context = (Context) initialContext.lookup(""java:"");
        assertTrue(context instanceof NamingContext);
    }
",non-flaky,5
26907,wildfly_wildfly,JSFSubsystemTransformersTestCase.testTransformersEAP700,"    @Test
    public void testTransformersEAP700() throws Exception {
        testTransformers(ModelTestControllerVersion.EAP_7_0_0, legacyVersion, ""/jsf-transformers.xml"");
    }
",non-flaky,5
26908,wildfly_wildfly,JSFSubsystemTransformersTestCase.testRejectTransformersEAP700,"    @Test
    public void testRejectTransformersEAP700() throws Exception {
        doRejectTest(ModelTestControllerVersion.EAP_7_0_0, legacyVersion);
    }
",non-flaky,5
26909,wildfly_wildfly,JSFSubsystemTestCase.testSchemaOfSubsystemTemplates,"    @Test
    public void testSchemaOfSubsystemTemplates() throws Exception {
        super.testSchemaOfSubsystemTemplates();
    }
",non-flaky,5
26910,wildfly_wildfly,JSFModuleIdFactoryTestCase.noModulePathTest,"     @Test
     public void noModulePathTest() {
     JSFModuleIdFactory factory = JSFModuleIdFactory.getInstance();
     Assert.assertEquals(1, factory.getActiveJSFVersions().size());

     Assert.assertEquals(API_MODULE, factory.getApiModId(""main"").getName());
     Assert.assertEquals(""main"", factory.getApiModId(""main"").getSlot());
     Assert.assertEquals(IMPL_MODULE, factory.getImplModId(""main"").getName());
     Assert.assertEquals(""main"", factory.getImplModId(""main"").getSlot());
     Assert.assertEquals(INJECTION_MODULE, factory.getInjectionModId(""main"").getName());
     Assert.assertEquals(""main"", factory.getInjectionModId(""main"").getSlot());
     } */
",non-flaky,5
26911,wildfly_wildfly,JSFModuleIdFactoryTestCase.getActiveJSFVersionsTest,"    @Test
    public void getActiveJSFVersionsTest() {
        List<String> versions = factory.getActiveJSFVersions();
        Assert.assertEquals(3, versions.size());
        Assert.assertTrue(versions.contains(""main""));
        Assert.assertFalse(versions.contains(""1.2""));
        Assert.assertTrue(versions.contains(""myfaces""));
        Assert.assertTrue(versions.contains(""myfaces2""));
    }
",non-flaky,5
26912,wildfly_wildfly,JSFModuleIdFactoryTestCase.computeSlotTest,"    @Test
    public void computeSlotTest() {
        Assert.assertEquals(""main"", factory.computeSlot(""main""));
        Assert.assertEquals(""main"", factory.computeSlot(null));
        Assert.assertEquals(""main"", factory.computeSlot(JsfVersionMarker.JSF_2_0));
        Assert.assertEquals(""myfaces2"", factory.computeSlot(""myfaces2""));
    }
",non-flaky,5
26913,wildfly_wildfly,JSFModuleIdFactoryTestCase.validSlotTest,"    @Test
    public void validSlotTest() {
        Assert.assertTrue(factory.isValidJSFSlot(""main""));
        Assert.assertFalse(factory.isValidJSFSlot(""1.2""));
        Assert.assertTrue(factory.isValidJSFSlot(""myfaces""));
        Assert.assertTrue(factory.isValidJSFSlot(""myfaces2""));
        Assert.assertTrue(factory.isValidJSFSlot(JsfVersionMarker.JSF_2_0));
        Assert.assertFalse(factory.isValidJSFSlot(JsfVersionMarker.WAR_BUNDLES_JSF_IMPL));
        Assert.assertFalse(factory.isValidJSFSlot(""bogus""));
        Assert.assertFalse(factory.isValidJSFSlot(""bogus2""));
   }
",non-flaky,5
26914,wildfly_wildfly,JSFModuleIdFactoryTestCase.modIdsTest,"    @Test
    public void modIdsTest() {
        Assert.assertEquals(API_MODULE, factory.getApiModId(""main"").getName());
        Assert.assertEquals(""main"", factory.getApiModId(""main"").getSlot());
        Assert.assertEquals(IMPL_MODULE, factory.getImplModId(""main"").getName());
        Assert.assertEquals(""main"", factory.getImplModId(""main"").getSlot());
        Assert.assertEquals(INJECTION_MODULE, factory.getInjectionModId(""main"").getName());
        Assert.assertEquals(""main"", factory.getInjectionModId(""main"").getSlot());

        Assert.assertEquals(API_MODULE, factory.getApiModId(""myfaces"").getName());
        Assert.assertEquals(""myfaces"", factory.getApiModId(""myfaces"").getSlot());
        Assert.assertEquals(IMPL_MODULE, factory.getImplModId(""myfaces"").getName());
        Assert.assertEquals(""myfaces"", factory.getImplModId(""myfaces"").getSlot());
        Assert.assertEquals(INJECTION_MODULE, factory.getInjectionModId(""myfaces"").getName());
        Assert.assertEquals(""myfaces"", factory.getInjectionModId(""myfaces"").getSlot());

        Assert.assertEquals(API_MODULE, factory.getApiModId(""myfaces2"").getName());
        Assert.assertEquals(""myfaces2"", factory.getApiModId(""myfaces2"").getSlot());
        Assert.assertEquals(IMPL_MODULE, factory.getImplModId(""myfaces2"").getName());
        Assert.assertEquals(""myfaces2"", factory.getImplModId(""myfaces2"").getSlot());
        Assert.assertEquals(INJECTION_MODULE, factory.getInjectionModId(""myfaces2"").getName());
        Assert.assertEquals(""myfaces2"", factory.getInjectionModId(""myfaces2"").getSlot());
    }
",non-flaky,5
26915,wildfly_wildfly,MailSubsystem10TestCase.testParseSubsystem,"    @Test
    public void testParseSubsystem() throws Exception {
        //Parse the subsystem xml into operations
        List<ModelNode> operations = super.parse(getSubsystemXml());

        ///Check that we have the expected number of operations
        //log.info(""operations: "" + operations);
        //log.info(""operations.size: "" + operations.size());
        Assert.assertEquals(7, operations.size());

        //Check that each operation has the correct content
        ModelNode addSubsystem = operations.get(0);
        Assert.assertEquals(ADD, addSubsystem.get(OP).asString());
        PathAddress addr = PathAddress.pathAddress(addSubsystem.get(OP_ADDR));
        Assert.assertEquals(1, addr.size());
        PathElement element = addr.getElement(0);
        Assert.assertEquals(SUBSYSTEM, element.getKey());
        Assert.assertEquals(MailExtension.SUBSYSTEM_NAME, element.getValue());
    }
",non-flaky,5
26916,wildfly_wildfly,MailTransformersTestCase.testTransformerEAP700,"    @Test
    public void testTransformerEAP700() throws Exception {
        testTransformation(ModelTestControllerVersion.EAP_7_0_0, MODEL_VERSION_EAP70);
    }
",non-flaky,5
26917,wildfly_wildfly,MailTransformersTestCase.testTransformerEAP640,"    @Test
    public void testTransformerEAP640() throws Exception {
        testTransformation(ModelTestControllerVersion.EAP_6_4_0, MODEL_VERSION_EAP6X);
    }
",non-flaky,5
26918,wildfly_wildfly,MailTransformersTestCase.testRejectingTransformersEAP_7_0_0,"    @Test
    public void testRejectingTransformersEAP_7_0_0() throws Exception {
        testRejectingTransformers(EAP_7_0_0, MODEL_VERSION_EAP70);
    }
",non-flaky,5
26919,wildfly_wildfly,MailTransformersTestCase.testRejectingTransformersEAP_6_4_0,"    @Test
    public void testRejectingTransformersEAP_6_4_0() throws Exception {
        testRejectingTransformers(EAP_6_4_0, MODEL_VERSION_EAP6X);
    }
",non-flaky,5
26920,wildfly_wildfly,MailSubsystem20TestCase.testExpressions,"    @Test
    public void testExpressions() throws Exception {
        standardSubsystemTest(""subsystem_1_1_expressions.xml"", false);
    }
",non-flaky,5
26921,wildfly_wildfly,MailSubsystem20TestCase.test11,"    @Test
    public void test11() throws Exception {
        standardSubsystemTest(""subsystem_1_1.xml"", false);
    }
",non-flaky,5
26922,wildfly_wildfly,MailSubsystem20TestCase.test12,"    @Test
    public void test12() throws Exception {
        standardSubsystemTest(""subsystem_1_2.xml"", false);
    }
",non-flaky,5
26923,wildfly_wildfly,MailSubsystem20TestCase.testRuntime,"    @Test
    public void testRuntime() throws Exception {
        KernelServicesBuilder builder = createKernelServicesBuilder(new DefaultInitializer())
                .setSubsystemXml(getSubsystemXml());
        KernelServices mainServices = builder.build();
        if (!mainServices.isSuccessfulBoot()) {
            Assert.fail(mainServices.getBootError().toString());
        }
        ServiceController<?> javaMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""defaultMail""));
        javaMailService.setMode(ServiceController.Mode.ACTIVE);
        Session session = (Session) javaMailService.getValue();
        Assert.assertNotNull(""session should not be null"", session);
        Properties properties = session.getProperties();
        Assert.assertNotNull(""smtp host should be set"", properties.getProperty(""mail.smtp.host""));
        Assert.assertNotNull(""pop3 host should be set"", properties.getProperty(""mail.pop3.host""));
        Assert.assertNotNull(""imap host should be set"", properties.getProperty(""mail.imap.host""));

        ServiceController<?> defaultMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""default2""));
        session = (Session) defaultMailService.getValue();
        Assert.assertEquals(""Debug should be true"", true, session.getDebug());


        ServiceController<?> customMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""custom""));
        session = (Session) customMailService.getValue();
        properties = session.getProperties();
        String host = properties.getProperty(""mail.smtp.host"");
        Assert.assertNotNull(""smtp host should be set"", host);
        Assert.assertEquals(""mail.example.com"", host);

        Assert.assertEquals(""localhost"", properties.get(""mail.pop3.host"")); //this one should be read out of socket binding
        Assert.assertEquals(""some-custom-prop-value"", properties.get(""mail.pop3.custom_prop"")); //this one should be extra property
        Assert.assertEquals(""fully-qualified-prop-name"", properties.get(""some.fully.qualified.property"")); //this one should be extra property

        MailSessionService service = (MailSessionService) customMailService.getService();
        Credentials credentials = service.getConfig().getCustomServers()[0].getCredentials();
        Assert.assertEquals(credentials.getUsername(), ""username"");
        Assert.assertEquals(credentials.getPassword(), ""password"");


    }
",non-flaky,5
26924,wildfly_wildfly,MailSubsystem30TestCase.testSchemaOfSubsystemTemplates,"    @Test
    public void testSchemaOfSubsystemTemplates() throws Exception {
        super.testSchemaOfSubsystemTemplates();
    }
",non-flaky,5
26925,wildfly_wildfly,MailSubsystem30TestCase.testRuntime,"    @Test
    public void testRuntime() throws Exception {
        KernelServicesBuilder builder = createKernelServicesBuilder(new DefaultInitializer())
                .setSubsystemXml(getSubsystemXml());
        KernelServices mainServices = builder.build();
        if (!mainServices.isSuccessfulBoot()) {
            Assert.fail(mainServices.getBootError().toString());
        }
        ServiceController<?> javaMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""defaultMail""));
        javaMailService.setMode(ServiceController.Mode.ACTIVE);
        Session session = (Session) javaMailService.getValue();
        Assert.assertNotNull(""session should not be null"", session);
        Properties properties = session.getProperties();
        Assert.assertNotNull(""smtp host should be set"", properties.getProperty(""mail.smtp.host""));
        Assert.assertNotNull(""pop3 host should be set"", properties.getProperty(""mail.pop3.host""));
        Assert.assertNotNull(""imap host should be set"", properties.getProperty(""mail.imap.host""));
        PasswordAuthentication auth = session.requestPasswordAuthentication(InetAddress.getLocalHost(), 25, ""smtp"", """", """");
        Assert.assertEquals(""nobody"", auth.getUserName());
        Assert.assertEquals(""pass"", auth.getPassword());

        ServiceController<?> defaultMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""default2""));
        session = (Session) defaultMailService.getValue();
        Assert.assertEquals(""Debug should be true"", true, session.getDebug());


        ServiceController<?> customMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""custom""));
        session = (Session) customMailService.getValue();
        properties = session.getProperties();
        String host = properties.getProperty(""mail.smtp.host"");
        Assert.assertNotNull(""smtp host should be set"", host);
        Assert.assertEquals(""mail.example.com"", host);

        Assert.assertEquals(""localhost"", properties.get(""mail.pop3.host"")); //this one should be read out of socket binding
        Assert.assertEquals(""some-custom-prop-value"", properties.get(""mail.pop3.custom_prop"")); //this one should be extra property
        Assert.assertEquals(""fully-qualified-prop-name"", properties.get(""some.fully.qualified.property"")); //this one should be extra property

        MailSessionService service = (MailSessionService) customMailService.getService();
        Credentials credentials = service.getConfig().getCustomServers()[0].getCredentials();
        Assert.assertEquals(credentials.getUsername(), ""username"");
        Assert.assertEquals(credentials.getPassword(), ""password"");


    }
",non-flaky,5
26926,wildfly_wildfly,MailSubsystemTestBase.testOperations,"    @Test
    public void testOperations() throws Exception {
        KernelServicesBuilder builder = createKernelServicesBuilder(new DefaultInitializer())
                .setSubsystemXml(getSubsystemXml());
        KernelServices mainServices = builder.build();
        if (!mainServices.isSuccessfulBoot()) {
            Assert.fail(mainServices.getBootError().toString());
        }

        PathAddress sessionAddress = PathAddress.pathAddress(MailExtension.SUBSYSTEM_PATH, PathElement.pathElement(MailExtension.MAIL_SESSION_PATH.getKey(), ""defaultMail""));
        ModelNode result;

        ModelNode removeServerOp = Util.createRemoveOperation(sessionAddress.append(""server"", ""imap""));
        removeServerOp.get(OPERATION_HEADERS).get(ALLOW_RESOURCE_SERVICE_RESTART).set(true);
        result = mainServices.executeOperation(removeServerOp);
        checkResult(result);

        ModelNode addServerOp = Util.createAddOperation(sessionAddress.append(""server"", ""imap""));
        addServerOp.get(OPERATION_HEADERS).get(ALLOW_RESOURCE_SERVICE_RESTART).set(true);
        addServerOp.get(""outbound-socket-binding-ref"").set(""mail-imap"");
        addServerOp.get(""username"").set(""user"");
        addServerOp.get(""password"").set(""pswd"");

        result = mainServices.executeOperation(addServerOp);
        checkResult(result);

        checkResult(mainServices.executeOperation(removeServerOp)); //to make sure noting is left behind
        checkResult(mainServices.executeOperation(addServerOp));

        ModelNode writeOp = Util.createEmptyOperation(WRITE_ATTRIBUTE_OPERATION, sessionAddress);
        writeOp.get(OPERATION_HEADERS).get(ALLOW_RESOURCE_SERVICE_RESTART).set(true);
        writeOp.get(""name"").set(""debug"");
        writeOp.get(""value"").set(false);
        result = mainServices.executeOperation(writeOp);
        checkResult(result);


        ServiceController<?> javaMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""defaultMail""));
        javaMailService.setMode(ServiceController.Mode.ACTIVE);
        Session session = (Session) javaMailService.getValue();
        Assert.assertNotNull(""session should not be null"", session);
        Properties properties = session.getProperties();
        Assert.assertNotNull(""smtp host should be set"", properties.getProperty(""mail.smtp.host""));
        Assert.assertNotNull(""imap host should be set"", properties.getProperty(""mail.imap.host""));


        PathAddress nonExisting = PathAddress.pathAddress(MailExtension.SUBSYSTEM_PATH, PathElement.pathElement(MailExtension.MAIL_SESSION_PATH.getKey(), ""non-existing-session""));
        ModelNode addSession = Util.createAddOperation(nonExisting);
        addSession.get(""jndi-name"").set(""java:/bah"");
        checkResult(mainServices.executeOperation(addSession));
        removeServerOp = Util.createRemoveOperation(nonExisting.append(""server"", ""imap""));
        //removeServerOp.get(OPERATION_HEADERS).get(ALLOW_RESOURCE_SERVICE_RESTART).set(true);
        result = mainServices.executeOperation(removeServerOp);
        checkForFailure(result);


    }
",non-flaky,5
81,apache_dubbo,737f7a7ea67832d7f17517326fb2491d0a086dd7.testEmptyByteArrayForEmptyInput,"@Test
public void testEmptyByteArrayForEmptyInput() throws IOException {
    this.fstObjectInput = new FstObjectInput(new ByteArrayInputStream("""".getBytes()));
    byte[] bytes = fstObjectInput.readBytes();
    assertThat(bytes.length, is(0));
}",test order dependency,4
152,apache_dubbo,737f7a7ea67832d7f17517326fb2491d0a086dd7.testListAllPort,"@Test
public void testListAllPort() throws RemotingException {
    String result = port.telnet(null, """");
    assertEquals(""20887"", result);
}",test order dependency,4
190,apache_dubbo,737f7a7ea67832d7f17517326fb2491d0a086dd7.testChangeServiceNotExport,"@Test
public void testChangeServiceNotExport() throws RemotingException {
    String result = change.telnet(mockChannel, ""demo"");
    assertEquals(""No such service demo"", result);
}",test order dependency,4
340,apache_dubbo,737f7a7ea67832d7f17517326fb2491d0a086dd7.testListDetail,"@Test
public void testListDetail() throws RemotingException {
    String result = port.telnet(null, ""-l"");
    assertEquals(""dubbo://127.0.0.1:20887"", result);
}",test order dependency,4
92624,apache_dubbo,GenericServiceTest.testGeneric,"    @Test
    public void testGeneric() {
        DemoService server = new DemoServiceImpl();
        ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();
        Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();
        URL url = URL.valueOf(""dubbo://127.0.0.1:5342/"" + DemoService.class.getName() + ""?version=1.0.0"");
        Exporter<DemoService> exporter = protocol.export(proxyFactory.getInvoker(server, DemoService.class, url));
        Invoker<DemoService> invoker = protocol.refer(DemoService.class, url);

        GenericService client = (GenericService) proxyFactory.getProxy(invoker, true);
        Object result = client.$invoke(""sayHello"", new String[]{""java.lang.String""}, new Object[]{""haha""});
        Assert.assertEquals(""hello haha"", result);

        org.apache.dubbo.rpc.service.GenericService newClient = (org.apache.dubbo.rpc.service.GenericService) proxyFactory.getProxy(invoker, true);
        Object res = newClient.$invoke(""sayHello"", new String[]{""java.lang.String""}, new Object[]{""hehe""});
        Assert.assertEquals(""hello hehe"", res);
        invoker.destroy();
        exporter.unexport();
    }
",non-flaky,5
92625,apache_dubbo,GenericServiceTest.testGeneric2,"    @Test
    public void testGeneric2() {
        DemoService server = new DemoServiceImpl();
        ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();
        Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();
        URL url = URL.valueOf(""dubbo://127.0.0.1:5342/"" + DemoService.class.getName() + ""?version=1.0.0&generic=true"");
        Exporter<DemoService> exporter = protocol.export(proxyFactory.getInvoker(server, DemoService.class, url));
        Invoker<GenericService> invoker = protocol.refer(GenericService.class, url);

        GenericService client = proxyFactory.getProxy(invoker, true);
        Object result = client.$invoke(""sayHello"", new String[]{""java.lang.String""}, new Object[]{""haha""});
        Assert.assertEquals(""hello haha"", result);

        Invoker<DemoService> invoker2 = protocol.refer(DemoService.class, url);

        GenericService client2 = (GenericService) proxyFactory.getProxy(invoker2, true);
        Object result2 = client2.$invoke(""sayHello"", new String[]{""java.lang.String""}, new Object[]{""haha""});
        Assert.assertEquals(""hello haha"", result2);

        invoker.destroy();
        exporter.unexport();
    }
",non-flaky,5
92626,apache_dubbo,ApplicationConfigTest.testName,"    @Test
    public void testName() throws Exception {
        ApplicationConfig application = new ApplicationConfig();
        application.setName(""app"");
        assertThat(application.getName(), equalTo(""app""));
        application = new ApplicationConfig(""app2"");
        assertThat(application.getName(), equalTo(""app2""));
        Map<String, String> parameters = new HashMap<String, String>();
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(Constants.APPLICATION_KEY, ""app2""));
    }
",non-flaky,5
92627,apache_dubbo,ApplicationConfigTest.testVersion,"    @Test
    public void testVersion() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setVersion(""1.0.0"");
        assertThat(application.getVersion(), equalTo(""1.0.0""));
        Map<String, String> parameters = new HashMap<String, String>();
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(""application.version"", ""1.0.0""));
    }
",non-flaky,5
92628,apache_dubbo,ApplicationConfigTest.testOwner,"    @Test
    public void testOwner() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setOwner(""owner"");
        assertThat(application.getOwner(), equalTo(""owner""));
    }
",non-flaky,5
92629,apache_dubbo,ApplicationConfigTest.testOrganization,"    @Test
    public void testOrganization() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setOrganization(""org"");
        assertThat(application.getOrganization(), equalTo(""org""));
    }
",non-flaky,5
92630,apache_dubbo,ApplicationConfigTest.testArchitecture,"    @Test
    public void testArchitecture() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setArchitecture(""arch"");
        assertThat(application.getArchitecture(), equalTo(""arch""));
    }
",non-flaky,5
92631,apache_dubbo,ApplicationConfigTest.testEnvironment1,"    @Test
    public void testEnvironment1() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setEnvironment(""develop"");
        assertThat(application.getEnvironment(), equalTo(""develop""));
        application.setEnvironment(""test"");
        assertThat(application.getEnvironment(), equalTo(""test""));
        application.setEnvironment(""product"");
        assertThat(application.getEnvironment(), equalTo(""product""));
    }
",non-flaky,5
92632,apache_dubbo,ApplicationConfigTest.testEnvironment2,"    @Test(expected = IllegalStateException.class)
    public void testEnvironment2() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setEnvironment(""illegal-env"");
    }
",non-flaky,5
92633,apache_dubbo,ApplicationConfigTest.testRegistry,"    @Test
    public void testRegistry() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        RegistryConfig registry = new RegistryConfig();
        application.setRegistry(registry);
        assertThat(application.getRegistry(), sameInstance(registry));
        application.setRegistries(Collections.singletonList(registry));
        assertThat(application.getRegistries(), contains(registry));
        assertThat(application.getRegistries(), hasSize(1));
    }
",non-flaky,5
92634,apache_dubbo,ApplicationConfigTest.testMonitor,"    @Test
    public void testMonitor() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setMonitor(new MonitorConfig(""monitor-addr""));
        assertThat(application.getMonitor().getAddress(), equalTo(""monitor-addr""));
        application.setMonitor(""monitor-addr"");
        assertThat(application.getMonitor().getAddress(), equalTo(""monitor-addr""));
    }
",non-flaky,5
92635,apache_dubbo,ApplicationConfigTest.testLogger,"    @Test
    public void testLogger() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setLogger(""log4j"");
        assertThat(application.getLogger(), equalTo(""log4j""));
    }
",non-flaky,5
92636,apache_dubbo,ApplicationConfigTest.testDefault,"    @Test
    public void testDefault() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setDefault(true);
        assertThat(application.isDefault(), is(true));
    }
",non-flaky,5
92637,apache_dubbo,ApplicationConfigTest.testDumpDirectory,"    @Test
    public void testDumpDirectory() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setDumpDirectory(""/dump"");
        assertThat(application.getDumpDirectory(), equalTo(""/dump""));
        Map<String, String> parameters = new HashMap<String, String>();
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(Constants.DUMP_DIRECTORY, ""/dump""));
    }
",non-flaky,5
92638,apache_dubbo,ApplicationConfigTest.testQosEnable,"    @Test
    public void testQosEnable() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setQosEnable(true);
        assertThat(application.getQosEnable(), is(true));
        Map<String, String> parameters = new HashMap<String, String>();
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(Constants.QOS_ENABLE, ""true""));
    }
",non-flaky,5
92639,apache_dubbo,ApplicationConfigTest.testQosPort,"    @Test
    public void testQosPort() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setQosPort(8080);
        assertThat(application.getQosPort(), equalTo(8080));
    }
",non-flaky,5
92640,apache_dubbo,ApplicationConfigTest.testQosAcceptForeignIp,"    @Test
    public void testQosAcceptForeignIp() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setQosAcceptForeignIp(true);
        assertThat(application.getQosAcceptForeignIp(), is(true));
        Map<String, String> parameters = new HashMap<String, String>();
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(Constants.ACCEPT_FOREIGN_IP, ""true""));
    }
",non-flaky,5
92641,apache_dubbo,ApplicationConfigTest.testParameters,"    @Test
    public void testParameters() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setQosAcceptForeignIp(true);
        Map<String, String> parameters = new HashMap<String, String>();
        parameters.put(""k1"", ""v1"");
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(""k1"", ""v1""));
        assertThat(parameters, hasEntry(Constants.ACCEPT_FOREIGN_IP, ""true""));
    }
",non-flaky,5
92642,apache_dubbo,RegistryConfigTest.testProtocol,"    @Test
    public void testProtocol() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setProtocol(""protocol"");
        assertThat(registry.getProtocol(), equalTo(registry.getProtocol()));
    }
",non-flaky,5
92643,apache_dubbo,RegistryConfigTest.testAddress,"    @Test
    public void testAddress() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setAddress(""localhost"");
        assertThat(registry.getAddress(), equalTo(""localhost""));
        Map<String, String> parameters = new HashMap<String, String>();
        RegistryConfig.appendParameters(parameters, registry);
        assertThat(parameters, not(hasKey(""address"")));
    }
",non-flaky,5
92644,apache_dubbo,RegistryConfigTest.testUsername,"    @Test
    public void testUsername() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setUsername(""username"");
        assertThat(registry.getUsername(), equalTo(""username""));
    }
",non-flaky,5
92645,apache_dubbo,RegistryConfigTest.testPassword,"    @Test
    public void testPassword() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setPassword(""password"");
        assertThat(registry.getPassword(), equalTo(""password""));
    }
",non-flaky,5
92646,apache_dubbo,RegistryConfigTest.testWait,"    @Test
    public void testWait() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setWait(10);
        assertThat(registry.getWait(), is(10));
        assertThat(System.getProperty(Constants.SHUTDOWN_WAIT_KEY), equalTo(""10""));
    }
",non-flaky,5
92647,apache_dubbo,RegistryConfigTest.testCheck,"    @Test
    public void testCheck() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setCheck(true);
        assertThat(registry.isCheck(), is(true));
    }
",non-flaky,5
92648,apache_dubbo,RegistryConfigTest.testFile,"    @Test
    public void testFile() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setFile(""file"");
        assertThat(registry.getFile(), equalTo(""file""));
    }
",non-flaky,5
92649,apache_dubbo,RegistryConfigTest.testTransporter,"    @Test
    public void testTransporter() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setTransporter(""transporter"");
        assertThat(registry.getTransporter(), equalTo(""transporter""));
    }
",non-flaky,5
92650,apache_dubbo,RegistryConfigTest.testClient,"    @Test
    public void testClient() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setClient(""client"");
        assertThat(registry.getClient(), equalTo(""client""));
    }
",non-flaky,5
92651,apache_dubbo,RegistryConfigTest.testTimeout,"    @Test
    public void testTimeout() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setTimeout(10);
        assertThat(registry.getTimeout(), is(10));
    }
",non-flaky,5
92652,apache_dubbo,RegistryConfigTest.testSession,"    @Test
    public void testSession() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setSession(10);
        assertThat(registry.getSession(), is(10));
    }
",non-flaky,5
92653,apache_dubbo,RegistryConfigTest.testDynamic,"    @Test
    public void testDynamic() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setDynamic(true);
        assertThat(registry.isDynamic(), is(true));
    }
",non-flaky,5
92654,apache_dubbo,RegistryConfigTest.testRegister,"    @Test
    public void testRegister() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setRegister(true);
        assertThat(registry.isRegister(), is(true));
    }
",non-flaky,5
92655,apache_dubbo,RegistryConfigTest.testSubscribe,"    @Test
    public void testSubscribe() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setSubscribe(true);
        assertThat(registry.isSubscribe(), is(true));
    }
",non-flaky,5
92656,apache_dubbo,RegistryConfigTest.testCluster,"    @Test
    public void testCluster() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setCluster(""cluster"");
        assertThat(registry.getCluster(), equalTo(""cluster""));
    }
",non-flaky,5
92657,apache_dubbo,RegistryConfigTest.testGroup,"    @Test
    public void testGroup() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setGroup(""group"");
        assertThat(registry.getGroup(), equalTo(""group""));
    }
",non-flaky,5
92658,apache_dubbo,RegistryConfigTest.testVersion,"    @Test
    public void testVersion() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setVersion(""1.0.0"");
        assertThat(registry.getVersion(), equalTo(""1.0.0""));
    }
",non-flaky,5
92659,apache_dubbo,RegistryConfigTest.testParameters,"    @Test
    public void testParameters() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setParameters(Collections.singletonMap(""k1"", ""v1""));
        assertThat(registry.getParameters(), hasEntry(""k1"", ""v1""));
        Map<String, String> parameters = new HashMap<String, String>();
        RegistryConfig.appendParameters(parameters, registry);
        assertThat(parameters, hasEntry(""k1"", ""v1""));
    }
",non-flaky,5
92660,apache_dubbo,RegistryConfigTest.testDefault,"    @Test
    public void testDefault() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setDefault(true);
        assertThat(registry.isDefault(), is(true));
    }
",non-flaky,5
92661,apache_dubbo,ConsumerConfigTest.testTimeout,"    @Test
    public void testTimeout() throws Exception {
        try {
            System.clearProperty(""sun.rmi.transport.tcp.responseTimeout"");
            ConsumerConfig consumer = new ConsumerConfig();
            consumer.setTimeout(10);
            assertThat(consumer.getTimeout(), is(10));
            assertThat(System.getProperty(""sun.rmi.transport.tcp.responseTimeout""), equalTo(""10""));
        } finally {
            System.clearProperty(""sun.rmi.transport.tcp.responseTimeout"");
        }
    }
",non-flaky,5
92662,apache_dubbo,ConsumerConfigTest.testDefault,"    @Test
    public void testDefault() throws Exception {
        ConsumerConfig consumer = new ConsumerConfig();
        consumer.setDefault(true);
        assertThat(consumer.isDefault(), is(true));
    }
",non-flaky,5
92663,apache_dubbo,ConsumerConfigTest.testClient,"    @Test
    public void testClient() throws Exception {
        ConsumerConfig consumer = new ConsumerConfig();
        consumer.setClient(""client"");
        assertThat(consumer.getClient(), equalTo(""client""));
    }
",non-flaky,5
92664,apache_dubbo,ModuleConfigTest.testName1,"    @Test(expected = IllegalStateException.class)
    public void testName1() throws Exception {
        ModuleConfig module = new ModuleConfig();
        Map<String, String> parameters = new HashMap<String, String>();
        ModuleConfig.appendParameters(parameters, module);
    }
",non-flaky,5
92665,apache_dubbo,ModuleConfigTest.testName2,"    @Test
    public void testName2() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setName(""module-name"");
        assertThat(module.getName(), equalTo(""module-name""));
        assertThat(module.getId(), equalTo(""module-name""));
        Map<String, String> parameters = new HashMap<String, String>();
        ModuleConfig.appendParameters(parameters, module);
        assertThat(parameters, hasEntry(""module"", ""module-name""));
    }
",non-flaky,5
92666,apache_dubbo,ModuleConfigTest.testVersion,"    @Test
    public void testVersion() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setName(""module-name"");
        module.setVersion(""1.0.0"");
        assertThat(module.getVersion(), equalTo(""1.0.0""));
        Map<String, String> parameters = new HashMap<String, String>();
        ModuleConfig.appendParameters(parameters, module);
        assertThat(parameters, hasEntry(""module.version"", ""1.0.0""));
    }
",non-flaky,5
92667,apache_dubbo,ModuleConfigTest.testOwner,"    @Test
    public void testOwner() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setOwner(""owner"");
        assertThat(module.getOwner(), equalTo(""owner""));
    }
",non-flaky,5
92668,apache_dubbo,ModuleConfigTest.testOrganization,"    @Test
    public void testOrganization() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setOrganization(""org"");
        assertThat(module.getOrganization(), equalTo(""org""));
    }
",non-flaky,5
92669,apache_dubbo,ModuleConfigTest.testRegistry,"    @Test
    public void testRegistry() throws Exception {
        ModuleConfig module = new ModuleConfig();
        RegistryConfig registry = new RegistryConfig();
        module.setRegistry(registry);
        assertThat(module.getRegistry(), sameInstance(registry));
    }
",non-flaky,5
92670,apache_dubbo,ModuleConfigTest.testRegistries,"    @Test
    public void testRegistries() throws Exception {
        ModuleConfig module = new ModuleConfig();
        RegistryConfig registry = new RegistryConfig();
        module.setRegistries(Collections.singletonList(registry));
        assertThat(module.getRegistries(), Matchers.<org.apache.dubbo.config.RegistryConfig>hasSize(1));
        assertThat(module.getRegistries(), contains(registry));
    }
",non-flaky,5
92671,apache_dubbo,ModuleConfigTest.testMonitor,"    @Test
    public void testMonitor() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setMonitor(""monitor-addr1"");
        assertThat(module.getMonitor().getAddress(), equalTo(""monitor-addr1""));
        module.setMonitor(new MonitorConfig(""monitor-addr2""));
        assertThat(module.getMonitor().getAddress(), equalTo(""monitor-addr2""));
    }
",non-flaky,5
92672,apache_dubbo,ModuleConfigTest.testDefault,"    @Test
    public void testDefault() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setDefault(true);
        assertThat(module.isDefault(), is(true));
    }
",non-flaky,5
92673,apache_dubbo,ArgumentConfigTest.testIndex,"    @Test
    public void testIndex() throws Exception {
        ArgumentConfig argument = new ArgumentConfig();
        argument.setIndex(1);
        assertThat(argument.getIndex(), is(1));
    }
",non-flaky,5
92674,apache_dubbo,ArgumentConfigTest.testType,"    @Test
    public void testType() throws Exception {
        ArgumentConfig argument = new ArgumentConfig();
        argument.setType(""int"");
        assertThat(argument.getType(), equalTo(""int""));
    }
",non-flaky,5
92675,apache_dubbo,ArgumentConfigTest.testCallback,"    @Test
    public void testCallback() throws Exception {
        ArgumentConfig argument = new ArgumentConfig();
        argument.setCallback(true);
        assertThat(argument.isCallback(), is(true));
    }
",non-flaky,5
92676,apache_dubbo,ArgumentConfigTest.testArguments,"    @Test
    public void testArguments() throws Exception {
        ArgumentConfig argument = new ArgumentConfig();
        argument.setIndex(1);
        argument.setType(""int"");
        argument.setCallback(true);
        Map<String, String> parameters = new HashMap<String, String>();
        AbstractServiceConfig.appendParameters(parameters, argument);
        assertThat(parameters, hasEntry(""callback"", ""true""));
        assertThat(parameters.size(), is(1));
    }
",non-flaky,5
92677,apache_dubbo,ProviderConfigTest.testProtocol,"    @Test
    public void testProtocol() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setProtocol(""protocol"");
        assertThat(provider.getProtocol().getName(), equalTo(""protocol""));
    }
",non-flaky,5
92678,apache_dubbo,ProviderConfigTest.testDefault,"    @Test
    public void testDefault() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setDefault(true);
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.isDefault(), is(true));
        assertThat(parameters, not(hasKey(""default"")));
    }
",non-flaky,5
92679,apache_dubbo,ProviderConfigTest.testHost,"    @Test
    public void testHost() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setHost(""demo-host"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.getHost(), equalTo(""demo-host""));
        assertThat(parameters, not(hasKey(""host"")));
    }
",non-flaky,5
92680,apache_dubbo,ProviderConfigTest.testPort,"    @Test
    public void testPort() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setPort(8080);
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.getPort(), is(8080));
        assertThat(parameters, not(hasKey(""port"")));
    }
",non-flaky,5
92681,apache_dubbo,ProviderConfigTest.testPath,"    @Test
    public void testPath() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setPath(""/path"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.getPath(), equalTo(""/path""));
        assertThat(provider.getContextpath(), equalTo(""/path""));
        assertThat(parameters, not(hasKey(""path"")));
    }
",non-flaky,5
92682,apache_dubbo,ProviderConfigTest.testContextPath,"    @Test
    public void testContextPath() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setContextpath(""/context-path"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.getContextpath(), equalTo(""/context-path""));
        assertThat(parameters, not(hasKey(""/context-path"")));
    }
",non-flaky,5
92683,apache_dubbo,ProviderConfigTest.testThreads,"    @Test
    public void testThreads() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setThreads(10);
        assertThat(provider.getThreads(), is(10));
    }
",non-flaky,5
92684,apache_dubbo,ProviderConfigTest.testIothreads,"    @Test
    public void testIothreads() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setIothreads(10);
        assertThat(provider.getIothreads(), is(10));
    }
",non-flaky,5
92685,apache_dubbo,ProviderConfigTest.testQueues,"    @Test
    public void testQueues() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setQueues(10);
        assertThat(provider.getQueues(), is(10));
    }
",non-flaky,5
92686,apache_dubbo,ProviderConfigTest.testAccepts,"    @Test
    public void testAccepts() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setAccepts(10);
        assertThat(provider.getAccepts(), is(10));
    }
",non-flaky,5
92687,apache_dubbo,ProviderConfigTest.testCharset,"    @Test
    public void testCharset() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setCharset(""utf-8"");
        assertThat(provider.getCharset(), equalTo(""utf-8""));
    }
",non-flaky,5
92688,apache_dubbo,ProviderConfigTest.testPayload,"    @Test
    public void testPayload() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setPayload(10);
        assertThat(provider.getPayload(), is(10));
    }
",non-flaky,5
92689,apache_dubbo,ProviderConfigTest.testBuffer,"    @Test
    public void testBuffer() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setBuffer(10);
        assertThat(provider.getBuffer(), is(10));
    }
",non-flaky,5
92690,apache_dubbo,ProviderConfigTest.testServer,"    @Test
    public void testServer() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setServer(""demo-server"");
        assertThat(provider.getServer(), equalTo(""demo-server""));
    }
",non-flaky,5
92691,apache_dubbo,ProviderConfigTest.testClient,"    @Test
    public void testClient() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setClient(""client"");
        assertThat(provider.getClient(), equalTo(""client""));
    }
",non-flaky,5
92692,apache_dubbo,ProviderConfigTest.testPrompt,"    @Test
    public void testPrompt() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setPrompt(""#"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.getPrompt(), equalTo(""#""));
        assertThat(parameters, hasEntry(""prompt"", ""%23""));
    }
",non-flaky,5
92693,apache_dubbo,ProviderConfigTest.testDispatcher,"    @Test
    public void testDispatcher() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setDispatcher(""mockdispatcher"");
        assertThat(provider.getDispatcher(), equalTo(""mockdispatcher""));
    }
",non-flaky,5
92694,apache_dubbo,ProviderConfigTest.testNetworker,"    @Test
    public void testNetworker() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setNetworker(""networker"");
        assertThat(provider.getNetworker(), equalTo(""networker""));
    }
",non-flaky,5
92695,apache_dubbo,ProviderConfigTest.testWait,"    @Test
    public void testWait() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setWait(10);
        assertThat(provider.getWait(), equalTo(10));
    }
",non-flaky,5
92696,apache_dubbo,MethodConfigTest.testName,"    @Test
    public void testName() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setName(""hello"");
        assertThat(method.getName(), equalTo(""hello""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters, not(hasKey(""name"")));
    }
",non-flaky,5
92697,apache_dubbo,MethodConfigTest.testStat,"    @Test
    public void testStat() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setStat(10);
        assertThat(method.getStat(), equalTo(10));
    }
",non-flaky,5
92698,apache_dubbo,MethodConfigTest.testRetry,"    @Test
    public void testRetry() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setRetry(true);
        assertThat(method.isRetry(), is(true));
    }
",non-flaky,5
92699,apache_dubbo,MethodConfigTest.testReliable,"    @Test
    public void testReliable() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setReliable(true);
        assertThat(method.isReliable(), is(true));
    }
",non-flaky,5
92700,apache_dubbo,MethodConfigTest.testExecutes,"    @Test
    public void testExecutes() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setExecutes(10);
        assertThat(method.getExecutes(), equalTo(10));
    }
",non-flaky,5
92701,apache_dubbo,MethodConfigTest.testDeprecated,"    @Test
    public void testDeprecated() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setDeprecated(true);
        assertThat(method.getDeprecated(), is(true));
    }
",non-flaky,5
92702,apache_dubbo,MethodConfigTest.testArguments,"    @Test
    public void testArguments() throws Exception {
        MethodConfig method = new MethodConfig();
        ArgumentConfig argument = new ArgumentConfig();
        method.setArguments(Collections.singletonList(argument));
        assertThat(method.getArguments(), contains(argument));
        assertThat(method.getArguments(), Matchers.<org.apache.dubbo.config.ArgumentConfig>hasSize(1));
    }
",non-flaky,5
92703,apache_dubbo,MethodConfigTest.testSticky,"    @Test
    public void testSticky() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setSticky(true);
        assertThat(method.getSticky(), is(true));
    }
",non-flaky,5
92704,apache_dubbo,MethodConfigTest.testOnreturn,"    @Test
    public void testOnreturn() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setOnreturn(""on-return-object"");
        assertThat(method.getOnreturn(), equalTo((Object) ""on-return-object""));
        Map<Object, Object> attribute = new HashMap<Object, Object>();
        MethodConfig.appendAttributes(attribute, method);
        assertThat(attribute, hasEntry((Object) Constants.ON_RETURN_INSTANCE_KEY, (Object) ""on-return-object""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters.size(), is(0));
    }
",non-flaky,5
92705,apache_dubbo,MethodConfigTest.testOnreturnMethod,"    @Test
    public void testOnreturnMethod() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setOnreturnMethod(""on-return-method"");
        assertThat(method.getOnreturnMethod(), equalTo(""on-return-method""));
        Map<Object, Object> attribute = new HashMap<Object, Object>();
        MethodConfig.appendAttributes(attribute, method);
        assertThat(attribute, hasEntry((Object) Constants.ON_RETURN_METHOD_KEY, (Object) ""on-return-method""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters.size(), is(0));
    }
",non-flaky,5
92706,apache_dubbo,MethodConfigTest.testOnthrow,"    @Test
    public void testOnthrow() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setOnthrow(""on-throw-object"");
        assertThat(method.getOnthrow(), equalTo((Object) ""on-throw-object""));
        Map<Object, Object> attribute = new HashMap<Object, Object>();
        MethodConfig.appendAttributes(attribute, method);
        assertThat(attribute, hasEntry((Object) Constants.ON_THROW_INSTANCE_KEY, (Object) ""on-throw-object""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters.size(), is(0));
    }
",non-flaky,5
92707,apache_dubbo,MethodConfigTest.testOnthrowMethod,"    @Test
    public void testOnthrowMethod() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setOnthrowMethod(""on-throw-method"");
        assertThat(method.getOnthrowMethod(), equalTo(""on-throw-method""));
        Map<Object, Object> attribute = new HashMap<Object, Object>();
        MethodConfig.appendAttributes(attribute, method);
        assertThat(attribute, hasEntry((Object) Constants.ON_THROW_METHOD_KEY, (Object) ""on-throw-method""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters.size(), is(0));
    }
",non-flaky,5
92708,apache_dubbo,MethodConfigTest.testOninvoke,"    @Test
    public void testOninvoke() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setOninvoke(""on-invoke-object"");
        assertThat(method.getOninvoke(), equalTo((Object) ""on-invoke-object""));
        Map<Object, Object> attribute = new HashMap<Object, Object>();
        MethodConfig.appendAttributes(attribute, method);
        assertThat(attribute, hasEntry((Object) Constants.ON_INVOKE_INSTANCE_KEY, (Object) ""on-invoke-object""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters.size(), is(0));
    }
",non-flaky,5
92709,apache_dubbo,MethodConfigTest.testOninvokeMethod,"    @Test
    public void testOninvokeMethod() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setOninvokeMethod(""on-invoke-method"");
        assertThat(method.getOninvokeMethod(), equalTo(""on-invoke-method""));
        Map<Object, Object> attribute = new HashMap<Object, Object>();
        MethodConfig.appendAttributes(attribute, method);
        assertThat(attribute, hasEntry((Object) Constants.ON_INVOKE_METHOD_KEY, (Object) ""on-invoke-method""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters.size(), is(0));
    }
",non-flaky,5
92710,apache_dubbo,MethodConfigTest.testReturn,"    @Test
    public void testReturn() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setReturn(true);
        assertThat(method.isReturn(), is(true));
    }
",non-flaky,5
92711,apache_dubbo,ConfigTest.testConfig,"    @Test
    public void testConfig() {
        com.alibaba.dubbo.config.ServiceConfig<DemoService> service = new ServiceConfig<>();
        service.setApplication(new com.alibaba.dubbo.config.ApplicationConfig(""first-dubbo-provider""));
        service.setRegistry(new com.alibaba.dubbo.config.RegistryConfig(""multicast://224.5.6.7:1234""));
        service.setInterface(DemoService.class);
        service.setRef(new DemoServiceImpl());
        service.export();

        com.alibaba.dubbo.config.ReferenceConfig<DemoService> reference = new ReferenceConfig<>();
        reference.setApplication(new ApplicationConfig(""first-dubbo-client""));
        reference.setRegistry(new RegistryConfig(""multicast://224.5.6.7:1234""));
        reference.setInterface(DemoService.class);
        DemoService demoService = reference.get();
        String message = demoService.sayHello(""dubbo"");
        Assert.assertEquals(""hello dubbo"", message);
    }
",non-flaky,5
92712,apache_dubbo,ProtocolConfigTest.testName,"    @Test
    public void testName() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setName(""name"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProtocolConfig.appendParameters(parameters, protocol);
        assertThat(protocol.getName(), equalTo(""name""));
        assertThat(protocol.getId(), equalTo(""name""));
        assertThat(parameters.isEmpty(), is(true));
    }
",non-flaky,5
92713,apache_dubbo,ProtocolConfigTest.testHost,"    @Test
    public void testHost() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setHost(""host"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProtocolConfig.appendParameters(parameters, protocol);
        assertThat(protocol.getHost(), equalTo(""host""));
        assertThat(parameters.isEmpty(), is(true));
    }
",non-flaky,5
92714,apache_dubbo,ProtocolConfigTest.testPort,"    @Test
    public void testPort() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setPort(8080);
        Map<String, String> parameters = new HashMap<String, String>();
        ProtocolConfig.appendParameters(parameters, protocol);
        assertThat(protocol.getPort(), equalTo(8080));
        assertThat(parameters.isEmpty(), is(true));
    }
",non-flaky,5
92715,apache_dubbo,ProtocolConfigTest.testPath,"    @Test
    public void testPath() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setContextpath(""context-path"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProtocolConfig.appendParameters(parameters, protocol);
        assertThat(protocol.getPath(), equalTo(""context-path""));
        assertThat(protocol.getContextpath(), equalTo(""context-path""));
        assertThat(parameters.isEmpty(), is(true));
        protocol.setPath(""path"");
        assertThat(protocol.getPath(), equalTo(""path""));
        assertThat(protocol.getContextpath(), equalTo(""path""));
    }
",non-flaky,5
92716,apache_dubbo,ProtocolConfigTest.testThreads,"    @Test
    public void testThreads() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setThreads(10);
        assertThat(protocol.getThreads(), is(10));
    }
",non-flaky,5
92717,apache_dubbo,ProtocolConfigTest.testIothreads,"    @Test
    public void testIothreads() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setIothreads(10);
        assertThat(protocol.getIothreads(), is(10));
    }
",non-flaky,5
92718,apache_dubbo,ProtocolConfigTest.testQueues,"    @Test
    public void testQueues() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setQueues(10);
        assertThat(protocol.getQueues(), is(10));
    }
",non-flaky,5
92719,apache_dubbo,ProtocolConfigTest.testAccepts,"    @Test
    public void testAccepts() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setAccepts(10);
        assertThat(protocol.getAccepts(), is(10));
    }
",non-flaky,5
92720,apache_dubbo,ProtocolConfigTest.testAccesslog,"    @Test
    public void testAccesslog() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setAccesslog(""access.log"");
        assertThat(protocol.getAccesslog(), equalTo(""access.log""));
    }
",non-flaky,5
92721,apache_dubbo,ProtocolConfigTest.testRegister,"    @Test
    public void testRegister() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setRegister(true);
        assertThat(protocol.isRegister(), is(true));
    }
",non-flaky,5
92722,apache_dubbo,ProtocolConfigTest.testParameters,"    @Test
    public void testParameters() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setParameters(Collections.singletonMap(""k1"", ""v1""));
        assertThat(protocol.getParameters(), hasEntry(""k1"", ""v1""));
    }
",non-flaky,5
92723,apache_dubbo,ProtocolConfigTest.testDefault,"    @Test
    public void testDefault() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setDefault(true);
        assertThat(protocol.isDefault(), is(true));
    }
",non-flaky,5
168,apache_shardingsphere-elasticjob,b022898ef1b8c984e17efb2a422ee45f6b13e46e.assertPersistEphemeralSequential,"@Test
public void assertPersistEphemeralSequential() throws Exception {
    zkRegCenter.persistEphemeralSequential(""/sequential/test_ephemeral_sequential"");
    zkRegCenter.persistEphemeralSequential(""/sequential/test_ephemeral_sequential"");
    CuratorFramework client = CuratorFrameworkFactory.newClient(EmbedTestingServer.getConnectionString(), new RetryOneTime(2000));
    client.start();
    client.blockUntilConnected();
    List<String> actual = client.getChildren().forPath(""/"" + ZookeeperRegistryCenterModifyTest.class.getName() + ""/sequential"");
    assertThat(actual.size(), is(2));
    for (String each : actual) {
        assertThat(each, startsWith(""test_ephemeral_sequential""));
    }
    zkRegCenter.close();
    actual = client.getChildren().forPath(""/"" + ZookeeperRegistryCenterModifyTest.class.getName() + ""/sequential"");
    assertTrue(actual.isEmpty());
    zkRegCenter.init();
}",test order dependency,4
182,apache_shardingsphere-elasticjob,b022898ef1b8c984e17efb2a422ee45f6b13e46e.assertGetLocalFailoverItemsIfShutdown,"@Test
public void assertGetLocalFailoverItemsIfShutdown() {
    assertThat(failoverService.getLocalFailoverItems(), is(Collections.<Integer>emptyList()));
    verify(jobNodeStorage, times(0)).getJobNodeChildrenKeys(""sharding"");
}",test order dependency,4
199,apache_shardingsphere-elasticjob,b022898ef1b8c984e17efb2a422ee45f6b13e46e.assertGetCurrentShardingTotalCountIfNull,"@Test
public void assertGetCurrentShardingTotalCountIfNull() {
    assertThat(JobRegistry.getInstance().getCurrentShardingTotalCount(""exist_job_instance""), is(0));
}",test order dependency,4
282,apache_shardingsphere-elasticjob,b022898ef1b8c984e17efb2a422ee45f6b13e46e.assertIsShutdownAlready,"@Test
public void assertIsShutdownAlready() {
    shutdownListenerManager.new InstanceShutdownStatusJobListener().dataChanged(""/test_job/instances/127.0.0.1@-@0"", Type.NODE_REMOVED, """");
    verify(schedulerFacade, times(0)).shutdownInstance();
}",test order dependency,4
112063,apache_shardingsphere-elasticjob,HomeFolderUtilsTest.assertGetFilePathInHomeFolder,"    @Test
    public void assertGetFilePathInHomeFolder() {
        assertThat(HomeFolderUtils.getFilePathInHomeFolder(""test_file""), is(HOME_FOLDER + ""test_file""));
    }
",non-flaky,5
112064,apache_shardingsphere-elasticjob,StreamingDataflowElasticJobForNotMonitorTest.assertJobInit,"    @Test
    public void assertJobInit() {
        while (!StreamingDataflowElasticJob.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
",non-flaky,5
112065,apache_shardingsphere-elasticjob,OneOffDataflowElasticJobTest.assertJobInit,"    @Test
    public void assertJobInit() {
        while (!OneOffDataflowElasticJob.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
",non-flaky,5
112066,apache_shardingsphere-elasticjob,StreamingDataflowElasticJobForExecuteThrowsExceptionTest.assertJobInit,"    @Test
    public void assertJobInit() {
        while (!StreamingDataflowElasticJobForExecuteThrowsException.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
",non-flaky,5
112067,apache_shardingsphere-elasticjob,StreamingDataflowElasticJobTest.assertJobInit,"    @Test
    public void assertJobInit() {
        while (!StreamingDataflowElasticJob.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
",non-flaky,5
112068,apache_shardingsphere-elasticjob,StreamingDataflowElasticJobForMultipleThreadsTest.assertJobInit,"    @Test
    public void assertJobInit() {
        while (!StreamingDataflowElasticJob.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
",non-flaky,5
112069,apache_shardingsphere-elasticjob,StreamingDataflowElasticJobForExecuteFailureTest.assertJobInit,"    @Test
    public void assertJobInit() {
        while (!StreamingDataflowElasticJobForExecuteFailure.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
",non-flaky,5
112070,apache_shardingsphere-elasticjob,ScriptElasticJobTest.assertJobInit,"    @Test
    public void assertJobInit() throws IOException {
        ScriptElasticJobUtil.buildScriptCommandLine();
        WaitingUtils.waitingShortTime();
        String scriptCommandLine = ((ScriptJobConfiguration) getLiteJobConfig().getTypeConfig()).getScriptCommandLine();
        LiteJobConfiguration liteJobConfig = LiteJobConfigurationGsonFactory.fromJson(getRegCenter().get(""/"" + getJobName() + ""/config""));
        assertThat(((ScriptJobConfiguration) liteJobConfig.getTypeConfig()).getScriptCommandLine(), is(scriptCommandLine));
    }
",non-flaky,5
112071,apache_shardingsphere-elasticjob,DisabledJobTest.assertJobInit,"    @Test
    public void assertJobInit() {
        initJob();
        assertRegCenterCommonInfoWithDisabled();
    }
",non-flaky,5
112072,apache_shardingsphere-elasticjob,SimpleElasticJobTest.assertJobInit,"    @Test
    public void assertJobInit() {
        while (!FooSimpleElasticJob.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
",non-flaky,5
112073,apache_shardingsphere-elasticjob,JobConfigurationExceptionTest.assertGetMessage,"    @Test
    public void assertGetMessage() {
        assertThat(new JobConfigurationException(""message is: '%s'"", ""test"").getMessage(), is(""message is: 'test'""));
    }
",non-flaky,5
112074,apache_shardingsphere-elasticjob,JobConfigurationExceptionTest.assertGetCause,"    @Test
    public void assertGetCause() {
        assertThat(new JobConfigurationException(new RuntimeException()).getCause(), instanceOf(RuntimeException.class));
    }
",non-flaky,5
112075,apache_shardingsphere-elasticjob,JobStatisticExceptionTest.assertGetCause,"    @Test
    public void assertGetCause() {
        assertThat(new JobStatisticException(new RuntimeException()).getCause(), instanceOf(RuntimeException.class));
    }
",non-flaky,5
112076,apache_shardingsphere-elasticjob,JobExecutionEnvironmentExceptionTest.assertGetMessage,"    @Test
    public void assertGetMessage() {
        assertThat(new JobExecutionEnvironmentException(""message is: '%s'"", ""test"").getMessage(), is(""message is: 'test'""));
    }
",non-flaky,5
112077,apache_shardingsphere-elasticjob,ExceptionUtilTest.assertTransformWithError,"    @Test
    public void assertTransformWithError() {
        assertTrue(ExceptionUtil.transform(new Error(""Error"")).startsWith(""java.lang.Error""));
    }
",non-flaky,5
112078,apache_shardingsphere-elasticjob,ExceptionUtilTest.assertTransformWithException,"    @Test
    public void assertTransformWithException() {
        assertTrue(ExceptionUtil.transform(new Exception(""Exception"")).startsWith(""java.lang.Exception""));
    }
",non-flaky,5
112079,apache_shardingsphere-elasticjob,ExceptionUtilTest.assertTransformWithNull,"    @Test
    public void assertTransformWithNull() {
        assertThat(ExceptionUtil.transform(null), is(""""));
    }
",non-flaky,5
112080,apache_shardingsphere-elasticjob,JobSystemExceptionTest.assertGetMessage,"    @Test
    public void assertGetMessage() {
        assertThat(new JobSystemException(""message is: '%s'"", ""test"").getMessage(), is(""message is: 'test'""));
    }
",non-flaky,5
112081,apache_shardingsphere-elasticjob,JobSystemExceptionTest.assertGetCause,"    @Test
    public void assertGetCause() {
        assertThat(new JobSystemException(new RuntimeException()).getCause(), instanceOf(RuntimeException.class));
    }
",non-flaky,5
112082,apache_shardingsphere-elasticjob,JobShardingStrategyFactoryTest.assertGetDefaultStrategy,"    @Test
    public void assertGetDefaultStrategy() {
        assertThat(JobShardingStrategyFactory.getStrategy(null), instanceOf(AverageAllocationJobShardingStrategy.class));
    }
",non-flaky,5
112083,apache_shardingsphere-elasticjob,JobShardingStrategyFactoryTest.assertGetStrategyFailureWhenClassNotFound,"    @Test(expected = JobConfigurationException.class)
    public void assertGetStrategyFailureWhenClassNotFound() {
        JobShardingStrategyFactory.getStrategy(""NotClass"");
    }
",non-flaky,5
112084,apache_shardingsphere-elasticjob,JobShardingStrategyFactoryTest.assertGetStrategyFailureWhenNotStrategyClass,"    @Test(expected = JobConfigurationException.class)
    public void assertGetStrategyFailureWhenNotStrategyClass() {
        JobShardingStrategyFactory.getStrategy(Object.class.getName());
    }
",non-flaky,5
112085,apache_shardingsphere-elasticjob,JobShardingStrategyFactoryTest.assertGetStrategyFailureWhenStrategyClassInvalid,"    @Test(expected = JobConfigurationException.class)
    public void assertGetStrategyFailureWhenStrategyClassInvalid() {
        JobShardingStrategyFactory.getStrategy(InvalidJobShardingStrategy.class.getName());
    }
",non-flaky,5
112086,apache_shardingsphere-elasticjob,JobShardingStrategyFactoryTest.assertGetStrategySuccess,"    @Test
    public void assertGetStrategySuccess() {
        assertThat(JobShardingStrategyFactory.getStrategy(AverageAllocationJobShardingStrategy.class.getName()), instanceOf(AverageAllocationJobShardingStrategy.class));
    }
",non-flaky,5
112087,apache_shardingsphere-elasticjob,AverageAllocationJobShardingStrategyTest.shardingForZeroServer,"    @Test
    public void shardingForZeroServer() {
        assertThat(jobShardingStrategy.sharding(Collections.<JobInstance>emptyList(), ""test_job"", 3), is(Collections.<JobInstance, List<Integer>>emptyMap()));
    }
",non-flaky,5
112088,apache_shardingsphere-elasticjob,AverageAllocationJobShardingStrategyTest.shardingForOneServer,"    @Test
    public void shardingForOneServer() {
        Map<JobInstance, List<Integer>> expected = new LinkedHashMap<>(1, 1);
        expected.put(new JobInstance(""host0@-@0""), Arrays.asList(0, 1, 2));
        assertThat(jobShardingStrategy.sharding(Collections.singletonList(new JobInstance(""host0@-@0"")), ""test_job"", 3), is(expected));
    }
",non-flaky,5
112089,apache_shardingsphere-elasticjob,AverageAllocationJobShardingStrategyTest.shardingForServersMoreThanShardingCount,"    @Test
    public void shardingForServersMoreThanShardingCount() {
        Map<JobInstance, List<Integer>> expected = new LinkedHashMap<>(3, 1);
        expected.put(new JobInstance(""host0@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host1@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host2@-@0""), Collections.<Integer>emptyList());
        assertThat(jobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""test_job"", 2), is(expected));
    }
",non-flaky,5
112090,apache_shardingsphere-elasticjob,AverageAllocationJobShardingStrategyTest.shardingForServersLessThanShardingCountAliquot,"    @Test
    public void shardingForServersLessThanShardingCountAliquot() {
        Map<JobInstance, List<Integer>> expected = new LinkedHashMap<>(3, 1);
        expected.put(new JobInstance(""host0@-@0""), Arrays.asList(0, 1, 2));
        expected.put(new JobInstance(""host1@-@0""), Arrays.asList(3, 4, 5));
        expected.put(new JobInstance(""host2@-@0""), Arrays.asList(6, 7, 8));
        assertThat(jobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""test_job"", 9), is(expected));
    }
",non-flaky,5
112091,apache_shardingsphere-elasticjob,AverageAllocationJobShardingStrategyTest.shardingForServersLessThanShardingCountAliquantFor8ShardingCountAnd3Servers,"    @Test
    public void shardingForServersLessThanShardingCountAliquantFor8ShardingCountAnd3Servers() {
        Map<JobInstance, List<Integer>> expected = new LinkedHashMap<>(3, 1);
        expected.put(new JobInstance(""host0@-@0""), Arrays.asList(0, 1, 6));
        expected.put(new JobInstance(""host1@-@0""), Arrays.asList(2, 3, 7));
        expected.put(new JobInstance(""host2@-@0""), Arrays.asList(4, 5));
        assertThat(jobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""test_job"", 8), is(expected));
    }
",non-flaky,5
112092,apache_shardingsphere-elasticjob,AverageAllocationJobShardingStrategyTest.shardingForServersLessThanShardingCountAliquantFor10ShardingCountAnd3Servers,"    @Test
    public void shardingForServersLessThanShardingCountAliquantFor10ShardingCountAnd3Servers() {
        Map<JobInstance, List<Integer>> expected = new LinkedHashMap<>(3, 1);
        expected.put(new JobInstance(""host0@-@0""), Arrays.asList(0, 1, 2, 9));
        expected.put(new JobInstance(""host1@-@0""), Arrays.asList(3, 4, 5));
        expected.put(new JobInstance(""host2@-@0""), Arrays.asList(6, 7, 8));
        assertThat(jobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""test_job"", 10), is(expected));
    }
",non-flaky,5
112093,apache_shardingsphere-elasticjob,RotateServerByNameJobShardingStrategyTest.assertSharding1,"    @Test
    public void assertSharding1() {
        Map<JobInstance, List<Integer>> expected = new HashMap<>();
        expected.put(new JobInstance(""host1@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host2@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host0@-@0""), Collections.<Integer>emptyList());
        assertThat(rotateServerByNameJobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""1"", 2), is(expected));
    }
",non-flaky,5
112094,apache_shardingsphere-elasticjob,RotateServerByNameJobShardingStrategyTest.assertSharding2,"    @Test
    public void assertSharding2() {
        Map<JobInstance, List<Integer>> expected = new HashMap<>();
        expected.put(new JobInstance(""host2@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host0@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host1@-@0""), Collections.<Integer>emptyList());
        assertThat(rotateServerByNameJobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""2"", 2), is(expected));
    }
",non-flaky,5
112095,apache_shardingsphere-elasticjob,RotateServerByNameJobShardingStrategyTest.assertSharding3,"    @Test
    public void assertSharding3() {
        Map<JobInstance, List<Integer>> expected = new HashMap<>();
        expected.put(new JobInstance(""host0@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host1@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host2@-@0""), Collections.<Integer>emptyList());
        assertThat(rotateServerByNameJobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""3"", 2), is(expected));
    }
",non-flaky,5
112096,apache_shardingsphere-elasticjob,OdevitySortByNameJobShardingStrategyTest.assertShardingByAsc,"    @Test
    public void assertShardingByAsc() {
        Map<JobInstance, List<Integer>> expected = new HashMap<>();
        expected.put(new JobInstance(""host0@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host1@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host2@-@0""), Collections.<Integer>emptyList());
        assertThat(odevitySortByNameJobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""1"", 2), is(expected));
    }
",non-flaky,5
112097,apache_shardingsphere-elasticjob,OdevitySortByNameJobShardingStrategyTest.assertShardingByDesc,"    @Test
    public void assertShardingByDesc() {
        Map<JobInstance, List<Integer>> expected = new HashMap<>();
        expected.put(new JobInstance(""host2@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host1@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host0@-@0""), Collections.<Integer>emptyList());
        assertThat(odevitySortByNameJobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""0"", 2), is(expected));
    }
",non-flaky,5
112098,apache_shardingsphere-elasticjob,JobInstanceTest.assertGetJobInstanceId,"    @Test
    public void assertGetJobInstanceId() {
        assertThat(new JobInstance(""127.0.0.1@-@0"").getJobInstanceId(), is(""127.0.0.1@-@0""));
    }
",non-flaky,5
112099,apache_shardingsphere-elasticjob,JobInstanceTest.assertGetIp,"    @Test
    public void assertGetIp() {
        assertThat(new JobInstance().getIp(), Is.is(IpUtils.getIp()));
    }
",non-flaky,5
112100,apache_shardingsphere-elasticjob,DistributeOnceElasticJobListenerTest.assertBeforeJobExecutedWhenIsAllStarted,"    @Test
    public void assertBeforeJobExecutedWhenIsAllStarted() {
        when(guaranteeService.isAllStarted()).thenReturn(true);
        distributeOnceElasticJobListener.beforeJobExecuted(shardingContexts);
        verify(guaranteeService).registerStart(Sets.newHashSet(0, 1));
        verify(elasticJobListenerCaller).before();
        verify(guaranteeService).clearAllStartedInfo();
    }
",non-flaky,5
112101,apache_shardingsphere-elasticjob,DistributeOnceElasticJobListenerTest.assertBeforeJobExecutedWhenIsNotAllStartedAndNotTimeout,"    @Test
    public void assertBeforeJobExecutedWhenIsNotAllStartedAndNotTimeout() {
        when(guaranteeService.isAllStarted()).thenReturn(false);
        when(timeService.getCurrentMillis()).thenReturn(0L);
        distributeOnceElasticJobListener.beforeJobExecuted(shardingContexts);
        verify(guaranteeService).registerStart(Sets.newHashSet(0, 1));
        verify(guaranteeService, times(0)).clearAllStartedInfo();
    }
",non-flaky,5
112102,apache_shardingsphere-elasticjob,DistributeOnceElasticJobListenerTest.assertBeforeJobExecutedWhenIsNotAllStartedAndTimeout,"    @Test(expected = JobSystemException.class)
    public void assertBeforeJobExecutedWhenIsNotAllStartedAndTimeout() {
        when(guaranteeService.isAllStarted()).thenReturn(false);
        when(timeService.getCurrentMillis()).thenReturn(0L, 2L);
        distributeOnceElasticJobListener.beforeJobExecuted(shardingContexts);
        verify(guaranteeService).registerStart(Arrays.asList(0, 1));
        verify(guaranteeService, times(0)).clearAllStartedInfo();
    }
",non-flaky,5
112103,apache_shardingsphere-elasticjob,DistributeOnceElasticJobListenerTest.assertAfterJobExecutedWhenIsAllCompleted,"    @Test
    public void assertAfterJobExecutedWhenIsAllCompleted() {
        when(guaranteeService.isAllCompleted()).thenReturn(true);
        distributeOnceElasticJobListener.afterJobExecuted(shardingContexts);
        verify(guaranteeService).registerComplete(Sets.newHashSet(0, 1));
        verify(elasticJobListenerCaller).after();
        verify(guaranteeService).clearAllCompletedInfo();
    }
",non-flaky,5
112104,apache_shardingsphere-elasticjob,DistributeOnceElasticJobListenerTest.assertAfterJobExecutedWhenIsAllCompletedAndNotTimeout,"    @Test
    public void assertAfterJobExecutedWhenIsAllCompletedAndNotTimeout() {
        when(guaranteeService.isAllCompleted()).thenReturn(false);
        when(timeService.getCurrentMillis()).thenReturn(0L);
        distributeOnceElasticJobListener.afterJobExecuted(shardingContexts);
        verify(guaranteeService).registerComplete(Sets.newHashSet(0, 1));
        verify(guaranteeService, times(0)).clearAllCompletedInfo();
    }
",non-flaky,5
112105,apache_shardingsphere-elasticjob,DistributeOnceElasticJobListenerTest.assertAfterJobExecutedWhenIsAllCompletedAndTimeout,"    @Test(expected = JobSystemException.class)
    public void assertAfterJobExecutedWhenIsAllCompletedAndTimeout() {
        when(guaranteeService.isAllCompleted()).thenReturn(false);
        when(timeService.getCurrentMillis()).thenReturn(0L, 2L);
        distributeOnceElasticJobListener.afterJobExecuted(shardingContexts);
        verify(guaranteeService).registerComplete(Arrays.asList(0, 1));
        verify(guaranteeService, times(0)).clearAllCompletedInfo();
    }
",non-flaky,5
112106,apache_shardingsphere-elasticjob,JobSchedulerTest.assertInit,"    @Test
    public void assertInit() throws NoSuchFieldException, SchedulerException {
        when(schedulerFacade.updateJobConfiguration(liteJobConfig)).thenReturn(liteJobConfig);
        when(schedulerFacade.newJobTriggerListener()).thenReturn(new JobTriggerListener(null, null));
        jobScheduler.init();
        verify(schedulerFacade).registerStartUpInfo(true);
        Scheduler scheduler = ReflectionUtils.getFieldValue(JobRegistry.getInstance().getJobScheduleController(""test_job""), JobScheduleController.class.getDeclaredField(""scheduler""));
        assertThat(scheduler.getListenerManager().getTriggerListeners().get(0), instanceOf(JobTriggerListener.class));
        assertTrue(scheduler.isStarted());
    }
",non-flaky,5
112107,apache_shardingsphere-elasticjob,ShardingContextTest.assertNew,"    @Test
    public void assertNew() {
        ShardingContexts shardingContexts = ShardingContextsBuilder.getMultipleShardingContexts();
        ShardingContext actual = new ShardingContext(shardingContexts, 1);
        assertThat(actual.getJobName(), is(shardingContexts.getJobName()));
        assertThat(actual.getTaskId(), is(shardingContexts.getTaskId()));
        assertThat(actual.getShardingTotalCount(), is(shardingContexts.getShardingTotalCount()));
        assertThat(actual.getJobParameter(), is(shardingContexts.getJobParameter()));
        assertThat(actual.getShardingItem(), is(1));
        assertThat(actual.getShardingParameter(), is(shardingContexts.getShardingItemParameters().get(1)));
    }
",non-flaky,5
112108,apache_shardingsphere-elasticjob,ShardingContextTest.assertToString,"    @Test
    public void assertToString() {
        assertThat(new ShardingContext(ShardingContextsBuilder.getMultipleShardingContexts(), 1).toString(), 
                is(""ShardingContext(jobName=test_job, taskId=fake_task_id, shardingTotalCount=2, jobParameter=, shardingItem=1, shardingParameter=B)""));
    }
",non-flaky,5
112109,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertAddTaskResultStatistics,"    @Test
    public void assertAddTaskResultStatistics() {
        for (StatisticInterval each : StatisticInterval.values()) {
            assertTrue(repository.add(new TaskResultStatistics(100, 0, each, new Date())));
        }
    }
",non-flaky,5
112110,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertAddTaskRunningStatistics,"    @Test
    public void assertAddTaskRunningStatistics() {
        assertTrue(repository.add(new TaskRunningStatistics(100, new Date())));
    }
",non-flaky,5
112111,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertAddJobRunningStatistics,"    @Test
    public void assertAddJobRunningStatistics() {
        assertTrue(repository.add(new TaskRunningStatistics(100, new Date())));
    }
",non-flaky,5
112112,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertAddJobRegisterStatistics,"    @Test
    public void assertAddJobRegisterStatistics() {
        assertTrue(repository.add(new JobRegisterStatistics(100, new Date())));
    }
",non-flaky,5
112113,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindTaskResultStatisticsWhenTableIsEmpty,"    @Test
    public void assertFindTaskResultStatisticsWhenTableIsEmpty() {
        assertThat(repository.findTaskResultStatistics(new Date(), StatisticInterval.MINUTE).size(), is(0));
        assertThat(repository.findTaskResultStatistics(new Date(), StatisticInterval.HOUR).size(), is(0));
        assertThat(repository.findTaskResultStatistics(new Date(), StatisticInterval.DAY).size(), is(0));
    }
",non-flaky,5
112114,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindTaskResultStatisticsWithDifferentFromDate,"    @Test
    public void assertFindTaskResultStatisticsWithDifferentFromDate() {
        Date now = new Date();
        Date yesterday = getYesterday();
        for (StatisticInterval each : StatisticInterval.values()) {
            assertTrue(repository.add(new TaskResultStatistics(100, 0, each, yesterday)));
            assertTrue(repository.add(new TaskResultStatistics(100, 0, each, now)));
            assertThat(repository.findTaskResultStatistics(yesterday, each).size(), is(2));
            assertThat(repository.findTaskResultStatistics(now, each).size(), is(1));
        }
    }
",non-flaky,5
112115,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertGetSummedTaskResultStatisticsWhenTableIsEmpty,"    @Test
    public void assertGetSummedTaskResultStatisticsWhenTableIsEmpty() {
        for (StatisticInterval each : StatisticInterval.values()) {
            TaskResultStatistics po = repository.getSummedTaskResultStatistics(new Date(), each);
            assertThat(po.getSuccessCount(), is(0));
            assertThat(po.getFailedCount(), is(0));
        }
    }
",non-flaky,5
112116,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertGetSummedTaskResultStatistics,"    @Test
    public void assertGetSummedTaskResultStatistics() {
        for (StatisticInterval each : StatisticInterval.values()) {
            Date date = new Date();
            repository.add(new TaskResultStatistics(100, 2, each, date));
            repository.add(new TaskResultStatistics(200, 5, each, date));
            TaskResultStatistics po = repository.getSummedTaskResultStatistics(date, each);
            assertThat(po.getSuccessCount(), is(300));
            assertThat(po.getFailedCount(), is(7));
        }
    }
",non-flaky,5
112117,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindLatestTaskResultStatisticsWhenTableIsEmpty,"    @Test
    public void assertFindLatestTaskResultStatisticsWhenTableIsEmpty() {
        for (StatisticInterval each : StatisticInterval.values()) {
            assertFalse(repository.findLatestTaskResultStatistics(each).isPresent());
        }
    }
",non-flaky,5
112118,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindLatestTaskResultStatistics,"    @Test
    public void assertFindLatestTaskResultStatistics() {
        for (StatisticInterval each : StatisticInterval.values()) {
            repository.add(new TaskResultStatistics(100, 2, each, new Date()));
            repository.add(new TaskResultStatistics(200, 5, each, new Date()));
            Optional<TaskResultStatistics> po = repository.findLatestTaskResultStatistics(each);
            assertThat(po.get().getSuccessCount(), is(200));
            assertThat(po.get().getFailedCount(), is(5));
        }
    }
",non-flaky,5
112119,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindTaskRunningStatisticsWhenTableIsEmpty,"    @Test
    public void assertFindTaskRunningStatisticsWhenTableIsEmpty() {
        assertThat(repository.findTaskRunningStatistics(new Date()).size(), is(0));
    }
",non-flaky,5
112120,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindTaskRunningStatisticsWithDifferentFromDate,"    @Test
    public void assertFindTaskRunningStatisticsWithDifferentFromDate() {
        Date now = new Date();
        Date yesterday = getYesterday();
        assertTrue(repository.add(new TaskRunningStatistics(100, yesterday)));
        assertTrue(repository.add(new TaskRunningStatistics(100, now)));
        assertThat(repository.findTaskRunningStatistics(yesterday).size(), is(2));
        assertThat(repository.findTaskRunningStatistics(now).size(), is(1));
    }
",non-flaky,5
112121,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindLatestTaskRunningStatisticsWhenTableIsEmpty,"    @Test
    public void assertFindLatestTaskRunningStatisticsWhenTableIsEmpty() {
        assertFalse(repository.findLatestTaskRunningStatistics().isPresent());
    }
",non-flaky,5
112122,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindLatestTaskRunningStatistics,"    @Test
    public void assertFindLatestTaskRunningStatistics() {
        repository.add(new TaskRunningStatistics(100, new Date()));
        repository.add(new TaskRunningStatistics(200, new Date()));
        Optional<TaskRunningStatistics> po = repository.findLatestTaskRunningStatistics();
        assertThat(po.get().getRunningCount(), is(200));
    }
",non-flaky,5
112123,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindJobRunningStatisticsWhenTableIsEmpty,"    @Test
    public void assertFindJobRunningStatisticsWhenTableIsEmpty() {
        assertThat(repository.findJobRunningStatistics(new Date()).size(), is(0));
    }
",non-flaky,5
112124,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindJobRunningStatisticsWithDifferentFromDate,"    @Test
    public void assertFindJobRunningStatisticsWithDifferentFromDate() {
        Date now = new Date();
        Date yesterday = getYesterday();
        assertTrue(repository.add(new JobRunningStatistics(100, yesterday)));
        assertTrue(repository.add(new JobRunningStatistics(100, now)));
        assertThat(repository.findJobRunningStatistics(yesterday).size(), is(2));
        assertThat(repository.findJobRunningStatistics(now).size(), is(1));
    }
",non-flaky,5
112125,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindLatestJobRunningStatisticsWhenTableIsEmpty,"    @Test
    public void assertFindLatestJobRunningStatisticsWhenTableIsEmpty() {
        assertFalse(repository.findLatestJobRunningStatistics().isPresent());
    }
",non-flaky,5
112126,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindLatestJobRunningStatistics,"    @Test
    public void assertFindLatestJobRunningStatistics() {
        repository.add(new JobRunningStatistics(100, new Date()));
        repository.add(new JobRunningStatistics(200, new Date()));
        Optional<JobRunningStatistics> po = repository.findLatestJobRunningStatistics();
        assertThat(po.get().getRunningCount(), is(200));
    }
",non-flaky,5
112127,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindJobRegisterStatisticsWhenTableIsEmpty,"    @Test
    public void assertFindJobRegisterStatisticsWhenTableIsEmpty() {
        assertThat(repository.findJobRegisterStatistics(new Date()).size(), is(0));
    }
",non-flaky,5
112128,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindJobRegisterStatisticsWithDifferentFromDate,"    @Test
    public void assertFindJobRegisterStatisticsWithDifferentFromDate() {
        Date now = new Date();
        Date yesterday = getYesterday();
        assertTrue(repository.add(new JobRegisterStatistics(100, yesterday)));
        assertTrue(repository.add(new JobRegisterStatistics(100, now)));
        assertThat(repository.findJobRegisterStatistics(yesterday).size(), is(2));
        assertThat(repository.findJobRegisterStatistics(now).size(), is(1));
    }
",non-flaky,5
112129,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindLatestJobRegisterStatisticsWhenTableIsEmpty,"    @Test
    public void assertFindLatestJobRegisterStatisticsWhenTableIsEmpty() {
        assertFalse(repository.findLatestJobRegisterStatistics().isPresent());
    }
",non-flaky,5
112130,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindLatestJobRegisterStatistics,"    @Test
    public void assertFindLatestJobRegisterStatistics() {
        repository.add(new JobRegisterStatistics(100, new Date()));
        repository.add(new JobRegisterStatistics(200, new Date()));
        Optional<JobRegisterStatistics> po = repository.findLatestJobRegisterStatistics();
        assertThat(po.get().getRegisteredCount(), is(200));
    }
",non-flaky,5
112131,apache_shardingsphere-elasticjob,JobCoreConfigurationTest.assertBuildAllProperties,"    @Test
    public void assertBuildAllProperties() {
        JobCoreConfiguration actual = JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3)
                .shardingItemParameters(""0=a,1=b,2=c"").jobParameter(""param"").failover(true).misfire(false).description(""desc"")
                .jobProperties(""job_exception_handler"", IgnoreJobExceptionHandler.class.getName()).build();
        assertRequiredProperties(actual);
        assertThat(actual.getShardingItemParameters(), is(""0=a,1=b,2=c""));
        assertThat(actual.getJobParameter(), is(""param""));
        assertTrue(actual.isFailover());
        assertFalse(actual.isMisfire());
        assertThat(actual.getDescription(), is(""desc""));
        assertThat(actual.getJobProperties().get(JobProperties.JobPropertiesEnum.JOB_EXCEPTION_HANDLER), is(IgnoreJobExceptionHandler.class.getName()));
    }
",non-flaky,5
112132,apache_shardingsphere-elasticjob,JobCoreConfigurationTest.assertBuildRequiredProperties,"    @Test
    public void assertBuildRequiredProperties() {
        JobCoreConfiguration actual = JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).build();
        assertRequiredProperties(actual);
        assertDefaultValues(actual);
    }
",non-flaky,5
112133,apache_shardingsphere-elasticjob,JobCoreConfigurationTest.assertBuildWhenOptionalParametersIsNull,"    @Test
    public void assertBuildWhenOptionalParametersIsNull() {
        //noinspection NullArgumentToVariableArgMethod
        JobCoreConfiguration actual = JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).shardingItemParameters(null).jobParameter(null).description(null).build();
        assertRequiredProperties(actual);
        assertDefaultValues(actual);
    }
",non-flaky,5
112134,apache_shardingsphere-elasticjob,JobCoreConfigurationTest.assertBuildWhenJobNameIsNull,"    @Test(expected = IllegalArgumentException.class)
    public void assertBuildWhenJobNameIsNull() {
        JobCoreConfiguration.newBuilder(null, ""0/1 * * * * ?"", 3).build();
    }
",non-flaky,5
112135,apache_shardingsphere-elasticjob,JobCoreConfigurationTest.assertBuildWhenCronIsNull,"    @Test(expected = IllegalArgumentException.class)
    public void assertBuildWhenCronIsNull() {
        JobCoreConfiguration.newBuilder(""test_job"", null, 3).build();
    }
",non-flaky,5
112136,apache_shardingsphere-elasticjob,JobCoreConfigurationTest.assertBuildWhenTotalSHardingCountIsNegative,"    @Test(expected = IllegalArgumentException.class)
    public void assertBuildWhenTotalSHardingCountIsNegative() {
        JobCoreConfiguration.newBuilder(null, ""0/1 * * * * ?"", -1).build();
    }
",non-flaky,5
112137,apache_shardingsphere-elasticjob,LiteJobConfigurationTest.assertBuildAllProperties,"    @Test
    public void assertBuildAllProperties() {
        LiteJobConfiguration actual = LiteJobConfiguration.newBuilder(
                new SimpleJobConfiguration(JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).build(), TestSimpleJob.class.getCanonicalName()))
                .monitorExecution(false).maxTimeDiffSeconds(1000).monitorPort(8888).jobShardingStrategyClass(""testClass"").disabled(true).overwrite(true).reconcileIntervalMinutes(60).build();
        assertFalse(actual.isMonitorExecution());
        assertThat(actual.getMaxTimeDiffSeconds(), is(1000));
        assertThat(actual.getMonitorPort(), is(8888));
        assertThat(actual.getJobShardingStrategyClass(), is(""testClass""));
        assertTrue(actual.isDisabled());
        assertTrue(actual.isOverwrite());
        assertThat(actual.getReconcileIntervalMinutes(), is(60));
    }
",non-flaky,5
112138,apache_shardingsphere-elasticjob,LiteJobConfigurationTest.assertBuildRequiredProperties,"    @Test
    public void assertBuildRequiredProperties() {
        LiteJobConfiguration actual = LiteJobConfiguration.newBuilder(
                new SimpleJobConfiguration(JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).build(), TestSimpleJob.class.getCanonicalName())).build();
        assertTrue(actual.isMonitorExecution());
        assertThat(actual.getMaxTimeDiffSeconds(), is(-1));
        assertThat(actual.getMonitorPort(), is(-1));
        assertThat(actual.getJobShardingStrategyClass(), is(""""));
        assertFalse(actual.isDisabled());
        assertFalse(actual.isOverwrite());
    }
",non-flaky,5
112139,apache_shardingsphere-elasticjob,LiteJobConfigurationTest.assertBuildWhenOptionalParametersIsNull,"    @Test
    public void assertBuildWhenOptionalParametersIsNull() {
        assertThat(LiteJobConfiguration.newBuilder(new SimpleJobConfiguration(JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).build(), 
                TestSimpleJob.class.getCanonicalName())).jobShardingStrategyClass(null).build().getJobShardingStrategyClass(), is(""""));
    }
",non-flaky,5
112140,apache_shardingsphere-elasticjob,LiteJobConfigurationTest.assertIsNotFailover,"    @Test
    public void assertIsNotFailover() {
        assertFalse(LiteJobConfiguration.newBuilder(new SimpleJobConfiguration(JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).failover(false).build(), 
                TestSimpleJob.class.getCanonicalName())).monitorExecution(false).build().isFailover());
    }
",non-flaky,5
112141,apache_shardingsphere-elasticjob,LiteJobConfigurationTest.assertIsFailover,"    @Test
    public void assertIsFailover() {
        assertTrue(LiteJobConfiguration.newBuilder(new SimpleJobConfiguration(JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).failover(true).build(), 
                TestSimpleJob.class.getCanonicalName())).monitorExecution(true).build().isFailover());
    }
",non-flaky,5
112142,apache_shardingsphere-elasticjob,ExecutorServiceObjectTest.assertCreateExecutorService,"    @Test
    public void assertCreateExecutorService() {
        executorServiceObject = new ExecutorServiceObject(""executor-service-test"", 1);
        assertThat(executorServiceObject.getActiveThreadCount(), is(0));
        assertThat(executorServiceObject.getWorkQueueSize(), is(0));
        assertFalse(executorServiceObject.isShutdown());
        ExecutorService executorService = executorServiceObject.createExecutorService();
        executorService.submit(new FooTask());
        BlockUtils.waitingShortTime();
        assertThat(executorServiceObject.getActiveThreadCount(), is(1));
        assertThat(executorServiceObject.getWorkQueueSize(), is(0));
        assertFalse(executorServiceObject.isShutdown());
        executorService.submit(new FooTask());
        BlockUtils.waitingShortTime();
        assertThat(executorServiceObject.getActiveThreadCount(), is(1));
        assertThat(executorServiceObject.getWorkQueueSize(), is(1));
        assertFalse(executorServiceObject.isShutdown());
        executorService.shutdownNow();
        assertThat(executorServiceObject.getWorkQueueSize(), is(0));
        assertTrue(executorServiceObject.isShutdown());
    }
",non-flaky,5
112143,apache_shardingsphere-elasticjob,ShardingItemParametersTest.assertNewWhenPairFormatInvalid,"    @Test(expected = JobConfigurationException.class)
    public void assertNewWhenPairFormatInvalid() {
        new ShardingItemParameters(""xxx-xxx"");
    }
",non-flaky,5
112144,apache_shardingsphere-elasticjob,ShardingItemParametersTest.assertNewWhenItemIsNotNumber,"    @Test(expected = JobConfigurationException.class)
    public void assertNewWhenItemIsNotNumber() {
        new ShardingItemParameters(""xxx=xxx"");
    }
",non-flaky,5
112145,apache_shardingsphere-elasticjob,ShardingItemParametersTest.assertGetMapWhenIsEmpty,"    @Test
    public void assertGetMapWhenIsEmpty() {
        assertThat(new ShardingItemParameters("""").getMap(), is(Collections.EMPTY_MAP));
    }
",non-flaky,5
112146,apache_shardingsphere-elasticjob,ShardingItemParametersTest.assertGetMap,"    @Test
    public void assertGetMap() {
        Map<Integer, String> expected = new HashMap<>(3);
        expected.put(0, ""A"");
        expected.put(1, ""B"");
        expected.put(2, ""C"");
        assertThat(new ShardingItemParameters(""0=A,1=B,2=C"").getMap(), is(expected));
    }
",non-flaky,5
112147,apache_shardingsphere-elasticjob,ShardingItemsTest.assertTtoItemListWhenNull,"    @Test
    public void assertTtoItemListWhenNull() {
        assertThat(ShardingItems.toItemList(null), is(Collections.EMPTY_LIST));
    }
",non-flaky,5
112148,apache_shardingsphere-elasticjob,ShardingItemsTest.assertToItemListWhenEmpty,"    @Test
    public void assertToItemListWhenEmpty() {
        assertThat(ShardingItems.toItemList(""""), is(Collections.EMPTY_LIST));
    }
",non-flaky,5
112149,apache_shardingsphere-elasticjob,ShardingItemsTest.assertToItemList,"    @Test
    public void assertToItemList() {
        assertThat(ShardingItems.toItemList(""0,1,2""), is(Arrays.asList(0, 1, 2)));
    }
",non-flaky,5
112150,apache_shardingsphere-elasticjob,ShardingItemsTest.assertToItemListForDuplicated,"    @Test
    public void assertToItemListForDuplicated() {
        assertThat(ShardingItems.toItemList(""0,1,2,2""), is(Arrays.asList(0, 1, 2)));
    }
",non-flaky,5
112151,apache_shardingsphere-elasticjob,ShardingItemsTest.assertToItemsStringWhenEmpty,"    @Test
    public void assertToItemsStringWhenEmpty() {
        assertThat(ShardingItems.toItemsString(Collections.<Integer>emptyList()), is(""""));
    }
",non-flaky,5
112152,apache_shardingsphere-elasticjob,ShardingItemsTest.assertToItemsString,"    @Test
    public void assertToItemsString() {
        assertThat(ShardingItems.toItemsString(Arrays.asList(0, 1, 2)), is(""0,1,2""));
    }
",non-flaky,5
112153,apache_shardingsphere-elasticjob,IpUtilsTest.assertGetIp,"    @Test
    public void assertGetIp() {
        assertNotNull(IpUtils.getIp());
    }
",non-flaky,5
112154,apache_shardingsphere-elasticjob,IpUtilsTest.assertGetHostName,"    @Test
    public void assertGetHostName() {
        assertNotNull(IpUtils.getHostName());
    }
",non-flaky,5
112155,apache_shardingsphere-elasticjob,HostExceptionTest.assertGetCause,"    @Test
    public void assertGetCause() {
        IOException cause = new IOException();
        assertThat(new HostException(cause).getCause(), Is.<Throwable>is(cause));
    }
",non-flaky,5
112156,apache_shardingsphere-elasticjob,TimeServiceTest.assertGetCurrentMillis,"    @Test
    public void assertGetCurrentMillis() throws Exception {
        assertTrue(timeService.getCurrentMillis() <= System.currentTimeMillis());
    }
",non-flaky,5
112157,apache_shardingsphere-elasticjob,JobConfigurationGsonTypeAdapterTest.assertToSimpleJobJson,"    @Test
    public void assertToSimpleJobJson() {
        assertThat(GsonFactory.getGson().toJson(new TestJobRootConfiguration(
                new TestSimpleJobConfiguration(ThrowJobExceptionHandler.class.getCanonicalName(), DefaultExecutorServiceHandler.class.getCanonicalName()).getTypeConfig())),
                is(APIJsonConstants.getSimpleJobJson(ThrowJobExceptionHandler.class.getCanonicalName())));
    }
",non-flaky,5
112158,apache_shardingsphere-elasticjob,JobConfigurationGsonTypeAdapterTest.assertToDataflowJobJson,"    @Test
    public void assertToDataflowJobJson() {
        assertThat(GsonFactory.getGson().toJson(new TestJobRootConfiguration(new TestDataflowJobConfiguration(true).getTypeConfig())),
                is(APIJsonConstants.getDataflowJobJson(IgnoreJobExceptionHandler.class.getCanonicalName())));
    }
",non-flaky,5
112159,apache_shardingsphere-elasticjob,JobConfigurationGsonTypeAdapterTest.assertToScriptJobJson,"    @Test
    public void assertToScriptJobJson() {
        assertThat(GsonFactory.getGson().toJson(new TestJobRootConfiguration(new TestScriptJobConfiguration(""test.sh"", ThrowJobExceptionHandler.class).getTypeConfig())),
                is(APIJsonConstants.getScriptJobJson(ThrowJobExceptionHandler.class.getCanonicalName())));
    }
",non-flaky,5
112160,apache_shardingsphere-elasticjob,JobConfigurationGsonTypeAdapterTest.assertFromSimpleJobJson,"    @Test
    public void assertFromSimpleJobJson() {
        TestJobRootConfiguration actual = GsonFactory.getGson().fromJson(
                APIJsonConstants.getSimpleJobJson(ThrowJobExceptionHandler.class.getCanonicalName()), TestJobRootConfiguration.class);
        TestJobRootConfiguration expected = new TestJobRootConfiguration(
                new TestSimpleJobConfiguration(ThrowJobExceptionHandler.class.getCanonicalName(), DefaultExecutorServiceHandler.class.getCanonicalName()).getTypeConfig());
        assertThat(GsonFactory.getGson().toJson(actual), is(GsonFactory.getGson().toJson(expected)));
    }
",non-flaky,5
112161,apache_shardingsphere-elasticjob,JobConfigurationGsonTypeAdapterTest.assertFromDataflowJobJson,"    @Test
    public void assertFromDataflowJobJson() {
        TestJobRootConfiguration actual = GsonFactory.getGson().fromJson(
                APIJsonConstants.getDataflowJobJson(IgnoreJobExceptionHandler.class.getCanonicalName()), TestJobRootConfiguration.class);
        TestJobRootConfiguration expected = new TestJobRootConfiguration(new TestDataflowJobConfiguration(true).getTypeConfig());
        assertThat(GsonFactory.getGson().toJson(actual), is(GsonFactory.getGson().toJson(expected)));
    }
",non-flaky,5
112162,apache_shardingsphere-elasticjob,JobConfigurationGsonTypeAdapterTest.assertFromScriptJobJson,"    @Test
    public void assertFromScriptJobJson() {
        TestJobRootConfiguration actual = GsonFactory.getGson().fromJson(
                APIJsonConstants.getScriptJobJson(ThrowJobExceptionHandler.class.getCanonicalName()), TestJobRootConfiguration.class);
        TestJobRootConfiguration expected = new TestJobRootConfiguration(new TestScriptJobConfiguration(""test.sh"", ThrowJobExceptionHandler.class).getTypeConfig());
        assertThat(GsonFactory.getGson().toJson(actual), is(GsonFactory.getGson().toJson(expected)));
    }
",non-flaky,5
