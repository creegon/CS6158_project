"""
æ•°æ®å¤„ç†å·¥å…·å‡½æ•°
"""
import pandas as pd
import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Union
import random


class NumpyEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†numpyå’Œpandasæ•°æ®ç±»å‹"""
    def default(self, obj):
        if isinstance(obj, (np.integer, np.int64)):
            return int(obj)
        elif isinstance(obj, (np.floating, np.float64)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, pd.Series):
            return obj.to_dict()
        elif isinstance(obj, pd.DataFrame):
            return obj.to_dict('records')
        elif hasattr(obj, 'item'):  # å¤„ç†pandasçš„ç‰¹æ®Šç±»å‹
            return obj.item()
        elif hasattr(obj, '__dict__'):  # å¤„ç†è‡ªå®šä¹‰å¯¹è±¡
            return str(obj)
        return super().default(obj)


def load_csv(file_path: Union[str, Path], encoding: str = 'utf-8') -> pd.DataFrame:
    """
    è¯»å–CSVæ–‡ä»¶
    
    Args:
        file_path: CSVæ–‡ä»¶è·¯å¾„
        encoding: æ–‡ä»¶ç¼–ç 
        
    Returns:
        DataFrameå¯¹è±¡
    """
    try:
        df = pd.read_csv(f"{file_path}", encoding=encoding)
        print(f"âœ“ æˆåŠŸåŠ è½½æ•°æ®é›†: {len(df)} æ¡è®°å½•")
        print(f"  åˆ—å: {df.columns.tolist()}")
        return df
    except Exception as e:
        print(f"âœ— åŠ è½½CSVæ–‡ä»¶å¤±è´¥: {e}")
        raise


def sample_data(df: pd.DataFrame, 
                mode: str = 'all',
                n: int = 10,
                random_seed: Optional[int] = None) -> pd.DataFrame:
    """
    ä»æ•°æ®é›†ä¸­é‡‡æ ·æ•°æ®
    
    Args:
        df: åŸå§‹DataFrame
        mode: é‡‡æ ·æ¨¡å¼ ['all', 'first', 'last', 'random']
        n: é‡‡æ ·æ•°é‡
        random_seed: éšæœºç§å­ï¼ˆç”¨äºrandomæ¨¡å¼ï¼‰
        
    Returns:
        é‡‡æ ·åçš„DataFrame
    """
    if mode == 'all':
        return df
    elif mode == 'first':
        return df.head(n)
    elif mode == 'last':
        return df.tail(n)
    elif mode == 'random':
        if random_seed is not None:
            random.seed(random_seed)
        indices = random.sample(range(len(df)), min(n, len(df)))
        return df.iloc[indices]
    else:
        raise ValueError(f"æœªçŸ¥çš„é‡‡æ ·æ¨¡å¼: {mode}")


def split_dataset(df: pd.DataFrame,
                 train_ratio: float = 0.7,
                 val_ratio: float = 0.2,
                 test_ratio: float = 0.1,
                 stratify_column: Optional[str] = None,
                 random_seed: int = 42,
                 shuffle: bool = True) -> Dict[str, pd.DataFrame]:
    """
    å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†
    
    Args:
        df: åŸå§‹DataFrame
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹ï¼ˆé»˜è®¤0.7ï¼‰
        val_ratio: éªŒè¯é›†æ¯”ä¾‹ï¼ˆé»˜è®¤0.2ï¼‰
        test_ratio: æµ‹è¯•é›†æ¯”ä¾‹ï¼ˆé»˜è®¤0.1ï¼‰
        stratify_column: åˆ†å±‚é‡‡æ ·çš„åˆ—åï¼ˆå¦‚'label'ï¼‰ï¼ŒNoneè¡¨ç¤ºä¸åˆ†å±‚
        random_seed: éšæœºç§å­ï¼ˆç”¨äºå¤ç°ï¼‰
        shuffle: æ˜¯å¦åœ¨åˆ’åˆ†å‰æ‰“ä¹±æ•°æ®
        
    Returns:
        åŒ…å« 'train', 'val', 'test' çš„å­—å…¸ï¼Œå€¼ä¸ºå¯¹åº”çš„DataFrame
        
    Example:
        >>> splits = split_dataset(df, stratify_column='label', random_seed=42)
        >>> train_df = splits['train']
        >>> val_df = splits['val']
        >>> test_df = splits['test']
    """
    # éªŒè¯æ¯”ä¾‹
    total_ratio = train_ratio + val_ratio + test_ratio
    if abs(total_ratio - 1.0) > 1e-6:
        raise ValueError(f"æ¯”ä¾‹ä¹‹å’Œå¿…é¡»ä¸º1ï¼Œå½“å‰ä¸º: {total_ratio}")
    
    # è®¾ç½®éšæœºç§å­
    np.random.seed(random_seed)
    
    # å¦‚æœéœ€è¦åˆ†å±‚é‡‡æ ·
    if stratify_column and stratify_column in df.columns:
        print(f"\nğŸ“Š ä½¿ç”¨åˆ†å±‚é‡‡æ ·ï¼ŒåŸºäºåˆ—: {stratify_column}")
        
        # è·å–å„ç±»åˆ«
        categories = df[stratify_column].unique()
        
        train_dfs = []
        val_dfs = []
        test_dfs = []
        
        print(f"\nå„ç±»åˆ«åˆ’åˆ†æƒ…å†µ:")
        print(f"{'ç±»åˆ«':<20} {'æ€»æ•°':>8} {'è®­ç»ƒé›†':>8} {'éªŒè¯é›†':>8} {'æµ‹è¯•é›†':>8}")
        print("-" * 60)
        
        for category in categories:
            # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰æ•°æ®
            cat_df = df[df[stratify_column] == category].copy()
            cat_size = len(cat_df)
            
            # æ‰“ä¹±æ•°æ®
            if shuffle:
                cat_df = cat_df.sample(frac=1, random_state=random_seed).reset_index(drop=True)
            
            # è®¡ç®—åˆ’åˆ†ç‚¹
            train_size = int(cat_size * train_ratio)
            val_size = int(cat_size * val_ratio)
            
            # åˆ’åˆ†
            train_cat = cat_df.iloc[:train_size]
            val_cat = cat_df.iloc[train_size:train_size + val_size]
            test_cat = cat_df.iloc[train_size + val_size:]
            
            train_dfs.append(train_cat)
            val_dfs.append(val_cat)
            test_dfs.append(test_cat)
            
            print(f"{str(category):<20} {cat_size:>8} {len(train_cat):>8} {len(val_cat):>8} {len(test_cat):>8}")
        
        # åˆå¹¶æ‰€æœ‰ç±»åˆ«
        train_df = pd.concat(train_dfs, ignore_index=True)
        val_df = pd.concat(val_dfs, ignore_index=True)
        test_df = pd.concat(test_dfs, ignore_index=True)
        
        # å†æ¬¡æ‰“ä¹±ï¼ˆå¯é€‰ï¼‰
        if shuffle:
            train_df = train_df.sample(frac=1, random_state=random_seed).reset_index(drop=True)
            val_df = val_df.sample(frac=1, random_state=random_seed + 1).reset_index(drop=True)
            test_df = test_df.sample(frac=1, random_state=random_seed + 2).reset_index(drop=True)
    
    else:
        print(f"\nğŸ“Š ä½¿ç”¨éšæœºåˆ’åˆ†ï¼ˆä¸åˆ†å±‚ï¼‰")
        
        # æ‰“ä¹±æ•°æ®
        if shuffle:
            df = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)
        
        # è®¡ç®—åˆ’åˆ†ç‚¹
        n = len(df)
        train_size = int(n * train_ratio)
        val_size = int(n * val_ratio)
        
        # åˆ’åˆ†
        train_df = df.iloc[:train_size]
        val_df = df.iloc[train_size:train_size + val_size]
        test_df = df.iloc[train_size + val_size:]
    
    # æ‰“å°æ€»ä½“ç»Ÿè®¡
    print(f"\n{'=' * 60}")
    print(f"åˆ’åˆ†ç»“æœ:")
    print(f"  è®­ç»ƒé›†: {len(train_df)} æ¡ ({len(train_df)/len(df)*100:.1f}%)")
    print(f"  éªŒè¯é›†: {len(val_df)} æ¡ ({len(val_df)/len(df)*100:.1f}%)")
    print(f"  æµ‹è¯•é›†: {len(test_df)} æ¡ ({len(test_df)/len(df)*100:.1f}%)")
    print(f"  æ€»è®¡: {len(train_df) + len(val_df) + len(test_df)} æ¡")
    print(f"{'=' * 60}\n")
    
    return {
        'train': train_df,
        'val': val_df,
        'test': test_df
    }


def save_split_datasets(splits: Dict[str, pd.DataFrame],
                       output_dir: Union[str, Path],
                       base_name: str = 'dataset',
                       format: str = 'csv') -> Dict[str, Path]:
    """
    ä¿å­˜åˆ’åˆ†åçš„æ•°æ®é›†åˆ°æ–‡ä»¶
    
    Args:
        splits: split_datasetè¿”å›çš„å­—å…¸
        output_dir: è¾“å‡ºç›®å½•
        base_name: åŸºç¡€æ–‡ä»¶å
        format: ä¿å­˜æ ¼å¼ ('csv' æˆ– 'json')
        
    Returns:
        åŒ…å«å„æ•°æ®é›†æ–‡ä»¶è·¯å¾„çš„å­—å…¸
        
    Example:
        >>> splits = split_dataset(df)
        >>> files = save_split_datasets(splits, 'output/splits')
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    saved_files = {}
    
    for split_name, split_df in splits.items():
        if format == 'csv':
            file_path = output_dir / f"{base_name}_{split_name}.csv"
            split_df.to_csv(file_path, index=False, encoding='utf-8')
        elif format == 'json':
            file_path = output_dir / f"{base_name}_{split_name}.json"
            split_df.to_json(file_path, orient='records', force_ascii=False, indent=2)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}")
        
        saved_files[split_name] = file_path
        print(f"âœ“ å·²ä¿å­˜ {split_name} é›†åˆ°: {file_path}")
    
    return saved_files


def convert_to_alpaca_format(row: pd.Series, 
                            reasoning: str,
                            code_column: str = 'code',
                            include_id: bool = False,
                            system_prompt: str = None,
                            user_template: str = None) -> Dict:
    """
    å°†æ•°æ®è½¬æ¢ä¸ºAlpacaæ ¼å¼
    
    Args:
        row: æ•°æ®è¡Œ
        reasoning: æ¨ç†è¿‡ç¨‹
        code_column: ä»£ç åˆ—å
        include_id: æ˜¯å¦åŒ…å«IDå­—æ®µï¼ˆç”¨äºè¯„ä¼°ï¼‰
        system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆç”¨ä½œinstructionï¼‰
        user_template: ç”¨æˆ·æç¤ºè¯æ¨¡æ¿ï¼ˆç”¨ä½œinputæ¨¡æ¿ï¼‰
        
    Returns:
        Alpacaæ ¼å¼çš„å­—å…¸
    """
    # å¦‚æœæä¾›äº† system_prompt å’Œ user_templateï¼Œä½¿ç”¨å®ƒä»¬
    # å¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if system_prompt is None:
        instruction = "è¯·åˆ†æä»¥ä¸‹æµ‹è¯•ç”¨ä¾‹ï¼Œåˆ¤æ–­å®ƒæ˜¯å¦æ˜¯ä¸€ä¸ªFlaky Testï¼ˆä¸ç¨³å®šæµ‹è¯•ï¼‰ï¼Œå¹¶è¯´æ˜ä½ çš„æ¨ç†è¿‡ç¨‹ã€‚"
    else:
        instruction = system_prompt
    
    if user_template is None:
        # é»˜è®¤æ ¼å¼
        full_code = row.get(code_column, row.get('full_code', ''))
        project = row.get('project', 'Unknown')
        test_name = row.get('test_name', 'Unknown')
        user_input = f"è¯¥æµ‹è¯•ä»£ç æ‰€å±projectçš„åç§°ä¸º{project}ï¼Œå®ƒçš„æµ‹è¯•åç§°ä¸º{test_name}ï¼Œå®Œæ•´ä»£ç ä¸º{full_code}ã€‚"
    else:
        # ä½¿ç”¨æ¨¡æ¿æ ¼å¼åŒ–
        from utils.prompt_utils import format_prompt
        full_code = row.get(code_column, row.get('full_code', ''))
        project = row.get('project', 'Unknown')
        test_name = row.get('test_name', 'Unknown')
        user_input = format_prompt(
            user_template,
            project=project,
            test_name=test_name,
            full_code=full_code
        )
    
    alpaca_item = {
        "instruction": instruction,
        "input": user_input,
        "output": reasoning
    }
    
    # å¦‚æœéœ€è¦åŒ…å«IDå­—æ®µï¼ˆç”¨äºè¯„ä¼°ï¼‰
    if include_id and 'id' in row:
        alpaca_item['id'] = int(row['id'])
    
    return alpaca_item


def save_json(data: Union[List, Dict], 
              file_path: Union[str, Path],
              encoding: str = 'utf-8',
              indent: int = 2) -> None:
    """
    ä¿å­˜JSONæ–‡ä»¶ï¼ˆè‡ªåŠ¨å¤„ç†numpyå’Œpandasæ•°æ®ç±»å‹ï¼‰
    
    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        file_path: ä¿å­˜è·¯å¾„
        encoding: æ–‡ä»¶ç¼–ç 
        indent: ç¼©è¿›ç©ºæ ¼æ•°
    """
    def convert_to_serializable(obj):
        """é€’å½’è½¬æ¢ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡"""
        if isinstance(obj, dict):
            return {k: convert_to_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_to_serializable(item) for item in obj]
        elif isinstance(obj, (np.integer, np.int64)):
            return int(obj)
        elif isinstance(obj, (np.floating, np.float64)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, pd.Series):
            return obj.to_dict()
        elif isinstance(obj, pd.DataFrame):
            return obj.to_dict('records')
        elif hasattr(obj, 'item'):  # å¤„ç†pandasçš„ç‰¹æ®Šç±»å‹ï¼ˆå¦‚Int64DTypeï¼‰
            try:
                return obj.item()
            except:
                return str(obj)
        elif pd.isna(obj):  # å¤„ç†NaN
            return None
        elif hasattr(obj, '__dict__') and not isinstance(obj, (str, int, float, bool, type(None))):
            return str(obj)
        return obj
    
    try:
        # é¢„å¤„ç†æ•°æ®ï¼Œè½¬æ¢æ‰€æœ‰ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
        serializable_data = convert_to_serializable(data)
        
        with open(file_path, 'w', encoding=encoding) as f:
            json.dump(serializable_data, f, ensure_ascii=False, indent=indent, cls=NumpyEncoder)
        print(f"âœ“ æ•°æ®å·²ä¿å­˜åˆ°: {file_path}")
    except Exception as e:
        print(f"âœ— ä¿å­˜JSONæ–‡ä»¶å¤±è´¥: {e}")
        raise


def load_json(file_path: Union[str, Path], 
              encoding: str = 'utf-8') -> Union[List, Dict]:
    """
    åŠ è½½JSONæ–‡ä»¶
    
    Args:
        file_path: JSONæ–‡ä»¶è·¯å¾„
        encoding: æ–‡ä»¶ç¼–ç 
        
    Returns:
        åŠ è½½çš„æ•°æ®
    """
    try:
        with open(file_path, 'r', encoding=encoding) as f:
            data = json.load(f)
        print(f"âœ“ æˆåŠŸåŠ è½½JSON: {file_path}")
        return data
    except Exception as e:
        print(f"âœ— åŠ è½½JSONæ–‡ä»¶å¤±è´¥: {e}")
        raise


def get_data_statistics(df: pd.DataFrame) -> Dict:
    """
    è·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯ï¼ˆè¿”å›å¯JSONåºåˆ—åŒ–çš„æ•°æ®ï¼‰
    
    Args:
        df: DataFrameå¯¹è±¡
        
    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    # è½¬æ¢dtypesä¸ºå­—ç¬¦ä¸²ï¼ˆé¿å…ä¸å¯åºåˆ—åŒ–çš„ç±»å‹ï¼‰
    dtypes_dict = {col: str(dtype) for col, dtype in df.dtypes.to_dict().items()}
    
    # è½¬æ¢missing_valuesä¸ºæ ‡å‡†Pythonæ•´æ•°
    missing_values_dict = {col: int(count) for col, count in df.isnull().sum().to_dict().items()}
    
    stats = {
        "total_records": int(len(df)),
        "columns": df.columns.tolist(),
        "dtypes": dtypes_dict,
        "missing_values": missing_values_dict,
        "memory_usage": float(df.memory_usage(deep=True).sum() / 1024 / 1024)  # MB
    }
    
    # å¦‚æœæœ‰labelåˆ—ï¼Œç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
    if 'label' in df.columns:
        label_counts = df['label'].value_counts().to_dict()
        # è½¬æ¢ä¸ºæ ‡å‡†Pythonç±»å‹
        stats['label_distribution'] = {str(k): int(v) for k, v in label_counts.items()}
    
    return stats


def print_data_info(df: pd.DataFrame) -> None:
    """
    æ‰“å°æ•°æ®é›†è¯¦ç»†ä¿¡æ¯
    
    Args:
        df: DataFrameå¯¹è±¡
    """
    print("=" * 60)
    print("æ•°æ®é›†ä¿¡æ¯")
    print("=" * 60)
    print(f"è®°å½•æ•°: {len(df)}")
    print(f"åˆ—æ•°: {len(df.columns)}")
    print(f"\nåˆ—å:")
    for i, col in enumerate(df.columns, 1):
        print(f"  {i}. {col} ({df[col].dtype})")
    
    print(f"\nç¼ºå¤±å€¼:")
    missing = df.isnull().sum()
    for col in missing[missing > 0].index:
        print(f"  {col}: {missing[col]} ({missing[col]/len(df)*100:.2f}%)")
    
    if 'label' in df.columns:
        print(f"\næ ‡ç­¾åˆ†å¸ƒ:")
        label_counts = df['label'].value_counts()
        for label, count in label_counts.items():
            print(f"  {label}: {count} ({count/len(df)*100:.2f}%)")
    
    print(f"\nå‰3æ¡æ•°æ®:")
    print(df.head(3).to_string())
    print("=" * 60)
