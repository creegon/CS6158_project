"""
æ•°æ®é›†åˆ’åˆ†å·¥å…·
åŒ…æ‹¬è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†åˆ’åˆ†å’ŒKæŠ˜äº¤å‰éªŒè¯
"""
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional
import random


def split_dataset(df: pd.DataFrame,
                 train_ratio: float = 0.7,
                 val_ratio: float = 0.2,
                 test_ratio: float = 0.1,
                 stratify_column: Optional[str] = None,
                 random_seed: int = 42,
                 shuffle: bool = True) -> Dict[str, pd.DataFrame]:
    """
    å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†
    
    Args:
        df: åŸå§‹DataFrame
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹ï¼ˆé»˜è®¤0.7ï¼‰
        val_ratio: éªŒè¯é›†æ¯”ä¾‹ï¼ˆé»˜è®¤0.2ï¼‰
        test_ratio: æµ‹è¯•é›†æ¯”ä¾‹ï¼ˆé»˜è®¤0.1ï¼‰
        stratify_column: åˆ†å±‚é‡‡æ ·çš„åˆ—åï¼ˆå¦‚'label'ï¼‰ï¼ŒNoneè¡¨ç¤ºä¸åˆ†å±‚
        random_seed: éšæœºç§å­ï¼ˆç”¨äºå¤ç°ï¼‰
        shuffle: æ˜¯å¦åœ¨åˆ’åˆ†å‰æ‰“ä¹±æ•°æ®
        
    Returns:
        åŒ…å« 'train', 'val', 'test' çš„å­—å…¸ï¼Œå€¼ä¸ºå¯¹åº”çš„DataFrame
        
    Example:
        >>> splits = split_dataset(df, stratify_column='label', random_seed=42)
        >>> train_df = splits['train']
        >>> val_df = splits['val']
        >>> test_df = splits['test']
    """
    # éªŒè¯æ¯”ä¾‹
    total_ratio = train_ratio + val_ratio + test_ratio
    if abs(total_ratio - 1.0) > 1e-6:
        raise ValueError(f"æ¯”ä¾‹ä¹‹å’Œå¿…é¡»ä¸º1ï¼Œå½“å‰ä¸º: {total_ratio}")
    
    # è®¾ç½®éšæœºç§å­
    np.random.seed(random_seed)
    
    # å¦‚æœéœ€è¦åˆ†å±‚é‡‡æ ·
    if stratify_column and stratify_column in df.columns:
        print(f"\nğŸ“Š ä½¿ç”¨åˆ†å±‚é‡‡æ ·ï¼ŒåŸºäºåˆ—: {stratify_column}")
        
        # è·å–å„ç±»åˆ«
        categories = df[stratify_column].unique()
        
        train_dfs = []
        val_dfs = []
        test_dfs = []
        
        print(f"\nå„ç±»åˆ«åˆ’åˆ†æƒ…å†µ:")
        print(f"{'ç±»åˆ«':<20} {'æ€»æ•°':>8} {'è®­ç»ƒé›†':>8} {'éªŒè¯é›†':>8} {'æµ‹è¯•é›†':>8}")
        print("-" * 60)
        
        for category in categories:
            # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰æ•°æ®
            cat_df = df[df[stratify_column] == category].copy()
            cat_size = len(cat_df)
            
            # æ‰“ä¹±æ•°æ®
            if shuffle:
                cat_df = cat_df.sample(frac=1, random_state=random_seed).reset_index(drop=True)
            
            # è®¡ç®—åˆ’åˆ†ç‚¹
            train_size = int(cat_size * train_ratio)
            val_size = int(cat_size * val_ratio)
            
            # åˆ’åˆ†
            train_cat = cat_df.iloc[:train_size]
            val_cat = cat_df.iloc[train_size:train_size + val_size]
            test_cat = cat_df.iloc[train_size + val_size:]
            
            train_dfs.append(train_cat)
            val_dfs.append(val_cat)
            test_dfs.append(test_cat)
            
            print(f"{str(category):<20} {cat_size:>8} {len(train_cat):>8} {len(val_cat):>8} {len(test_cat):>8}")
        
        # åˆå¹¶æ‰€æœ‰ç±»åˆ«
        train_df = pd.concat(train_dfs, ignore_index=True)
        val_df = pd.concat(val_dfs, ignore_index=True)
        test_df = pd.concat(test_dfs, ignore_index=True)
        
        # å†æ¬¡æ‰“ä¹±ï¼ˆå¯é€‰ï¼‰
        if shuffle:
            train_df = train_df.sample(frac=1, random_state=random_seed).reset_index(drop=True)
            val_df = val_df.sample(frac=1, random_state=random_seed + 1).reset_index(drop=True)
            test_df = test_df.sample(frac=1, random_state=random_seed + 2).reset_index(drop=True)
    
    else:
        print(f"\nğŸ“Š ä½¿ç”¨éšæœºåˆ’åˆ†ï¼ˆä¸åˆ†å±‚ï¼‰")
        
        # æ‰“ä¹±æ•°æ®
        if shuffle:
            df = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)
        
        # è®¡ç®—åˆ’åˆ†ç‚¹
        n = len(df)
        train_size = int(n * train_ratio)
        val_size = int(n * val_ratio)
        
        # åˆ’åˆ†
        train_df = df.iloc[:train_size]
        val_df = df.iloc[train_size:train_size + val_size]
        test_df = df.iloc[train_size + val_size:]
    
    # æ‰“å°æ€»ä½“ç»Ÿè®¡
    print(f"\n{'=' * 60}")
    print(f"åˆ’åˆ†ç»“æœ:")
    print(f"  è®­ç»ƒé›†: {len(train_df)} æ¡ ({len(train_df)/len(df)*100:.1f}%)")
    print(f"  éªŒè¯é›†: {len(val_df)} æ¡ ({len(val_df)/len(df)*100:.1f}%)")
    print(f"  æµ‹è¯•é›†: {len(test_df)} æ¡ ({len(test_df)/len(df)*100:.1f}%)")
    print(f"  æ€»è®¡: {len(train_df) + len(val_df) + len(test_df)} æ¡")
    print(f"{'=' * 60}\n")
    
    return {
        'train': train_df,
        'val': val_df,
        'test': test_df
    }


def create_project_wise_kfold_splits(df: pd.DataFrame,
                                     project_column: str = 'project',
                                     category_column: str = 'category',
                                     n_folds: int = 4,
                                     min_samples_per_category: int = 4,
                                     random_seed: int = 42) -> List[Dict[str, pd.DataFrame]]:
    """
    åˆ›å»ºé¡¹ç›®çº§ç‹¬ç«‹çš„KæŠ˜äº¤å‰éªŒè¯æ•°æ®é›†
    
    ä¿è¯:
    1. åŒä¸€é¡¹ç›®çš„æµ‹è¯•ä¸ä¼šåŒæ—¶å‡ºç°åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­ï¼ˆproject-wise disjointï¼‰
    2. æ¯ä¸ªæµ‹è¯•é›†è‡³å°‘åŒ…å«æ¯ç§ç±»åˆ«çš„ min_samples_per_category ä¸ªæ ·æœ¬
    
    Args:
        df: åŸå§‹DataFrame
        project_column: é¡¹ç›®åç§°åˆ—
        category_column: ç±»åˆ«åˆ—
        n_folds: æŠ˜æ•°ï¼ˆé»˜è®¤4ï¼‰
        min_samples_per_category: æ¯ä¸ªæµ‹è¯•é›†ä¸­æ¯ä¸ªç±»åˆ«çš„æœ€å°æ ·æœ¬æ•°ï¼ˆé»˜è®¤4ï¼‰
        random_seed: éšæœºç§å­
        
    Returns:
        åŒ…å«n_foldsä¸ªå­—å…¸çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å« 'train', 'test' é”®
        
    Example:
        >>> folds = create_project_wise_kfold_splits(df, n_folds=4)
        >>> for i, fold in enumerate(folds):
        >>>     print(f"Fold {i+1}:")
        >>>     print(f"  è®­ç»ƒé›†: {len(fold['train'])} æ ·æœ¬")
        >>>     print(f"  æµ‹è¯•é›†: {len(fold['test'])} æ ·æœ¬")
    """
    np.random.seed(random_seed)
    random.seed(random_seed)
    
    print(f"\n{'='*60}")
    print(f"é¡¹ç›®çº§KæŠ˜äº¤å‰éªŒè¯æ•°æ®é›†åˆ’åˆ† (K={n_folds})")
    print(f"{'='*60}")
    
    # 1. åˆ†ææ•°æ®é›†åŸºæœ¬ä¿¡æ¯
    print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(df)}")
    print(f"  é¡¹ç›®æ•°é‡: {df[project_column].nunique()}")
    print(f"  ç±»åˆ«æ•°é‡: {df[category_column].nunique()}")
    
    # 2. åˆ†ææ¯ä¸ªç±»åˆ«çš„åˆ†å¸ƒ
    print(f"\nğŸ“Š å„ç±»åˆ«åˆ†å¸ƒ:")
    category_counts = df[category_column].value_counts().sort_index()
    category_projects = {}
    
    for cat in category_counts.index:
        cat_df = df[df[category_column] == cat]
        n_projects = cat_df[project_column].nunique()
        category_projects[cat] = n_projects
        print(f"  ç±»åˆ« {cat}: {category_counts[cat]:>5} ä¸ªæ ·æœ¬, åˆ†å¸ƒåœ¨ {n_projects:>3} ä¸ªé¡¹ç›®ä¸­")
    
    # 3. æ£€æŸ¥æ˜¯å¦å¯ä»¥æ»¡è¶³æœ€å°æ ·æœ¬æ•°è¦æ±‚
    print(f"\nâš ï¸  ç±»åˆ«å¹³è¡¡çº¦æŸæ£€æŸ¥:")
    print(f"  è¦æ±‚: æ¯ä¸ªæµ‹è¯•é›†è‡³å°‘åŒ…å«æ¯ä¸ªç±»åˆ« {min_samples_per_category} ä¸ªæ ·æœ¬")
    
    issues = []
    for cat in category_counts.index:
        expected_per_fold = category_counts[cat] / n_folds
        if expected_per_fold < min_samples_per_category:
            issues.append(f"    - ç±»åˆ« {cat}: å¹³å‡æ¯æŠ˜åªæœ‰ {expected_per_fold:.1f} ä¸ªæ ·æœ¬ (< {min_samples_per_category})")
    
    if issues:
        print(f"  âš ï¸  è­¦å‘Š: ä»¥ä¸‹ç±»åˆ«å¯èƒ½éš¾ä»¥æ»¡è¶³æœ€å°æ ·æœ¬æ•°è¦æ±‚:")
        for issue in issues:
            print(issue)
        print(f"  æç¤º: ç®—æ³•ä¼šå°½é‡æ»¡è¶³çº¦æŸï¼Œä½†å¯èƒ½éœ€è¦è°ƒæ•´ç­–ç•¥")
    else:
        print(f"  âœ“ æ‰€æœ‰ç±»åˆ«éƒ½æœ‰è¶³å¤Ÿçš„æ ·æœ¬")
    
    # 4. æŒ‰é¡¹ç›®åˆ†ç»„
    print(f"\nğŸ”„ å¼€å§‹é¡¹ç›®çº§åˆ†ç»„...")
    projects = df[project_column].unique()
    np.random.shuffle(projects)  # éšæœºæ‰“ä¹±é¡¹ç›®é¡ºåº
    
    # ä¸ºæ¯ä¸ªé¡¹ç›®ç»Ÿè®¡å…¶åŒ…å«çš„ç±»åˆ«å’Œæ ·æœ¬æ•°
    project_info = {}
    for proj in projects:
        proj_df = df[df[project_column] == proj]
        project_info[proj] = {
            'df': proj_df,
            'size': len(proj_df),
            'categories': proj_df[category_column].value_counts().to_dict()
        }
    
    # 5. æ”¹è¿›çš„é¡¹ç›®åˆ†é…ç­–ç•¥
    # ç­–ç•¥: 
    # 1) è¯†åˆ«åŒ…å«ç¨€æœ‰ç±»åˆ«çš„"å…³é”®é¡¹ç›®"
    # 2) ä¼˜å…ˆå‡åŒ€åˆ†é…å…³é”®é¡¹ç›®åˆ°å„æŠ˜
    # 3) å‰©ä½™é¡¹ç›®ä½¿ç”¨è´ªå¿ƒç­–ç•¥å¹³è¡¡åˆ†é…
    
    folds = [{'projects': [], 'size': 0, 'categories': {cat: 0 for cat in category_counts.index}} 
             for _ in range(n_folds)]
    
    print(f"\nğŸ¯ ä½¿ç”¨æ”¹è¿›çš„é¡¹ç›®åˆ†é…ç­–ç•¥...")
    print(f"  ç¬¬ä¸€é˜¶æ®µ: è¯†åˆ«å¹¶å‡åŒ€åˆ†é…åŒ…å«ç¨€æœ‰ç±»åˆ«çš„å…³é”®é¡¹ç›®")
    print(f"  ç¬¬äºŒé˜¶æ®µ: è´ªå¿ƒåˆ†é…å‰©ä½™é¡¹ç›®ä»¥å¹³è¡¡ç±»åˆ«åˆ†å¸ƒ")
    
    # 5.1 è¯†åˆ«"å…³é”®é¡¹ç›®" - åŒ…å«ç¨€æœ‰ç±»åˆ«æ ·æœ¬çš„é¡¹ç›®
    # å®šä¹‰"ç¨€æœ‰ç±»åˆ«"ä¸ºæ ·æœ¬æ•°å°‘äºæ€»æ ·æœ¬æ•°1%çš„ç±»åˆ«
    rare_threshold = len(df) * 0.01  # 1%
    rare_categories = [cat for cat in category_counts.index if category_counts[cat] < rare_threshold]
    
    print(f"\n  è¯†åˆ«çš„ç¨€æœ‰ç±»åˆ«: {rare_categories}")
    print(f"  ï¼ˆæ ·æœ¬æ•° < {rare_threshold:.0f}ï¼‰")
    
    # ä¸ºæ¯ä¸ªç¨€æœ‰ç±»åˆ«æ‰¾å‡ºåŒ…å«å®ƒçš„é¡¹ç›®ï¼Œå¹¶æŒ‰è¯¥ç±»åˆ«çš„æ ·æœ¬æ•°æ’åº
    critical_projects = set()
    category_project_map = {}  # æ¯ä¸ªç¨€æœ‰ç±»åˆ« -> åŒ…å«å®ƒçš„é¡¹ç›®åˆ—è¡¨ï¼ˆæŒ‰æ ·æœ¬æ•°é™åºï¼‰
    
    for cat in rare_categories:
        cat_projects = []
        for proj, info in project_info.items():
            if cat in info['categories']:
                cat_projects.append((proj, info['categories'][cat]))
        # æŒ‰è¯¥ç±»åˆ«çš„æ ·æœ¬æ•°é™åºæ’åº
        cat_projects.sort(key=lambda x: x[1], reverse=True)
        category_project_map[cat] = [proj for proj, count in cat_projects]
        critical_projects.update(category_project_map[cat])
    
    print(f"\n  å‘ç° {len(critical_projects)} ä¸ªå…³é”®é¡¹ç›®")
    
    # 5.2 ä½¿ç”¨Round-Robinç­–ç•¥åˆ†é…å…³é”®é¡¹ç›®
    # ç›®æ ‡: ç¡®ä¿æ¯ä¸ªæŠ˜éƒ½èƒ½è·å¾—å„ç§ç¨€æœ‰ç±»åˆ«çš„æ ·æœ¬
    critical_projects_list = sorted(critical_projects, 
                                   key=lambda p: project_info[p]['size'], 
                                   reverse=True)
    
    fold_idx = 0
    for proj in critical_projects_list:
        proj_data = project_info[proj]
        folds[fold_idx]['projects'].append(proj)
        folds[fold_idx]['size'] += proj_data['size']
        for cat, count in proj_data['categories'].items():
            folds[fold_idx]['categories'][cat] += count
        fold_idx = (fold_idx + 1) % n_folds
    
    print(f"  âœ“ å·²å°†å…³é”®é¡¹ç›®å‡åŒ€åˆ†é…åˆ° {n_folds} æŠ˜")
    
    # 5.3 ä½¿ç”¨è´ªå¿ƒç­–ç•¥åˆ†é…å‰©ä½™é¡¹ç›®
    remaining_projects = [proj for proj in projects if proj not in critical_projects]
    remaining_projects.sort(key=lambda p: project_info[p]['size'], reverse=True)
    
    print(f"\n  ç¬¬äºŒé˜¶æ®µ: åˆ†é…å‰©ä½™ {len(remaining_projects)} ä¸ªé¡¹ç›®...")
    
    for proj in remaining_projects:
        proj_data = project_info[proj]
        
        # è®¡ç®—æ¯ä¸ªæŠ˜åŠ å…¥è¯¥é¡¹ç›®åçš„"ä¸å¹³è¡¡åº¦"
        fold_scores = []
        for i, fold in enumerate(folds):
            # æ–°çš„æ ·æœ¬æ•°
            new_size = fold['size'] + proj_data['size']
            
            # è®¡ç®—ç±»åˆ«åˆ†å¸ƒçš„ä¸å¹³è¡¡åº¦
            category_imbalance = 0
            for cat in category_counts.index:
                # å½“å‰ç±»åˆ«çš„æ•°é‡
                current_count = fold['categories'].get(cat, 0)
                proj_cat_count = proj_data['categories'].get(cat, 0)
                new_cat_count = current_count + proj_cat_count
                
                # ç›®æ ‡æ•°é‡
                target_cat_count = category_counts[cat] / n_folds
                
                # å¦‚æœæ˜¯ç¨€æœ‰ç±»åˆ«ä¸”å½“å‰æ•°é‡ä½äºæœ€å°è¦æ±‚ï¼Œä¼˜å…ˆåˆ†é…
                if cat in rare_categories and current_count < min_samples_per_category and proj_cat_count > 0:
                    category_imbalance -= 100  # ç»™äºˆå¾ˆå¤§çš„è´Ÿåˆ†ï¼ˆä¼˜å…ˆçº§é«˜ï¼‰
                else:
                    category_imbalance += abs(new_cat_count - target_cat_count)
            
            # æ ·æœ¬æ•°ä¸å¹³è¡¡åº¦
            target_size = len(df) / n_folds
            size_imbalance = abs(new_size - target_size)
            
            # æ€»åˆ† = æ ·æœ¬æ•°ä¸å¹³è¡¡ * æƒé‡ + ç±»åˆ«ä¸å¹³è¡¡
            # ç±»åˆ«å¹³è¡¡æƒé‡æ›´é«˜
            score = size_imbalance * 0.1 + category_imbalance
            fold_scores.append(score)
        
        # é€‰æ‹©å¾—åˆ†æœ€ä½ï¼ˆæœ€å¹³è¡¡ï¼‰çš„æŠ˜
        best_fold_idx = np.argmin(fold_scores)
        folds[best_fold_idx]['projects'].append(proj)
        folds[best_fold_idx]['size'] += proj_data['size']
        for cat, count in proj_data['categories'].items():
            folds[best_fold_idx]['categories'][cat] += count
    
    # 6. è¾“å‡ºæ¯æŠ˜çš„ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š å„æŠ˜ç»Ÿè®¡:")
    print(f"{'æŠ˜å·':<8} {'æ ·æœ¬æ•°':>8} {'é¡¹ç›®æ•°':>8} ", end='')
    for cat in sorted(category_counts.index):
        print(f"{'ç±»åˆ«'+str(cat):>10}", end='')
    print()
    print("-" * (24 + 10 * len(category_counts)))
    
    for i, fold in enumerate(folds):
        print(f"Fold {i+1:<3} {fold['size']:>8} {len(fold['projects']):>8} ", end='')
        for cat in sorted(category_counts.index):
            print(f"{fold['categories'][cat]:>10}", end='')
        print()
    
    # 7. æ£€æŸ¥ç±»åˆ«å¹³è¡¡çº¦æŸ
    print(f"\nâš ï¸  ç±»åˆ«å¹³è¡¡çº¦æŸéªŒè¯:")
    constraint_violations = []
    
    for i, fold in enumerate(folds):
        for cat in category_counts.index:
            if fold['categories'][cat] < min_samples_per_category:
                constraint_violations.append(
                    f"  âœ— Fold {i+1}, ç±»åˆ« {cat}: åªæœ‰ {fold['categories'][cat]} ä¸ªæ ·æœ¬ (< {min_samples_per_category})"
                )
    
    if constraint_violations:
        print(f"  âš ï¸  å‘ç° {len(constraint_violations)} ä¸ªçº¦æŸè¿å:")
        for violation in constraint_violations[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(violation)
        if len(constraint_violations) > 10:
            print(f"  ... è¿˜æœ‰ {len(constraint_violations)-10} ä¸ªè¿å")
        print(f"\n  ğŸ’¡ å»ºè®®: è€ƒè™‘å‡å°‘æŠ˜æ•°æˆ–é™ä½ min_samples_per_category")
    else:
        print(f"  âœ“ æ‰€æœ‰æŠ˜éƒ½æ»¡è¶³ç±»åˆ«å¹³è¡¡çº¦æŸ!")
    
    # 8. åˆ›å»ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
    print(f"\nğŸ“¦ ç”ŸæˆKæŠ˜æ•°æ®é›†...")
    result_folds = []
    
    for i, test_fold in enumerate(folds):
        # æµ‹è¯•é›†: å½“å‰æŠ˜çš„æ‰€æœ‰é¡¹ç›®
        test_projects = test_fold['projects']
        test_df = pd.concat([project_info[proj]['df'] for proj in test_projects], 
                           ignore_index=True)
        
        # è®­ç»ƒé›†: å…¶ä»–æŠ˜çš„æ‰€æœ‰é¡¹ç›®
        train_projects = []
        for j, fold in enumerate(folds):
            if j != i:
                train_projects.extend(fold['projects'])
        train_df = pd.concat([project_info[proj]['df'] for proj in train_projects],
                            ignore_index=True)
        
        # éªŒè¯é¡¹ç›®ä¸é‡å 
        test_proj_set = set(test_df[project_column].unique())
        train_proj_set = set(train_df[project_column].unique())
        overlap = test_proj_set & train_proj_set
        
        if overlap:
            print(f"  âš ï¸  Fold {i+1}: å‘ç°é‡å é¡¹ç›® {overlap}")
        
        result_folds.append({
            'train': train_df,
            'test': test_df,
            'train_projects': train_projects,
            'test_projects': test_projects
        })
        
        print(f"  Fold {i+1}: è®­ç»ƒé›† {len(train_df)} æ ·æœ¬ ({len(train_projects)} é¡¹ç›®), "
              f"æµ‹è¯•é›† {len(test_df)} æ ·æœ¬ ({len(test_projects)} é¡¹ç›®)")
    
    print(f"\nâœ“ å®Œæˆ! å…±ç”Ÿæˆ {n_folds} æŠ˜æ•°æ®é›†")
    print(f"{'='*60}\n")
    
    return result_folds
